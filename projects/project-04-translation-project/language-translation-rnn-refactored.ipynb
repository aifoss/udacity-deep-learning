{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Language Translation RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "from distutils.version import LooseVersion\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \n",
    "    def load_data(self, path):\n",
    "        \"\"\"\n",
    "        Load dataset from file.\n",
    "        \"\"\"\n",
    "        input_file = os.path.join(path)\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_path = 'data/small_vocab_en'\n",
    "target_path = 'data/small_vocab_fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataLoader = DataLoader()\n",
    "\n",
    "source_text = dataLoader.load_data(source_path)\n",
    "target_text = dataLoader.load_data(target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataExplorer:\n",
    "    \n",
    "    def explore_data(self, source_text, target_text, sent_range):\n",
    "        \"\"\"\n",
    "        Explore sample sentences from dataset.\n",
    "        \"\"\"\n",
    "        print('Dataset Stats')\n",
    "        print('Roughly the number of unique words: {}'\\\n",
    "              .format(len({word: None for word in source_text.split()})))\n",
    "\n",
    "        sentences = source_text.split('\\n')\n",
    "        word_counts = [len(sentence.split()) for sentence in sentences]\n",
    "        \n",
    "        print('Number of sentences: {}'.format(len(sentences)))\n",
    "        print('Average number of words in a sentence: {}'.format(np.average(word_counts)))\n",
    "\n",
    "        print()\n",
    "        print('English sentences {} to {}:'.format(*sent_range))\n",
    "        print('\\n'.join(source_text.split('\\n')[sent_range[0]:sent_range[1]]))\n",
    "        print()\n",
    "        print('French sentences {} to {}:'.format(*sent_range))\n",
    "        print('\\n'.join(target_text.split('\\n')[sent_range[0]:sent_range[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "view_sentence_range = (0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 227\n",
      "Number of sentences: 137861\n",
      "Average number of words in a sentence: 13.225277634719028\n",
      "\n",
      "English sentences 0 to 10:\n",
      "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "the united states is usually chilly during july , and it is usually freezing in november .\n",
      "california is usually quiet during march , and it is usually hot in june .\n",
      "the united states is sometimes mild during june , and it is cold in september .\n",
      "your least liked fruit is the grape , but my least liked is the apple .\n",
      "his favorite fruit is the orange , but my favorite is the grape .\n",
      "paris is relaxing during december , but it is usually chilly in july .\n",
      "new jersey is busy during spring , and it is never hot in march .\n",
      "our least liked fruit is the lemon , but my least liked is the grape .\n",
      "the united states is sometimes busy during january , and it is sometimes warm in november .\n",
      "\n",
      "French sentences 0 to 10:\n",
      "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "california est généralement calme en mars , et il est généralement chaud en juin .\n",
      "les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
      "votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n",
      "son fruit préféré est l'orange , mais mon préféré est le raisin .\n",
      "paris est relaxant en décembre , mais il est généralement froid en juillet .\n",
      "new jersey est occupé au printemps , et il est jamais chaude en mars .\n",
      "notre fruit est moins aimé le citron , mais mon moins aimé est le raisin .\n",
      "les états-unis est parfois occupé en janvier , et il est parfois chaud en novembre .\n"
     ]
    }
   ],
   "source": [
    "dataExplorer = DataExplorer()\n",
    "\n",
    "dataExplorer.explore_data(source_text, target_text, view_sentence_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    \n",
    "    def preprocess_and_save_data(self, source_text, target_text):\n",
    "        \"\"\"\n",
    "        Preprocess text data and save to file.\n",
    "        \"\"\"\n",
    "        source_text = source_text.lower()\n",
    "        target_text = target_text.lower()\n",
    "\n",
    "        source_vocab_to_int, source_int_to_vocab = self.create_lookup_tables(source_text)\n",
    "        target_vocab_to_int, target_int_to_vocab = self.create_lookup_tables(target_text)\n",
    "\n",
    "        source_id_text, target_id_text = self.text_to_ids(source_text, \n",
    "                                                          target_text, \n",
    "                                                          source_vocab_to_int, \n",
    "                                                          target_vocab_to_int)\n",
    "\n",
    "        PickleHelper().save_preprocessed_data(((source_text, target_text),\n",
    "                                               (source_id_text, target_id_text),\n",
    "                                               (source_vocab_to_int, target_vocab_to_int),\n",
    "                                               (source_int_to_vocab, target_int_to_vocab)))\n",
    "                                              \n",
    "                                              \n",
    "    def create_lookup_tables(self, text):\n",
    "        \"\"\"\n",
    "        Create lookup tables for vocabulary.\n",
    "        \"\"\"\n",
    "        CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3}\n",
    "        \n",
    "        vocab = set(text.split())\n",
    "        vocab_to_int = copy.copy(CODES)\n",
    "\n",
    "        for v_i, v in enumerate(vocab, len(CODES)):\n",
    "            vocab_to_int[v] = v_i\n",
    "\n",
    "        int_to_vocab = {v_i: v for v, v_i in vocab_to_int.items()}\n",
    "\n",
    "        return (vocab_to_int, int_to_vocab)\n",
    "\n",
    "    \n",
    "    def text_to_ids(self, source_text, target_text, source_vocab_to_int, target_vocab_to_int):\n",
    "        \"\"\"\n",
    "        Convert source and target text to proper word ids.\n",
    "\n",
    "        :param source_text: String that contains all the source text.\n",
    "        :param target_text: String that contains all the target text.\n",
    "        :param source_vocab_to_int: Dictionary to go from the source words to an id\n",
    "        :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "        :return: A tuple of lists (source_id_text, target_id_text)\n",
    "        \"\"\"\n",
    "        source_id_text = [[source_vocab_to_int[word] for word in line.split(' ') if word != ''] \\\n",
    "                          for line in source_text.split('\\n')]\n",
    "        \n",
    "        target_id_text = [[target_vocab_to_int[word] for word in line.split(' ') if word != ''] \\\n",
    "                              + [target_vocab_to_int['<EOS>']] \\\n",
    "                          for line in target_text.split('\\n')]\n",
    "\n",
    "        return (source_id_text, target_id_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PickleHelper:\n",
    "    \n",
    "    def save_preprocessed_data(self, data):\n",
    "        \"\"\"\n",
    "        Save preprocessed training data.\n",
    "        \"\"\"\n",
    "        pickle.dump(data, open('preprocess.p', 'wb'))\n",
    "        \n",
    "    def load_preprocessed_data(self):\n",
    "        \"\"\"\n",
    "        Load the Preprocessed training data and return them in batches of <batch_size> or less.\n",
    "        \"\"\"\n",
    "        return pickle.load(open('preprocess.p', mode='rb'))\n",
    "    \n",
    "    def save_params(self, params):\n",
    "        \"\"\"\n",
    "        Save parameters to file.\n",
    "        \"\"\"\n",
    "        pickle.dump(params, open('params.p', 'wb'))\n",
    "    \n",
    "    def load_params(self):\n",
    "        \"\"\"\n",
    "        Load parameters from file.\n",
    "        \"\"\"\n",
    "        return pickle.load(open('params.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPreprocessor = DataPreprocessor()\n",
    "\n",
    "dataPreprocessor.preprocess_and_save_data(source_text, target_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickleHelper = PickleHelper()\n",
    "\n",
    "((source_text, target_text),\n",
    " (source_int_text, target_int_text), \n",
    " (source_vocab_to_int, target_vocab_to_int),\n",
    " (source_int_to_vocab, target_int_to_vocab)) = pickleHelper.load_preprocessed_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking TensorFlow Version and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TensorFlowGPUChecker:\n",
    "    \n",
    "    def check(self):\n",
    "        # Check TensorFlow Version\n",
    "        assert LooseVersion(tf.__version__) >= LooseVersion('1.1'), \\\n",
    "            'Please use TensorFlow version 1.1 or newer'\n",
    "        print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "        # Check for a GPU\n",
    "        if not tf.test.gpu_device_name():\n",
    "            warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "        else:\n",
    "            print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.1.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "versionChecker = TensorFlowGPUChecker()\n",
    "\n",
    "versionChecker.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqRNN:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.inputs = None\n",
    "        self.targets = None\n",
    "        \n",
    "        self.learning_rate = None\n",
    "        self.keep_prob = None\n",
    "        \n",
    "        self.source_seq_len = None\n",
    "        self.target_seq_len = None\n",
    "        self.max_target_len = None\n",
    "        \n",
    "#         self.encoder_output = None\n",
    "#         self.encoder_state = None\n",
    "        \n",
    "#         self.decoder_input = None\n",
    "#         self.training_decoder_output = None\n",
    "#         self.inference_decoder_output = None\n",
    "        \n",
    "        self.training_logits = None\n",
    "        self.inference_logits = None\n",
    "        \n",
    "        self.cost = None\n",
    "        self.train_op = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNBuilder:\n",
    "    \n",
    "    def create_placeholders(self):\n",
    "        \"\"\"\n",
    "        Create TF Placeholders for input, targets, learning rate, \n",
    "        and lengths of source and target sequences.\n",
    "\n",
    "        :return: Tuple (inputs, targets, learning_rate, keep_prob,\n",
    "                        source_seq_len, target_seq_len, max_target_len)\n",
    "        \"\"\"\n",
    "        inputs = tf.placeholder(tf.int32, (None, None), name='input')\n",
    "        targets = tf.placeholder(tf.int32, (None, None), name='targets')\n",
    "\n",
    "        learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "        keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "        source_seq_len = tf.placeholder(tf.float32, (None,), name='source_seq_len')\n",
    "        target_seq_len = tf.placeholder(tf.int32, (None,), name='target_seq_len')\n",
    "        max_target_len = tf.reduce_max(target_seq_len, name='max_target_len')\n",
    "        \n",
    "        return (inputs, targets, learning_rate, keep_prob, \\\n",
    "                source_seq_len, target_seq_len, max_target_len)\n",
    "\n",
    "    \n",
    "    def build_encoding_layer(self, \n",
    "                             rnn_inputs, \n",
    "                             rnn_size, \n",
    "                             num_layers, \n",
    "                             keep_probability, \n",
    "                             source_seq_len,\n",
    "                             source_vocab_size,\n",
    "                             enc_embedding_size):\n",
    "        \"\"\"\n",
    "        Create encoding layer.\n",
    "\n",
    "        :param rnn_inputs: Inputs for the RNN\n",
    "        :param rnn_size: RNN Size\n",
    "        :param num_layers: Number of layers\n",
    "        :param keep_prob: Dropout keep probability\n",
    "        :param source_seq_len: List of the lengths of each sequence in the batch\n",
    "        :param source_vocab_size: Vocabulary size of source data\n",
    "        :param enc_embedding_size: Embedding size of source data\n",
    "        :return: Tuple (enc_output, enc_state)\n",
    "        \"\"\"\n",
    "        # Encodder embedding\n",
    "        enc_embed = tf.contrib.layers.embed_sequence(rnn_inputs,\n",
    "                                                     source_vocab_size,\n",
    "                                                     enc_embedding_size)\n",
    "\n",
    "        # Encoder cell\n",
    "        def make_cell(rnn_size):\n",
    "            initializer = tf.random_uniform_initializer(-0.1, 0.1, seed=2)\n",
    "            cell = tf.contrib.rnn.LSTMCell(rnn_size, initializer)\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell, keep_probability)\n",
    "            return cell\n",
    "\n",
    "        enc_cell = tf.contrib.rnn.MultiRNNCell(\n",
    "            [make_cell(rnn_size) for _ in range(num_layers)])\n",
    "\n",
    "        enc_output, enc_state = tf.nn.dynamic_rnn(enc_cell, \n",
    "                                                  enc_embed, \n",
    "                                                  source_seq_len,\n",
    "                                                  dtype=tf.float32)\n",
    "\n",
    "        return (enc_output, enc_state)\n",
    "    \n",
    "    \n",
    "    def process_decoder_input(self, targets, target_vocab_to_int, batch_size):\n",
    "        \"\"\"\n",
    "        Preprocess target data for encoding.\n",
    "\n",
    "        :param targets: Target Placehoder\n",
    "        :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "        :param batch_size: Batch Size\n",
    "        :return: Preprocessed target data\n",
    "        \"\"\"\n",
    "        ending = tf.strided_slice(targets, [0,0], [batch_size, -1], [1,1])\n",
    "        dec_input = tf.concat([tf.fill([batch_size, 1], target_vocab_to_int['<GO>']), \n",
    "                               ending], 1)        \n",
    "        return dec_input\n",
    "    \n",
    "    \n",
    "    def build_decoding_layer(self, \n",
    "                             enc_state,\n",
    "                             dec_input, \n",
    "                             target_seq_len, \n",
    "                             max_target_len,\n",
    "                             rnn_size,\n",
    "                             num_layers,\n",
    "                             target_vocab_to_int,\n",
    "                             target_vocab_size,\n",
    "                             batch_size,\n",
    "                             keep_probability,\n",
    "                             dec_embedding_size):\n",
    "        \"\"\"\n",
    "        Create decoding layer.\n",
    "\n",
    "        :param enc_state: Encoder state\n",
    "        :param dec_input: Decoder input\n",
    "        :param target_seq_len: The lengths of each sequence in the target batch\n",
    "        :param max_target_len: Maximum length of target sequences\n",
    "        :param rnn_size: RNN Size\n",
    "        :param num_layers: Number of layers\n",
    "        :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "        :param target_vocab_size: Size of target vocabulary\n",
    "        :param batch_size: The size of the batch\n",
    "        :param keep_prob: Dropout keep probability\n",
    "        :param dec_embedding_size: Decoding embedding size\n",
    "        :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "        \"\"\"\n",
    "        # Decoder embedding\n",
    "        dec_embedding = tf.Variable(tf.random_uniform([target_vocab_size, dec_embedding_size]))\n",
    "        dec_embed = tf.nn.embedding_lookup(dec_embedding, dec_input)\n",
    "\n",
    "        # Decoder cell\n",
    "        def make_cell(rnn_size):\n",
    "            initializer = tf.random_uniform_initializer(-0.1, 0.1, seed=2)\n",
    "            cell = tf.contrib.rnn.LSTMCell(rnn_size, initializer)\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell, keep_probability)\n",
    "            return cell\n",
    "\n",
    "        dec_cell = tf.contrib.rnn.MultiRNNCell([make_cell(rnn_size) for _ in range(num_layers)])\n",
    "\n",
    "        # Dense layer to translate the decoder's output at each time step\n",
    "        # into a chocie from the target vocabulary\n",
    "        initializer = tf.truncated_normal_initializer(mean=0.0, stddev=0.1)\n",
    "        output_layer = Dense(target_vocab_size,\n",
    "                             kernel_initializer=initializer)\n",
    "\n",
    "        # Training decoder\n",
    "        with tf.variable_scope(\"decode\"):\n",
    "            training_decoder_output = self.get_training_decoding(enc_state, \n",
    "                                                                 dec_cell, \n",
    "                                                                 dec_embed, \n",
    "                                                                 target_seq_len, \n",
    "                                                                 max_target_len, \n",
    "                                                                 output_layer)\n",
    "\n",
    "        # Inference decoder\n",
    "        with tf.variable_scope(\"decode\", reuse=True):\n",
    "            inference_decoder_output = self.get_inference_decoding(enc_state, \n",
    "                                                                   dec_cell, \n",
    "                                                                   dec_embedding, \n",
    "                                                                   target_vocab_to_int['<GO>'],\n",
    "                                                                   target_vocab_to_int['<EOS>'],\n",
    "                                                                   max_target_len,\n",
    "                                                                   target_vocab_size,\n",
    "                                                                   output_layer,\n",
    "                                                                   batch_size)\n",
    "\n",
    "        return (training_decoder_output, inference_decoder_output)\n",
    "\n",
    "    \n",
    "    def get_training_decoding(self,\n",
    "                              enc_state, \n",
    "                              dec_cell, \n",
    "                              dec_embed_input, \n",
    "                              target_seq_len,\n",
    "                              max_target_len,\n",
    "                              output_layer):\n",
    "        \"\"\"\n",
    "        Create a decoding layer for training.\n",
    "\n",
    "        :param enc_state: Encoder state\n",
    "        :param dec_cell: Decoder RNN cell\n",
    "        :param dec_embed_input: Decoder embedded input\n",
    "        :param target_seq_len: The lengths of each sequence in the target batch\n",
    "        :param max_target_len: Maximum length of target sequences\n",
    "        :param output_layer: Function to apply the output layer\n",
    "        :return: BasicDecoderOutput containing training logits and sample_id\n",
    "        \"\"\"\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(dec_embed_input,\n",
    "                                                   target_seq_len,\n",
    "                                                   time_major=False)\n",
    "\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, helper, enc_state, output_layer)\n",
    "\n",
    "        return tf.contrib.seq2seq.dynamic_decode(decoder,\n",
    "                                                 impute_finished=True,\n",
    "                                                 maximum_iterations=max_target_len)[0]\n",
    "    \n",
    "    \n",
    "    def get_inference_decoding(self,\n",
    "                               enc_state, \n",
    "                               dec_cell, \n",
    "                               dec_embeddings, \n",
    "                               start_of_seq_id,\n",
    "                               end_of_seq_id,\n",
    "                               max_target_len,\n",
    "                               vocab_size,\n",
    "                               output_layer,\n",
    "                               bacth_size):\n",
    "        \"\"\"\n",
    "        Create a decoding layer for inference.\n",
    "\n",
    "        :param enc_state: Encoder state\n",
    "        :param dec_cell: Decoder RNN cell\n",
    "        :param dec_embeddings: Decoder embeddings\n",
    "        :param start_of_seq_id: <GO> ID\n",
    "        :param end_of_seq_id: <EOS> ID\n",
    "        :param max_target_len: Maximum length of target sequences\n",
    "        :param vocab_size: Size of decoder/target vocabulary\n",
    "        :param output_layer: Function to apply the output layer\n",
    "        :param batch_size: Batch size\n",
    "        :return: BasicDecoderOutput containing inference logits and sample_id\n",
    "        \"\"\"\n",
    "        start_tokens = tf.tile(tf.constant([start_of_seq_id], dtype=tf.int32),\n",
    "                               [batch_size],\n",
    "                               name='start_tokens')\n",
    "\n",
    "        helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(dec_embeddings,\n",
    "                                                          start_tokens,\n",
    "                                                          end_of_seq_id)\n",
    "\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, helper, enc_state, output_layer)\n",
    "\n",
    "        return tf.contrib.seq2seq.dynamic_decode(decoder,\n",
    "                                                 impute_finished=True,\n",
    "                                                 maximum_iterations=max_target_len)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqGraphBuilder:\n",
    "    \n",
    "    def build_train_graph(self,\n",
    "                          batch_size,\n",
    "                          rnn_size,\n",
    "                          num_layers,\n",
    "                          enc_embedding_size,\n",
    "                          dec_embedding_size,\n",
    "                          keep_probability,\n",
    "                          source_vocab_size,\n",
    "                          target_vocab_size,\n",
    "                          target_vocab_to_int):\n",
    "                          \n",
    "        \"\"\"\n",
    "        Build the training graph with the Seq2Seq RNN.\n",
    "\n",
    "        :param batch_size: Batch Size\n",
    "        :param rnn_size: RNN Size\n",
    "        :param num_layers: Number of layers\n",
    "        :param enc_embedding_size: Decoder embedding size\n",
    "        :param dec_embedding_size: Encoder embedding size\n",
    "        :param keep_probability: Dropout keep probability\n",
    "        :param source_vocab_size: Source vocabulary size\n",
    "        :param target_vocab_size: Target vocabulary size\n",
    "        :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "        :return: RNN and training graph\n",
    "        \"\"\"\n",
    "        \n",
    "        train_graph = tf.Graph()\n",
    "        \n",
    "        rnn = Seq2SeqRNN()\n",
    "        rnnBuilder = RNNBuilder()\n",
    "        optimizerTuner = OptimizerTuner()\n",
    "  \n",
    "        with train_graph.as_default():\n",
    "        \n",
    "            # Create placeholders\n",
    "            inputs, targets, lr, keep_prob, source_seq_len, target_seq_len, max_target_len = \\\n",
    "                rnnBuilder.create_placeholders()\n",
    "            \n",
    "            rnn.inputs, rnn.targets = inputs, targets\n",
    "            rnn.learning_rate, rnn.keep_prob = lr, keep_prob\n",
    "            rnn.source_seq_len, rnn.target_seq_len, rnn.max_target_len = \\\n",
    "                source_seq_len, target_seq_len, max_target_len\n",
    "        \n",
    "            # Build encoding layer\n",
    "            enc_output, enc_state = rnnBuilder.build_encoding_layer(tf.reverse(inputs, [-1]),\n",
    "                                                                    rnn_size,\n",
    "                                                                    num_layers,\n",
    "                                                                    keep_probability,\n",
    "                                                                    source_seq_len,\n",
    "                                                                    source_vocab_size,\n",
    "                                                                    enc_embedding_size)\n",
    "            \n",
    "            # Process decoder input\n",
    "            dec_input = rnnBuilder.process_decoder_input(targets, \n",
    "                                                         target_vocab_to_int, \n",
    "                                                         batch_size)             \n",
    "                                     \n",
    "            # Build decoding layer\n",
    "            training_decoder_output, inference_decoder_output = \\\n",
    "                rnnBuilder.build_decoding_layer(enc_state,\n",
    "                                                dec_input, \n",
    "                                                target_seq_len, \n",
    "                                                max_target_len,\n",
    "                                                rnn_size,\n",
    "                                                num_layers,\n",
    "                                                target_vocab_to_int,\n",
    "                                                target_vocab_size,\n",
    "                                                batch_size,\n",
    "                                                keep_probability,\n",
    "                                                dec_embedding_size)\n",
    "                \n",
    "            training_logits = tf.identity(training_decoder_output.rnn_output, name='logits')\n",
    "            inference_logits = tf.identity(inference_decoder_output.sample_id, name='predictions')\n",
    "\n",
    "            rnn.training_logits, rnn.inference_logits = training_logits, inference_logits\n",
    "            \n",
    "            masks = tf.sequence_mask(target_seq_len, max_target_len, \n",
    "                                     dtype=tf.float32, \n",
    "                                     name='masks')\n",
    "            \n",
    "            with tf.name_scope(\"optimization\"):\n",
    "                # Loss function\n",
    "                cost = tf.contrib.seq2seq.sequence_loss(training_logits, targets, masks)\n",
    "                \n",
    "                # Optimizer\n",
    "                optimizer = tf.train.AdamOptimizer(lr)\n",
    "                train_op = optimizerTuner.get_gradient_clipped_optimizer(optimizer, cost)\n",
    "            \n",
    "                rnn.cost, rnn.train_op = cost, train_op\n",
    "            \n",
    "        return (rnn, train_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OptimizerTuner:\n",
    "    \n",
    "    def get_gradient_clipped_optimizer(self, optimizer, cost):\n",
    "        \"\"\"\n",
    "        Apply gradient clipping to optimizer.\n",
    "        \n",
    "        :param optimizer: Optimizer to apply gradient clipping to\n",
    "        :param cost: Loss function\n",
    "        :return: Optimizer with gradient clipping\n",
    "        \"\"\"\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) \\\n",
    "                            for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)\n",
    "        return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 128\n",
    "rnn_size = 256\n",
    "num_layers = 2\n",
    "encoding_embedding_size = 20\n",
    "decoding_embedding_size = 20\n",
    "learning_rate = 0.001\n",
    "keep_probability = 0.75\n",
    "display_step = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_vocab_size = len(source_vocab_to_int)\n",
    "target_vocab_size = len(target_vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.LSTMCell object at 0x7f8301f32128>: The input_size parameter is deprecated.\n",
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.LSTMCell object at 0x7f831f38e9b0>: The input_size parameter is deprecated.\n",
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.LSTMCell object at 0x7f82e251a358>: The input_size parameter is deprecated.\n",
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.LSTMCell object at 0x7f82e2547cf8>: The input_size parameter is deprecated.\n"
     ]
    }
   ],
   "source": [
    "graphBuilder = Seq2SeqGraphBuilder()\n",
    "\n",
    "rnn, train_graph = graphBuilder.build_train_graph(batch_size,\n",
    "                                                  rnn_size,\n",
    "                                                  num_layers,\n",
    "                                                  encoding_embedding_size,\n",
    "                                                  decoding_embedding_size,\n",
    "                                                  keep_probability,\n",
    "                                                  source_vocab_size,\n",
    "                                                  target_vocab_size,\n",
    "                                                  target_vocab_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \n",
    "    def train_seq2seq_model(self, rnn, train_graph):\n",
    "        \"\"\"\n",
    "        Train and save the Seq2Seq model.\n",
    "        \n",
    "        :param rnn: Seq2Seq RNN model\n",
    "        :param train_graph: TensorFlow graph\n",
    "        \"\"\"\n",
    "        \n",
    "        with tf.Session(graph=train_graph) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            batchGenerator = DataBatchGenerator()\n",
    "            accuracyCalculator = AccuracyCalculator()\n",
    "            \n",
    "            for epoch_i in range(epochs):\n",
    "                batches = batchGenerator.get_batches(batch_size,\n",
    "                                                     train_source,\n",
    "                                                     train_target,\n",
    "                                                     source_pad_int,\n",
    "                                                     target_pad_int)\n",
    "                \n",
    "                for batch_i, (source_batch, target_batch, source_lengths, target_lengths) \\\n",
    "                        in enumerate(batches):\n",
    "                        \n",
    "                    # Training step\n",
    "                    feed = {rnn.inputs: source_batch,\n",
    "                            rnn.targets: target_batch,\n",
    "                            rnn.learning_rate: learning_rate,\n",
    "                            rnn.keep_prob: keep_probability,\n",
    "                            rnn.source_seq_len: source_lengths,\n",
    "                            rnn.target_seq_len: target_lengths}\n",
    "                    \n",
    "                    loss, _ = sess.run([rnn.cost, rnn.train_op],\n",
    "                                       feed_dict=feed)\n",
    "\n",
    "                    if batch_i % display_step == 0 and batch_i > 0:\n",
    "                        \n",
    "                        train_feed = {rnn.inputs: source_batch,\n",
    "                                      rnn.keep_prob: 1.0,\n",
    "                                      rnn.source_seq_len: source_lengths,\n",
    "                                      rnn.target_seq_len: target_lengths}\n",
    "                        train_logits = sess.run(rnn.inference_logits,\n",
    "                                                feed_dict=train_feed)\n",
    "                        \n",
    "                        valid_feed = {rnn.inputs: valid_source_batch,\n",
    "                                      rnn.keep_prob: 1.0,\n",
    "                                      rnn.source_seq_len: valid_source_lengths,\n",
    "                                      rnn.target_seq_len: valid_target_lengths}\n",
    "                        valid_logits = sess.run(rnn.inference_logits,\n",
    "                                                feed_dict=valid_feed)\n",
    "                        \n",
    "                        train_acc = accuracyCalculator.get_accuracy(target_batch, \n",
    "                                                                    train_logits)\n",
    "                        valid_acc = accuracyCalculator.get_accuracy(valid_target_batch,\n",
    "                                                                    valid_logits)\n",
    "                        \n",
    "                        print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.4f}, Validation Accuracy: {:>6.4f}, Loss: {:>6.4f}'\\\n",
    "                              .format(epoch_i+1, batch_i, len(source_int_text)//batch_size, \n",
    "                                      train_acc, valid_acc, loss))\n",
    "             \n",
    "            saver = tf.train.Saver()\n",
    "            saver.save(sess, save_path)\n",
    "        \n",
    "            print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainingValidationSetCreator:\n",
    "    \n",
    "    def create_train_val_sets(self, batch_size, source_letter_ids, target_letter_ids):\n",
    "        \"\"\"\n",
    "        Create training and validation sets.\n",
    "        \n",
    "        :param batch_size: Batch size\n",
    "        :param source_letter_ids: Mapping of source text letters to ints\n",
    "        :param target_letter_ids: Mapping of target text letters to ints\n",
    "        :return Tuple (train_source, train_target, valid_source, valid_target)\n",
    "        \"\"\"\n",
    "        \n",
    "        train_source = source_letter_ids[batch_size:]\n",
    "        train_target = target_letter_ids[batch_size:]\n",
    "        valid_source = source_letter_ids[:batch_size]\n",
    "        valid_target = target_letter_ids[:batch_size]\n",
    "\n",
    "        return (train_source, train_target, valid_source, valid_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ValidationSetBatchCreator:\n",
    "    \n",
    "    def get_val_set_batches(self, \n",
    "                            batch_size, \n",
    "                            valid_source, \n",
    "                            valid_target, \n",
    "                            source_pad_int, \n",
    "                            target_pad_int):\n",
    "        \"\"\"\n",
    "        Get batches from validation datasets.\n",
    "\n",
    "        :param batch_size: Batch size\n",
    "        :param valid_source: Validation source dataset\n",
    "        :param valid_target: Validation target dataset\n",
    "        :param source_pad_int: Int ID for <PAD> in source\n",
    "        :param target_pad_int: Int ID for <PAD> in target\n",
    "        :return: Tuple (valid_source_batch, valid_target_batch, \\\n",
    "                        valid_source_lengths, valid_target_lengths)\n",
    "        \"\"\"\n",
    "\n",
    "        dataBatchGenerator = DataBatchGenerator()\n",
    "        \n",
    "        (valid_source_batch, valid_target_batch, \\\n",
    "         valid_source_lengths, valid_target_lengths) = \\\n",
    "            next(dataBatchGenerator.get_batches(batch_size, \n",
    "                                                valid_source, \n",
    "                                                valid_target,\n",
    "                                                source_pad_int,\n",
    "                                                target_pad_int))\n",
    "        \n",
    "        return (valid_source_batch, valid_target_batch, \n",
    "                valid_source_lengths, valid_target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataBatchGenerator:\n",
    "    \n",
    "    def get_batches(self, \n",
    "                    batch_size, \n",
    "                    sources, \n",
    "                    targets, \n",
    "                    source_pad_int, \n",
    "                    target_pad_int):\n",
    "        \"\"\"\n",
    "        Batch targets, sources, and the lengths of their sentences together.\n",
    "        \n",
    "        :param batch_size: Batch size\n",
    "        :param sources: Source dataset\n",
    "        :param targets: Target datasest\n",
    "        :param source_pad_int: Int ID for <PAD> in source\n",
    "        :param target_pad_int: Int ID for <PAD> in target\n",
    "        :return: Batch generator to yield (pad_source_batch, pad_target_batch, \\\n",
    "                                           pad_source_lengths, pad_target_lengths)\n",
    "        \"\"\"\n",
    "        \n",
    "        for batch_i in range(0, len(sources)//batch_size):\n",
    "            start_i = batch_i * batch_size\n",
    "            \n",
    "            source_batch = sources[start_i:start_i + batch_size]\n",
    "            target_batch = targets[start_i:start_i + batch_size]\n",
    "            \n",
    "            pad_source_batch = np.array(\n",
    "                self.pad_sentence_batch(source_batch, source_pad_int))\n",
    "            pad_target_batch = np.array(\n",
    "                self.pad_sentence_batch(target_batch, target_pad_int))\n",
    "\n",
    "            # Need the lengths for the _lengths parameters\n",
    "            pad_source_lengths = []\n",
    "            for source in pad_source_batch:\n",
    "                pad_source_lengths.append(len(source))\n",
    "                \n",
    "            pad_target_lengths = []\n",
    "            for target in pad_target_batch:\n",
    "                pad_target_lengths.append(len(target))\n",
    "\n",
    "            yield pad_source_batch, pad_target_batch, \\\n",
    "                  pad_source_lengths, pad_target_lengths\n",
    "  \n",
    "            \n",
    "    def pad_sentence_batch(self, sentence_batch, pad_int):\n",
    "        \"\"\"\n",
    "        Pad sentences with <PAD> so that each sentence of a batch has the same length.\n",
    "        \n",
    "        :param sentence_batch: Batch of sentences\n",
    "        :param pad_int: Int ID for <PAD>\n",
    "        :return: Batch of sentences padded with <PAD>\n",
    "        \"\"\"\n",
    "        max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "        return [sentence + [pad_int] * (max_sentence - len(sentence)) \\\n",
    "                    for sentence in sentence_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AccuracyCalculator:\n",
    "    \n",
    "    def get_accuracy(self, target, logits):\n",
    "        \"\"\"\n",
    "        Calculate accuracy.\n",
    "        \"\"\"\n",
    "        max_seq = max(target.shape[1], logits.shape[1])\n",
    "        \n",
    "        if max_seq - target.shape[1]:\n",
    "            target = np.pad(\n",
    "                target,\n",
    "                [(0,0),(0,max_seq - target.shape[1])],\n",
    "                'constant')\n",
    "        if max_seq - logits.shape[1]:\n",
    "            logits = np.pad(\n",
    "                logits,\n",
    "                [(0,0),(0,max_seq - logits.shape[1])],\n",
    "                'constant')\n",
    "\n",
    "        return np.mean(np.equal(target, logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingValidationSetCreator = TrainingValidationSetCreator()\n",
    "\n",
    "train_source, train_target, valid_source, valid_target = \\\n",
    "    trainingValidationSetCreator.create_train_val_sets(batch_size, \n",
    "                                                       source_int_text, \n",
    "                                                       target_int_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_pad_int = source_vocab_to_int['<PAD>']\n",
    "target_pad_int = target_vocab_to_int['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validationSetBatchCreator = ValidationSetBatchCreator()\n",
    "\n",
    "(valid_source_batch, valid_target_batch, \\\n",
    " valid_source_lengths, valid_target_lengths) = \\\n",
    "    validationSetBatchCreator.get_val_set_batches(\n",
    "        batch_size, valid_source, valid_target, source_pad_int, target_pad_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = 'checkpoints/dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 Batch   20/1077 - Train Accuracy: 0.3031, Validation Accuracy: 0.3668, Loss: 3.2330\n",
      "Epoch   1 Batch   40/1077 - Train Accuracy: 0.3891, Validation Accuracy: 0.4403, Loss: 2.7994\n",
      "Epoch   1 Batch   60/1077 - Train Accuracy: 0.4338, Validation Accuracy: 0.4638, Loss: 2.4672\n",
      "Epoch   1 Batch   80/1077 - Train Accuracy: 0.4133, Validation Accuracy: 0.4805, Loss: 2.4023\n",
      "Epoch   1 Batch  100/1077 - Train Accuracy: 0.4367, Validation Accuracy: 0.4801, Loss: 2.3186\n",
      "Epoch   1 Batch  120/1077 - Train Accuracy: 0.4258, Validation Accuracy: 0.4844, Loss: 2.2001\n",
      "Epoch   1 Batch  140/1077 - Train Accuracy: 0.4013, Validation Accuracy: 0.4908, Loss: 2.2065\n",
      "Epoch   1 Batch  160/1077 - Train Accuracy: 0.4379, Validation Accuracy: 0.4982, Loss: 1.9768\n",
      "Epoch   1 Batch  180/1077 - Train Accuracy: 0.4520, Validation Accuracy: 0.5138, Loss: 1.8648\n",
      "Epoch   1 Batch  200/1077 - Train Accuracy: 0.4391, Validation Accuracy: 0.4940, Loss: 1.7436\n",
      "Epoch   1 Batch  220/1077 - Train Accuracy: 0.4420, Validation Accuracy: 0.5025, Loss: 1.6956\n",
      "Epoch   1 Batch  240/1077 - Train Accuracy: 0.4668, Validation Accuracy: 0.5039, Loss: 1.4906\n",
      "Epoch   1 Batch  260/1077 - Train Accuracy: 0.4773, Validation Accuracy: 0.5202, Loss: 1.4021\n",
      "Epoch   1 Batch  280/1077 - Train Accuracy: 0.4652, Validation Accuracy: 0.4883, Loss: 1.4335\n",
      "Epoch   1 Batch  300/1077 - Train Accuracy: 0.4309, Validation Accuracy: 0.5032, Loss: 1.4167\n",
      "Epoch   1 Batch  320/1077 - Train Accuracy: 0.4938, Validation Accuracy: 0.5206, Loss: 1.3567\n",
      "Epoch   1 Batch  340/1077 - Train Accuracy: 0.4457, Validation Accuracy: 0.5181, Loss: 1.3150\n",
      "Epoch   1 Batch  360/1077 - Train Accuracy: 0.4801, Validation Accuracy: 0.5046, Loss: 1.2374\n",
      "Epoch   1 Batch  380/1077 - Train Accuracy: 0.4688, Validation Accuracy: 0.5266, Loss: 1.1662\n",
      "Epoch   1 Batch  400/1077 - Train Accuracy: 0.4910, Validation Accuracy: 0.5369, Loss: 1.1615\n",
      "Epoch   1 Batch  420/1077 - Train Accuracy: 0.4668, Validation Accuracy: 0.5384, Loss: 1.1124\n",
      "Epoch   1 Batch  440/1077 - Train Accuracy: 0.4988, Validation Accuracy: 0.5405, Loss: 1.1053\n",
      "Epoch   1 Batch  460/1077 - Train Accuracy: 0.4684, Validation Accuracy: 0.5245, Loss: 1.0581\n",
      "Epoch   1 Batch  480/1077 - Train Accuracy: 0.5226, Validation Accuracy: 0.5483, Loss: 1.0168\n",
      "Epoch   1 Batch  500/1077 - Train Accuracy: 0.5109, Validation Accuracy: 0.5547, Loss: 0.9654\n",
      "Epoch   1 Batch  520/1077 - Train Accuracy: 0.5554, Validation Accuracy: 0.5511, Loss: 0.8909\n",
      "Epoch   1 Batch  540/1077 - Train Accuracy: 0.5410, Validation Accuracy: 0.5515, Loss: 0.8879\n",
      "Epoch   1 Batch  560/1077 - Train Accuracy: 0.5270, Validation Accuracy: 0.5529, Loss: 0.8722\n",
      "Epoch   1 Batch  580/1077 - Train Accuracy: 0.5748, Validation Accuracy: 0.5692, Loss: 0.7852\n",
      "Epoch   1 Batch  600/1077 - Train Accuracy: 0.5651, Validation Accuracy: 0.5763, Loss: 0.8137\n",
      "Epoch   1 Batch  620/1077 - Train Accuracy: 0.5340, Validation Accuracy: 0.5497, Loss: 0.8271\n",
      "Epoch   1 Batch  640/1077 - Train Accuracy: 0.5290, Validation Accuracy: 0.5490, Loss: 0.7916\n",
      "Epoch   1 Batch  660/1077 - Train Accuracy: 0.5664, Validation Accuracy: 0.5604, Loss: 0.8207\n",
      "Epoch   1 Batch  680/1077 - Train Accuracy: 0.5294, Validation Accuracy: 0.5621, Loss: 0.7864\n",
      "Epoch   1 Batch  700/1077 - Train Accuracy: 0.5309, Validation Accuracy: 0.5554, Loss: 0.7735\n",
      "Epoch   1 Batch  720/1077 - Train Accuracy: 0.5481, Validation Accuracy: 0.5710, Loss: 0.8224\n",
      "Epoch   1 Batch  740/1077 - Train Accuracy: 0.5742, Validation Accuracy: 0.5806, Loss: 0.7533\n",
      "Epoch   1 Batch  760/1077 - Train Accuracy: 0.5738, Validation Accuracy: 0.5646, Loss: 0.7577\n",
      "Epoch   1 Batch  780/1077 - Train Accuracy: 0.5703, Validation Accuracy: 0.5810, Loss: 0.7698\n",
      "Epoch   1 Batch  800/1077 - Train Accuracy: 0.5398, Validation Accuracy: 0.5746, Loss: 0.7300\n",
      "Epoch   1 Batch  820/1077 - Train Accuracy: 0.5414, Validation Accuracy: 0.5827, Loss: 0.7481\n",
      "Epoch   1 Batch  840/1077 - Train Accuracy: 0.5758, Validation Accuracy: 0.5803, Loss: 0.6847\n",
      "Epoch   1 Batch  860/1077 - Train Accuracy: 0.5818, Validation Accuracy: 0.5813, Loss: 0.6976\n",
      "Epoch   1 Batch  880/1077 - Train Accuracy: 0.5723, Validation Accuracy: 0.5920, Loss: 0.6959\n",
      "Epoch   1 Batch  900/1077 - Train Accuracy: 0.5617, Validation Accuracy: 0.5788, Loss: 0.7017\n",
      "Epoch   1 Batch  920/1077 - Train Accuracy: 0.5832, Validation Accuracy: 0.5866, Loss: 0.7039\n",
      "Epoch   1 Batch  940/1077 - Train Accuracy: 0.5719, Validation Accuracy: 0.5845, Loss: 0.6818\n",
      "Epoch   1 Batch  960/1077 - Train Accuracy: 0.5990, Validation Accuracy: 0.5987, Loss: 0.6462\n",
      "Epoch   1 Batch  980/1077 - Train Accuracy: 0.5918, Validation Accuracy: 0.5966, Loss: 0.6667\n",
      "Epoch   1 Batch 1000/1077 - Train Accuracy: 0.6391, Validation Accuracy: 0.6143, Loss: 0.6211\n",
      "Epoch   1 Batch 1020/1077 - Train Accuracy: 0.5914, Validation Accuracy: 0.5927, Loss: 0.6293\n",
      "Epoch   1 Batch 1040/1077 - Train Accuracy: 0.5752, Validation Accuracy: 0.5941, Loss: 0.6740\n",
      "Epoch   1 Batch 1060/1077 - Train Accuracy: 0.5707, Validation Accuracy: 0.6030, Loss: 0.6244\n",
      "Epoch   2 Batch   20/1077 - Train Accuracy: 0.6145, Validation Accuracy: 0.6051, Loss: 0.6154\n",
      "Epoch   2 Batch   40/1077 - Train Accuracy: 0.6031, Validation Accuracy: 0.6044, Loss: 0.6281\n",
      "Epoch   2 Batch   60/1077 - Train Accuracy: 0.6142, Validation Accuracy: 0.6044, Loss: 0.5918\n",
      "Epoch   2 Batch   80/1077 - Train Accuracy: 0.6156, Validation Accuracy: 0.6236, Loss: 0.6238\n",
      "Epoch   2 Batch  100/1077 - Train Accuracy: 0.6180, Validation Accuracy: 0.6261, Loss: 0.6211\n",
      "Epoch   2 Batch  120/1077 - Train Accuracy: 0.6383, Validation Accuracy: 0.6264, Loss: 0.6173\n",
      "Epoch   2 Batch  140/1077 - Train Accuracy: 0.5798, Validation Accuracy: 0.6225, Loss: 0.6052\n",
      "Epoch   2 Batch  160/1077 - Train Accuracy: 0.6395, Validation Accuracy: 0.6428, Loss: 0.5703\n",
      "Epoch   2 Batch  180/1077 - Train Accuracy: 0.6141, Validation Accuracy: 0.6278, Loss: 0.5719\n",
      "Epoch   2 Batch  200/1077 - Train Accuracy: 0.5914, Validation Accuracy: 0.6286, Loss: 0.5989\n",
      "Epoch   2 Batch  220/1077 - Train Accuracy: 0.6180, Validation Accuracy: 0.6303, Loss: 0.5736\n",
      "Epoch   2 Batch  240/1077 - Train Accuracy: 0.6480, Validation Accuracy: 0.6303, Loss: 0.5468\n",
      "Epoch   2 Batch  260/1077 - Train Accuracy: 0.6231, Validation Accuracy: 0.6339, Loss: 0.5140\n",
      "Epoch   2 Batch  280/1077 - Train Accuracy: 0.6414, Validation Accuracy: 0.6442, Loss: 0.5668\n",
      "Epoch   2 Batch  300/1077 - Train Accuracy: 0.6073, Validation Accuracy: 0.6381, Loss: 0.5440\n",
      "Epoch   2 Batch  320/1077 - Train Accuracy: 0.6332, Validation Accuracy: 0.6538, Loss: 0.5196\n",
      "Epoch   2 Batch  340/1077 - Train Accuracy: 0.5958, Validation Accuracy: 0.6275, Loss: 0.5332\n",
      "Epoch   2 Batch  360/1077 - Train Accuracy: 0.6406, Validation Accuracy: 0.6541, Loss: 0.5156\n",
      "Epoch   2 Batch  380/1077 - Train Accuracy: 0.6316, Validation Accuracy: 0.6481, Loss: 0.5050\n",
      "Epoch   2 Batch  400/1077 - Train Accuracy: 0.6594, Validation Accuracy: 0.6449, Loss: 0.5283\n",
      "Epoch   2 Batch  420/1077 - Train Accuracy: 0.6441, Validation Accuracy: 0.6527, Loss: 0.4889\n",
      "Epoch   2 Batch  440/1077 - Train Accuracy: 0.6301, Validation Accuracy: 0.6534, Loss: 0.5349\n",
      "Epoch   2 Batch  460/1077 - Train Accuracy: 0.6355, Validation Accuracy: 0.6506, Loss: 0.5123\n",
      "Epoch   2 Batch  480/1077 - Train Accuracy: 0.7101, Validation Accuracy: 0.6520, Loss: 0.4917\n",
      "Epoch   2 Batch  500/1077 - Train Accuracy: 0.6105, Validation Accuracy: 0.6616, Loss: 0.4888\n",
      "Epoch   2 Batch  520/1077 - Train Accuracy: 0.6834, Validation Accuracy: 0.6669, Loss: 0.4550\n",
      "Epoch   2 Batch  540/1077 - Train Accuracy: 0.6559, Validation Accuracy: 0.6673, Loss: 0.4454\n",
      "Epoch   2 Batch  560/1077 - Train Accuracy: 0.6395, Validation Accuracy: 0.6765, Loss: 0.4535\n",
      "Epoch   2 Batch  580/1077 - Train Accuracy: 0.6815, Validation Accuracy: 0.6754, Loss: 0.4238\n",
      "Epoch   2 Batch  600/1077 - Train Accuracy: 0.6812, Validation Accuracy: 0.6690, Loss: 0.4304\n",
      "Epoch   2 Batch  620/1077 - Train Accuracy: 0.6531, Validation Accuracy: 0.6626, Loss: 0.4483\n",
      "Epoch   2 Batch  640/1077 - Train Accuracy: 0.6332, Validation Accuracy: 0.6555, Loss: 0.4463\n",
      "Epoch   2 Batch  660/1077 - Train Accuracy: 0.6789, Validation Accuracy: 0.6616, Loss: 0.4610\n",
      "Epoch   2 Batch  680/1077 - Train Accuracy: 0.6659, Validation Accuracy: 0.6839, Loss: 0.4448\n",
      "Epoch   2 Batch  700/1077 - Train Accuracy: 0.6309, Validation Accuracy: 0.6573, Loss: 0.4342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2 Batch  720/1077 - Train Accuracy: 0.6464, Validation Accuracy: 0.6786, Loss: 0.4793\n",
      "Epoch   2 Batch  740/1077 - Train Accuracy: 0.6715, Validation Accuracy: 0.6836, Loss: 0.4280\n",
      "Epoch   2 Batch  760/1077 - Train Accuracy: 0.6750, Validation Accuracy: 0.6765, Loss: 0.4308\n",
      "Epoch   2 Batch  780/1077 - Train Accuracy: 0.6727, Validation Accuracy: 0.6942, Loss: 0.4421\n",
      "Epoch   2 Batch  800/1077 - Train Accuracy: 0.6516, Validation Accuracy: 0.6655, Loss: 0.4224\n",
      "Epoch   2 Batch  820/1077 - Train Accuracy: 0.6449, Validation Accuracy: 0.6538, Loss: 0.4455\n",
      "Epoch   2 Batch  840/1077 - Train Accuracy: 0.6957, Validation Accuracy: 0.6811, Loss: 0.3990\n",
      "Epoch   2 Batch  860/1077 - Train Accuracy: 0.6633, Validation Accuracy: 0.6808, Loss: 0.4066\n",
      "Epoch   2 Batch  880/1077 - Train Accuracy: 0.7035, Validation Accuracy: 0.6726, Loss: 0.4041\n",
      "Epoch   2 Batch  900/1077 - Train Accuracy: 0.7082, Validation Accuracy: 0.6925, Loss: 0.3986\n",
      "Epoch   2 Batch  920/1077 - Train Accuracy: 0.6867, Validation Accuracy: 0.6850, Loss: 0.4014\n",
      "Epoch   2 Batch  940/1077 - Train Accuracy: 0.6602, Validation Accuracy: 0.6811, Loss: 0.3867\n",
      "Epoch   2 Batch  960/1077 - Train Accuracy: 0.6938, Validation Accuracy: 0.6776, Loss: 0.3749\n",
      "Epoch   2 Batch  980/1077 - Train Accuracy: 0.6801, Validation Accuracy: 0.6790, Loss: 0.3971\n",
      "Epoch   2 Batch 1000/1077 - Train Accuracy: 0.7031, Validation Accuracy: 0.6875, Loss: 0.3536\n",
      "Epoch   2 Batch 1020/1077 - Train Accuracy: 0.6965, Validation Accuracy: 0.6989, Loss: 0.3724\n",
      "Epoch   2 Batch 1040/1077 - Train Accuracy: 0.7134, Validation Accuracy: 0.6871, Loss: 0.3880\n",
      "Epoch   2 Batch 1060/1077 - Train Accuracy: 0.7035, Validation Accuracy: 0.6712, Loss: 0.3442\n",
      "Epoch   3 Batch   20/1077 - Train Accuracy: 0.6770, Validation Accuracy: 0.6850, Loss: 0.3636\n",
      "Epoch   3 Batch   40/1077 - Train Accuracy: 0.6887, Validation Accuracy: 0.7088, Loss: 0.3540\n",
      "Epoch   3 Batch   60/1077 - Train Accuracy: 0.6737, Validation Accuracy: 0.6893, Loss: 0.3375\n",
      "Epoch   3 Batch   80/1077 - Train Accuracy: 0.6621, Validation Accuracy: 0.6701, Loss: 0.3553\n",
      "Epoch   3 Batch  100/1077 - Train Accuracy: 0.6797, Validation Accuracy: 0.6985, Loss: 0.3404\n",
      "Epoch   3 Batch  120/1077 - Train Accuracy: 0.7094, Validation Accuracy: 0.6875, Loss: 0.3553\n",
      "Epoch   3 Batch  140/1077 - Train Accuracy: 0.6854, Validation Accuracy: 0.6811, Loss: 0.3430\n",
      "Epoch   3 Batch  160/1077 - Train Accuracy: 0.7133, Validation Accuracy: 0.7006, Loss: 0.3308\n",
      "Epoch   3 Batch  180/1077 - Train Accuracy: 0.6695, Validation Accuracy: 0.6964, Loss: 0.3169\n",
      "Epoch   3 Batch  200/1077 - Train Accuracy: 0.6996, Validation Accuracy: 0.7120, Loss: 0.3340\n",
      "Epoch   3 Batch  220/1077 - Train Accuracy: 0.7056, Validation Accuracy: 0.7003, Loss: 0.2971\n",
      "Epoch   3 Batch  240/1077 - Train Accuracy: 0.7590, Validation Accuracy: 0.6815, Loss: 0.2947\n",
      "Epoch   3 Batch  260/1077 - Train Accuracy: 0.7132, Validation Accuracy: 0.6939, Loss: 0.2817\n",
      "Epoch   3 Batch  280/1077 - Train Accuracy: 0.6969, Validation Accuracy: 0.7138, Loss: 0.3062\n",
      "Epoch   3 Batch  300/1077 - Train Accuracy: 0.7331, Validation Accuracy: 0.7102, Loss: 0.2975\n",
      "Epoch   3 Batch  320/1077 - Train Accuracy: 0.7598, Validation Accuracy: 0.7379, Loss: 0.2993\n",
      "Epoch   3 Batch  340/1077 - Train Accuracy: 0.7393, Validation Accuracy: 0.7170, Loss: 0.3035\n",
      "Epoch   3 Batch  360/1077 - Train Accuracy: 0.7570, Validation Accuracy: 0.7479, Loss: 0.2818\n",
      "Epoch   3 Batch  380/1077 - Train Accuracy: 0.7469, Validation Accuracy: 0.7322, Loss: 0.2633\n",
      "Epoch   3 Batch  400/1077 - Train Accuracy: 0.7246, Validation Accuracy: 0.7283, Loss: 0.3060\n",
      "Epoch   3 Batch  420/1077 - Train Accuracy: 0.7547, Validation Accuracy: 0.7301, Loss: 0.2532\n",
      "Epoch   3 Batch  440/1077 - Train Accuracy: 0.7156, Validation Accuracy: 0.7280, Loss: 0.2964\n",
      "Epoch   3 Batch  460/1077 - Train Accuracy: 0.7625, Validation Accuracy: 0.7163, Loss: 0.2755\n",
      "Epoch   3 Batch  480/1077 - Train Accuracy: 0.7685, Validation Accuracy: 0.7205, Loss: 0.2495\n",
      "Epoch   3 Batch  500/1077 - Train Accuracy: 0.7621, Validation Accuracy: 0.7209, Loss: 0.2588\n",
      "Epoch   3 Batch  520/1077 - Train Accuracy: 0.7917, Validation Accuracy: 0.7418, Loss: 0.2281\n",
      "Epoch   3 Batch  540/1077 - Train Accuracy: 0.7457, Validation Accuracy: 0.7180, Loss: 0.2205\n",
      "Epoch   3 Batch  560/1077 - Train Accuracy: 0.7363, Validation Accuracy: 0.7315, Loss: 0.2474\n",
      "Epoch   3 Batch  580/1077 - Train Accuracy: 0.7649, Validation Accuracy: 0.7237, Loss: 0.2182\n",
      "Epoch   3 Batch  600/1077 - Train Accuracy: 0.7716, Validation Accuracy: 0.7354, Loss: 0.2274\n",
      "Epoch   3 Batch  620/1077 - Train Accuracy: 0.7453, Validation Accuracy: 0.7347, Loss: 0.2361\n",
      "Epoch   3 Batch  640/1077 - Train Accuracy: 0.7504, Validation Accuracy: 0.7692, Loss: 0.2368\n",
      "Epoch   3 Batch  660/1077 - Train Accuracy: 0.7434, Validation Accuracy: 0.7290, Loss: 0.2458\n",
      "Epoch   3 Batch  680/1077 - Train Accuracy: 0.7842, Validation Accuracy: 0.7532, Loss: 0.2306\n",
      "Epoch   3 Batch  700/1077 - Train Accuracy: 0.7559, Validation Accuracy: 0.7745, Loss: 0.2168\n",
      "Epoch   3 Batch  720/1077 - Train Accuracy: 0.7718, Validation Accuracy: 0.7621, Loss: 0.2484\n",
      "Epoch   3 Batch  740/1077 - Train Accuracy: 0.7719, Validation Accuracy: 0.7358, Loss: 0.2197\n",
      "Epoch   3 Batch  760/1077 - Train Accuracy: 0.7953, Validation Accuracy: 0.7525, Loss: 0.2259\n",
      "Epoch   3 Batch  780/1077 - Train Accuracy: 0.7699, Validation Accuracy: 0.7525, Loss: 0.2392\n",
      "Epoch   3 Batch  800/1077 - Train Accuracy: 0.7832, Validation Accuracy: 0.7699, Loss: 0.2235\n",
      "Epoch   3 Batch  820/1077 - Train Accuracy: 0.7543, Validation Accuracy: 0.7603, Loss: 0.2439\n",
      "Epoch   3 Batch  840/1077 - Train Accuracy: 0.7703, Validation Accuracy: 0.7496, Loss: 0.2119\n",
      "Epoch   3 Batch  860/1077 - Train Accuracy: 0.7604, Validation Accuracy: 0.7731, Loss: 0.2136\n",
      "Epoch   3 Batch  880/1077 - Train Accuracy: 0.8113, Validation Accuracy: 0.7784, Loss: 0.2107\n",
      "Epoch   3 Batch  900/1077 - Train Accuracy: 0.7797, Validation Accuracy: 0.7631, Loss: 0.2089\n",
      "Epoch   3 Batch  920/1077 - Train Accuracy: 0.8055, Validation Accuracy: 0.7731, Loss: 0.2113\n",
      "Epoch   3 Batch  940/1077 - Train Accuracy: 0.7777, Validation Accuracy: 0.7607, Loss: 0.1828\n",
      "Epoch   3 Batch  960/1077 - Train Accuracy: 0.8021, Validation Accuracy: 0.7702, Loss: 0.1904\n",
      "Epoch   3 Batch  980/1077 - Train Accuracy: 0.7617, Validation Accuracy: 0.7752, Loss: 0.2042\n",
      "Epoch   3 Batch 1000/1077 - Train Accuracy: 0.8285, Validation Accuracy: 0.7795, Loss: 0.1730\n",
      "Epoch   3 Batch 1020/1077 - Train Accuracy: 0.7906, Validation Accuracy: 0.7585, Loss: 0.1951\n",
      "Epoch   3 Batch 1040/1077 - Train Accuracy: 0.8006, Validation Accuracy: 0.7844, Loss: 0.2105\n",
      "Epoch   3 Batch 1060/1077 - Train Accuracy: 0.8055, Validation Accuracy: 0.7617, Loss: 0.1743\n",
      "Epoch   4 Batch   20/1077 - Train Accuracy: 0.8004, Validation Accuracy: 0.7567, Loss: 0.1756\n",
      "Epoch   4 Batch   40/1077 - Train Accuracy: 0.8168, Validation Accuracy: 0.7773, Loss: 0.1837\n",
      "Epoch   4 Batch   60/1077 - Train Accuracy: 0.7712, Validation Accuracy: 0.8111, Loss: 0.1731\n",
      "Epoch   4 Batch   80/1077 - Train Accuracy: 0.7895, Validation Accuracy: 0.7756, Loss: 0.1793\n",
      "Epoch   4 Batch  100/1077 - Train Accuracy: 0.8164, Validation Accuracy: 0.8267, Loss: 0.1724\n",
      "Epoch   4 Batch  120/1077 - Train Accuracy: 0.7785, Validation Accuracy: 0.7447, Loss: 0.1831\n",
      "Epoch   4 Batch  140/1077 - Train Accuracy: 0.8039, Validation Accuracy: 0.7763, Loss: 0.1743\n",
      "Epoch   4 Batch  160/1077 - Train Accuracy: 0.7918, Validation Accuracy: 0.7805, Loss: 0.1632\n",
      "Epoch   4 Batch  180/1077 - Train Accuracy: 0.7961, Validation Accuracy: 0.7979, Loss: 0.1649\n",
      "Epoch   4 Batch  200/1077 - Train Accuracy: 0.7871, Validation Accuracy: 0.8175, Loss: 0.1733\n",
      "Epoch   4 Batch  220/1077 - Train Accuracy: 0.8273, Validation Accuracy: 0.7901, Loss: 0.1594\n",
      "Epoch   4 Batch  240/1077 - Train Accuracy: 0.8680, Validation Accuracy: 0.7958, Loss: 0.1459\n",
      "Epoch   4 Batch  260/1077 - Train Accuracy: 0.8173, Validation Accuracy: 0.7777, Loss: 0.1388\n",
      "Epoch   4 Batch  280/1077 - Train Accuracy: 0.7832, Validation Accuracy: 0.7926, Loss: 0.1612\n",
      "Epoch   4 Batch  300/1077 - Train Accuracy: 0.8425, Validation Accuracy: 0.7905, Loss: 0.1414\n",
      "Epoch   4 Batch  320/1077 - Train Accuracy: 0.8211, Validation Accuracy: 0.8033, Loss: 0.1735\n",
      "Epoch   4 Batch  340/1077 - Train Accuracy: 0.8257, Validation Accuracy: 0.7784, Loss: 0.1555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4 Batch  360/1077 - Train Accuracy: 0.8086, Validation Accuracy: 0.8196, Loss: 0.1430\n",
      "Epoch   4 Batch  380/1077 - Train Accuracy: 0.8402, Validation Accuracy: 0.8136, Loss: 0.1348\n",
      "Epoch   4 Batch  400/1077 - Train Accuracy: 0.8098, Validation Accuracy: 0.8398, Loss: 0.1607\n",
      "Epoch   4 Batch  420/1077 - Train Accuracy: 0.8395, Validation Accuracy: 0.7987, Loss: 0.1354\n",
      "Epoch   4 Batch  440/1077 - Train Accuracy: 0.7543, Validation Accuracy: 0.7997, Loss: 0.1761\n",
      "Epoch   4 Batch  460/1077 - Train Accuracy: 0.8266, Validation Accuracy: 0.8075, Loss: 0.1484\n",
      "Epoch   4 Batch  480/1077 - Train Accuracy: 0.8405, Validation Accuracy: 0.7798, Loss: 0.1372\n",
      "Epoch   4 Batch  500/1077 - Train Accuracy: 0.8223, Validation Accuracy: 0.7773, Loss: 0.1456\n",
      "Epoch   4 Batch  520/1077 - Train Accuracy: 0.8761, Validation Accuracy: 0.8185, Loss: 0.1287\n",
      "Epoch   4 Batch  540/1077 - Train Accuracy: 0.8301, Validation Accuracy: 0.8029, Loss: 0.1284\n",
      "Epoch   4 Batch  560/1077 - Train Accuracy: 0.8203, Validation Accuracy: 0.7962, Loss: 0.1326\n",
      "Epoch   4 Batch  580/1077 - Train Accuracy: 0.8233, Validation Accuracy: 0.8196, Loss: 0.1182\n",
      "Epoch   4 Batch  600/1077 - Train Accuracy: 0.8371, Validation Accuracy: 0.8022, Loss: 0.1322\n",
      "Epoch   4 Batch  620/1077 - Train Accuracy: 0.8086, Validation Accuracy: 0.8058, Loss: 0.1243\n",
      "Epoch   4 Batch  640/1077 - Train Accuracy: 0.7939, Validation Accuracy: 0.8189, Loss: 0.1345\n",
      "Epoch   4 Batch  660/1077 - Train Accuracy: 0.8230, Validation Accuracy: 0.8189, Loss: 0.1291\n",
      "Epoch   4 Batch  680/1077 - Train Accuracy: 0.8118, Validation Accuracy: 0.8281, Loss: 0.1262\n",
      "Epoch   4 Batch  700/1077 - Train Accuracy: 0.8250, Validation Accuracy: 0.8434, Loss: 0.1164\n",
      "Epoch   4 Batch  720/1077 - Train Accuracy: 0.8158, Validation Accuracy: 0.8235, Loss: 0.1356\n",
      "Epoch   4 Batch  740/1077 - Train Accuracy: 0.8605, Validation Accuracy: 0.8377, Loss: 0.1077\n",
      "Epoch   4 Batch  760/1077 - Train Accuracy: 0.8363, Validation Accuracy: 0.8391, Loss: 0.1146\n",
      "Epoch   4 Batch  780/1077 - Train Accuracy: 0.8219, Validation Accuracy: 0.8189, Loss: 0.1297\n",
      "Epoch   4 Batch  800/1077 - Train Accuracy: 0.8426, Validation Accuracy: 0.8519, Loss: 0.1172\n",
      "Epoch   4 Batch  820/1077 - Train Accuracy: 0.7992, Validation Accuracy: 0.8136, Loss: 0.1324\n",
      "Epoch   4 Batch  840/1077 - Train Accuracy: 0.8348, Validation Accuracy: 0.8345, Loss: 0.1192\n",
      "Epoch   4 Batch  860/1077 - Train Accuracy: 0.7883, Validation Accuracy: 0.8466, Loss: 0.1274\n",
      "Epoch   4 Batch  880/1077 - Train Accuracy: 0.8723, Validation Accuracy: 0.8473, Loss: 0.1222\n",
      "Epoch   4 Batch  900/1077 - Train Accuracy: 0.8539, Validation Accuracy: 0.8356, Loss: 0.1210\n",
      "Epoch   4 Batch  920/1077 - Train Accuracy: 0.8543, Validation Accuracy: 0.8590, Loss: 0.1184\n",
      "Epoch   4 Batch  940/1077 - Train Accuracy: 0.8480, Validation Accuracy: 0.8320, Loss: 0.1061\n",
      "Epoch   4 Batch  960/1077 - Train Accuracy: 0.8583, Validation Accuracy: 0.8292, Loss: 0.1218\n",
      "Epoch   4 Batch  980/1077 - Train Accuracy: 0.8313, Validation Accuracy: 0.8409, Loss: 0.1243\n",
      "Epoch   4 Batch 1000/1077 - Train Accuracy: 0.8754, Validation Accuracy: 0.8342, Loss: 0.1022\n",
      "Epoch   4 Batch 1020/1077 - Train Accuracy: 0.8789, Validation Accuracy: 0.8583, Loss: 0.1027\n",
      "Epoch   4 Batch 1040/1077 - Train Accuracy: 0.8581, Validation Accuracy: 0.8125, Loss: 0.1135\n",
      "Epoch   4 Batch 1060/1077 - Train Accuracy: 0.8703, Validation Accuracy: 0.8377, Loss: 0.0962\n",
      "Epoch   5 Batch   20/1077 - Train Accuracy: 0.8512, Validation Accuracy: 0.8484, Loss: 0.1040\n",
      "Epoch   5 Batch   40/1077 - Train Accuracy: 0.9016, Validation Accuracy: 0.8651, Loss: 0.0977\n",
      "Epoch   5 Batch   60/1077 - Train Accuracy: 0.8873, Validation Accuracy: 0.8548, Loss: 0.0947\n",
      "Epoch   5 Batch   80/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8583, Loss: 0.1016\n",
      "Epoch   5 Batch  100/1077 - Train Accuracy: 0.8879, Validation Accuracy: 0.8612, Loss: 0.0913\n",
      "Epoch   5 Batch  120/1077 - Train Accuracy: 0.8684, Validation Accuracy: 0.8551, Loss: 0.1031\n",
      "Epoch   5 Batch  140/1077 - Train Accuracy: 0.8799, Validation Accuracy: 0.8530, Loss: 0.0913\n",
      "Epoch   5 Batch  160/1077 - Train Accuracy: 0.8797, Validation Accuracy: 0.8654, Loss: 0.0931\n",
      "Epoch   5 Batch  180/1077 - Train Accuracy: 0.8820, Validation Accuracy: 0.8469, Loss: 0.0891\n",
      "Epoch   5 Batch  200/1077 - Train Accuracy: 0.8785, Validation Accuracy: 0.8743, Loss: 0.0980\n",
      "Epoch   5 Batch  220/1077 - Train Accuracy: 0.9021, Validation Accuracy: 0.8643, Loss: 0.0821\n",
      "Epoch   5 Batch  240/1077 - Train Accuracy: 0.9215, Validation Accuracy: 0.8633, Loss: 0.0794\n",
      "Epoch   5 Batch  260/1077 - Train Accuracy: 0.8958, Validation Accuracy: 0.8842, Loss: 0.0838\n",
      "Epoch   5 Batch  280/1077 - Train Accuracy: 0.8535, Validation Accuracy: 0.8608, Loss: 0.0836\n",
      "Epoch   5 Batch  300/1077 - Train Accuracy: 0.9100, Validation Accuracy: 0.8601, Loss: 0.0769\n",
      "Epoch   5 Batch  320/1077 - Train Accuracy: 0.9098, Validation Accuracy: 0.8612, Loss: 0.0856\n",
      "Epoch   5 Batch  340/1077 - Train Accuracy: 0.8935, Validation Accuracy: 0.8615, Loss: 0.0846\n",
      "Epoch   5 Batch  360/1077 - Train Accuracy: 0.9250, Validation Accuracy: 0.8803, Loss: 0.0688\n",
      "Epoch   5 Batch  380/1077 - Train Accuracy: 0.8797, Validation Accuracy: 0.8714, Loss: 0.0750\n",
      "Epoch   5 Batch  400/1077 - Train Accuracy: 0.8879, Validation Accuracy: 0.8814, Loss: 0.0887\n",
      "Epoch   5 Batch  420/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.8974, Loss: 0.0718\n",
      "Epoch   5 Batch  440/1077 - Train Accuracy: 0.8676, Validation Accuracy: 0.8626, Loss: 0.0918\n",
      "Epoch   5 Batch  460/1077 - Train Accuracy: 0.9059, Validation Accuracy: 0.8533, Loss: 0.0790\n",
      "Epoch   5 Batch  480/1077 - Train Accuracy: 0.9013, Validation Accuracy: 0.8928, Loss: 0.0746\n",
      "Epoch   5 Batch  500/1077 - Train Accuracy: 0.9020, Validation Accuracy: 0.8512, Loss: 0.0659\n",
      "Epoch   5 Batch  520/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.8853, Loss: 0.0648\n",
      "Epoch   5 Batch  540/1077 - Train Accuracy: 0.9062, Validation Accuracy: 0.8754, Loss: 0.0594\n",
      "Epoch   5 Batch  560/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.8743, Loss: 0.0670\n",
      "Epoch   5 Batch  580/1077 - Train Accuracy: 0.9208, Validation Accuracy: 0.8764, Loss: 0.0641\n",
      "Epoch   5 Batch  600/1077 - Train Accuracy: 0.9118, Validation Accuracy: 0.8991, Loss: 0.0789\n",
      "Epoch   5 Batch  620/1077 - Train Accuracy: 0.9148, Validation Accuracy: 0.8860, Loss: 0.0620\n",
      "Epoch   5 Batch  640/1077 - Train Accuracy: 0.8824, Validation Accuracy: 0.9070, Loss: 0.0681\n",
      "Epoch   5 Batch  660/1077 - Train Accuracy: 0.9152, Validation Accuracy: 0.8771, Loss: 0.0737\n",
      "Epoch   5 Batch  680/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.8583, Loss: 0.0730\n",
      "Epoch   5 Batch  700/1077 - Train Accuracy: 0.9187, Validation Accuracy: 0.8690, Loss: 0.0637\n",
      "Epoch   5 Batch  720/1077 - Train Accuracy: 0.8898, Validation Accuracy: 0.8974, Loss: 0.0699\n",
      "Epoch   5 Batch  740/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.9059, Loss: 0.0553\n",
      "Epoch   5 Batch  760/1077 - Train Accuracy: 0.9012, Validation Accuracy: 0.9158, Loss: 0.0673\n",
      "Epoch   5 Batch  780/1077 - Train Accuracy: 0.8703, Validation Accuracy: 0.9023, Loss: 0.0855\n",
      "Epoch   5 Batch  800/1077 - Train Accuracy: 0.9004, Validation Accuracy: 0.9020, Loss: 0.0605\n",
      "Epoch   5 Batch  820/1077 - Train Accuracy: 0.8727, Validation Accuracy: 0.8991, Loss: 0.0679\n",
      "Epoch   5 Batch  840/1077 - Train Accuracy: 0.9184, Validation Accuracy: 0.8984, Loss: 0.0594\n",
      "Epoch   5 Batch  860/1077 - Train Accuracy: 0.9208, Validation Accuracy: 0.8981, Loss: 0.0630\n",
      "Epoch   5 Batch  880/1077 - Train Accuracy: 0.9117, Validation Accuracy: 0.8881, Loss: 0.0706\n",
      "Epoch   5 Batch  900/1077 - Train Accuracy: 0.9078, Validation Accuracy: 0.8931, Loss: 0.0622\n",
      "Epoch   5 Batch  920/1077 - Train Accuracy: 0.9289, Validation Accuracy: 0.8931, Loss: 0.0541\n",
      "Epoch   5 Batch  940/1077 - Train Accuracy: 0.9043, Validation Accuracy: 0.8920, Loss: 0.0662\n",
      "Epoch   5 Batch  960/1077 - Train Accuracy: 0.9092, Validation Accuracy: 0.8952, Loss: 0.0604\n",
      "Epoch   5 Batch  980/1077 - Train Accuracy: 0.8914, Validation Accuracy: 0.8640, Loss: 0.0738\n",
      "Epoch   5 Batch 1000/1077 - Train Accuracy: 0.9122, Validation Accuracy: 0.8768, Loss: 0.0593\n",
      "Epoch   5 Batch 1020/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9016, Loss: 0.0509\n",
      "Epoch   5 Batch 1040/1077 - Train Accuracy: 0.9132, Validation Accuracy: 0.8857, Loss: 0.0627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5 Batch 1060/1077 - Train Accuracy: 0.9184, Validation Accuracy: 0.8967, Loss: 0.0449\n",
      "Epoch   6 Batch   20/1077 - Train Accuracy: 0.9191, Validation Accuracy: 0.9031, Loss: 0.0493\n",
      "Epoch   6 Batch   40/1077 - Train Accuracy: 0.9289, Validation Accuracy: 0.9094, Loss: 0.0471\n",
      "Epoch   6 Batch   60/1077 - Train Accuracy: 0.9178, Validation Accuracy: 0.8917, Loss: 0.0481\n",
      "Epoch   6 Batch   80/1077 - Train Accuracy: 0.8871, Validation Accuracy: 0.8949, Loss: 0.0512\n",
      "Epoch   6 Batch  100/1077 - Train Accuracy: 0.9273, Validation Accuracy: 0.9034, Loss: 0.0545\n",
      "Epoch   6 Batch  120/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.8956, Loss: 0.0531\n",
      "Epoch   6 Batch  140/1077 - Train Accuracy: 0.9289, Validation Accuracy: 0.8864, Loss: 0.0558\n",
      "Epoch   6 Batch  160/1077 - Train Accuracy: 0.9098, Validation Accuracy: 0.8928, Loss: 0.0528\n",
      "Epoch   6 Batch  180/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.8956, Loss: 0.0534\n",
      "Epoch   6 Batch  200/1077 - Train Accuracy: 0.8938, Validation Accuracy: 0.8814, Loss: 0.0651\n",
      "Epoch   6 Batch  220/1077 - Train Accuracy: 0.8775, Validation Accuracy: 0.9123, Loss: 0.0464\n",
      "Epoch   6 Batch  240/1077 - Train Accuracy: 0.9437, Validation Accuracy: 0.8960, Loss: 0.0490\n",
      "Epoch   6 Batch  260/1077 - Train Accuracy: 0.9237, Validation Accuracy: 0.9034, Loss: 0.0452\n",
      "Epoch   6 Batch  280/1077 - Train Accuracy: 0.8992, Validation Accuracy: 0.8938, Loss: 0.0501\n",
      "Epoch   6 Batch  300/1077 - Train Accuracy: 0.9391, Validation Accuracy: 0.8846, Loss: 0.0473\n",
      "Epoch   6 Batch  320/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.8995, Loss: 0.0582\n",
      "Epoch   6 Batch  340/1077 - Train Accuracy: 0.9428, Validation Accuracy: 0.9165, Loss: 0.0536\n",
      "Epoch   6 Batch  360/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.8928, Loss: 0.0412\n",
      "Epoch   6 Batch  380/1077 - Train Accuracy: 0.9273, Validation Accuracy: 0.8991, Loss: 0.0414\n",
      "Epoch   6 Batch  400/1077 - Train Accuracy: 0.9227, Validation Accuracy: 0.8835, Loss: 0.0559\n",
      "Epoch   6 Batch  420/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9077, Loss: 0.0433\n",
      "Epoch   6 Batch  440/1077 - Train Accuracy: 0.8852, Validation Accuracy: 0.9134, Loss: 0.0637\n",
      "Epoch   6 Batch  460/1077 - Train Accuracy: 0.9219, Validation Accuracy: 0.8974, Loss: 0.0549\n",
      "Epoch   6 Batch  480/1077 - Train Accuracy: 0.9182, Validation Accuracy: 0.8853, Loss: 0.0501\n",
      "Epoch   6 Batch  500/1077 - Train Accuracy: 0.9176, Validation Accuracy: 0.8970, Loss: 0.0456\n",
      "Epoch   6 Batch  520/1077 - Train Accuracy: 0.9647, Validation Accuracy: 0.9045, Loss: 0.0434\n",
      "Epoch   6 Batch  540/1077 - Train Accuracy: 0.9215, Validation Accuracy: 0.9016, Loss: 0.0428\n",
      "Epoch   6 Batch  560/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.9062, Loss: 0.0420\n",
      "Epoch   6 Batch  580/1077 - Train Accuracy: 0.9412, Validation Accuracy: 0.9126, Loss: 0.0400\n",
      "Epoch   6 Batch  600/1077 - Train Accuracy: 0.9208, Validation Accuracy: 0.8814, Loss: 0.0531\n",
      "Epoch   6 Batch  620/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9098, Loss: 0.0459\n",
      "Epoch   6 Batch  640/1077 - Train Accuracy: 0.9178, Validation Accuracy: 0.9144, Loss: 0.0432\n",
      "Epoch   6 Batch  660/1077 - Train Accuracy: 0.9352, Validation Accuracy: 0.9208, Loss: 0.0467\n",
      "Epoch   6 Batch  680/1077 - Train Accuracy: 0.9271, Validation Accuracy: 0.9048, Loss: 0.0460\n",
      "Epoch   6 Batch  700/1077 - Train Accuracy: 0.9313, Validation Accuracy: 0.8956, Loss: 0.0395\n",
      "Epoch   6 Batch  720/1077 - Train Accuracy: 0.9071, Validation Accuracy: 0.8952, Loss: 0.0477\n",
      "Epoch   6 Batch  740/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.9020, Loss: 0.0495\n",
      "Epoch   6 Batch  760/1077 - Train Accuracy: 0.9316, Validation Accuracy: 0.8913, Loss: 0.0486\n",
      "Epoch   6 Batch  780/1077 - Train Accuracy: 0.9051, Validation Accuracy: 0.9187, Loss: 0.0653\n",
      "Epoch   6 Batch  800/1077 - Train Accuracy: 0.9164, Validation Accuracy: 0.9165, Loss: 0.0499\n",
      "Epoch   6 Batch  820/1077 - Train Accuracy: 0.9066, Validation Accuracy: 0.9268, Loss: 0.0498\n",
      "Epoch   6 Batch  840/1077 - Train Accuracy: 0.9078, Validation Accuracy: 0.9297, Loss: 0.0427\n",
      "Epoch   6 Batch  860/1077 - Train Accuracy: 0.9442, Validation Accuracy: 0.9052, Loss: 0.0498\n",
      "Epoch   6 Batch  880/1077 - Train Accuracy: 0.9191, Validation Accuracy: 0.9134, Loss: 0.0588\n",
      "Epoch   6 Batch  900/1077 - Train Accuracy: 0.9332, Validation Accuracy: 0.9219, Loss: 0.0529\n",
      "Epoch   6 Batch  920/1077 - Train Accuracy: 0.9203, Validation Accuracy: 0.9077, Loss: 0.0482\n",
      "Epoch   6 Batch  940/1077 - Train Accuracy: 0.9574, Validation Accuracy: 0.8931, Loss: 0.0382\n",
      "Epoch   6 Batch  960/1077 - Train Accuracy: 0.9315, Validation Accuracy: 0.9077, Loss: 0.0389\n",
      "Epoch   6 Batch  980/1077 - Train Accuracy: 0.9039, Validation Accuracy: 0.9126, Loss: 0.0500\n",
      "Epoch   6 Batch 1000/1077 - Train Accuracy: 0.9092, Validation Accuracy: 0.9016, Loss: 0.0396\n",
      "Epoch   6 Batch 1020/1077 - Train Accuracy: 0.9437, Validation Accuracy: 0.9329, Loss: 0.0357\n",
      "Epoch   6 Batch 1040/1077 - Train Accuracy: 0.9342, Validation Accuracy: 0.9062, Loss: 0.0521\n",
      "Epoch   6 Batch 1060/1077 - Train Accuracy: 0.9391, Validation Accuracy: 0.9183, Loss: 0.0409\n",
      "Epoch   7 Batch   20/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.9208, Loss: 0.0383\n",
      "Epoch   7 Batch   40/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9382, Loss: 0.0385\n",
      "Epoch   7 Batch   60/1077 - Train Accuracy: 0.9494, Validation Accuracy: 0.9137, Loss: 0.0371\n",
      "Epoch   7 Batch   80/1077 - Train Accuracy: 0.9180, Validation Accuracy: 0.9158, Loss: 0.0386\n",
      "Epoch   7 Batch  100/1077 - Train Accuracy: 0.9223, Validation Accuracy: 0.9073, Loss: 0.0423\n",
      "Epoch   7 Batch  120/1077 - Train Accuracy: 0.9137, Validation Accuracy: 0.9055, Loss: 0.1565\n",
      "Epoch   7 Batch  140/1077 - Train Accuracy: 0.9334, Validation Accuracy: 0.9084, Loss: 0.0470\n",
      "Epoch   7 Batch  160/1077 - Train Accuracy: 0.9113, Validation Accuracy: 0.9080, Loss: 0.0420\n",
      "Epoch   7 Batch  180/1077 - Train Accuracy: 0.9285, Validation Accuracy: 0.9009, Loss: 0.0376\n",
      "Epoch   7 Batch  200/1077 - Train Accuracy: 0.9234, Validation Accuracy: 0.9190, Loss: 0.0470\n",
      "Epoch   7 Batch  220/1077 - Train Accuracy: 0.9330, Validation Accuracy: 0.9261, Loss: 0.0377\n",
      "Epoch   7 Batch  240/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9205, Loss: 0.0305\n",
      "Epoch   7 Batch  260/1077 - Train Accuracy: 0.9304, Validation Accuracy: 0.9148, Loss: 0.0376\n",
      "Epoch   7 Batch  280/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.9229, Loss: 0.0389\n",
      "Epoch   7 Batch  300/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.9073, Loss: 0.0382\n",
      "Epoch   7 Batch  320/1077 - Train Accuracy: 0.9332, Validation Accuracy: 0.9126, Loss: 0.0507\n",
      "Epoch   7 Batch  340/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9055, Loss: 0.0408\n",
      "Epoch   7 Batch  360/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9027, Loss: 0.0321\n",
      "Epoch   7 Batch  380/1077 - Train Accuracy: 0.9418, Validation Accuracy: 0.9311, Loss: 0.0335\n",
      "Epoch   7 Batch  400/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.9155, Loss: 0.0447\n",
      "Epoch   7 Batch  420/1077 - Train Accuracy: 0.9477, Validation Accuracy: 0.9105, Loss: 0.0309\n",
      "Epoch   7 Batch  440/1077 - Train Accuracy: 0.9121, Validation Accuracy: 0.9066, Loss: 0.0462\n",
      "Epoch   7 Batch  460/1077 - Train Accuracy: 0.9313, Validation Accuracy: 0.9226, Loss: 0.0382\n",
      "Epoch   7 Batch  480/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9137, Loss: 0.0374\n",
      "Epoch   7 Batch  500/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9066, Loss: 0.0325\n",
      "Epoch   7 Batch  520/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.8999, Loss: 0.0347\n",
      "Epoch   7 Batch  540/1077 - Train Accuracy: 0.9477, Validation Accuracy: 0.9027, Loss: 0.0289\n",
      "Epoch   7 Batch  560/1077 - Train Accuracy: 0.9430, Validation Accuracy: 0.9148, Loss: 0.0322\n",
      "Epoch   7 Batch  580/1077 - Train Accuracy: 0.9394, Validation Accuracy: 0.9119, Loss: 0.0312\n",
      "Epoch   7 Batch  600/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9148, Loss: 0.0391\n",
      "Epoch   7 Batch  620/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.9212, Loss: 0.0388\n",
      "Epoch   7 Batch  640/1077 - Train Accuracy: 0.9349, Validation Accuracy: 0.9304, Loss: 0.0366\n",
      "Epoch   7 Batch  660/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9308, Loss: 0.0358\n",
      "Epoch   7 Batch  680/1077 - Train Accuracy: 0.9289, Validation Accuracy: 0.9151, Loss: 0.0393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7 Batch  700/1077 - Train Accuracy: 0.9211, Validation Accuracy: 0.9215, Loss: 0.0301\n",
      "Epoch   7 Batch  720/1077 - Train Accuracy: 0.9071, Validation Accuracy: 0.9226, Loss: 0.0414\n",
      "Epoch   7 Batch  740/1077 - Train Accuracy: 0.9250, Validation Accuracy: 0.9308, Loss: 0.0389\n",
      "Epoch   7 Batch  760/1077 - Train Accuracy: 0.9160, Validation Accuracy: 0.9190, Loss: 0.0380\n",
      "Epoch   7 Batch  780/1077 - Train Accuracy: 0.9121, Validation Accuracy: 0.9205, Loss: 0.0482\n",
      "Epoch   7 Batch  800/1077 - Train Accuracy: 0.9270, Validation Accuracy: 0.9261, Loss: 0.0361\n",
      "Epoch   7 Batch  820/1077 - Train Accuracy: 0.9086, Validation Accuracy: 0.9155, Loss: 0.0335\n",
      "Epoch   7 Batch  840/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.9226, Loss: 0.0348\n",
      "Epoch   7 Batch  860/1077 - Train Accuracy: 0.9356, Validation Accuracy: 0.9325, Loss: 0.0359\n",
      "Epoch   7 Batch  880/1077 - Train Accuracy: 0.9383, Validation Accuracy: 0.9272, Loss: 0.0459\n",
      "Epoch   7 Batch  900/1077 - Train Accuracy: 0.9355, Validation Accuracy: 0.9240, Loss: 0.0381\n",
      "Epoch   7 Batch  920/1077 - Train Accuracy: 0.9242, Validation Accuracy: 0.9141, Loss: 0.0382\n",
      "Epoch   7 Batch  940/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.9407, Loss: 0.0271\n",
      "Epoch   7 Batch  960/1077 - Train Accuracy: 0.9375, Validation Accuracy: 0.9244, Loss: 0.0351\n",
      "Epoch   7 Batch  980/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.9325, Loss: 0.0402\n",
      "Epoch   7 Batch 1000/1077 - Train Accuracy: 0.9286, Validation Accuracy: 0.9208, Loss: 0.0362\n",
      "Epoch   7 Batch 1020/1077 - Train Accuracy: 0.9508, Validation Accuracy: 0.9332, Loss: 0.0330\n",
      "Epoch   7 Batch 1040/1077 - Train Accuracy: 0.9326, Validation Accuracy: 0.9361, Loss: 0.0362\n",
      "Epoch   7 Batch 1060/1077 - Train Accuracy: 0.9516, Validation Accuracy: 0.9219, Loss: 0.0272\n",
      "Epoch   8 Batch   20/1077 - Train Accuracy: 0.9410, Validation Accuracy: 0.9265, Loss: 0.0295\n",
      "Epoch   8 Batch   40/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9286, Loss: 0.0315\n",
      "Epoch   8 Batch   60/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9403, Loss: 0.0278\n",
      "Epoch   8 Batch   80/1077 - Train Accuracy: 0.9395, Validation Accuracy: 0.9240, Loss: 0.0350\n",
      "Epoch   8 Batch  100/1077 - Train Accuracy: 0.9262, Validation Accuracy: 0.9176, Loss: 0.0421\n",
      "Epoch   8 Batch  120/1077 - Train Accuracy: 0.9367, Validation Accuracy: 0.9304, Loss: 0.0391\n",
      "Epoch   8 Batch  140/1077 - Train Accuracy: 0.9424, Validation Accuracy: 0.9304, Loss: 0.0389\n",
      "Epoch   8 Batch  160/1077 - Train Accuracy: 0.9293, Validation Accuracy: 0.9371, Loss: 0.0286\n",
      "Epoch   8 Batch  180/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.9371, Loss: 0.0317\n",
      "Epoch   8 Batch  200/1077 - Train Accuracy: 0.9406, Validation Accuracy: 0.9570, Loss: 0.0299\n",
      "Epoch   8 Batch  220/1077 - Train Accuracy: 0.9260, Validation Accuracy: 0.9375, Loss: 0.0280\n",
      "Epoch   8 Batch  240/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9066, Loss: 0.0313\n",
      "Epoch   8 Batch  260/1077 - Train Accuracy: 0.9438, Validation Accuracy: 0.9087, Loss: 0.0315\n",
      "Epoch   8 Batch  280/1077 - Train Accuracy: 0.9320, Validation Accuracy: 0.9439, Loss: 0.0322\n",
      "Epoch   8 Batch  300/1077 - Train Accuracy: 0.9564, Validation Accuracy: 0.9311, Loss: 0.0275\n",
      "Epoch   8 Batch  320/1077 - Train Accuracy: 0.9324, Validation Accuracy: 0.9382, Loss: 0.0407\n",
      "Epoch   8 Batch  340/1077 - Train Accuracy: 0.9622, Validation Accuracy: 0.9297, Loss: 0.0342\n",
      "Epoch   8 Batch  360/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9261, Loss: 0.0279\n",
      "Epoch   8 Batch  380/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9407, Loss: 0.0261\n",
      "Epoch   8 Batch  400/1077 - Train Accuracy: 0.9363, Validation Accuracy: 0.9467, Loss: 0.0363\n",
      "Epoch   8 Batch  420/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.9368, Loss: 0.0245\n",
      "Epoch   8 Batch  440/1077 - Train Accuracy: 0.9391, Validation Accuracy: 0.9276, Loss: 0.0367\n",
      "Epoch   8 Batch  460/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9389, Loss: 0.0315\n",
      "Epoch   8 Batch  480/1077 - Train Accuracy: 0.9428, Validation Accuracy: 0.9237, Loss: 0.0278\n",
      "Epoch   8 Batch  500/1077 - Train Accuracy: 0.9574, Validation Accuracy: 0.9492, Loss: 0.0261\n",
      "Epoch   8 Batch  520/1077 - Train Accuracy: 0.9747, Validation Accuracy: 0.9073, Loss: 0.0311\n",
      "Epoch   8 Batch  540/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.9119, Loss: 0.0246\n",
      "Epoch   8 Batch  560/1077 - Train Accuracy: 0.9246, Validation Accuracy: 0.9482, Loss: 0.0296\n",
      "Epoch   8 Batch  580/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9144, Loss: 0.0266\n",
      "Epoch   8 Batch  600/1077 - Train Accuracy: 0.9561, Validation Accuracy: 0.9343, Loss: 0.0418\n",
      "Epoch   8 Batch  620/1077 - Train Accuracy: 0.9352, Validation Accuracy: 0.9442, Loss: 0.0306\n",
      "Epoch   8 Batch  640/1077 - Train Accuracy: 0.9345, Validation Accuracy: 0.9659, Loss: 0.0370\n",
      "Epoch   8 Batch  660/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9400, Loss: 0.0221\n",
      "Epoch   8 Batch  680/1077 - Train Accuracy: 0.9208, Validation Accuracy: 0.9329, Loss: 0.0259\n",
      "Epoch   8 Batch  700/1077 - Train Accuracy: 0.9395, Validation Accuracy: 0.9361, Loss: 0.0264\n",
      "Epoch   8 Batch  720/1077 - Train Accuracy: 0.9264, Validation Accuracy: 0.9396, Loss: 0.0314\n",
      "Epoch   8 Batch  740/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9421, Loss: 0.0282\n",
      "Epoch   8 Batch  760/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9513, Loss: 0.0299\n",
      "Epoch   8 Batch  780/1077 - Train Accuracy: 0.9023, Validation Accuracy: 0.9233, Loss: 0.0412\n",
      "Epoch   8 Batch  800/1077 - Train Accuracy: 0.9348, Validation Accuracy: 0.9592, Loss: 0.0317\n",
      "Epoch   8 Batch  820/1077 - Train Accuracy: 0.9441, Validation Accuracy: 0.9556, Loss: 0.0353\n",
      "Epoch   8 Batch  840/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9432, Loss: 0.0308\n",
      "Epoch   8 Batch  860/1077 - Train Accuracy: 0.9401, Validation Accuracy: 0.9471, Loss: 0.0394\n",
      "Epoch   8 Batch  880/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9361, Loss: 0.0366\n",
      "Epoch   8 Batch  900/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9471, Loss: 0.0366\n",
      "Epoch   8 Batch  920/1077 - Train Accuracy: 0.9480, Validation Accuracy: 0.9435, Loss: 0.0279\n",
      "Epoch   8 Batch  940/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9680, Loss: 0.0253\n",
      "Epoch   8 Batch  960/1077 - Train Accuracy: 0.9423, Validation Accuracy: 0.9446, Loss: 0.0272\n",
      "Epoch   8 Batch  980/1077 - Train Accuracy: 0.9414, Validation Accuracy: 0.9450, Loss: 0.0314\n",
      "Epoch   8 Batch 1000/1077 - Train Accuracy: 0.9513, Validation Accuracy: 0.9265, Loss: 0.0303\n",
      "Epoch   8 Batch 1020/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9357, Loss: 0.0294\n",
      "Epoch   8 Batch 1040/1077 - Train Accuracy: 0.9564, Validation Accuracy: 0.9506, Loss: 0.0354\n",
      "Epoch   8 Batch 1060/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9496, Loss: 0.0211\n",
      "Epoch   9 Batch   20/1077 - Train Accuracy: 0.9512, Validation Accuracy: 0.9439, Loss: 0.0269\n",
      "Epoch   9 Batch   40/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9478, Loss: 0.0301\n",
      "Epoch   9 Batch   60/1077 - Train Accuracy: 0.9461, Validation Accuracy: 0.9421, Loss: 0.0259\n",
      "Epoch   9 Batch   80/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.9464, Loss: 0.0282\n",
      "Epoch   9 Batch  100/1077 - Train Accuracy: 0.9551, Validation Accuracy: 0.9329, Loss: 0.0285\n",
      "Epoch   9 Batch  120/1077 - Train Accuracy: 0.9480, Validation Accuracy: 0.9535, Loss: 0.0286\n",
      "Epoch   9 Batch  140/1077 - Train Accuracy: 0.9601, Validation Accuracy: 0.9311, Loss: 0.0286\n",
      "Epoch   9 Batch  160/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9304, Loss: 0.0237\n",
      "Epoch   9 Batch  180/1077 - Train Accuracy: 0.9578, Validation Accuracy: 0.9357, Loss: 0.0269\n",
      "Epoch   9 Batch  200/1077 - Train Accuracy: 0.9434, Validation Accuracy: 0.9371, Loss: 0.0263\n",
      "Epoch   9 Batch  220/1077 - Train Accuracy: 0.9671, Validation Accuracy: 0.9350, Loss: 0.0237\n",
      "Epoch   9 Batch  240/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9442, Loss: 0.0246\n",
      "Epoch   9 Batch  260/1077 - Train Accuracy: 0.9345, Validation Accuracy: 0.9396, Loss: 0.0239\n",
      "Epoch   9 Batch  280/1077 - Train Accuracy: 0.9094, Validation Accuracy: 0.9119, Loss: 0.0273\n",
      "Epoch   9 Batch  300/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9300, Loss: 0.0240\n",
      "Epoch   9 Batch  320/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9194, Loss: 0.0345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9 Batch  340/1077 - Train Accuracy: 0.9576, Validation Accuracy: 0.9411, Loss: 0.0270\n",
      "Epoch   9 Batch  360/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9158, Loss: 0.0181\n",
      "Epoch   9 Batch  380/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9364, Loss: 0.0241\n",
      "Epoch   9 Batch  400/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.9347, Loss: 0.0286\n",
      "Epoch   9 Batch  420/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9482, Loss: 0.0198\n",
      "Epoch   9 Batch  440/1077 - Train Accuracy: 0.9371, Validation Accuracy: 0.9347, Loss: 0.0307\n",
      "Epoch   9 Batch  460/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.9400, Loss: 0.0269\n",
      "Epoch   9 Batch  480/1077 - Train Accuracy: 0.9424, Validation Accuracy: 0.9375, Loss: 0.0207\n",
      "Epoch   9 Batch  500/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9432, Loss: 0.0227\n",
      "Epoch   9 Batch  520/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9173, Loss: 0.0248\n",
      "Epoch   9 Batch  540/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9432, Loss: 0.0244\n",
      "Epoch   9 Batch  560/1077 - Train Accuracy: 0.9250, Validation Accuracy: 0.9386, Loss: 0.0279\n",
      "Epoch   9 Batch  580/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9176, Loss: 0.0205\n",
      "Epoch   9 Batch  600/1077 - Train Accuracy: 0.9513, Validation Accuracy: 0.9638, Loss: 0.0293\n",
      "Epoch   9 Batch  620/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9290, Loss: 0.0249\n",
      "Epoch   9 Batch  640/1077 - Train Accuracy: 0.9661, Validation Accuracy: 0.9389, Loss: 0.0231\n",
      "Epoch   9 Batch  660/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9592, Loss: 0.0223\n",
      "Epoch   9 Batch  680/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9549, Loss: 0.0217\n",
      "Epoch   9 Batch  700/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9535, Loss: 0.0208\n",
      "Epoch   9 Batch  720/1077 - Train Accuracy: 0.9404, Validation Accuracy: 0.9542, Loss: 0.0289\n",
      "Epoch   9 Batch  740/1077 - Train Accuracy: 0.9570, Validation Accuracy: 0.9517, Loss: 0.0180\n",
      "Epoch   9 Batch  760/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9695, Loss: 0.0287\n",
      "Epoch   9 Batch  780/1077 - Train Accuracy: 0.9297, Validation Accuracy: 0.9478, Loss: 0.0385\n",
      "Epoch   9 Batch  800/1077 - Train Accuracy: 0.9266, Validation Accuracy: 0.9322, Loss: 0.0231\n",
      "Epoch   9 Batch  820/1077 - Train Accuracy: 0.9469, Validation Accuracy: 0.9158, Loss: 0.0221\n",
      "Epoch   9 Batch  840/1077 - Train Accuracy: 0.9465, Validation Accuracy: 0.9506, Loss: 0.0258\n",
      "Epoch   9 Batch  860/1077 - Train Accuracy: 0.9501, Validation Accuracy: 0.9595, Loss: 0.0270\n",
      "Epoch   9 Batch  880/1077 - Train Accuracy: 0.9238, Validation Accuracy: 0.9499, Loss: 0.0307\n",
      "Epoch   9 Batch  900/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9407, Loss: 0.0294\n",
      "Epoch   9 Batch  920/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9371, Loss: 0.0255\n",
      "Epoch   9 Batch  940/1077 - Train Accuracy: 0.9492, Validation Accuracy: 0.9510, Loss: 0.0263\n",
      "Epoch   9 Batch  960/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9609, Loss: 0.0196\n",
      "Epoch   9 Batch  980/1077 - Train Accuracy: 0.9258, Validation Accuracy: 0.9688, Loss: 0.0282\n",
      "Epoch   9 Batch 1000/1077 - Train Accuracy: 0.9453, Validation Accuracy: 0.9460, Loss: 0.0256\n",
      "Epoch   9 Batch 1020/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9560, Loss: 0.0299\n",
      "Epoch   9 Batch 1040/1077 - Train Accuracy: 0.9700, Validation Accuracy: 0.9474, Loss: 0.0228\n",
      "Epoch   9 Batch 1060/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9432, Loss: 0.0148\n",
      "Epoch  10 Batch   20/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9624, Loss: 0.0194\n",
      "Epoch  10 Batch   40/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9513, Loss: 0.0197\n",
      "Epoch  10 Batch   60/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9467, Loss: 0.0194\n",
      "Epoch  10 Batch   80/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9400, Loss: 0.0228\n",
      "Epoch  10 Batch  100/1077 - Train Accuracy: 0.9555, Validation Accuracy: 0.9425, Loss: 0.0196\n",
      "Epoch  10 Batch  120/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9400, Loss: 0.0215\n",
      "Epoch  10 Batch  140/1077 - Train Accuracy: 0.9589, Validation Accuracy: 0.9371, Loss: 0.0245\n",
      "Epoch  10 Batch  160/1077 - Train Accuracy: 0.9500, Validation Accuracy: 0.9556, Loss: 0.0210\n",
      "Epoch  10 Batch  180/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9691, Loss: 0.0218\n",
      "Epoch  10 Batch  200/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9808, Loss: 0.0247\n",
      "Epoch  10 Batch  220/1077 - Train Accuracy: 0.9720, Validation Accuracy: 0.9620, Loss: 0.0223\n",
      "Epoch  10 Batch  240/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9510, Loss: 0.0299\n",
      "Epoch  10 Batch  260/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9453, Loss: 0.0182\n",
      "Epoch  10 Batch  280/1077 - Train Accuracy: 0.9477, Validation Accuracy: 0.9538, Loss: 0.0226\n",
      "Epoch  10 Batch  300/1077 - Train Accuracy: 0.9671, Validation Accuracy: 0.9627, Loss: 0.0196\n",
      "Epoch  10 Batch  320/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9695, Loss: 0.0302\n",
      "Epoch  10 Batch  340/1077 - Train Accuracy: 0.9753, Validation Accuracy: 0.9471, Loss: 0.0288\n",
      "Epoch  10 Batch  360/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9595, Loss: 0.0173\n",
      "Epoch  10 Batch  380/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9393, Loss: 0.0227\n",
      "Epoch  10 Batch  400/1077 - Train Accuracy: 0.9488, Validation Accuracy: 0.9510, Loss: 0.0283\n",
      "Epoch  10 Batch  420/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9545, Loss: 0.0197\n",
      "Epoch  10 Batch  440/1077 - Train Accuracy: 0.9559, Validation Accuracy: 0.9329, Loss: 0.0281\n",
      "Epoch  10 Batch  460/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9585, Loss: 0.0226\n",
      "Epoch  10 Batch  480/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9300, Loss: 0.0186\n",
      "Epoch  10 Batch  500/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9421, Loss: 0.0176\n",
      "Epoch  10 Batch  520/1077 - Train Accuracy: 0.9814, Validation Accuracy: 0.9503, Loss: 0.0186\n",
      "Epoch  10 Batch  540/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9609, Loss: 0.0191\n",
      "Epoch  10 Batch  560/1077 - Train Accuracy: 0.9156, Validation Accuracy: 0.9478, Loss: 0.0200\n",
      "Epoch  10 Batch  580/1077 - Train Accuracy: 0.9524, Validation Accuracy: 0.9418, Loss: 0.0167\n",
      "Epoch  10 Batch  600/1077 - Train Accuracy: 0.9635, Validation Accuracy: 0.9538, Loss: 0.0266\n",
      "Epoch  10 Batch  620/1077 - Train Accuracy: 0.9508, Validation Accuracy: 0.9634, Loss: 0.0226\n",
      "Epoch  10 Batch  640/1077 - Train Accuracy: 0.9509, Validation Accuracy: 0.9670, Loss: 0.0255\n",
      "Epoch  10 Batch  660/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9620, Loss: 0.0193\n",
      "Epoch  10 Batch  680/1077 - Train Accuracy: 0.9457, Validation Accuracy: 0.9457, Loss: 0.0196\n",
      "Epoch  10 Batch  700/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9499, Loss: 0.0164\n",
      "Epoch  10 Batch  720/1077 - Train Accuracy: 0.9507, Validation Accuracy: 0.9737, Loss: 0.0234\n",
      "Epoch  10 Batch  740/1077 - Train Accuracy: 0.9422, Validation Accuracy: 0.9482, Loss: 0.0224\n",
      "Epoch  10 Batch  760/1077 - Train Accuracy: 0.9563, Validation Accuracy: 0.9453, Loss: 0.0190\n",
      "Epoch  10 Batch  780/1077 - Train Accuracy: 0.9430, Validation Accuracy: 0.9616, Loss: 0.0278\n",
      "Epoch  10 Batch  800/1077 - Train Accuracy: 0.9285, Validation Accuracy: 0.9648, Loss: 0.0250\n",
      "Epoch  10 Batch  820/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9602, Loss: 0.0245\n",
      "Epoch  10 Batch  840/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9709, Loss: 0.0211\n",
      "Epoch  10 Batch  860/1077 - Train Accuracy: 0.9583, Validation Accuracy: 0.9631, Loss: 0.0221\n",
      "Epoch  10 Batch  880/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9538, Loss: 0.0232\n",
      "Epoch  10 Batch  900/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9499, Loss: 0.0218\n",
      "Epoch  10 Batch  920/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9606, Loss: 0.0200\n",
      "Epoch  10 Batch  940/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9624, Loss: 0.0263\n",
      "Epoch  10 Batch  960/1077 - Train Accuracy: 0.9647, Validation Accuracy: 0.9695, Loss: 0.0189\n",
      "Epoch  10 Batch  980/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9446, Loss: 0.0199\n",
      "Epoch  10 Batch 1000/1077 - Train Accuracy: 0.9472, Validation Accuracy: 0.9556, Loss: 0.0222\n",
      "Epoch  10 Batch 1020/1077 - Train Accuracy: 0.9574, Validation Accuracy: 0.9503, Loss: 0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10 Batch 1040/1077 - Train Accuracy: 0.9618, Validation Accuracy: 0.9421, Loss: 0.0199\n",
      "Epoch  10 Batch 1060/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9503, Loss: 0.0183\n",
      "Epoch  11 Batch   20/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9656, Loss: 0.0181\n",
      "Epoch  11 Batch   40/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9428, Loss: 0.0192\n",
      "Epoch  11 Batch   60/1077 - Train Accuracy: 0.9643, Validation Accuracy: 0.9421, Loss: 0.0176\n",
      "Epoch  11 Batch   80/1077 - Train Accuracy: 0.9539, Validation Accuracy: 0.9723, Loss: 0.0221\n",
      "Epoch  11 Batch  100/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9528, Loss: 0.0216\n",
      "Epoch  11 Batch  120/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9485, Loss: 0.0174\n",
      "Epoch  11 Batch  140/1077 - Train Accuracy: 0.9716, Validation Accuracy: 0.9386, Loss: 0.0200\n",
      "Epoch  11 Batch  160/1077 - Train Accuracy: 0.9590, Validation Accuracy: 0.9620, Loss: 0.0159\n",
      "Epoch  11 Batch  180/1077 - Train Accuracy: 0.9543, Validation Accuracy: 0.9510, Loss: 0.0228\n",
      "Epoch  11 Batch  200/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9602, Loss: 0.0244\n",
      "Epoch  11 Batch  220/1077 - Train Accuracy: 0.9560, Validation Accuracy: 0.9503, Loss: 0.0184\n",
      "Epoch  11 Batch  240/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9521, Loss: 0.0166\n",
      "Epoch  11 Batch  260/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9595, Loss: 0.0152\n",
      "Epoch  11 Batch  280/1077 - Train Accuracy: 0.9387, Validation Accuracy: 0.9506, Loss: 0.0187\n",
      "Epoch  11 Batch  300/1077 - Train Accuracy: 0.9667, Validation Accuracy: 0.9556, Loss: 0.0251\n",
      "Epoch  11 Batch  320/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9570, Loss: 0.0243\n",
      "Epoch  11 Batch  340/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9471, Loss: 0.0201\n",
      "Epoch  11 Batch  360/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9510, Loss: 0.0219\n",
      "Epoch  11 Batch  380/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9673, Loss: 0.0157\n",
      "Epoch  11 Batch  400/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9563, Loss: 0.0272\n",
      "Epoch  11 Batch  420/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9450, Loss: 0.0134\n",
      "Epoch  11 Batch  440/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9375, Loss: 0.0241\n",
      "Epoch  11 Batch  460/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9432, Loss: 0.0252\n",
      "Epoch  11 Batch  480/1077 - Train Accuracy: 0.9535, Validation Accuracy: 0.9343, Loss: 0.0167\n",
      "Epoch  11 Batch  500/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.9581, Loss: 0.0182\n",
      "Epoch  11 Batch  520/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9492, Loss: 0.0150\n",
      "Epoch  11 Batch  540/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9677, Loss: 0.0202\n",
      "Epoch  11 Batch  560/1077 - Train Accuracy: 0.9422, Validation Accuracy: 0.9602, Loss: 0.0176\n",
      "Epoch  11 Batch  580/1077 - Train Accuracy: 0.9513, Validation Accuracy: 0.9585, Loss: 0.0143\n",
      "Epoch  11 Batch  600/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9748, Loss: 0.0182\n",
      "Epoch  11 Batch  620/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9705, Loss: 0.0187\n",
      "Epoch  11 Batch  640/1077 - Train Accuracy: 0.9568, Validation Accuracy: 0.9542, Loss: 0.0218\n",
      "Epoch  11 Batch  660/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9407, Loss: 0.0134\n",
      "Epoch  11 Batch  680/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9677, Loss: 0.0178\n",
      "Epoch  11 Batch  700/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9677, Loss: 0.0126\n",
      "Epoch  11 Batch  720/1077 - Train Accuracy: 0.9511, Validation Accuracy: 0.9684, Loss: 0.0227\n",
      "Epoch  11 Batch  740/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9570, Loss: 0.0162\n",
      "Epoch  11 Batch  760/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9659, Loss: 0.0159\n",
      "Epoch  11 Batch  780/1077 - Train Accuracy: 0.9410, Validation Accuracy: 0.9723, Loss: 0.0233\n",
      "Epoch  11 Batch  800/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9627, Loss: 0.0223\n",
      "Epoch  11 Batch  820/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9599, Loss: 0.0147\n",
      "Epoch  11 Batch  840/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9496, Loss: 0.0216\n",
      "Epoch  11 Batch  860/1077 - Train Accuracy: 0.9665, Validation Accuracy: 0.9734, Loss: 0.0213\n",
      "Epoch  11 Batch  880/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9553, Loss: 0.0233\n",
      "Epoch  11 Batch  900/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9510, Loss: 0.0202\n",
      "Epoch  11 Batch  920/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9592, Loss: 0.0136\n",
      "Epoch  11 Batch  940/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9581, Loss: 0.0158\n",
      "Epoch  11 Batch  960/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9560, Loss: 0.0142\n",
      "Epoch  11 Batch  980/1077 - Train Accuracy: 0.9504, Validation Accuracy: 0.9613, Loss: 0.0188\n",
      "Epoch  11 Batch 1000/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9293, Loss: 0.0197\n",
      "Epoch  11 Batch 1020/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9535, Loss: 0.0153\n",
      "Epoch  11 Batch 1040/1077 - Train Accuracy: 0.9753, Validation Accuracy: 0.9542, Loss: 0.0198\n",
      "Epoch  11 Batch 1060/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9606, Loss: 0.0196\n",
      "Epoch  12 Batch   20/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9631, Loss: 0.0174\n",
      "Epoch  12 Batch   40/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9599, Loss: 0.0172\n",
      "Epoch  12 Batch   60/1077 - Train Accuracy: 0.9528, Validation Accuracy: 0.9506, Loss: 0.0166\n",
      "Epoch  12 Batch   80/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9585, Loss: 0.0191\n",
      "Epoch  12 Batch  100/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9411, Loss: 0.0177\n",
      "Epoch  12 Batch  120/1077 - Train Accuracy: 0.9664, Validation Accuracy: 0.9744, Loss: 0.0181\n",
      "Epoch  12 Batch  140/1077 - Train Accuracy: 0.9692, Validation Accuracy: 0.9407, Loss: 0.0191\n",
      "Epoch  12 Batch  160/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9673, Loss: 0.0133\n",
      "Epoch  12 Batch  180/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9595, Loss: 0.0181\n",
      "Epoch  12 Batch  200/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9585, Loss: 0.0222\n",
      "Epoch  12 Batch  220/1077 - Train Accuracy: 0.9618, Validation Accuracy: 0.9599, Loss: 0.0147\n",
      "Epoch  12 Batch  240/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9531, Loss: 0.0151\n",
      "Epoch  12 Batch  260/1077 - Train Accuracy: 0.9673, Validation Accuracy: 0.9616, Loss: 0.0152\n",
      "Epoch  12 Batch  280/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9624, Loss: 0.0222\n",
      "Epoch  12 Batch  300/1077 - Train Accuracy: 0.9737, Validation Accuracy: 0.9709, Loss: 0.0156\n",
      "Epoch  12 Batch  320/1077 - Train Accuracy: 0.9621, Validation Accuracy: 0.9634, Loss: 0.0258\n",
      "Epoch  12 Batch  340/1077 - Train Accuracy: 0.9675, Validation Accuracy: 0.9538, Loss: 0.0196\n",
      "Epoch  12 Batch  360/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9457, Loss: 0.0133\n",
      "Epoch  12 Batch  380/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9542, Loss: 0.0208\n",
      "Epoch  12 Batch  400/1077 - Train Accuracy: 0.9520, Validation Accuracy: 0.9432, Loss: 0.0210\n",
      "Epoch  12 Batch  420/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9670, Loss: 0.0098\n",
      "Epoch  12 Batch  440/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9538, Loss: 0.0164\n",
      "Epoch  12 Batch  460/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9563, Loss: 0.0211\n",
      "Epoch  12 Batch  480/1077 - Train Accuracy: 0.9786, Validation Accuracy: 0.9599, Loss: 0.0169\n",
      "Epoch  12 Batch  500/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9599, Loss: 0.0151\n",
      "Epoch  12 Batch  520/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9432, Loss: 0.0132\n",
      "Epoch  12 Batch  540/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9570, Loss: 0.0126\n",
      "Epoch  12 Batch  560/1077 - Train Accuracy: 0.9543, Validation Accuracy: 0.9489, Loss: 0.0206\n",
      "Epoch  12 Batch  580/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9709, Loss: 0.0159\n",
      "Epoch  12 Batch  600/1077 - Train Accuracy: 0.9702, Validation Accuracy: 0.9744, Loss: 0.0232\n",
      "Epoch  12 Batch  620/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9482, Loss: 0.0190\n",
      "Epoch  12 Batch  640/1077 - Train Accuracy: 0.9583, Validation Accuracy: 0.9620, Loss: 0.0172\n",
      "Epoch  12 Batch  660/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9588, Loss: 0.0134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  12 Batch  680/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9432, Loss: 0.0159\n",
      "Epoch  12 Batch  700/1077 - Train Accuracy: 0.9473, Validation Accuracy: 0.9599, Loss: 0.0167\n",
      "Epoch  12 Batch  720/1077 - Train Accuracy: 0.9490, Validation Accuracy: 0.9780, Loss: 0.0172\n",
      "Epoch  12 Batch  740/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9595, Loss: 0.0200\n",
      "Epoch  12 Batch  760/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9606, Loss: 0.0157\n",
      "Epoch  12 Batch  780/1077 - Train Accuracy: 0.9477, Validation Accuracy: 0.9545, Loss: 0.0232\n",
      "Epoch  12 Batch  800/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.9616, Loss: 0.0129\n",
      "Epoch  12 Batch  820/1077 - Train Accuracy: 0.9605, Validation Accuracy: 0.9538, Loss: 0.0153\n",
      "Epoch  12 Batch  840/1077 - Train Accuracy: 0.9566, Validation Accuracy: 0.9538, Loss: 0.0171\n",
      "Epoch  12 Batch  860/1077 - Train Accuracy: 0.9784, Validation Accuracy: 0.9506, Loss: 0.0203\n",
      "Epoch  12 Batch  880/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9631, Loss: 0.0177\n",
      "Epoch  12 Batch  900/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9705, Loss: 0.0188\n",
      "Epoch  12 Batch  920/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9545, Loss: 0.0145\n",
      "Epoch  12 Batch  940/1077 - Train Accuracy: 0.9633, Validation Accuracy: 0.9670, Loss: 0.0223\n",
      "Epoch  12 Batch  960/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9510, Loss: 0.0127\n",
      "Epoch  12 Batch  980/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9467, Loss: 0.0188\n",
      "Epoch  12 Batch 1000/1077 - Train Accuracy: 0.9639, Validation Accuracy: 0.9368, Loss: 0.0202\n",
      "Epoch  12 Batch 1020/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9691, Loss: 0.0152\n",
      "Epoch  12 Batch 1040/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9638, Loss: 0.0133\n",
      "Epoch  12 Batch 1060/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9545, Loss: 0.0119\n",
      "Epoch  13 Batch   20/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9553, Loss: 0.0122\n",
      "Epoch  13 Batch   40/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9734, Loss: 0.0138\n",
      "Epoch  13 Batch   60/1077 - Train Accuracy: 0.9401, Validation Accuracy: 0.9510, Loss: 0.0124\n",
      "Epoch  13 Batch   80/1077 - Train Accuracy: 0.9484, Validation Accuracy: 0.9709, Loss: 0.0174\n",
      "Epoch  13 Batch  100/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9599, Loss: 0.0160\n",
      "Epoch  13 Batch  120/1077 - Train Accuracy: 0.9637, Validation Accuracy: 0.9670, Loss: 0.0156\n",
      "Epoch  13 Batch  140/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9450, Loss: 0.0185\n",
      "Epoch  13 Batch  160/1077 - Train Accuracy: 0.9703, Validation Accuracy: 0.9599, Loss: 0.0140\n",
      "Epoch  13 Batch  180/1077 - Train Accuracy: 0.9523, Validation Accuracy: 0.9595, Loss: 0.0134\n",
      "Epoch  13 Batch  200/1077 - Train Accuracy: 0.9586, Validation Accuracy: 0.9727, Loss: 0.0160\n",
      "Epoch  13 Batch  220/1077 - Train Accuracy: 0.9560, Validation Accuracy: 0.9581, Loss: 0.0198\n",
      "Epoch  13 Batch  240/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9648, Loss: 0.0126\n",
      "Epoch  13 Batch  260/1077 - Train Accuracy: 0.9743, Validation Accuracy: 0.9677, Loss: 0.0147\n",
      "Epoch  13 Batch  280/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9652, Loss: 0.0169\n",
      "Epoch  13 Batch  300/1077 - Train Accuracy: 0.9679, Validation Accuracy: 0.9638, Loss: 0.0160\n",
      "Epoch  13 Batch  320/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9393, Loss: 0.0209\n",
      "Epoch  13 Batch  340/1077 - Train Accuracy: 0.9831, Validation Accuracy: 0.9606, Loss: 0.0177\n",
      "Epoch  13 Batch  360/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9553, Loss: 0.0183\n",
      "Epoch  13 Batch  380/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9727, Loss: 0.0110\n",
      "Epoch  13 Batch  400/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9606, Loss: 0.0220\n",
      "Epoch  13 Batch  420/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9620, Loss: 0.0120\n",
      "Epoch  13 Batch  440/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9581, Loss: 0.0163\n",
      "Epoch  13 Batch  460/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9585, Loss: 0.0131\n",
      "Epoch  13 Batch  480/1077 - Train Accuracy: 0.9696, Validation Accuracy: 0.9581, Loss: 0.0137\n",
      "Epoch  13 Batch  500/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9542, Loss: 0.0132\n",
      "Epoch  13 Batch  520/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9830, Loss: 0.0121\n",
      "Epoch  13 Batch  540/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9627, Loss: 0.0216\n",
      "Epoch  13 Batch  560/1077 - Train Accuracy: 0.9582, Validation Accuracy: 0.9411, Loss: 0.0120\n",
      "Epoch  13 Batch  580/1077 - Train Accuracy: 0.9665, Validation Accuracy: 0.9503, Loss: 0.0152\n",
      "Epoch  13 Batch  600/1077 - Train Accuracy: 0.9669, Validation Accuracy: 0.9680, Loss: 0.0233\n",
      "Epoch  13 Batch  620/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9730, Loss: 0.0249\n",
      "Epoch  13 Batch  640/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9727, Loss: 0.0149\n",
      "Epoch  13 Batch  660/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9609, Loss: 0.0153\n",
      "Epoch  13 Batch  680/1077 - Train Accuracy: 0.9565, Validation Accuracy: 0.9609, Loss: 0.0166\n",
      "Epoch  13 Batch  700/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9741, Loss: 0.0142\n",
      "Epoch  13 Batch  720/1077 - Train Accuracy: 0.9655, Validation Accuracy: 0.9567, Loss: 0.0217\n",
      "Epoch  13 Batch  740/1077 - Train Accuracy: 0.9496, Validation Accuracy: 0.9549, Loss: 0.0130\n",
      "Epoch  13 Batch  760/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9492, Loss: 0.0158\n",
      "Epoch  13 Batch  780/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9656, Loss: 0.0214\n",
      "Epoch  13 Batch  800/1077 - Train Accuracy: 0.9668, Validation Accuracy: 0.9602, Loss: 0.0115\n",
      "Epoch  13 Batch  820/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9542, Loss: 0.0136\n",
      "Epoch  13 Batch  840/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9680, Loss: 0.0121\n",
      "Epoch  13 Batch  860/1077 - Train Accuracy: 0.9714, Validation Accuracy: 0.9666, Loss: 0.0162\n",
      "Epoch  13 Batch  880/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9553, Loss: 0.0189\n",
      "Epoch  13 Batch  900/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9620, Loss: 0.0161\n",
      "Epoch  13 Batch  920/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9773, Loss: 0.0172\n",
      "Epoch  13 Batch  940/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9659, Loss: 0.0159\n",
      "Epoch  13 Batch  960/1077 - Train Accuracy: 0.9710, Validation Accuracy: 0.9606, Loss: 0.0155\n",
      "Epoch  13 Batch  980/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9510, Loss: 0.0176\n",
      "Epoch  13 Batch 1000/1077 - Train Accuracy: 0.9661, Validation Accuracy: 0.9801, Loss: 0.0163\n",
      "Epoch  13 Batch 1020/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9705, Loss: 0.0139\n",
      "Epoch  13 Batch 1040/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9716, Loss: 0.0179\n",
      "Epoch  13 Batch 1060/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9517, Loss: 0.0110\n",
      "Epoch  14 Batch   20/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9553, Loss: 0.0121\n",
      "Epoch  14 Batch   40/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9801, Loss: 0.0123\n",
      "Epoch  14 Batch   60/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9659, Loss: 0.0155\n",
      "Epoch  14 Batch   80/1077 - Train Accuracy: 0.9531, Validation Accuracy: 0.9609, Loss: 0.0150\n",
      "Epoch  14 Batch  100/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9631, Loss: 0.0150\n",
      "Epoch  14 Batch  120/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9606, Loss: 0.0182\n",
      "Epoch  14 Batch  140/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9545, Loss: 0.0178\n",
      "Epoch  14 Batch  160/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9581, Loss: 0.0164\n",
      "Epoch  14 Batch  180/1077 - Train Accuracy: 0.9449, Validation Accuracy: 0.9585, Loss: 0.0253\n",
      "Epoch  14 Batch  200/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9563, Loss: 0.0131\n",
      "Epoch  14 Batch  220/1077 - Train Accuracy: 0.9716, Validation Accuracy: 0.9759, Loss: 0.0126\n",
      "Epoch  14 Batch  240/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9545, Loss: 0.0116\n",
      "Epoch  14 Batch  260/1077 - Train Accuracy: 0.9673, Validation Accuracy: 0.9680, Loss: 0.0124\n",
      "Epoch  14 Batch  280/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9712, Loss: 0.0173\n",
      "Epoch  14 Batch  300/1077 - Train Accuracy: 0.9720, Validation Accuracy: 0.9577, Loss: 0.0203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  14 Batch  320/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9719, Loss: 0.0161\n",
      "Epoch  14 Batch  340/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9677, Loss: 0.0141\n",
      "Epoch  14 Batch  360/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9663, Loss: 0.0116\n",
      "Epoch  14 Batch  380/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9634, Loss: 0.0111\n",
      "Epoch  14 Batch  400/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9606, Loss: 0.0174\n",
      "Epoch  14 Batch  420/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9577, Loss: 0.0091\n",
      "Epoch  14 Batch  440/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9489, Loss: 0.0147\n",
      "Epoch  14 Batch  460/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9609, Loss: 0.0152\n",
      "Epoch  14 Batch  480/1077 - Train Accuracy: 0.9712, Validation Accuracy: 0.9751, Loss: 0.0115\n",
      "Epoch  14 Batch  500/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9549, Loss: 0.0099\n",
      "Epoch  14 Batch  520/1077 - Train Accuracy: 0.9900, Validation Accuracy: 0.9684, Loss: 0.0130\n",
      "Epoch  14 Batch  540/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9506, Loss: 0.0119\n",
      "Epoch  14 Batch  560/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9567, Loss: 0.0128\n",
      "Epoch  14 Batch  580/1077 - Train Accuracy: 0.9833, Validation Accuracy: 0.9673, Loss: 0.0120\n",
      "Epoch  14 Batch  600/1077 - Train Accuracy: 0.9650, Validation Accuracy: 0.9719, Loss: 0.0184\n",
      "Epoch  14 Batch  620/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9719, Loss: 0.0180\n",
      "Epoch  14 Batch  640/1077 - Train Accuracy: 0.9788, Validation Accuracy: 0.9783, Loss: 0.0171\n",
      "Epoch  14 Batch  660/1077 - Train Accuracy: 0.9914, Validation Accuracy: 0.9691, Loss: 0.0118\n",
      "Epoch  14 Batch  680/1077 - Train Accuracy: 0.9583, Validation Accuracy: 0.9755, Loss: 0.0145\n",
      "Epoch  14 Batch  700/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9712, Loss: 0.0107\n",
      "Epoch  14 Batch  720/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9798, Loss: 0.0206\n",
      "Epoch  14 Batch  740/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9712, Loss: 0.0109\n",
      "Epoch  14 Batch  760/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9673, Loss: 0.0126\n",
      "Epoch  14 Batch  780/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9719, Loss: 0.0160\n",
      "Epoch  14 Batch  800/1077 - Train Accuracy: 0.9527, Validation Accuracy: 0.9695, Loss: 0.0133\n",
      "Epoch  14 Batch  820/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9489, Loss: 0.0130\n",
      "Epoch  14 Batch  840/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9673, Loss: 0.0129\n",
      "Epoch  14 Batch  860/1077 - Train Accuracy: 0.9643, Validation Accuracy: 0.9478, Loss: 0.0129\n",
      "Epoch  14 Batch  880/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9595, Loss: 0.0182\n",
      "Epoch  14 Batch  900/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9588, Loss: 0.0146\n",
      "Epoch  14 Batch  920/1077 - Train Accuracy: 0.9629, Validation Accuracy: 0.9556, Loss: 0.0115\n",
      "Epoch  14 Batch  940/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9790, Loss: 0.0157\n",
      "Epoch  14 Batch  960/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9744, Loss: 0.0124\n",
      "Epoch  14 Batch  980/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9585, Loss: 0.0164\n",
      "Epoch  14 Batch 1000/1077 - Train Accuracy: 0.9706, Validation Accuracy: 0.9382, Loss: 0.0129\n",
      "Epoch  14 Batch 1020/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9705, Loss: 0.0091\n",
      "Epoch  14 Batch 1040/1077 - Train Accuracy: 0.9720, Validation Accuracy: 0.9751, Loss: 0.0156\n",
      "Epoch  14 Batch 1060/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9705, Loss: 0.0114\n",
      "Epoch  15 Batch   20/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9751, Loss: 0.0102\n",
      "Epoch  15 Batch   40/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9620, Loss: 0.0109\n",
      "Epoch  15 Batch   60/1077 - Train Accuracy: 0.9673, Validation Accuracy: 0.9577, Loss: 0.0135\n",
      "Epoch  15 Batch   80/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9634, Loss: 0.0159\n",
      "Epoch  15 Batch  100/1077 - Train Accuracy: 0.9648, Validation Accuracy: 0.9698, Loss: 0.0101\n",
      "Epoch  15 Batch  120/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9727, Loss: 0.0113\n",
      "Epoch  15 Batch  140/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9691, Loss: 0.0119\n",
      "Epoch  15 Batch  160/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9592, Loss: 0.0119\n",
      "Epoch  15 Batch  180/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9673, Loss: 0.0117\n",
      "Epoch  15 Batch  200/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9670, Loss: 0.0137\n",
      "Epoch  15 Batch  220/1077 - Train Accuracy: 0.9716, Validation Accuracy: 0.9670, Loss: 0.0130\n",
      "Epoch  15 Batch  240/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9727, Loss: 0.0130\n",
      "Epoch  15 Batch  260/1077 - Train Accuracy: 0.9788, Validation Accuracy: 0.9751, Loss: 0.0129\n",
      "Epoch  15 Batch  280/1077 - Train Accuracy: 0.9594, Validation Accuracy: 0.9648, Loss: 0.0193\n",
      "Epoch  15 Batch  300/1077 - Train Accuracy: 0.9601, Validation Accuracy: 0.9677, Loss: 0.0183\n",
      "Epoch  15 Batch  320/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9624, Loss: 0.0184\n",
      "Epoch  15 Batch  340/1077 - Train Accuracy: 0.9819, Validation Accuracy: 0.9727, Loss: 0.0142\n",
      "Epoch  15 Batch  360/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9741, Loss: 0.0120\n",
      "Epoch  15 Batch  380/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9677, Loss: 0.0111\n",
      "Epoch  15 Batch  400/1077 - Train Accuracy: 0.9738, Validation Accuracy: 0.9663, Loss: 0.0143\n",
      "Epoch  15 Batch  420/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9769, Loss: 0.0100\n",
      "Epoch  15 Batch  440/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9677, Loss: 0.0113\n",
      "Epoch  15 Batch  460/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9606, Loss: 0.0115\n",
      "Epoch  15 Batch  480/1077 - Train Accuracy: 0.9745, Validation Accuracy: 0.9641, Loss: 0.0095\n",
      "Epoch  15 Batch  500/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9751, Loss: 0.0160\n",
      "Epoch  15 Batch  520/1077 - Train Accuracy: 0.9996, Validation Accuracy: 0.9698, Loss: 0.0084\n",
      "Epoch  15 Batch  540/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9624, Loss: 0.0099\n",
      "Epoch  15 Batch  560/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9592, Loss: 0.0127\n",
      "Epoch  15 Batch  580/1077 - Train Accuracy: 0.9717, Validation Accuracy: 0.9734, Loss: 0.0121\n",
      "Epoch  15 Batch  600/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9805, Loss: 0.0147\n",
      "Epoch  15 Batch  620/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9666, Loss: 0.0147\n",
      "Epoch  15 Batch  640/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9723, Loss: 0.0116\n",
      "Epoch  15 Batch  660/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9819, Loss: 0.0143\n",
      "Epoch  15 Batch  680/1077 - Train Accuracy: 0.9598, Validation Accuracy: 0.9670, Loss: 0.0110\n",
      "Epoch  15 Batch  700/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9602, Loss: 0.0156\n",
      "Epoch  15 Batch  720/1077 - Train Accuracy: 0.9712, Validation Accuracy: 0.9666, Loss: 0.0119\n",
      "Epoch  15 Batch  740/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9705, Loss: 0.0138\n",
      "Epoch  15 Batch  760/1077 - Train Accuracy: 0.9641, Validation Accuracy: 0.9766, Loss: 0.0151\n",
      "Epoch  15 Batch  780/1077 - Train Accuracy: 0.9617, Validation Accuracy: 0.9801, Loss: 0.0184\n",
      "Epoch  15 Batch  800/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9702, Loss: 0.0122\n",
      "Epoch  15 Batch  820/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9677, Loss: 0.0122\n",
      "Epoch  15 Batch  840/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9609, Loss: 0.0108\n",
      "Epoch  15 Batch  860/1077 - Train Accuracy: 0.9606, Validation Accuracy: 0.9737, Loss: 0.0128\n",
      "Epoch  15 Batch  880/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9645, Loss: 0.0162\n",
      "Epoch  15 Batch  900/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9648, Loss: 0.0142\n",
      "Epoch  15 Batch  920/1077 - Train Accuracy: 0.9656, Validation Accuracy: 0.9762, Loss: 0.0154\n",
      "Epoch  15 Batch  940/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9730, Loss: 0.0111\n",
      "Epoch  15 Batch  960/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9719, Loss: 0.0108\n",
      "Epoch  15 Batch  980/1077 - Train Accuracy: 0.9727, Validation Accuracy: 0.9659, Loss: 0.0155\n",
      "Epoch  15 Batch 1000/1077 - Train Accuracy: 0.9751, Validation Accuracy: 0.9634, Loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  15 Batch 1020/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9727, Loss: 0.0112\n",
      "Epoch  15 Batch 1040/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9652, Loss: 0.0102\n",
      "Epoch  15 Batch 1060/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9641, Loss: 0.0096\n",
      "Epoch  16 Batch   20/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9723, Loss: 0.0091\n",
      "Epoch  16 Batch   40/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9691, Loss: 0.0106\n",
      "Epoch  16 Batch   60/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9656, Loss: 0.0125\n",
      "Epoch  16 Batch   80/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9577, Loss: 0.0095\n",
      "Epoch  16 Batch  100/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9634, Loss: 0.0130\n",
      "Epoch  16 Batch  120/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9826, Loss: 0.0123\n",
      "Epoch  16 Batch  140/1077 - Train Accuracy: 0.9823, Validation Accuracy: 0.9794, Loss: 0.0118\n",
      "Epoch  16 Batch  160/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9737, Loss: 0.0099\n",
      "Epoch  16 Batch  180/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9677, Loss: 0.0132\n",
      "Epoch  16 Batch  200/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9723, Loss: 0.0107\n",
      "Epoch  16 Batch  220/1077 - Train Accuracy: 0.9770, Validation Accuracy: 0.9677, Loss: 0.0135\n",
      "Epoch  16 Batch  240/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9748, Loss: 0.0090\n",
      "Epoch  16 Batch  260/1077 - Train Accuracy: 0.9833, Validation Accuracy: 0.9599, Loss: 0.0154\n",
      "Epoch  16 Batch  280/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9624, Loss: 0.0099\n",
      "Epoch  16 Batch  300/1077 - Train Accuracy: 0.9749, Validation Accuracy: 0.9680, Loss: 0.0116\n",
      "Epoch  16 Batch  320/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9574, Loss: 0.0188\n",
      "Epoch  16 Batch  340/1077 - Train Accuracy: 0.9905, Validation Accuracy: 0.9609, Loss: 0.0151\n",
      "Epoch  16 Batch  360/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9812, Loss: 0.0193\n",
      "Epoch  16 Batch  380/1077 - Train Accuracy: 0.9613, Validation Accuracy: 0.9751, Loss: 0.0079\n",
      "Epoch  16 Batch  400/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9712, Loss: 0.0123\n",
      "Epoch  16 Batch  420/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9677, Loss: 0.0127\n",
      "Epoch  16 Batch  440/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9730, Loss: 0.0117\n",
      "Epoch  16 Batch  460/1077 - Train Accuracy: 0.9891, Validation Accuracy: 0.9673, Loss: 0.0118\n",
      "Epoch  16 Batch  480/1077 - Train Accuracy: 0.9774, Validation Accuracy: 0.9716, Loss: 0.0148\n",
      "Epoch  16 Batch  500/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9698, Loss: 0.0090\n",
      "Epoch  16 Batch  520/1077 - Train Accuracy: 0.9818, Validation Accuracy: 0.9819, Loss: 0.0153\n",
      "Epoch  16 Batch  540/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9776, Loss: 0.0129\n",
      "Epoch  16 Batch  560/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9730, Loss: 0.0098\n",
      "Epoch  16 Batch  580/1077 - Train Accuracy: 0.9743, Validation Accuracy: 0.9734, Loss: 0.0129\n",
      "Epoch  16 Batch  600/1077 - Train Accuracy: 0.9728, Validation Accuracy: 0.9808, Loss: 0.0151\n",
      "Epoch  16 Batch  620/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9698, Loss: 0.0123\n",
      "Epoch  16 Batch  640/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9744, Loss: 0.0109\n",
      "Epoch  16 Batch  660/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9709, Loss: 0.0086\n",
      "Epoch  16 Batch  680/1077 - Train Accuracy: 0.9818, Validation Accuracy: 0.9680, Loss: 0.0074\n",
      "Epoch  16 Batch  700/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9801, Loss: 0.0125\n",
      "Epoch  16 Batch  720/1077 - Train Accuracy: 0.9716, Validation Accuracy: 0.9801, Loss: 0.0101\n",
      "Epoch  16 Batch  740/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9744, Loss: 0.0120\n",
      "Epoch  16 Batch  760/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9684, Loss: 0.0111\n",
      "Epoch  16 Batch  780/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9673, Loss: 0.0202\n",
      "Epoch  16 Batch  800/1077 - Train Accuracy: 0.9699, Validation Accuracy: 0.9627, Loss: 0.0139\n",
      "Epoch  16 Batch  820/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9645, Loss: 0.0124\n",
      "Epoch  16 Batch  840/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9499, Loss: 0.0079\n",
      "Epoch  16 Batch  860/1077 - Train Accuracy: 0.9903, Validation Accuracy: 0.9741, Loss: 0.0121\n",
      "Epoch  16 Batch  880/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9734, Loss: 0.0155\n",
      "Epoch  16 Batch  900/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9815, Loss: 0.0138\n",
      "Epoch  16 Batch  920/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9755, Loss: 0.0103\n",
      "Epoch  16 Batch  940/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9766, Loss: 0.0093\n",
      "Epoch  16 Batch  960/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9695, Loss: 0.0101\n",
      "Epoch  16 Batch  980/1077 - Train Accuracy: 0.9543, Validation Accuracy: 0.9585, Loss: 0.0106\n",
      "Epoch  16 Batch 1000/1077 - Train Accuracy: 0.9821, Validation Accuracy: 0.9702, Loss: 0.0091\n",
      "Epoch  16 Batch 1020/1077 - Train Accuracy: 0.9695, Validation Accuracy: 0.9595, Loss: 0.0097\n",
      "Epoch  16 Batch 1040/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9680, Loss: 0.0129\n",
      "Epoch  16 Batch 1060/1077 - Train Accuracy: 0.9945, Validation Accuracy: 0.9759, Loss: 0.0111\n",
      "Epoch  17 Batch   20/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9730, Loss: 0.0091\n",
      "Epoch  17 Batch   40/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9748, Loss: 0.0110\n",
      "Epoch  17 Batch   60/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9688, Loss: 0.0098\n",
      "Epoch  17 Batch   80/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9641, Loss: 0.0119\n",
      "Epoch  17 Batch  100/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9709, Loss: 0.0129\n",
      "Epoch  17 Batch  120/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9723, Loss: 0.0213\n",
      "Epoch  17 Batch  140/1077 - Train Accuracy: 0.9704, Validation Accuracy: 0.9656, Loss: 0.0113\n",
      "Epoch  17 Batch  160/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9695, Loss: 0.0101\n",
      "Epoch  17 Batch  180/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9616, Loss: 0.0103\n",
      "Epoch  17 Batch  200/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9748, Loss: 0.0085\n",
      "Epoch  17 Batch  220/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9794, Loss: 0.0096\n",
      "Epoch  17 Batch  240/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9883, Loss: 0.0150\n",
      "Epoch  17 Batch  260/1077 - Train Accuracy: 0.9799, Validation Accuracy: 0.9698, Loss: 0.0146\n",
      "Epoch  17 Batch  280/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9606, Loss: 0.0110\n",
      "Epoch  17 Batch  300/1077 - Train Accuracy: 0.9790, Validation Accuracy: 0.9698, Loss: 0.0091\n",
      "Epoch  17 Batch  320/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9716, Loss: 0.0132\n",
      "Epoch  17 Batch  340/1077 - Train Accuracy: 0.9831, Validation Accuracy: 0.9698, Loss: 0.0138\n",
      "Epoch  17 Batch  360/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9695, Loss: 0.0084\n",
      "Epoch  17 Batch  380/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9712, Loss: 0.0104\n",
      "Epoch  17 Batch  400/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9712, Loss: 0.0136\n",
      "Epoch  17 Batch  420/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9719, Loss: 0.0104\n",
      "Epoch  17 Batch  440/1077 - Train Accuracy: 0.9680, Validation Accuracy: 0.9620, Loss: 0.0129\n",
      "Epoch  17 Batch  460/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9624, Loss: 0.0113\n",
      "Epoch  17 Batch  480/1077 - Train Accuracy: 0.9786, Validation Accuracy: 0.9812, Loss: 0.0111\n",
      "Epoch  17 Batch  500/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9677, Loss: 0.0089\n",
      "Epoch  17 Batch  520/1077 - Train Accuracy: 0.9721, Validation Accuracy: 0.9794, Loss: 0.0105\n",
      "Epoch  17 Batch  540/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9755, Loss: 0.0107\n",
      "Epoch  17 Batch  560/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9538, Loss: 0.0081\n",
      "Epoch  17 Batch  580/1077 - Train Accuracy: 0.9788, Validation Accuracy: 0.9712, Loss: 0.0123\n",
      "Epoch  17 Batch  600/1077 - Train Accuracy: 0.9766, Validation Accuracy: 0.9744, Loss: 0.0114\n",
      "Epoch  17 Batch  620/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9808, Loss: 0.0138\n",
      "Epoch  17 Batch  640/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9719, Loss: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  17 Batch  660/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9744, Loss: 0.0087\n",
      "Epoch  17 Batch  680/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9698, Loss: 0.0152\n",
      "Epoch  17 Batch  700/1077 - Train Accuracy: 0.9793, Validation Accuracy: 0.9744, Loss: 0.0087\n",
      "Epoch  17 Batch  720/1077 - Train Accuracy: 0.9778, Validation Accuracy: 0.9741, Loss: 0.0108\n",
      "Epoch  17 Batch  740/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9719, Loss: 0.0118\n",
      "Epoch  17 Batch  760/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9751, Loss: 0.0103\n",
      "Epoch  17 Batch  780/1077 - Train Accuracy: 0.9742, Validation Accuracy: 0.9606, Loss: 0.0161\n",
      "Epoch  17 Batch  800/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9702, Loss: 0.0109\n",
      "Epoch  17 Batch  820/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9762, Loss: 0.0092\n",
      "Epoch  17 Batch  840/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9773, Loss: 0.0151\n",
      "Epoch  17 Batch  860/1077 - Train Accuracy: 0.9829, Validation Accuracy: 0.9751, Loss: 0.0126\n",
      "Epoch  17 Batch  880/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9783, Loss: 0.0132\n",
      "Epoch  17 Batch  900/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9702, Loss: 0.0184\n",
      "Epoch  17 Batch  920/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9727, Loss: 0.0073\n",
      "Epoch  17 Batch  940/1077 - Train Accuracy: 0.9602, Validation Accuracy: 0.9787, Loss: 0.0136\n",
      "Epoch  17 Batch  960/1077 - Train Accuracy: 0.9814, Validation Accuracy: 0.9780, Loss: 0.0085\n",
      "Epoch  17 Batch  980/1077 - Train Accuracy: 0.9781, Validation Accuracy: 0.9624, Loss: 0.0112\n",
      "Epoch  17 Batch 1000/1077 - Train Accuracy: 0.9673, Validation Accuracy: 0.9744, Loss: 0.0118\n",
      "Epoch  17 Batch 1020/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9656, Loss: 0.0113\n",
      "Epoch  17 Batch 1040/1077 - Train Accuracy: 0.9803, Validation Accuracy: 0.9645, Loss: 0.0104\n",
      "Epoch  17 Batch 1060/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9837, Loss: 0.0073\n",
      "Epoch  18 Batch   20/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9862, Loss: 0.0095\n",
      "Epoch  18 Batch   40/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9822, Loss: 0.0079\n",
      "Epoch  18 Batch   60/1077 - Train Accuracy: 0.9769, Validation Accuracy: 0.9727, Loss: 0.0100\n",
      "Epoch  18 Batch   80/1077 - Train Accuracy: 0.9785, Validation Accuracy: 0.9705, Loss: 0.0095\n",
      "Epoch  18 Batch  100/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9677, Loss: 0.0078\n",
      "Epoch  18 Batch  120/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9602, Loss: 0.0136\n",
      "Epoch  18 Batch  140/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9577, Loss: 0.0148\n",
      "Epoch  18 Batch  160/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9741, Loss: 0.0106\n",
      "Epoch  18 Batch  180/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9812, Loss: 0.0096\n",
      "Epoch  18 Batch  200/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9794, Loss: 0.0124\n",
      "Epoch  18 Batch  220/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9798, Loss: 0.0088\n",
      "Epoch  18 Batch  240/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9730, Loss: 0.0161\n",
      "Epoch  18 Batch  260/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9709, Loss: 0.0087\n",
      "Epoch  18 Batch  280/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9620, Loss: 0.0115\n",
      "Epoch  18 Batch  300/1077 - Train Accuracy: 0.9790, Validation Accuracy: 0.9808, Loss: 0.0107\n",
      "Epoch  18 Batch  320/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9716, Loss: 0.0122\n",
      "Epoch  18 Batch  340/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9673, Loss: 0.0125\n",
      "Epoch  18 Batch  360/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9684, Loss: 0.0068\n",
      "Epoch  18 Batch  380/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9822, Loss: 0.0135\n",
      "Epoch  18 Batch  400/1077 - Train Accuracy: 0.9773, Validation Accuracy: 0.9808, Loss: 0.0136\n",
      "Epoch  18 Batch  420/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9755, Loss: 0.0047\n",
      "Epoch  18 Batch  440/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9705, Loss: 0.0100\n",
      "Epoch  18 Batch  460/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9780, Loss: 0.0086\n",
      "Epoch  18 Batch  480/1077 - Train Accuracy: 0.9889, Validation Accuracy: 0.9755, Loss: 0.0106\n",
      "Epoch  18 Batch  500/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9769, Loss: 0.0095\n",
      "Epoch  18 Batch  520/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9698, Loss: 0.0046\n",
      "Epoch  18 Batch  540/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9698, Loss: 0.0073\n",
      "Epoch  18 Batch  560/1077 - Train Accuracy: 0.9625, Validation Accuracy: 0.9798, Loss: 0.0082\n",
      "Epoch  18 Batch  580/1077 - Train Accuracy: 0.9736, Validation Accuracy: 0.9755, Loss: 0.0131\n",
      "Epoch  18 Batch  600/1077 - Train Accuracy: 0.9985, Validation Accuracy: 0.9769, Loss: 0.0094\n",
      "Epoch  18 Batch  620/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9844, Loss: 0.0120\n",
      "Epoch  18 Batch  640/1077 - Train Accuracy: 0.9833, Validation Accuracy: 0.9830, Loss: 0.0066\n",
      "Epoch  18 Batch  660/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9727, Loss: 0.0102\n",
      "Epoch  18 Batch  680/1077 - Train Accuracy: 0.9751, Validation Accuracy: 0.9737, Loss: 0.0098\n",
      "Epoch  18 Batch  700/1077 - Train Accuracy: 0.9676, Validation Accuracy: 0.9762, Loss: 0.0075\n",
      "Epoch  18 Batch  720/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9719, Loss: 0.0130\n",
      "Epoch  18 Batch  740/1077 - Train Accuracy: 0.9652, Validation Accuracy: 0.9766, Loss: 0.0107\n",
      "Epoch  18 Batch  760/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9766, Loss: 0.0077\n",
      "Epoch  18 Batch  780/1077 - Train Accuracy: 0.9645, Validation Accuracy: 0.9727, Loss: 0.0172\n",
      "Epoch  18 Batch  800/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9776, Loss: 0.0090\n",
      "Epoch  18 Batch  820/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9766, Loss: 0.0108\n",
      "Epoch  18 Batch  840/1077 - Train Accuracy: 0.9961, Validation Accuracy: 0.9652, Loss: 0.0073\n",
      "Epoch  18 Batch  860/1077 - Train Accuracy: 0.9959, Validation Accuracy: 0.9741, Loss: 0.0078\n",
      "Epoch  18 Batch  880/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9773, Loss: 0.0134\n",
      "Epoch  18 Batch  900/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9734, Loss: 0.0094\n",
      "Epoch  18 Batch  920/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9773, Loss: 0.0090\n",
      "Epoch  18 Batch  940/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9727, Loss: 0.0082\n",
      "Epoch  18 Batch  960/1077 - Train Accuracy: 0.9877, Validation Accuracy: 0.9641, Loss: 0.0082\n",
      "Epoch  18 Batch  980/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9719, Loss: 0.0089\n",
      "Epoch  18 Batch 1000/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9648, Loss: 0.0100\n",
      "Epoch  18 Batch 1020/1077 - Train Accuracy: 0.9691, Validation Accuracy: 0.9727, Loss: 0.0089\n",
      "Epoch  18 Batch 1040/1077 - Train Accuracy: 0.9807, Validation Accuracy: 0.9719, Loss: 0.0129\n",
      "Epoch  18 Batch 1060/1077 - Train Accuracy: 0.9973, Validation Accuracy: 0.9780, Loss: 0.0061\n",
      "Epoch  19 Batch   20/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9755, Loss: 0.0093\n",
      "Epoch  19 Batch   40/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9812, Loss: 0.0079\n",
      "Epoch  19 Batch   60/1077 - Train Accuracy: 0.9885, Validation Accuracy: 0.9780, Loss: 0.0105\n",
      "Epoch  19 Batch   80/1077 - Train Accuracy: 0.9805, Validation Accuracy: 0.9702, Loss: 0.0060\n",
      "Epoch  19 Batch  100/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9730, Loss: 0.0066\n",
      "Epoch  19 Batch  120/1077 - Train Accuracy: 0.9812, Validation Accuracy: 0.9794, Loss: 0.0071\n",
      "Epoch  19 Batch  140/1077 - Train Accuracy: 0.9819, Validation Accuracy: 0.9673, Loss: 0.0099\n",
      "Epoch  19 Batch  160/1077 - Train Accuracy: 0.9930, Validation Accuracy: 0.9773, Loss: 0.0086\n",
      "Epoch  19 Batch  180/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9631, Loss: 0.0074\n",
      "Epoch  19 Batch  200/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9695, Loss: 0.0110\n",
      "Epoch  19 Batch  220/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9741, Loss: 0.0075\n",
      "Epoch  19 Batch  240/1077 - Train Accuracy: 0.9797, Validation Accuracy: 0.9684, Loss: 0.0091\n",
      "Epoch  19 Batch  260/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9776, Loss: 0.0073\n",
      "Epoch  19 Batch  280/1077 - Train Accuracy: 0.9777, Validation Accuracy: 0.9854, Loss: 0.0108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  19 Batch  300/1077 - Train Accuracy: 0.9762, Validation Accuracy: 0.9815, Loss: 0.0107\n",
      "Epoch  19 Batch  320/1077 - Train Accuracy: 0.9609, Validation Accuracy: 0.9631, Loss: 0.0121\n",
      "Epoch  19 Batch  340/1077 - Train Accuracy: 0.9794, Validation Accuracy: 0.9805, Loss: 0.0095\n",
      "Epoch  19 Batch  360/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9712, Loss: 0.0063\n",
      "Epoch  19 Batch  380/1077 - Train Accuracy: 0.9801, Validation Accuracy: 0.9830, Loss: 0.0108\n",
      "Epoch  19 Batch  400/1077 - Train Accuracy: 0.9688, Validation Accuracy: 0.9773, Loss: 0.0132\n",
      "Epoch  19 Batch  420/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9585, Loss: 0.0049\n",
      "Epoch  19 Batch  440/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9716, Loss: 0.0097\n",
      "Epoch  19 Batch  460/1077 - Train Accuracy: 0.9957, Validation Accuracy: 0.9627, Loss: 0.0087\n",
      "Epoch  19 Batch  480/1077 - Train Accuracy: 0.9823, Validation Accuracy: 0.9748, Loss: 0.0093\n",
      "Epoch  19 Batch  500/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9673, Loss: 0.0100\n",
      "Epoch  19 Batch  520/1077 - Train Accuracy: 0.9896, Validation Accuracy: 0.9826, Loss: 0.0067\n",
      "Epoch  19 Batch  540/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9673, Loss: 0.0072\n",
      "Epoch  19 Batch  560/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9705, Loss: 0.0093\n",
      "Epoch  19 Batch  580/1077 - Train Accuracy: 0.9639, Validation Accuracy: 0.9794, Loss: 0.0186\n",
      "Epoch  19 Batch  600/1077 - Train Accuracy: 0.9684, Validation Accuracy: 0.9751, Loss: 0.0135\n",
      "Epoch  19 Batch  620/1077 - Train Accuracy: 0.9547, Validation Accuracy: 0.9766, Loss: 0.0131\n",
      "Epoch  19 Batch  640/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9744, Loss: 0.0124\n",
      "Epoch  19 Batch  660/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9691, Loss: 0.0066\n",
      "Epoch  19 Batch  680/1077 - Train Accuracy: 0.9851, Validation Accuracy: 0.9751, Loss: 0.0078\n",
      "Epoch  19 Batch  700/1077 - Train Accuracy: 0.9750, Validation Accuracy: 0.9712, Loss: 0.0069\n",
      "Epoch  19 Batch  720/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9847, Loss: 0.0144\n",
      "Epoch  19 Batch  740/1077 - Train Accuracy: 0.9863, Validation Accuracy: 0.9826, Loss: 0.0078\n",
      "Epoch  19 Batch  760/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9759, Loss: 0.0116\n",
      "Epoch  19 Batch  780/1077 - Train Accuracy: 0.9672, Validation Accuracy: 0.9751, Loss: 0.0111\n",
      "Epoch  19 Batch  800/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9730, Loss: 0.0068\n",
      "Epoch  19 Batch  820/1077 - Train Accuracy: 0.9898, Validation Accuracy: 0.9780, Loss: 0.0082\n",
      "Epoch  19 Batch  840/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9812, Loss: 0.0048\n",
      "Epoch  19 Batch  860/1077 - Train Accuracy: 0.9922, Validation Accuracy: 0.9712, Loss: 0.0101\n",
      "Epoch  19 Batch  880/1077 - Train Accuracy: 0.9734, Validation Accuracy: 0.9677, Loss: 0.0165\n",
      "Epoch  19 Batch  900/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9822, Loss: 0.0084\n",
      "Epoch  19 Batch  920/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9844, Loss: 0.0153\n",
      "Epoch  19 Batch  940/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9698, Loss: 0.0107\n",
      "Epoch  19 Batch  960/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9698, Loss: 0.0087\n",
      "Epoch  19 Batch  980/1077 - Train Accuracy: 0.9707, Validation Accuracy: 0.9787, Loss: 0.0107\n",
      "Epoch  19 Batch 1000/1077 - Train Accuracy: 0.9859, Validation Accuracy: 0.9776, Loss: 0.0108\n",
      "Epoch  19 Batch 1020/1077 - Train Accuracy: 0.9906, Validation Accuracy: 0.9776, Loss: 0.0100\n",
      "Epoch  19 Batch 1040/1077 - Train Accuracy: 0.9737, Validation Accuracy: 0.9826, Loss: 0.0106\n",
      "Epoch  19 Batch 1060/1077 - Train Accuracy: 0.9832, Validation Accuracy: 0.9776, Loss: 0.0048\n",
      "Epoch  20 Batch   20/1077 - Train Accuracy: 0.9809, Validation Accuracy: 0.9787, Loss: 0.0084\n",
      "Epoch  20 Batch   40/1077 - Train Accuracy: 0.9824, Validation Accuracy: 0.9748, Loss: 0.0065\n",
      "Epoch  20 Batch   60/1077 - Train Accuracy: 0.9665, Validation Accuracy: 0.9684, Loss: 0.0120\n",
      "Epoch  20 Batch   80/1077 - Train Accuracy: 0.9723, Validation Accuracy: 0.9652, Loss: 0.0103\n",
      "Epoch  20 Batch  100/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9688, Loss: 0.0089\n",
      "Epoch  20 Batch  120/1077 - Train Accuracy: 0.9910, Validation Accuracy: 0.9723, Loss: 0.0077\n",
      "Epoch  20 Batch  140/1077 - Train Accuracy: 0.9860, Validation Accuracy: 0.9723, Loss: 0.0087\n",
      "Epoch  20 Batch  160/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9759, Loss: 0.0074\n",
      "Epoch  20 Batch  180/1077 - Train Accuracy: 0.9719, Validation Accuracy: 0.9684, Loss: 0.0170\n",
      "Epoch  20 Batch  200/1077 - Train Accuracy: 0.9887, Validation Accuracy: 0.9822, Loss: 0.0072\n",
      "Epoch  20 Batch  220/1077 - Train Accuracy: 0.9848, Validation Accuracy: 0.9847, Loss: 0.0082\n",
      "Epoch  20 Batch  240/1077 - Train Accuracy: 0.9941, Validation Accuracy: 0.9723, Loss: 0.0079\n",
      "Epoch  20 Batch  260/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9737, Loss: 0.0081\n",
      "Epoch  20 Batch  280/1077 - Train Accuracy: 0.9871, Validation Accuracy: 0.9613, Loss: 0.0069\n",
      "Epoch  20 Batch  300/1077 - Train Accuracy: 0.9856, Validation Accuracy: 0.9627, Loss: 0.0065\n",
      "Epoch  20 Batch  320/1077 - Train Accuracy: 0.9902, Validation Accuracy: 0.9776, Loss: 0.0111\n",
      "Epoch  20 Batch  340/1077 - Train Accuracy: 0.9934, Validation Accuracy: 0.9862, Loss: 0.0097\n",
      "Epoch  20 Batch  360/1077 - Train Accuracy: 0.9938, Validation Accuracy: 0.9670, Loss: 0.0071\n",
      "Epoch  20 Batch  380/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9659, Loss: 0.0058\n",
      "Epoch  20 Batch  400/1077 - Train Accuracy: 0.9660, Validation Accuracy: 0.9663, Loss: 0.0125\n",
      "Epoch  20 Batch  420/1077 - Train Accuracy: 0.9789, Validation Accuracy: 0.9780, Loss: 0.0063\n",
      "Epoch  20 Batch  440/1077 - Train Accuracy: 0.9844, Validation Accuracy: 0.9677, Loss: 0.0108\n",
      "Epoch  20 Batch  460/1077 - Train Accuracy: 0.9926, Validation Accuracy: 0.9616, Loss: 0.0085\n",
      "Epoch  20 Batch  480/1077 - Train Accuracy: 0.9873, Validation Accuracy: 0.9719, Loss: 0.0091\n",
      "Epoch  20 Batch  500/1077 - Train Accuracy: 0.9992, Validation Accuracy: 0.9641, Loss: 0.0101\n",
      "Epoch  20 Batch  520/1077 - Train Accuracy: 0.9933, Validation Accuracy: 0.9769, Loss: 0.0056\n",
      "Epoch  20 Batch  540/1077 - Train Accuracy: 0.9820, Validation Accuracy: 0.9769, Loss: 0.0103\n",
      "Epoch  20 Batch  560/1077 - Train Accuracy: 0.9746, Validation Accuracy: 0.9748, Loss: 0.0098\n",
      "Epoch  20 Batch  580/1077 - Train Accuracy: 0.9792, Validation Accuracy: 0.9759, Loss: 0.0084\n",
      "Epoch  20 Batch  600/1077 - Train Accuracy: 0.9818, Validation Accuracy: 0.9822, Loss: 0.0111\n",
      "Epoch  20 Batch  620/1077 - Train Accuracy: 0.9715, Validation Accuracy: 0.9865, Loss: 0.0125\n",
      "Epoch  20 Batch  640/1077 - Train Accuracy: 0.9874, Validation Accuracy: 0.9808, Loss: 0.0099\n",
      "Epoch  20 Batch  660/1077 - Train Accuracy: 0.9852, Validation Accuracy: 0.9688, Loss: 0.0057\n",
      "Epoch  20 Batch  680/1077 - Train Accuracy: 0.9918, Validation Accuracy: 0.9659, Loss: 0.0080\n",
      "Epoch  20 Batch  700/1077 - Train Accuracy: 0.9855, Validation Accuracy: 0.9563, Loss: 0.0069\n",
      "Epoch  20 Batch  720/1077 - Train Accuracy: 0.9778, Validation Accuracy: 0.9744, Loss: 0.0115\n",
      "Epoch  20 Batch  740/1077 - Train Accuracy: 0.9828, Validation Accuracy: 0.9759, Loss: 0.0074\n",
      "Epoch  20 Batch  760/1077 - Train Accuracy: 0.9867, Validation Accuracy: 0.9773, Loss: 0.0091\n",
      "Epoch  20 Batch  780/1077 - Train Accuracy: 0.9711, Validation Accuracy: 0.9790, Loss: 0.0123\n",
      "Epoch  20 Batch  800/1077 - Train Accuracy: 0.9840, Validation Accuracy: 0.9794, Loss: 0.0064\n",
      "Epoch  20 Batch  820/1077 - Train Accuracy: 0.9879, Validation Accuracy: 0.9705, Loss: 0.0139\n",
      "Epoch  20 Batch  840/1077 - Train Accuracy: 0.9875, Validation Accuracy: 0.9748, Loss: 0.0059\n",
      "Epoch  20 Batch  860/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9734, Loss: 0.0081\n",
      "Epoch  20 Batch  880/1077 - Train Accuracy: 0.9953, Validation Accuracy: 0.9585, Loss: 0.0115\n",
      "Epoch  20 Batch  900/1077 - Train Accuracy: 0.9836, Validation Accuracy: 0.9748, Loss: 0.0068\n",
      "Epoch  20 Batch  920/1077 - Train Accuracy: 0.9758, Validation Accuracy: 0.9652, Loss: 0.0084\n",
      "Epoch  20 Batch  940/1077 - Train Accuracy: 0.9754, Validation Accuracy: 0.9613, Loss: 0.0087\n",
      "Epoch  20 Batch  960/1077 - Train Accuracy: 0.9825, Validation Accuracy: 0.9751, Loss: 0.0074\n",
      "Epoch  20 Batch  980/1077 - Train Accuracy: 0.9816, Validation Accuracy: 0.9840, Loss: 0.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20 Batch 1000/1077 - Train Accuracy: 0.9862, Validation Accuracy: 0.9783, Loss: 0.0071\n",
      "Epoch  20 Batch 1020/1077 - Train Accuracy: 0.9883, Validation Accuracy: 0.9695, Loss: 0.0082\n",
      "Epoch  20 Batch 1040/1077 - Train Accuracy: 0.9856, Validation Accuracy: 0.9830, Loss: 0.0143\n",
      "Epoch  20 Batch 1060/1077 - Train Accuracy: 0.9730, Validation Accuracy: 0.9556, Loss: 0.0079\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "modelTrainer = ModelTrainer()\n",
    "\n",
    "modelTrainer.train_seq2seq_model(rnn, train_graph) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickleHelper.save_params(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(_, _, \n",
    "(source_vocab_to_int, target_vocab_to_int), \n",
    "(source_int_to_vocab, target_int_to_vocab)) = pickleHelper.load_preprocessed_data()\n",
    "\n",
    "load_path = pickleHelper.load_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TranslationChecker:\n",
    "    \n",
    "    def check_translation(self, \n",
    "                          checkpoint, \n",
    "                          sentence, \n",
    "                          source_vocab_to_int,\n",
    "                          source_int_to_vocab,\n",
    "                          target_int_to_vocab):\n",
    "        \"\"\"\n",
    "        Check translation of a sample sentence.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert input sentence into int seq\n",
    "        inputSentencePreparer = InputSentencePreparer()\n",
    "        input_seq = inputSentencePreparer.sentence_to_seq(sentence, source_vocab_to_int)\n",
    "        \n",
    "        # Get translation logits\n",
    "        translation_logits = self.get_translation_logits(checkpoint, input_seq)\n",
    "        \n",
    "        # Print translation\n",
    "        self.print_translation(input_seq, \n",
    "                               translation_logits, \n",
    "                               source_int_to_vocab, \n",
    "                               target_int_to_vocab)\n",
    "        \n",
    "        \n",
    "    def get_translation_logits(self, checkpoint, input_seq):\n",
    "        \"\"\"\n",
    "        Load saved model and get output logits.\n",
    "        \n",
    "        :param checkpoint: Checkpoint\n",
    "        :param input_seq: Input sequence\n",
    "        \"\"\"\n",
    "        loaded_graph = tf.Graph()\n",
    "        \n",
    "        with tf.Session(graph=loaded_graph) as sess:\n",
    "            # Load saved model\n",
    "            loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "            loader.restore(sess, checkpoint)\n",
    "            \n",
    "            # Load tensors\n",
    "            inputs = loaded_graph.get_tensor_by_name('input:0')\n",
    "            logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "            source_seq_len = loaded_graph.get_tensor_by_name('source_seq_len:0')\n",
    "            target_seq_len = loaded_graph.get_tensor_by_name('target_seq_len:0')\n",
    "            keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "            \n",
    "            # Get translation logits\n",
    "            feed = {inputs: [input_seq]*batch_size,\n",
    "                    source_seq_len: [len(input_seq)]*batch_size,\n",
    "                    target_seq_len: [len(input_seq)*2]*batch_size,\n",
    "                    keep_prob: 1.0}\n",
    "            \n",
    "            translation_logits = sess.run(logits,\n",
    "                                          feed_dict=feed)[0]\n",
    "            \n",
    "            return translation_logits\n",
    "\n",
    "    \n",
    "    def print_translation(self, \n",
    "                          input_seq, \n",
    "                          logits, \n",
    "                          source_int_to_vocab, \n",
    "                          target_int_to_vocab):\n",
    "        \n",
    "        print('Input')\n",
    "        print('  Word Ids:      {}'.format([i for i in input_seq]))\n",
    "        print('  English Words: {}'.format([source_int_to_vocab[i] for i in input_seq]))\n",
    "\n",
    "        print('\\nPrediction')\n",
    "        print('  Word Ids:      {}'.format([i for i in logits]))\n",
    "        print('  French Words: {}'.format(\" \".join([target_int_to_vocab[i] for i in logits])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InputSentencePreparer:\n",
    "    \n",
    "    def sentence_to_seq(self, sentence, vocab_to_int):\n",
    "        \"\"\"\n",
    "        Convert a sentence to a sequence of ids.\n",
    "        \n",
    "        :param sentence: String\n",
    "        :param vocab_to_int: Dictionary to go from the words to an id\n",
    "        :return: List of word ids\n",
    "        \"\"\"\n",
    "        words = sentence.lower().split(' ')\n",
    "        return [vocab_to_int.get(word, vocab_to_int['<UNK>']) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = 'he saw a old yellow truck .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/dev\n",
      "Input\n",
      "  Word Ids:      [101, 213, 150, 167, 29, 93, 215]\n",
      "  English Words: ['he', 'saw', 'a', 'old', 'yellow', 'truck', '.']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [283, 315, 292, 153, 89, 34, 97, 1, 0, 0, 0, 0, 0, 0]\n",
      "  French Words: il est conduit à l' automne . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "translationChecker = TranslationChecker()\n",
    "\n",
    "translationChecker.check_translation(load_path, \n",
    "                                     sentence, \n",
    "                                     source_vocab_to_int, \n",
    "                                     source_int_to_vocab,\n",
    "                                     target_int_to_vocab)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
