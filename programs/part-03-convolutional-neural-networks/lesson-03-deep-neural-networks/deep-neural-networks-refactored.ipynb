{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TwoLayerNeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNeuralNetwork:\n",
    "    \n",
    "    def build(self, features, hidden_weights, out_weights, n_hidden_classes, n_out_classes):\n",
    "        self.features = tf.Variable(features)\n",
    "        \n",
    "        self.weights = [tf.Variable(hidden_weights),\n",
    "                        tf.Variable(out_weights)]\n",
    "        self.biases = [tf.Variable(tf.zeros(n_hidden_classes)),\n",
    "                       tf.Variable(tf.zeros(n_out_classes))]\n",
    "        \n",
    "        self.hidden_layer = tf.add(tf.matmul(self.features, self.weights[0]), self.biases[0])\n",
    "        self.hidden_layer = tf.nn.relu(self.hidden_layer)\n",
    "        \n",
    "        self.logits = tf.add(tf.matmul(self.hidden_layer, self.weights[1]), self.biases[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TwoLayerNetworkRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNetworkRunner:\n",
    "    \n",
    "    def run(self, network):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            output = sess.run(network.logits)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.11000013   8.44000053]\n",
      " [  0.           0.        ]\n",
      " [ 24.01000023  38.24000168]]\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    [1.0, 2.0, 3.0, 4.0], \n",
    "    [-1.0, -2.0, -3.0, -4.0], \n",
    "    [11.0, 12.0, 13.0, 14.0]]\n",
    "\n",
    "hidden_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "n_hidden_classes = 3\n",
    "n_out_classes = 2\n",
    "\n",
    "network = TwoLayerNeuralNetwork()\n",
    "network.build(features, hidden_weights, out_weights, n_hidden_classes, n_out_classes)\n",
    "\n",
    "networkRunner = TwoLayerNetworkRunner()\n",
    "output = networkRunner.run(network)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel:\n",
    "\n",
    "    def build(self,\n",
    "              n_input_h=28, # MNISt data input image height\n",
    "              n_input_w=28, # MNIST data input image width\n",
    "              n_input=784,  # MNIST data input (28*28)\n",
    "              n_classes=10, # output classes (0-9 digits)\n",
    "              n_hidden=256, # number of hidden-layer features\n",
    "              learning_rate=0.001):\n",
    "        \n",
    "        # Store layer weights and biases\n",
    "        self.weights = {\n",
    "            'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])),\n",
    "            'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "        }\n",
    "        self.biases = {\n",
    "            'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "            'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "        }\n",
    "        \n",
    "        # Create placeholders\n",
    "        self.x = tf.placeholder(\"float\", [None, n_input_h, n_input_w, 1])\n",
    "        self.y = tf.placeholder(\"float\", [None, n_classes])\n",
    "        self.x_flat = tf.reshape(self.x, [-1, n_input])\n",
    "        \n",
    "        # Hidden layer with RELU activation\n",
    "        self.hidden_layer = tf.add(tf.matmul(self.x_flat, self.weights['hidden']), self.biases['hidden'])\n",
    "        self.hidden_layer = tf.nn.relu(self.hidden_layer)\n",
    "        \n",
    "        # Output layer with linear activation\n",
    "        self.logits = tf.add(tf.matmul(self.hidden_layer, self.weights['out']), self.biases['out'])\n",
    "        \n",
    "        # Define loss and optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.y))\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
    "        \n",
    "        print(\"Model Built!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModelTrainer:\n",
    "    \n",
    "    def train_model(self, \n",
    "                    model, \n",
    "                    mnist, \n",
    "                    epochs=20, \n",
    "                    batch_size=128, \n",
    "                    display_step=1,\n",
    "                    test_size=256):\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                total_batch = int(mnist.train.num_examples//batch_size)\n",
    "                \n",
    "                for i in range(total_batch):\n",
    "                    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                    \n",
    "                    sess.run(model.optimizer, feed_dict={model.x: batch_x, model.y: batch_y})\n",
    "                    \n",
    "                if epoch % display_step == 0:\n",
    "                    cost = sess.run(model.cost, feed_dict={model.x: batch_x, model.y: batch_y})\n",
    "                    print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(cost))\n",
    "                    \n",
    "            print(\"Model Trained!\")\n",
    "            \n",
    "            correct_prediction = tf.equal(tf.argmax(model.logits, 1), tf.argmax(model.y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "            print(\"Accuracy:\", accuracy.eval({model.x: mnist.test.images[:test_size], \n",
    "                                              model.y: mnist.test.labels[:test_size]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n",
      "MNIST data extracted\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "print(\"MNIST data extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Built!\n"
     ]
    }
   ],
   "source": [
    "n_input_h = 28        # MNISt data input image height\n",
    "n_input_w = 28        # MNIST data input image width\n",
    "n_input = 784         # MNIST data input (28*28)\n",
    "n_classes = 10        # output classes (0-9 digits)\n",
    "n_hidden = 256        # number of hidden-layer features\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = MNISTModel()\n",
    "model.build(n_input_h, n_input_w, n_input, n_classes, n_hidden, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 46.776885986\n",
      "Epoch: 0002 cost= 32.840759277\n",
      "Epoch: 0003 cost= 24.942396164\n",
      "Epoch: 0004 cost= 16.812906265\n",
      "Epoch: 0005 cost= 18.122219086\n",
      "Epoch: 0006 cost= 13.160085678\n",
      "Epoch: 0007 cost= 12.865661621\n",
      "Epoch: 0008 cost= 12.599981308\n",
      "Epoch: 0009 cost= 8.308866501\n",
      "Epoch: 0010 cost= 13.246831894\n",
      "Epoch: 0011 cost= 9.821405411\n",
      "Epoch: 0012 cost= 8.793862343\n",
      "Epoch: 0013 cost= 8.955377579\n",
      "Epoch: 0014 cost= 8.206196785\n",
      "Epoch: 0015 cost= 9.860222816\n",
      "Epoch: 0016 cost= 10.348557472\n",
      "Epoch: 0017 cost= 5.440186501\n",
      "Epoch: 0018 cost= 6.582940102\n",
      "Epoch: 0019 cost= 10.446672440\n",
      "Epoch: 0020 cost= 7.052401543\n",
      "Model Trained!\n",
      "Accuracy: 0.828125\n"
     ]
    }
   ],
   "source": [
    "epochs = 20 \n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "test_size = 256\n",
    "\n",
    "trainer = MNISTModelTrainer()\n",
    "trainer.train_model(model, mnist, epochs, batch_size, display_step, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VariableSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableSaver:\n",
    "    \n",
    "    def save_variables(self):\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            print('Weights:\\n{}'.format(sess.run(weights)))\n",
    "            print('Bias:\\n{}\\n'.format(sess.run(bias)))\n",
    "            \n",
    "            saver.save(sess, save_file)\n",
    "            \n",
    "            print('Variables saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "[[ 0.08909809  0.41268998  0.11217824]\n",
      " [ 0.1776848   0.10354891  0.05375071]]\n",
      "Bias:\n",
      "[ 1.30110919  0.51036555 -0.25158417]\n",
      "\n",
      "Variables saved\n"
     ]
    }
   ],
   "source": [
    "variableSaver = VariableSaver()\n",
    "\n",
    "save_file='./model.ckpt'\n",
    "\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "variableSaver.save_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VariableRestorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableRestorer:\n",
    "    \n",
    "    def load_variables(self):\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, save_file)\n",
    "            \n",
    "            print('Weights:\\n{}'.format(sess.run(weights)))\n",
    "            print('Bias:\\n{}\\n'.format(sess.run(bias)))\n",
    "            \n",
    "            print('Variables loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt\n",
      "Weights:\n",
      "[[ 0.08909809  0.41268998  0.11217824]\n",
      " [ 0.1776848   0.10354891  0.05375071]]\n",
      "Bias:\n",
      "[ 1.30110919  0.51036555 -0.25158417]\n",
      "\n",
      "Variables loaded\n"
     ]
    }
   ],
   "source": [
    "variableRestorer = VariableRestorer()\n",
    "variableRestorer.load_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NamedVariableSaveDemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamedVariableSaveDemo:\n",
    "    \n",
    "    def run(self):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        weights = tf.Variable(tf.truncated_normal([2, 3]), name='weights_0')\n",
    "        bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "        \n",
    "        print('Save Weights as: {}'.format(weights.name))\n",
    "        print('Save Bias as: {}'.format(bias.name))\n",
    "        print('')\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        save_file = 'model.ckpt'\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            print('Save Weight:\\n{}'.format(sess.run(weights)))\n",
    "            print('Save Bias:\\n{}'.format(sess.run(bias)))\n",
    "            print('')\n",
    "            \n",
    "            saver.save(sess, save_file)\n",
    "            \n",
    "        # Remove the previous weights and bias\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "        weights = tf.Variable(tf.truncated_normal([2, 3]), name='weights_0')\n",
    "        \n",
    "        print('Load Weights as: {}'.format(weights.name))\n",
    "        print('Load Bias as: {}'.format(bias.name))\n",
    "        print('')\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, save_file)\n",
    "            \n",
    "            print('Load Weight:\\n{}'.format(sess.run(weights)))\n",
    "            print('Load Bias:\\n{}'.format(sess.run(bias)))\n",
    "            print('')\n",
    "            \n",
    "        print('Loaded weights and bias successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Weights as: weights_0:0\n",
      "Save Bias as: bias_0:0\n",
      "\n",
      "Save Weight:\n",
      "[[-1.39367366 -0.30744788  1.78195381]\n",
      " [-0.37186858  1.16486955  0.95979202]]\n",
      "Save Bias:\n",
      "[-1.78415215  0.51852614  0.5955745 ]\n",
      "\n",
      "Load Weights as: weights_0:0\n",
      "Load Bias as: bias_0:0\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from model.ckpt\n",
      "Load Weight:\n",
      "[[-1.39367366 -0.30744788  1.78195381]\n",
      " [-0.37186858  1.16486955  0.95979202]]\n",
      "Load Bias:\n",
      "[-1.78415215  0.51852614  0.5955745 ]\n",
      "\n",
      "Loaded weights and bias successfully\n"
     ]
    }
   ],
   "source": [
    "NamedVariableSaveDemo().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel2:\n",
    "    \n",
    "    def build(self, learning_rate=0.001, n_input=784, n_classes=10):\n",
    "        self.features = tf.placeholder(tf.float32, [None, n_input])\n",
    "        self.labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "        \n",
    "        self.weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "        self.bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "        \n",
    "        self.logits = tf.add(tf.matmul(self.features, self.weights), self.bias)\n",
    "        \n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, \n",
    "                                                                labels=self.labels)\n",
    "        self.cost = tf.reduce_mean(cross_entropy)\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "                .minimize(self.cost)\n",
    "            \n",
    "        self.correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.labels, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "        \n",
    "        print('Model Built!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTModelTrainer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModelTrainer2:\n",
    "    \n",
    "    def train_model(self, model, mnist, epochs=100, batch_size=128, save_file='./train_model.ckpt'):\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                n_batches = math.ceil(mnist.train.num_examples//batch_size)\n",
    "                \n",
    "                for i in range(n_batches):\n",
    "                    batch_features, batch_labels = mnist.train.next_batch(batch_size)\n",
    "                    sess.run(model.optimizer,\n",
    "                             feed_dict={model.features: batch_features,\n",
    "                                        model.labels: batch_labels})\n",
    "                    \n",
    "                if epoch % 10 == 0:\n",
    "                    valid_accuracy = sess.run(model.accuracy,\n",
    "                                              feed_dict={model.features: mnist.validation.images,\n",
    "                                                         model.labels: mnist.validation.labels})\n",
    "                    \n",
    "                    print('Epoch {:<3} - Validation Accuracy: {}'.format(epoch, valid_accuracy))\n",
    "             \n",
    "            saver.save(sess, save_file)\n",
    "                          \n",
    "            print('Trained Model Saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTModelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModelLoader:\n",
    "    \n",
    "    def load_model(self, save_file='./train_model.ckpt'):\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, save_file)\n",
    "            \n",
    "            test_accuracy = sess.run(model.accuracy,\n",
    "                                     feed_dict={model.features: mnist.test.images,\n",
    "                                                model.labels: mnist.test.labels})\n",
    "        print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous Tensors and Operations\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Built!\n"
     ]
    }
   ],
   "source": [
    "model = MNISTModel2()\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n",
      "Epoch 0   - Validation Accuracy: 0.11039999127388\n",
      "Epoch 10  - Validation Accuracy: 0.2573999762535095\n",
      "Epoch 20  - Validation Accuracy: 0.42079997062683105\n",
      "Epoch 30  - Validation Accuracy: 0.518799901008606\n",
      "Epoch 40  - Validation Accuracy: 0.5843998789787292\n",
      "Epoch 50  - Validation Accuracy: 0.6237999200820923\n",
      "Epoch 60  - Validation Accuracy: 0.6589999198913574\n",
      "Epoch 70  - Validation Accuracy: 0.6783998608589172\n",
      "Epoch 80  - Validation Accuracy: 0.6987998485565186\n",
      "Epoch 90  - Validation Accuracy: 0.7149998545646667\n",
      "Trained Model Saved!\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('.', one_hot=True)\n",
    "\n",
    "modelTrainer = MNISTModelTrainer2()\n",
    "modelTrainer.train_model(model, mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./train_model.ckpt\n",
      "Test Accuracy: 0.7200000286102295\n"
     ]
    }
   ],
   "source": [
    "modelLoader = MNISTModelLoader()\n",
    "modelLoader.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelWithDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithDropout:\n",
    "    \n",
    "    def build(self, \n",
    "              features, \n",
    "              hidden_weights, \n",
    "              out_weights, \n",
    "              n_hidden_classes, \n",
    "              n_out_classes):\n",
    "        \n",
    "        self.features = tf.Variable(features)\n",
    "        \n",
    "        self.weights = [tf.Variable(hidden_weights), \n",
    "                        tf.Variable(out_weights)]\n",
    "        self.biases = [tf.Variable(tf.zeros(n_hidden_classes)), \n",
    "                       tf.Variable(tf.zeros(n_out_classes))]\n",
    "        \n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        self.hidden_layer = tf.add(tf.matmul(self.features, self.weights[0]), self.biases[0])\n",
    "        self.hidden_layer = tf.nn.relu(self.hidden_layer)\n",
    "        self.hidden_layer = tf.nn.dropout(self.hidden_layer, self.keep_prob)\n",
    "        \n",
    "        self.logits = tf.add(tf.matmul(self.hidden_layer, self.weights[1]), self.biases[1])\n",
    "        \n",
    "        print('Model with Dropout Built!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelWithDropoutRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithDropoutRunner:\n",
    "    \n",
    "    def run_model(self, model, keep_prob=0.5):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            output = sess.run(model.logits, feed_dict={model.keep_prob: keep_prob})\n",
    "            print('Model Output:\\n{}'.format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with Dropout Built!\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    [0.0, 2.0, 3.0, 4.0], \n",
    "    [0.1, 0.2, 0.3, 0.4], \n",
    "    [11.0, 12.0, 13.0, 14.0]]\n",
    "\n",
    "hidden_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "n_hidden_classes = 3\n",
    "n_out_classes = 2\n",
    "\n",
    "model = ModelWithDropout()\n",
    "model.build(features, hidden_weights, out_weights, n_hidden_classes, n_out_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output:\n",
      "[[  1.10000002   6.60000038]\n",
      " [  0.19600001   0.098     ]\n",
      " [ 43.29999924  48.15999985]]\n"
     ]
    }
   ],
   "source": [
    "modelRunner = ModelWithDropoutRunner()\n",
    "modelRunner.run_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
