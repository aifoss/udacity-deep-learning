<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>character-wise-rnn-refactored</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Character-wise-Recurrent-Neural-Network">Character-wise Recurrent Neural Network<a class="anchor-link" href="#Character-wise-Recurrent-Neural-Network">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Getting-and-Preprocessing-Data">Getting and Preprocessing Data<a class="anchor-link" href="#Getting-and-Preprocessing-Data">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Data">Data<a class="anchor-link" href="#Data">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Data</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">text</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">chars</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">chars_to_ints</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">ints_to_chars</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="DataPreprocessor">DataPreprocessor<a class="anchor-link" href="#DataPreprocessor">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">DataPreprocessor</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">load_and_preprocess_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_file</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load and preprocess data.</span>
<span class="sd">        </span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        : input_file: Input file name</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Loading and preprocesing data ...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">data</span> <span class="o">=</span> <span class="n">Data</span><span class="p">()</span>
        
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">data</span><span class="o">.</span><span class="n">text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
                
        <span class="n">data</span><span class="o">.</span><span class="n">chars</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">text</span><span class="p">))</span>
        <span class="n">data</span><span class="o">.</span><span class="n">chars_to_ints</span> <span class="o">=</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">chars</span><span class="p">)}</span>
        <span class="n">data</span><span class="o">.</span><span class="n">ints_to_chars</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">chars</span><span class="p">))</span>
        <span class="n">data</span><span class="o">.</span><span class="n">encoded</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">data</span><span class="o">.</span><span class="n">chars_to_ints</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">text</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loaded and preprocessed data</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">data</span>
    
    
    <span class="k">def</span> <span class="nf">log_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">txt</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">):</span>
            <span class="n">ch</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">text</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span>
            <span class="n">ch</span> <span class="o">=</span> <span class="s1">&#39;(NEWLINE)&#39;</span> <span class="k">if</span> <span class="n">ch</span> <span class="o">==</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="k">else</span> <span class="n">ch</span>
            <span class="n">txt</span> <span class="o">+=</span> <span class="n">ch</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;text[:100]:</span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">txt</span><span class="p">))</span>    
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;len(chars):</span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">chars</span><span class="p">)))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;chars[:50]:</span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">chars</span><span class="p">[:</span><span class="mi">50</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;chars_to_ints:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
            <span class="n">ch</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">chars</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span>
            <span class="n">ch</span> <span class="o">=</span> <span class="s1">&#39;NEWLINE&#39;</span> <span class="k">if</span> <span class="n">ch</span> <span class="o">==</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="k">else</span> <span class="s1">&#39;SPACE&#39;</span> <span class="k">if</span> <span class="n">ch</span> <span class="o">==</span> <span class="s1">&#39; &#39;</span> <span class="k">else</span> <span class="n">ch</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;chars_to_ints[</span><span class="si">{}</span><span class="s2">]: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ch</span><span class="p">,</span> <span class="n">ii</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ints_to_chars:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
            <span class="n">ch</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">ints_to_chars</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span>
            <span class="n">ch</span> <span class="o">=</span> <span class="s1">&#39;NEWLINE&#39;</span> <span class="k">if</span> <span class="n">ch</span> <span class="o">==</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="k">else</span> <span class="s1">&#39;SPACE&#39;</span> <span class="k">if</span> <span class="n">ch</span> <span class="o">==</span> <span class="s1">&#39; &#39;</span> <span class="k">else</span> <span class="n">ch</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ints_to_chars[</span><span class="si">{}</span><span class="s2">]: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ii</span><span class="p">,</span> <span class="n">ch</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;encoded.shape:</span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">encoded</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;encoded[:100]:</span><span class="se">\n</span><span class="si">{}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">encoded</span><span class="p">[:</span><span class="mi">100</span><span class="p">]))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_file</span> <span class="o">=</span> <span class="s1">&#39;anna.txt&#39;</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dataPreprocessor</span> <span class="o">=</span> <span class="n">DataPreprocessor</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">dataPreprocessor</span><span class="o">.</span><span class="n">load_and_preprocess_data</span><span class="p">(</span><span class="n">input_file</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Loading and preprocesing data ...

text[:100]:
Chapter 1(NEWLINE)(NEWLINE)(NEWLINE)Happy families are all alike; every unhappy family is unhappy in its own(NEWLINE)way.(NEWLINE)(NEWLINE)Everythin

len(chars):
83

chars[:50]:
[&#39;\n&#39;, &#39; &#39;, &#39;!&#39;, &#39;&#34;&#39;, &#39;$&#39;, &#39;%&#39;, &#39;&amp;&#39;, &#34;&#39;&#34;, &#39;(&#39;, &#39;)&#39;, &#39;*&#39;, &#39;,&#39;, &#39;-&#39;, &#39;.&#39;, &#39;/&#39;, &#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;, &#39;:&#39;, &#39;;&#39;, &#39;?&#39;, &#39;@&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;, &#39;J&#39;, &#39;K&#39;, &#39;L&#39;, &#39;M&#39;, &#39;N&#39;, &#39;O&#39;, &#39;P&#39;, &#39;Q&#39;, &#39;R&#39;, &#39;S&#39;, &#39;T&#39;, &#39;U&#39;]

chars_to_ints:

chars_to_ints[NEWLINE]: 0
chars_to_ints[SPACE]: 1
chars_to_ints[!]: 2
chars_to_ints[&#34;]: 3
chars_to_ints[$]: 4
chars_to_ints[%]: 5
chars_to_ints[&amp;]: 6
chars_to_ints[&#39;]: 7
chars_to_ints[(]: 8
chars_to_ints[)]: 9

ints_to_chars:

ints_to_chars[0]: NEWLINE
ints_to_chars[1]: SPACE
ints_to_chars[2]: !
ints_to_chars[3]: &#34;
ints_to_chars[4]: $
ints_to_chars[5]: %
ints_to_chars[6]: &amp;
ints_to_chars[7]: &#39;
ints_to_chars[8]: (
ints_to_chars[9]: )

encoded.shape:
(1985223,)

encoded[:100]:
[31 64 57 72 76 61 74  1 16  0  0  0 36 57 72 72 81  1 62 57 69 65 68 65 61
 75  1 57 74 61  1 57 68 68  1 57 68 65 67 61 26  1 61 78 61 74 81  1 77 70
 64 57 72 72 81  1 62 57 69 65 68 81  1 65 75  1 77 70 64 57 72 72 81  1 65
 70  1 65 76 75  1 71 79 70  0 79 57 81 13  0  0 33 78 61 74 81 76 64 65 70]

Loaded and preprocessed data

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Building-Character-wise-RNN-Model">Building Character-wise RNN Model<a class="anchor-link" href="#Building-Character-wise-RNN-Model">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="RNNetwork">RNNetwork<a class="anchor-link" href="#RNNetwork">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">RNNetwork</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">create_placeholders</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">        Define placeholders for inputs, targets, and dropout </span>
<span class="sd">    </span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        : batch_size: Batch size, number of sequences per batch</span>
<span class="sd">        : num_steps: Number of sequence steps in a batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;inputs&#39;</span><span class="p">)</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;targets&#39;</span><span class="p">)</span>
        <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;keep_prob&#39;</span><span class="p">)</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Created placeholders</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">keep_prob</span>
    
    
    <span class="k">def</span> <span class="nf">build_lstm_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build LSTM layers.</span>
<span class="sd">    </span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        : keep_prob: Scalar tensor (tf.placeholder) for the dropout keep probability</span>
<span class="sd">        : lstm_size: Size of the hidden layers in the LSTM cells</span>
<span class="sd">        : num_layers: Number of LSTM layers</span>
<span class="sd">        : batch_size: Batch size</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">build_lstm_cell</span><span class="p">(</span><span class="n">lstm_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
        <span class="n">initial_state</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Built LSTM layers</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">cell</span><span class="p">,</span> <span class="n">initial_state</span>
    
        
    <span class="k">def</span> <span class="nf">build_lstm_cell</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build LSTM cell.</span>
<span class="sd">    </span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        : lstm_size: Size of the hidden layers in the LSTM cells</span>
<span class="sd">        : keep_prob: Scalar tensor (tf.placeholder) for the dropout keep probability</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">lstm_size</span><span class="p">)</span>
        <span class="n">drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Built LSTM cell&quot;</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">drop</span>
    
    
    <span class="k">def</span> <span class="nf">build_output_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lstm_output</span><span class="p">,</span> <span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build a softmax layer, return the softmax output and logits.</span>
<span class="sd">    </span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        : lstm_output: List of output tensors from the LSTM layer</span>
<span class="sd">        : in_size: Size of the input tensor, for example, size of the LSTM cells</span>
<span class="sd">        : out_size: Size of this softmax layer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># Reshape output so it&#39;s a bunch of rows, one row for each step for each sequence.</span>
        <span class="c1"># That is, the shape should be batch_size*num_steps rows by lstm_size columns</span>
        
        <span class="c1"># Concatenate lstm_output over axis 1 (the columns)</span>
        <span class="n">seq_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">lstm_output</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Reshape seq_output to a 2D tensor with lstm_size columns</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">seq_output</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">in_size</span><span class="p">])</span>
        
        <span class="c1"># Connect the RNN outputs to a softmax layer</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">):</span>
            <span class="n">softmax_w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">((</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">),</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
            <span class="n">softmax_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">out_size</span><span class="p">))</span>
            
        <span class="c1"># Since output is a bunch of rows of RNN cell outputs, logits will be a bunch</span>
        <span class="c1"># of rows of logit outputs, one for each step and sequence    </span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">softmax_w</span><span class="p">),</span> <span class="n">softmax_b</span><span class="p">)</span>
        
        <span class="c1"># Use softmax to get the probabilities for predicted characters</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Built output layer</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">logits</span>
    

    <span class="k">def</span> <span class="nf">add_training_loss_computation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lstm_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the loss from the logits and the targets.</span>
<span class="sd">    </span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        : logits: Logits from final fully connected layer</span>
<span class="sd">        : targets: Targets for supervised learning</span>
<span class="sd">        : lstm_size: Number of LSTM hidden units</span>
<span class="sd">        : num_classes: Number of classes in targets</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># One-hot encode targets and reshape to match logits, one row per sequence per step</span>
        <span class="n">y_one_hot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="n">y_reshaped</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_one_hot</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span>
        
        <span class="c1"># Softmax cross entropy loss</span>
        <span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y_reshaped</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">cross_entropy</span><span class="p">)</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Added training loss computation</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">loss</span>
    
    
    <span class="k">def</span> <span class="nf">build_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">grad_clip</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build optmizer for training, using gradient clipping.</span>
<span class="sd">    </span>
<span class="sd">        Arguments:</span>
<span class="sd">        ---------</span>
<span class="sd">        : loss: Network loss</span>
<span class="sd">        : learning_rate: Learning rate for optimizer</span>
<span class="sd">        : grad_clip: For gradient clipping </span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># Optimizer for training, using gradient clipping to control exploding gradients</span>
        <span class="n">tvars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()</span>
        <span class="n">grads</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">clip_by_global_norm</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">tvars</span><span class="p">),</span> <span class="n">grad_clip</span><span class="p">)</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">train_op</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">tvars</span><span class="p">))</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Built optimizer</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">optimizer</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="CharRNNModel">CharRNNModel<a class="anchor-link" href="#CharRNNModel">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">CharRNNModel</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">num_classes</span><span class="p">,</span> 
                 <span class="n">batch_size</span><span class="p">,</span> 
                 <span class="n">num_steps</span><span class="p">,</span>
                 <span class="n">lstm_size</span><span class="p">,</span> 
                 <span class="n">num_layers</span><span class="p">,</span> 
                 <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">grad_clip</span><span class="p">,</span> 
                 <span class="n">sampling</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build CharRNN model.</span>
<span class="sd">        </span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        : num_classes: Number of classes in targets</span>
<span class="sd">        : batch_size: Batch size, number of sequences per batch</span>
<span class="sd">        : num_steps: Number of sequence steps in a batch</span>
<span class="sd">        : lstm_size: Number of LSTM hidden units</span>
<span class="sd">        : num_layers: Number of LSTM layers</span>
<span class="sd">        : learning_rate: Learning rate</span>
<span class="sd">        : grad_clip: For gradient clipping</span>
<span class="sd">        : sampling: Whether or not the model is used for sampling</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Building CharRNN model ...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="c1"># When we&#39;re using this network for sampling later, we&#39;ll be passing in</span>
        <span class="c1"># one character at a time, so providing an option for that</span>
        <span class="k">if</span> <span class="n">sampling</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm_size</span> <span class="o">=</span> <span class="n">lstm_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_steps</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span>
        
        <span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
        
        <span class="c1"># Create RNNetwork object</span>
        <span class="n">network</span> <span class="o">=</span> <span class="n">RNNetwork</span><span class="p">()</span>
        
        <span class="c1"># Build the placeholder tensors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">keep_prob</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">create_placeholders</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> 
                                                                                <span class="bp">self</span><span class="o">.</span><span class="n">num_steps</span><span class="p">)</span>
        
        <span class="c1"># Build the LSTM layers</span>
        <span class="n">cell</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_state</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">build_lstm_layers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keep_prob</span><span class="p">,</span> 
                                                             <span class="bp">self</span><span class="o">.</span><span class="n">lstm_size</span><span class="p">,</span> 
                                                             <span class="n">num_layers</span><span class="p">,</span>
                                                             <span class="n">batch_size</span><span class="p">)</span>
        
        <span class="c1">### Run the data through the RNN layers</span>
        <span class="c1"># First, one-hot encode the input tokens</span>
        <span class="n">x_one_hot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        
        <span class="c1"># Run each sequence step through the RNN with tf.nn.dynamic_rnn</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">x_one_hot</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_state</span> <span class="o">=</span> <span class="n">state</span>
        
        <span class="c1"># Get softmax predictions and logits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prediction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">logits</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">build_output_layer</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> 
                                                                  <span class="bp">self</span><span class="o">.</span><span class="n">lstm_size</span><span class="p">,</span>
                                                                  <span class="n">num_classes</span><span class="p">)</span>
        
        <span class="c1"># Loss and optimizer (with gradient clipping)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">add_training_loss_computation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> 
                                                          <span class="bp">self</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> 
                                                          <span class="bp">self</span><span class="o">.</span><span class="n">lstm_size</span><span class="p">,</span> 
                                                          <span class="n">num_classes</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">build_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">grad_clip</span><span class="p">)</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Built CharRNN model</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">chars</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">num_steps</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">lstm_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">grad_clip</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">CharRNNModel</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span>
                     <span class="n">batch_size</span><span class="p">,</span>
                     <span class="n">num_steps</span><span class="p">,</span>
                     <span class="n">lstm_size</span><span class="p">,</span>
                     <span class="n">num_layers</span><span class="p">,</span>
                     <span class="n">learning_rate</span><span class="p">,</span>
                     <span class="n">grad_clip</span><span class="p">,</span>
                     <span class="kc">False</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Building CharRNN model ...

Created placeholders

Built LSTM cell
Built LSTM cell
Built LSTM layers

Built output layer

Added training loss computation

Built optimizer

Built CharRNN model

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Training-Character-wise-RNN-Model">Training Character-wise RNN Model<a class="anchor-link" href="#Training-Character-wise-RNN-Model">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="DataBatchGenerator">DataBatchGenerator<a class="anchor-link" href="#DataBatchGenerator">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">DataBatchGenerator</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arr</span><span class="p">,</span> <span class="n">n_seqs</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a generator that returns batches of size n_seqs x n_steps from arr.</span>
<span class="sd">        </span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        : arr: Array you want to make batches from</span>
<span class="sd">        : n_seqs: Number of sequences per batch</span>
<span class="sd">        : n_steps: Number of sequence steps per batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># Get the number of characters per batch and number of batches we can make</span>
        <span class="n">chars_per_batch</span> <span class="o">=</span> <span class="n">n_seqs</span> <span class="o">*</span> <span class="n">n_steps</span> <span class="c1"># batch size</span>
        <span class="n">n_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span><span class="o">//</span><span class="n">chars_per_batch</span>
        
        <span class="c1"># Keep only enough characters to make full batches</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">arr</span><span class="p">[:</span><span class="n">n_batches</span> <span class="o">*</span> <span class="n">chars_per_batch</span><span class="p">]</span>
        
        <span class="c1"># Reshape into n_seqs rows</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_seqs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        
        <span class="c1"># Generate each batch</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_steps</span><span class="p">):</span>
            <span class="c1"># features</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">arr</span><span class="p">[:,</span> <span class="n">n</span><span class="p">:</span><span class="n">n</span><span class="o">+</span><span class="n">n_steps</span><span class="p">]</span>
            <span class="c1"># targets</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            
            <span class="c1"># Targets are inputs shifted by one character</span>
            <span class="c1"># First input character is last target character</span>
            <span class="n">y</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
            
            <span class="k">yield</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="RNNModelTrainer">RNNModelTrainer<a class="anchor-link" href="#RNNModelTrainer">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">RNNModelTrainer</span><span class="p">:</span>
        
    <span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                    <span class="n">model</span><span class="p">,</span> 
                    <span class="n">data</span><span class="p">,</span> 
                    <span class="n">epochs</span><span class="p">,</span> 
                    <span class="n">keep_prob</span><span class="p">,</span> 
                    <span class="n">save_every_n</span><span class="p">,</span>
                    <span class="n">max_to_keep</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train RNN model.</span>
<span class="sd">        </span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        : model: Model to train</span>
<span class="sd">        : data: Data to train model on</span>
<span class="sd">        : epochs: Number of epochs to train</span>
<span class="sd">        : keep_prob: Keep proability to pass to model</span>
<span class="sd">        : save_every_n: Interval to save session</span>
<span class="sd">        : max_to_keep: Param to pass to session saver</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Training CharRNN model ...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
            
            <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span><span class="n">max_to_keep</span><span class="o">=</span><span class="n">max_to_keep</span><span class="p">)</span>
            
            <span class="c1"># Load a checkpoint and resume training</span>
            <span class="c1">#saver.restore(sess, &#39;checkpoints/_____.ckpt&#39;)</span>
            
            <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
            
            <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
                <span class="n">new_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">initial_state</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
                
                <span class="n">dataBatchGenerator</span> <span class="o">=</span> <span class="n">DataBatchGenerator</span><span class="p">()</span>
                <span class="n">batches</span> <span class="o">=</span> <span class="n">dataBatchGenerator</span><span class="o">.</span><span class="n">get_batches</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">encoded</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">num_steps</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>
                    <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                    
                    <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span><span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                            <span class="n">model</span><span class="o">.</span><span class="n">targets</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span>
                            <span class="n">model</span><span class="o">.</span><span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_prob</span><span class="p">,</span>
                            <span class="n">model</span><span class="o">.</span><span class="n">initial_state</span><span class="p">:</span> <span class="n">new_state</span><span class="p">}</span>
                    
                    <span class="n">batch_loss</span><span class="p">,</span> <span class="n">new_state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span>
                                                         <span class="n">model</span><span class="o">.</span><span class="n">final_state</span><span class="p">,</span>
                                                         <span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="p">],</span>
                                                         <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>
                    
                    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                    
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch: </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">... &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">),</span>
                          <span class="s1">&#39;Training Step: </span><span class="si">{}</span><span class="s1">... &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">counter</span><span class="p">),</span>
                          <span class="s1">&#39;Training loss: </span><span class="si">{:.4f}</span><span class="s1">... &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">batch_loss</span><span class="p">),</span>
                          <span class="s1">&#39;</span><span class="si">{:.4f}</span><span class="s1"> sec/batch&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="p">)))</span>
                    
                    <span class="k">if</span> <span class="p">(</span><span class="n">counter</span> <span class="o">%</span> <span class="n">save_every_n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                        <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s2">&quot;checkpoints/i</span><span class="si">{}</span><span class="s2">_l</span><span class="si">{}</span><span class="s2">.ckpt&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> 
                                                                           <span class="n">model</span><span class="o">.</span><span class="n">lstm_size</span><span class="p">))</span>
        
            <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s2">&quot;checkpoints/i</span><span class="si">{}</span><span class="s2">_l</span><span class="si">{}</span><span class="s2">.ckpt&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">lstm_size</span><span class="p">))</span>
            
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Training complete</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">keep_prob</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">save_every_n</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">max_to_keep</span> <span class="o">=</span> <span class="mi">100</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mkdir</span> <span class="s2">&quot;./checkpoints&quot;</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">modelTrainer</span> <span class="o">=</span> <span class="n">RNNModelTrainer</span><span class="p">()</span>

<span class="n">modelTrainer</span><span class="o">.</span><span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
                         <span class="n">data</span><span class="p">,</span>
                         <span class="n">epochs</span><span class="p">,</span>
                         <span class="n">keep_prob</span><span class="p">,</span>
                         <span class="n">save_every_n</span><span class="p">,</span>
                         <span class="n">max_to_keep</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Training CharRNN model ...

Epoch: 1/20...  Training Step: 1...  Training loss: 4.4212...  0.2310 sec/batch
Epoch: 1/20...  Training Step: 2...  Training loss: 4.4082...  0.0523 sec/batch
Epoch: 1/20...  Training Step: 3...  Training loss: 4.3935...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 4...  Training loss: 4.3727...  0.0578 sec/batch
Epoch: 1/20...  Training Step: 5...  Training loss: 4.3413...  0.0524 sec/batch
Epoch: 1/20...  Training Step: 6...  Training loss: 4.2838...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 7...  Training loss: 4.1652...  0.0524 sec/batch
Epoch: 1/20...  Training Step: 8...  Training loss: 3.9284...  0.0524 sec/batch
Epoch: 1/20...  Training Step: 9...  Training loss: 3.7249...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 10...  Training loss: 3.6379...  0.0577 sec/batch
Epoch: 1/20...  Training Step: 11...  Training loss: 3.6006...  0.0524 sec/batch
Epoch: 1/20...  Training Step: 12...  Training loss: 3.5656...  0.0591 sec/batch
Epoch: 1/20...  Training Step: 13...  Training loss: 3.5008...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 14...  Training loss: 3.4517...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 15...  Training loss: 3.4196...  0.0540 sec/batch
Epoch: 1/20...  Training Step: 16...  Training loss: 3.4211...  0.0558 sec/batch
Epoch: 1/20...  Training Step: 17...  Training loss: 3.4172...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 18...  Training loss: 3.3668...  0.0548 sec/batch
Epoch: 1/20...  Training Step: 19...  Training loss: 3.3630...  0.0519 sec/batch
Epoch: 1/20...  Training Step: 20...  Training loss: 3.3592...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 21...  Training loss: 3.3359...  0.0546 sec/batch
Epoch: 1/20...  Training Step: 22...  Training loss: 3.3581...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 23...  Training loss: 3.3326...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 24...  Training loss: 3.3422...  0.0546 sec/batch
Epoch: 1/20...  Training Step: 25...  Training loss: 3.3115...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 26...  Training loss: 3.3127...  0.0557 sec/batch
Epoch: 1/20...  Training Step: 27...  Training loss: 3.2887...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 28...  Training loss: 3.3029...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 29...  Training loss: 3.2601...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 30...  Training loss: 3.2755...  0.0524 sec/batch
Epoch: 1/20...  Training Step: 31...  Training loss: 3.2566...  0.0542 sec/batch
Epoch: 1/20...  Training Step: 32...  Training loss: 3.2780...  0.0524 sec/batch
Epoch: 1/20...  Training Step: 33...  Training loss: 3.2626...  0.0602 sec/batch
Epoch: 1/20...  Training Step: 34...  Training loss: 3.2425...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 35...  Training loss: 3.2362...  0.0547 sec/batch
Epoch: 1/20...  Training Step: 36...  Training loss: 3.2645...  0.0550 sec/batch
Epoch: 1/20...  Training Step: 37...  Training loss: 3.2170...  0.0517 sec/batch
Epoch: 1/20...  Training Step: 38...  Training loss: 3.2533...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 39...  Training loss: 3.2664...  0.0523 sec/batch
Epoch: 1/20...  Training Step: 40...  Training loss: 3.2520...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 41...  Training loss: 3.2223...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 42...  Training loss: 3.2189...  0.0573 sec/batch
Epoch: 1/20...  Training Step: 43...  Training loss: 3.2049...  0.0573 sec/batch
Epoch: 1/20...  Training Step: 44...  Training loss: 3.2125...  0.0580 sec/batch
Epoch: 1/20...  Training Step: 45...  Training loss: 3.2334...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 46...  Training loss: 3.2094...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 47...  Training loss: 3.1995...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 48...  Training loss: 3.2389...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 49...  Training loss: 3.1987...  0.0584 sec/batch
Epoch: 1/20...  Training Step: 50...  Training loss: 3.1728...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 51...  Training loss: 3.1737...  0.0550 sec/batch
Epoch: 1/20...  Training Step: 52...  Training loss: 3.1982...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 53...  Training loss: 3.2090...  0.0568 sec/batch
Epoch: 1/20...  Training Step: 54...  Training loss: 3.2337...  0.0544 sec/batch
Epoch: 1/20...  Training Step: 55...  Training loss: 3.2375...  0.0523 sec/batch
Epoch: 1/20...  Training Step: 56...  Training loss: 3.1892...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 57...  Training loss: 3.2095...  0.0572 sec/batch
Epoch: 1/20...  Training Step: 58...  Training loss: 3.1557...  0.0581 sec/batch
Epoch: 1/20...  Training Step: 59...  Training loss: 3.1675...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 60...  Training loss: 3.1864...  0.0566 sec/batch
Epoch: 1/20...  Training Step: 61...  Training loss: 3.1705...  0.0569 sec/batch
Epoch: 1/20...  Training Step: 62...  Training loss: 3.1851...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 63...  Training loss: 3.1987...  0.0550 sec/batch
Epoch: 1/20...  Training Step: 64...  Training loss: 3.1757...  0.0518 sec/batch
Epoch: 1/20...  Training Step: 65...  Training loss: 3.1492...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 66...  Training loss: 3.1449...  0.0543 sec/batch
Epoch: 1/20...  Training Step: 67...  Training loss: 3.1485...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 68...  Training loss: 3.1602...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 69...  Training loss: 3.1867...  0.0547 sec/batch
Epoch: 1/20...  Training Step: 70...  Training loss: 3.1299...  0.0561 sec/batch
Epoch: 1/20...  Training Step: 71...  Training loss: 3.1518...  0.0586 sec/batch
Epoch: 1/20...  Training Step: 72...  Training loss: 3.1787...  0.0577 sec/batch
Epoch: 1/20...  Training Step: 73...  Training loss: 3.1900...  0.0596 sec/batch
Epoch: 1/20...  Training Step: 74...  Training loss: 3.1476...  0.0574 sec/batch
Epoch: 1/20...  Training Step: 75...  Training loss: 3.1716...  0.0558 sec/batch
Epoch: 1/20...  Training Step: 76...  Training loss: 3.1717...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 77...  Training loss: 3.2210...  0.0566 sec/batch
Epoch: 1/20...  Training Step: 78...  Training loss: 3.1582...  0.0523 sec/batch
Epoch: 1/20...  Training Step: 79...  Training loss: 3.2160...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 80...  Training loss: 3.1461...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 81...  Training loss: 3.1908...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 82...  Training loss: 3.1362...  0.0583 sec/batch
Epoch: 1/20...  Training Step: 83...  Training loss: 3.1545...  0.0546 sec/batch
Epoch: 1/20...  Training Step: 84...  Training loss: 3.1842...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 85...  Training loss: 3.1563...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 86...  Training loss: 3.1427...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 87...  Training loss: 3.1839...  0.0572 sec/batch
Epoch: 1/20...  Training Step: 88...  Training loss: 3.2215...  0.0568 sec/batch
Epoch: 1/20...  Training Step: 89...  Training loss: 3.1723...  0.0522 sec/batch
Epoch: 1/20...  Training Step: 90...  Training loss: 3.1912...  0.0572 sec/batch
Epoch: 1/20...  Training Step: 91...  Training loss: 3.1654...  0.0567 sec/batch
Epoch: 1/20...  Training Step: 92...  Training loss: 3.1577...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 93...  Training loss: 3.1812...  0.0537 sec/batch
Epoch: 1/20...  Training Step: 94...  Training loss: 3.1529...  0.0522 sec/batch
Epoch: 1/20...  Training Step: 95...  Training loss: 3.1843...  0.0582 sec/batch
Epoch: 1/20...  Training Step: 96...  Training loss: 3.1517...  0.0582 sec/batch
Epoch: 1/20...  Training Step: 97...  Training loss: 3.1908...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 98...  Training loss: 3.1603...  0.0582 sec/batch
Epoch: 1/20...  Training Step: 99...  Training loss: 3.1657...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 100...  Training loss: 3.1475...  0.0521 sec/batch
Epoch: 1/20...  Training Step: 101...  Training loss: 3.1457...  0.0583 sec/batch
Epoch: 1/20...  Training Step: 102...  Training loss: 3.1534...  0.0580 sec/batch
Epoch: 1/20...  Training Step: 103...  Training loss: 3.1360...  0.0548 sec/batch
Epoch: 1/20...  Training Step: 104...  Training loss: 3.1376...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 105...  Training loss: 3.1503...  0.0544 sec/batch
Epoch: 1/20...  Training Step: 106...  Training loss: 3.1465...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 107...  Training loss: 3.1825...  0.0581 sec/batch
Epoch: 1/20...  Training Step: 108...  Training loss: 3.1358...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 109...  Training loss: 3.1054...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 110...  Training loss: 3.1176...  0.0547 sec/batch
Epoch: 1/20...  Training Step: 111...  Training loss: 3.1491...  0.0582 sec/batch
Epoch: 1/20...  Training Step: 112...  Training loss: 3.1678...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 113...  Training loss: 3.1867...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 114...  Training loss: 3.1324...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 115...  Training loss: 3.1420...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 116...  Training loss: 3.1285...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 117...  Training loss: 3.1518...  0.0535 sec/batch
Epoch: 1/20...  Training Step: 118...  Training loss: 3.1748...  0.0521 sec/batch
Epoch: 1/20...  Training Step: 119...  Training loss: 3.1240...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 120...  Training loss: 3.1271...  0.0585 sec/batch
Epoch: 1/20...  Training Step: 121...  Training loss: 3.1397...  0.0603 sec/batch
Epoch: 1/20...  Training Step: 122...  Training loss: 3.1061...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 123...  Training loss: 3.1286...  0.0576 sec/batch
Epoch: 1/20...  Training Step: 124...  Training loss: 3.1411...  0.0580 sec/batch
Epoch: 1/20...  Training Step: 125...  Training loss: 3.1616...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 126...  Training loss: 3.1057...  0.0545 sec/batch
Epoch: 1/20...  Training Step: 127...  Training loss: 3.1571...  0.0548 sec/batch
Epoch: 1/20...  Training Step: 128...  Training loss: 3.1361...  0.0521 sec/batch
Epoch: 1/20...  Training Step: 129...  Training loss: 3.1172...  0.0578 sec/batch
Epoch: 1/20...  Training Step: 130...  Training loss: 3.1227...  0.0573 sec/batch
Epoch: 1/20...  Training Step: 131...  Training loss: 3.0938...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 132...  Training loss: 3.1504...  0.0557 sec/batch
Epoch: 1/20...  Training Step: 133...  Training loss: 3.1596...  0.0562 sec/batch
Epoch: 1/20...  Training Step: 134...  Training loss: 3.1246...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 135...  Training loss: 3.1197...  0.0539 sec/batch
Epoch: 1/20...  Training Step: 136...  Training loss: 3.1010...  0.0547 sec/batch
Epoch: 1/20...  Training Step: 137...  Training loss: 3.1494...  0.0547 sec/batch
Epoch: 1/20...  Training Step: 138...  Training loss: 3.1360...  0.0546 sec/batch
Epoch: 1/20...  Training Step: 139...  Training loss: 3.1441...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 140...  Training loss: 3.1170...  0.0547 sec/batch
Epoch: 1/20...  Training Step: 141...  Training loss: 3.1295...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 142...  Training loss: 3.1236...  0.0610 sec/batch
Epoch: 1/20...  Training Step: 143...  Training loss: 3.1323...  0.0521 sec/batch
Epoch: 1/20...  Training Step: 144...  Training loss: 3.1334...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 145...  Training loss: 3.1169...  0.0594 sec/batch
Epoch: 1/20...  Training Step: 146...  Training loss: 3.1400...  0.0546 sec/batch
Epoch: 1/20...  Training Step: 147...  Training loss: 3.0823...  0.0546 sec/batch
Epoch: 1/20...  Training Step: 148...  Training loss: 3.1614...  0.0545 sec/batch
Epoch: 1/20...  Training Step: 149...  Training loss: 3.1164...  0.0541 sec/batch
Epoch: 1/20...  Training Step: 150...  Training loss: 3.1166...  0.0523 sec/batch
Epoch: 1/20...  Training Step: 151...  Training loss: 3.1495...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 152...  Training loss: 3.1324...  0.0523 sec/batch
Epoch: 1/20...  Training Step: 153...  Training loss: 3.1050...  0.0577 sec/batch
Epoch: 1/20...  Training Step: 154...  Training loss: 3.1611...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 155...  Training loss: 3.1304...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 156...  Training loss: 3.1199...  0.0548 sec/batch
Epoch: 1/20...  Training Step: 157...  Training loss: 3.0671...  0.0625 sec/batch
Epoch: 1/20...  Training Step: 158...  Training loss: 3.1164...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 159...  Training loss: 3.1328...  0.0545 sec/batch
Epoch: 1/20...  Training Step: 160...  Training loss: 3.1163...  0.0569 sec/batch
Epoch: 1/20...  Training Step: 161...  Training loss: 3.1103...  0.0571 sec/batch
Epoch: 1/20...  Training Step: 162...  Training loss: 3.1061...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 163...  Training loss: 3.0941...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 164...  Training loss: 3.1123...  0.0557 sec/batch
Epoch: 1/20...  Training Step: 165...  Training loss: 3.1195...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 166...  Training loss: 3.0721...  0.0523 sec/batch
Epoch: 1/20...  Training Step: 167...  Training loss: 3.0928...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 168...  Training loss: 3.0719...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 169...  Training loss: 3.0969...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 170...  Training loss: 3.0950...  0.0524 sec/batch
Epoch: 1/20...  Training Step: 171...  Training loss: 3.0719...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 172...  Training loss: 3.0625...  0.0567 sec/batch
Epoch: 1/20...  Training Step: 173...  Training loss: 3.0868...  0.0559 sec/batch
Epoch: 1/20...  Training Step: 174...  Training loss: 3.0957...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 175...  Training loss: 3.0525...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 176...  Training loss: 3.1128...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 177...  Training loss: 3.0895...  0.0564 sec/batch
Epoch: 1/20...  Training Step: 178...  Training loss: 3.0828...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 179...  Training loss: 3.1055...  0.0534 sec/batch
Epoch: 1/20...  Training Step: 180...  Training loss: 3.0548...  0.0559 sec/batch
Epoch: 1/20...  Training Step: 181...  Training loss: 3.0825...  0.0523 sec/batch
Epoch: 1/20...  Training Step: 182...  Training loss: 3.0965...  0.0548 sec/batch
Epoch: 1/20...  Training Step: 183...  Training loss: 3.0955...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 184...  Training loss: 3.0157...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 185...  Training loss: 3.0731...  0.0586 sec/batch
Epoch: 1/20...  Training Step: 186...  Training loss: 3.0851...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 187...  Training loss: 2.9994...  0.0559 sec/batch
Epoch: 1/20...  Training Step: 188...  Training loss: 3.0382...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 189...  Training loss: 3.0539...  0.0560 sec/batch
Epoch: 1/20...  Training Step: 190...  Training loss: 3.0674...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 191...  Training loss: 3.0813...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 192...  Training loss: 3.0647...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 193...  Training loss: 3.0586...  0.0533 sec/batch
Epoch: 1/20...  Training Step: 194...  Training loss: 3.0482...  0.0584 sec/batch
Epoch: 1/20...  Training Step: 195...  Training loss: 3.0278...  0.0613 sec/batch
Epoch: 1/20...  Training Step: 196...  Training loss: 3.0631...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 197...  Training loss: 3.0411...  0.0540 sec/batch
Epoch: 1/20...  Training Step: 198...  Training loss: 2.9948...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 199...  Training loss: 3.0283...  0.0584 sec/batch
Epoch: 1/20...  Training Step: 200...  Training loss: 3.0089...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 201...  Training loss: 2.9868...  0.0563 sec/batch
Epoch: 1/20...  Training Step: 202...  Training loss: 2.9883...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 203...  Training loss: 3.0046...  0.0533 sec/batch
Epoch: 1/20...  Training Step: 204...  Training loss: 3.0023...  0.0584 sec/batch
Epoch: 1/20...  Training Step: 205...  Training loss: 3.0024...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 206...  Training loss: 3.0014...  0.0533 sec/batch
Epoch: 1/20...  Training Step: 207...  Training loss: 2.9861...  0.0524 sec/batch
Epoch: 1/20...  Training Step: 208...  Training loss: 3.0394...  0.0604 sec/batch
Epoch: 1/20...  Training Step: 209...  Training loss: 3.0042...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 210...  Training loss: 2.9627...  0.0522 sec/batch
Epoch: 1/20...  Training Step: 211...  Training loss: 2.9870...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 212...  Training loss: 3.0226...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 213...  Training loss: 2.9869...  0.0561 sec/batch
Epoch: 1/20...  Training Step: 214...  Training loss: 3.0003...  0.0557 sec/batch
Epoch: 1/20...  Training Step: 215...  Training loss: 2.9986...  0.0561 sec/batch
Epoch: 1/20...  Training Step: 216...  Training loss: 2.9795...  0.0594 sec/batch
Epoch: 1/20...  Training Step: 217...  Training loss: 2.9478...  0.0542 sec/batch
Epoch: 1/20...  Training Step: 218...  Training loss: 2.9706...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 219...  Training loss: 2.9926...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 220...  Training loss: 2.9850...  0.0542 sec/batch
Epoch: 1/20...  Training Step: 221...  Training loss: 2.9564...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 222...  Training loss: 2.9373...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 223...  Training loss: 2.9736...  0.0572 sec/batch
Epoch: 1/20...  Training Step: 224...  Training loss: 2.9391...  0.0548 sec/batch
Epoch: 1/20...  Training Step: 225...  Training loss: 2.9500...  0.0558 sec/batch
Epoch: 1/20...  Training Step: 226...  Training loss: 2.9890...  0.0585 sec/batch
Epoch: 1/20...  Training Step: 227...  Training loss: 2.9516...  0.0587 sec/batch
Epoch: 1/20...  Training Step: 228...  Training loss: 2.9218...  0.0522 sec/batch
Epoch: 1/20...  Training Step: 229...  Training loss: 2.9446...  0.0596 sec/batch
Epoch: 1/20...  Training Step: 230...  Training loss: 2.9382...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 231...  Training loss: 2.9256...  0.0584 sec/batch
Epoch: 1/20...  Training Step: 232...  Training loss: 2.9754...  0.0588 sec/batch
Epoch: 1/20...  Training Step: 233...  Training loss: 2.9170...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 234...  Training loss: 2.9450...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 235...  Training loss: 2.9080...  0.0543 sec/batch
Epoch: 1/20...  Training Step: 236...  Training loss: 2.9045...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 237...  Training loss: 2.9054...  0.0575 sec/batch
Epoch: 1/20...  Training Step: 238...  Training loss: 2.8519...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 239...  Training loss: 2.8926...  0.0558 sec/batch
Epoch: 1/20...  Training Step: 240...  Training loss: 2.9354...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 241...  Training loss: 2.9194...  0.0556 sec/batch
Epoch: 1/20...  Training Step: 242...  Training loss: 2.9009...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 243...  Training loss: 2.8706...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 244...  Training loss: 2.9032...  0.0626 sec/batch
Epoch: 1/20...  Training Step: 245...  Training loss: 2.8704...  0.0533 sec/batch
Epoch: 1/20...  Training Step: 246...  Training loss: 2.9088...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 247...  Training loss: 2.8594...  0.0525 sec/batch
Epoch: 1/20...  Training Step: 248...  Training loss: 2.8620...  0.0563 sec/batch
Epoch: 1/20...  Training Step: 249...  Training loss: 2.8604...  0.0557 sec/batch
Epoch: 1/20...  Training Step: 250...  Training loss: 2.8735...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 251...  Training loss: 2.8410...  0.0522 sec/batch
Epoch: 1/20...  Training Step: 252...  Training loss: 2.8468...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 253...  Training loss: 2.8555...  0.0568 sec/batch
Epoch: 1/20...  Training Step: 254...  Training loss: 2.8698...  0.0571 sec/batch
Epoch: 1/20...  Training Step: 255...  Training loss: 2.8364...  0.0524 sec/batch
Epoch: 1/20...  Training Step: 256...  Training loss: 2.8745...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 257...  Training loss: 2.8750...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 258...  Training loss: 2.8736...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 259...  Training loss: 2.8366...  0.0562 sec/batch
Epoch: 1/20...  Training Step: 260...  Training loss: 2.8086...  0.0583 sec/batch
Epoch: 1/20...  Training Step: 261...  Training loss: 2.8288...  0.0578 sec/batch
Epoch: 1/20...  Training Step: 262...  Training loss: 2.8448...  0.0600 sec/batch
Epoch: 1/20...  Training Step: 263...  Training loss: 2.8432...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 264...  Training loss: 2.9045...  0.0546 sec/batch
Epoch: 1/20...  Training Step: 265...  Training loss: 2.8633...  0.0560 sec/batch
Epoch: 1/20...  Training Step: 266...  Training loss: 2.7896...  0.0588 sec/batch
Epoch: 1/20...  Training Step: 267...  Training loss: 2.8214...  0.0525 sec/batch
Epoch: 1/20...  Training Step: 268...  Training loss: 2.8304...  0.0546 sec/batch
Epoch: 1/20...  Training Step: 269...  Training loss: 2.8384...  0.0566 sec/batch
Epoch: 1/20...  Training Step: 270...  Training loss: 2.8299...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 271...  Training loss: 2.8377...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 272...  Training loss: 2.7703...  0.0573 sec/batch
Epoch: 1/20...  Training Step: 273...  Training loss: 2.7994...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 274...  Training loss: 2.7668...  0.0547 sec/batch
Epoch: 1/20...  Training Step: 275...  Training loss: 2.8096...  0.0542 sec/batch
Epoch: 1/20...  Training Step: 276...  Training loss: 2.8248...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 277...  Training loss: 2.7902...  0.0562 sec/batch
Epoch: 1/20...  Training Step: 278...  Training loss: 2.7974...  0.0545 sec/batch
Epoch: 1/20...  Training Step: 279...  Training loss: 2.8173...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 280...  Training loss: 2.8160...  0.0598 sec/batch
Epoch: 1/20...  Training Step: 281...  Training loss: 2.7616...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 282...  Training loss: 2.7912...  0.0587 sec/batch
Epoch: 1/20...  Training Step: 283...  Training loss: 2.7995...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 284...  Training loss: 2.7565...  0.0521 sec/batch
Epoch: 1/20...  Training Step: 285...  Training loss: 2.7292...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 286...  Training loss: 2.7617...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 287...  Training loss: 2.7490...  0.0570 sec/batch
Epoch: 1/20...  Training Step: 288...  Training loss: 2.7552...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 289...  Training loss: 2.7749...  0.0560 sec/batch
Epoch: 1/20...  Training Step: 290...  Training loss: 2.7916...  0.0546 sec/batch
Epoch: 1/20...  Training Step: 291...  Training loss: 2.7448...  0.0564 sec/batch
Epoch: 1/20...  Training Step: 292...  Training loss: 2.7876...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 293...  Training loss: 2.7940...  0.0573 sec/batch
Epoch: 1/20...  Training Step: 294...  Training loss: 2.7549...  0.0525 sec/batch
Epoch: 1/20...  Training Step: 295...  Training loss: 2.7563...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 296...  Training loss: 2.7620...  0.0550 sec/batch
Epoch: 1/20...  Training Step: 297...  Training loss: 2.7737...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 298...  Training loss: 2.7826...  0.0605 sec/batch
Epoch: 1/20...  Training Step: 299...  Training loss: 2.7817...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 300...  Training loss: 2.7489...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 301...  Training loss: 2.7194...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 302...  Training loss: 2.7600...  0.0561 sec/batch
Epoch: 1/20...  Training Step: 303...  Training loss: 2.7280...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 304...  Training loss: 2.7325...  0.0525 sec/batch
Epoch: 1/20...  Training Step: 305...  Training loss: 2.7841...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 306...  Training loss: 2.7509...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 307...  Training loss: 2.7608...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 308...  Training loss: 2.7182...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 309...  Training loss: 2.7439...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 310...  Training loss: 2.6692...  0.0594 sec/batch
Epoch: 1/20...  Training Step: 311...  Training loss: 2.7383...  0.0548 sec/batch
Epoch: 1/20...  Training Step: 312...  Training loss: 2.7406...  0.0537 sec/batch
Epoch: 1/20...  Training Step: 313...  Training loss: 2.7505...  0.0564 sec/batch
Epoch: 1/20...  Training Step: 314...  Training loss: 2.7238...  0.0543 sec/batch
Epoch: 1/20...  Training Step: 315...  Training loss: 2.7519...  0.0574 sec/batch
Epoch: 1/20...  Training Step: 316...  Training loss: 2.7156...  0.0556 sec/batch
Epoch: 1/20...  Training Step: 317...  Training loss: 2.6569...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 318...  Training loss: 2.6923...  0.0522 sec/batch
Epoch: 1/20...  Training Step: 319...  Training loss: 2.7078...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 320...  Training loss: 2.7507...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 321...  Training loss: 2.7014...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 322...  Training loss: 2.6800...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 323...  Training loss: 2.6914...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 324...  Training loss: 2.6553...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 325...  Training loss: 2.7079...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 326...  Training loss: 2.6784...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 327...  Training loss: 2.7079...  0.0540 sec/batch
Epoch: 1/20...  Training Step: 328...  Training loss: 2.6610...  0.0536 sec/batch
Epoch: 1/20...  Training Step: 329...  Training loss: 2.7235...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 330...  Training loss: 2.6970...  0.0559 sec/batch
Epoch: 1/20...  Training Step: 331...  Training loss: 2.6704...  0.0556 sec/batch
Epoch: 1/20...  Training Step: 332...  Training loss: 2.6955...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 333...  Training loss: 2.6448...  0.0563 sec/batch
Epoch: 1/20...  Training Step: 334...  Training loss: 2.6869...  0.0617 sec/batch
Epoch: 1/20...  Training Step: 335...  Training loss: 2.7094...  0.0546 sec/batch
Epoch: 1/20...  Training Step: 336...  Training loss: 2.7134...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 337...  Training loss: 2.6783...  0.0593 sec/batch
Epoch: 1/20...  Training Step: 338...  Training loss: 2.6831...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 339...  Training loss: 2.6509...  0.0550 sec/batch
Epoch: 1/20...  Training Step: 340...  Training loss: 2.7038...  0.0583 sec/batch
Epoch: 1/20...  Training Step: 341...  Training loss: 2.6978...  0.0542 sec/batch
Epoch: 1/20...  Training Step: 342...  Training loss: 2.6730...  0.0523 sec/batch
Epoch: 1/20...  Training Step: 343...  Training loss: 2.6553...  0.0543 sec/batch
Epoch: 1/20...  Training Step: 344...  Training loss: 2.6671...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 345...  Training loss: 2.6604...  0.0573 sec/batch
Epoch: 1/20...  Training Step: 346...  Training loss: 2.7112...  0.0578 sec/batch
Epoch: 1/20...  Training Step: 347...  Training loss: 2.6671...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 348...  Training loss: 2.6251...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 349...  Training loss: 2.6529...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 350...  Training loss: 2.6208...  0.0550 sec/batch
Epoch: 1/20...  Training Step: 351...  Training loss: 2.6389...  0.0594 sec/batch
Epoch: 1/20...  Training Step: 352...  Training loss: 2.6644...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 353...  Training loss: 2.6842...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 354...  Training loss: 2.6523...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 355...  Training loss: 2.6588...  0.0540 sec/batch
Epoch: 1/20...  Training Step: 356...  Training loss: 2.7178...  0.0565 sec/batch
Epoch: 1/20...  Training Step: 357...  Training loss: 2.7198...  0.0566 sec/batch
Epoch: 1/20...  Training Step: 358...  Training loss: 2.6890...  0.0573 sec/batch
Epoch: 1/20...  Training Step: 359...  Training loss: 2.6272...  0.0547 sec/batch
Epoch: 1/20...  Training Step: 360...  Training loss: 2.6597...  0.0521 sec/batch
Epoch: 1/20...  Training Step: 361...  Training loss: 2.6842...  0.0577 sec/batch
Epoch: 1/20...  Training Step: 362...  Training loss: 2.6581...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 363...  Training loss: 2.6096...  0.0572 sec/batch
Epoch: 1/20...  Training Step: 364...  Training loss: 2.6361...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 365...  Training loss: 2.6478...  0.0557 sec/batch
Epoch: 1/20...  Training Step: 366...  Training loss: 2.6842...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 367...  Training loss: 2.6495...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 368...  Training loss: 2.6551...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 369...  Training loss: 2.6364...  0.0557 sec/batch
Epoch: 1/20...  Training Step: 370...  Training loss: 2.6479...  0.0612 sec/batch
Epoch: 1/20...  Training Step: 371...  Training loss: 2.6750...  0.0581 sec/batch
Epoch: 1/20...  Training Step: 372...  Training loss: 2.6880...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 373...  Training loss: 2.6789...  0.0537 sec/batch
Epoch: 1/20...  Training Step: 374...  Training loss: 2.6501...  0.0587 sec/batch
Epoch: 1/20...  Training Step: 375...  Training loss: 2.6148...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 376...  Training loss: 2.6619...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 377...  Training loss: 2.6460...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 378...  Training loss: 2.6485...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 379...  Training loss: 2.6835...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 380...  Training loss: 2.6304...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 381...  Training loss: 2.5974...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 382...  Training loss: 2.6388...  0.0547 sec/batch
Epoch: 1/20...  Training Step: 383...  Training loss: 2.6097...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 384...  Training loss: 2.6409...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 385...  Training loss: 2.6313...  0.0563 sec/batch
Epoch: 1/20...  Training Step: 386...  Training loss: 2.5852...  0.0571 sec/batch
Epoch: 1/20...  Training Step: 387...  Training loss: 2.5929...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 388...  Training loss: 2.6772...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 389...  Training loss: 2.5460...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 390...  Training loss: 2.5928...  0.0573 sec/batch
Epoch: 1/20...  Training Step: 391...  Training loss: 2.6146...  0.0580 sec/batch
Epoch: 1/20...  Training Step: 392...  Training loss: 2.5698...  0.0580 sec/batch
Epoch: 1/20...  Training Step: 393...  Training loss: 2.6135...  0.0559 sec/batch
Epoch: 1/20...  Training Step: 394...  Training loss: 2.5688...  0.0590 sec/batch
Epoch: 1/20...  Training Step: 395...  Training loss: 2.5927...  0.0541 sec/batch
Epoch: 1/20...  Training Step: 396...  Training loss: 2.6041...  0.0566 sec/batch
Epoch: 1/20...  Training Step: 397...  Training loss: 2.6009...  0.0545 sec/batch
Epoch: 1/20...  Training Step: 398...  Training loss: 2.6162...  0.0563 sec/batch
Epoch: 1/20...  Training Step: 399...  Training loss: 2.5889...  0.0525 sec/batch
Epoch: 1/20...  Training Step: 400...  Training loss: 2.5892...  0.0561 sec/batch
Epoch: 1/20...  Training Step: 401...  Training loss: 2.5948...  0.0543 sec/batch
Epoch: 1/20...  Training Step: 402...  Training loss: 2.6151...  0.0556 sec/batch
Epoch: 1/20...  Training Step: 403...  Training loss: 2.6173...  0.0593 sec/batch
Epoch: 1/20...  Training Step: 404...  Training loss: 2.5908...  0.0562 sec/batch
Epoch: 1/20...  Training Step: 405...  Training loss: 2.6703...  0.0566 sec/batch
Epoch: 1/20...  Training Step: 406...  Training loss: 2.6186...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 407...  Training loss: 2.6175...  0.0557 sec/batch
Epoch: 1/20...  Training Step: 408...  Training loss: 2.5954...  0.0520 sec/batch
Epoch: 1/20...  Training Step: 409...  Training loss: 2.6139...  0.0593 sec/batch
Epoch: 1/20...  Training Step: 410...  Training loss: 2.5897...  0.0558 sec/batch
Epoch: 1/20...  Training Step: 411...  Training loss: 2.5770...  0.0534 sec/batch
Epoch: 1/20...  Training Step: 412...  Training loss: 2.6020...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 413...  Training loss: 2.5677...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 414...  Training loss: 2.5891...  0.0589 sec/batch
Epoch: 1/20...  Training Step: 415...  Training loss: 2.5513...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 416...  Training loss: 2.5477...  0.0612 sec/batch
Epoch: 1/20...  Training Step: 417...  Training loss: 2.5681...  0.0537 sec/batch
Epoch: 1/20...  Training Step: 418...  Training loss: 2.6038...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 419...  Training loss: 2.5910...  0.0566 sec/batch
Epoch: 1/20...  Training Step: 420...  Training loss: 2.5980...  0.0604 sec/batch
Epoch: 1/20...  Training Step: 421...  Training loss: 2.5609...  0.0581 sec/batch
Epoch: 1/20...  Training Step: 422...  Training loss: 2.5869...  0.0569 sec/batch
Epoch: 1/20...  Training Step: 423...  Training loss: 2.5935...  0.0534 sec/batch
Epoch: 1/20...  Training Step: 424...  Training loss: 2.6054...  0.0536 sec/batch
Epoch: 1/20...  Training Step: 425...  Training loss: 2.6070...  0.0559 sec/batch
Epoch: 1/20...  Training Step: 426...  Training loss: 2.6170...  0.0578 sec/batch
Epoch: 1/20...  Training Step: 427...  Training loss: 2.5816...  0.0592 sec/batch
Epoch: 1/20...  Training Step: 428...  Training loss: 2.5777...  0.0543 sec/batch
Epoch: 1/20...  Training Step: 429...  Training loss: 2.5791...  0.0599 sec/batch
Epoch: 1/20...  Training Step: 430...  Training loss: 2.5513...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 431...  Training loss: 2.5758...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 432...  Training loss: 2.5928...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 433...  Training loss: 2.5729...  0.0563 sec/batch
Epoch: 1/20...  Training Step: 434...  Training loss: 2.5556...  0.0547 sec/batch
Epoch: 1/20...  Training Step: 435...  Training loss: 2.5733...  0.0537 sec/batch
Epoch: 1/20...  Training Step: 436...  Training loss: 2.5737...  0.0550 sec/batch
Epoch: 1/20...  Training Step: 437...  Training loss: 2.5449...  0.0560 sec/batch
Epoch: 1/20...  Training Step: 438...  Training loss: 2.5911...  0.0582 sec/batch
Epoch: 1/20...  Training Step: 439...  Training loss: 2.5721...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 440...  Training loss: 2.5622...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 441...  Training loss: 2.5647...  0.0585 sec/batch
Epoch: 1/20...  Training Step: 442...  Training loss: 2.5416...  0.0582 sec/batch
Epoch: 1/20...  Training Step: 443...  Training loss: 2.5706...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 444...  Training loss: 2.5661...  0.0562 sec/batch
Epoch: 1/20...  Training Step: 445...  Training loss: 2.5903...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 446...  Training loss: 2.5434...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 447...  Training loss: 2.5762...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 448...  Training loss: 2.5744...  0.0557 sec/batch
Epoch: 1/20...  Training Step: 449...  Training loss: 2.5599...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 450...  Training loss: 2.5698...  0.0538 sec/batch
Epoch: 1/20...  Training Step: 451...  Training loss: 2.6686...  0.0558 sec/batch
Epoch: 1/20...  Training Step: 452...  Training loss: 2.5258...  0.0594 sec/batch
Epoch: 1/20...  Training Step: 453...  Training loss: 2.5529...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 454...  Training loss: 2.5515...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 455...  Training loss: 2.5342...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 456...  Training loss: 2.6155...  0.0556 sec/batch
Epoch: 1/20...  Training Step: 457...  Training loss: 2.5549...  0.0585 sec/batch
Epoch: 1/20...  Training Step: 458...  Training loss: 2.5871...  0.0550 sec/batch
Epoch: 1/20...  Training Step: 459...  Training loss: 2.5657...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 460...  Training loss: 2.5660...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 461...  Training loss: 2.5498...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 462...  Training loss: 2.5695...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 463...  Training loss: 2.5327...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 464...  Training loss: 2.5542...  0.0593 sec/batch
Epoch: 1/20...  Training Step: 465...  Training loss: 2.5800...  0.0579 sec/batch
Epoch: 1/20...  Training Step: 466...  Training loss: 2.5619...  0.0588 sec/batch
Epoch: 1/20...  Training Step: 467...  Training loss: 2.6110...  0.0580 sec/batch
Epoch: 1/20...  Training Step: 468...  Training loss: 2.5512...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 469...  Training loss: 2.5968...  0.0622 sec/batch
Epoch: 1/20...  Training Step: 470...  Training loss: 2.5501...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 471...  Training loss: 2.5340...  0.0567 sec/batch
Epoch: 1/20...  Training Step: 472...  Training loss: 2.5059...  0.0596 sec/batch
Epoch: 1/20...  Training Step: 473...  Training loss: 2.5204...  0.0562 sec/batch
Epoch: 1/20...  Training Step: 474...  Training loss: 2.5303...  0.0594 sec/batch
Epoch: 1/20...  Training Step: 475...  Training loss: 2.5856...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 476...  Training loss: 2.5892...  0.0589 sec/batch
Epoch: 1/20...  Training Step: 477...  Training loss: 2.5365...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 478...  Training loss: 2.6166...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 479...  Training loss: 2.5232...  0.0562 sec/batch
Epoch: 1/20...  Training Step: 480...  Training loss: 2.5560...  0.0558 sec/batch
Epoch: 1/20...  Training Step: 481...  Training loss: 2.5656...  0.0606 sec/batch
Epoch: 1/20...  Training Step: 482...  Training loss: 2.5248...  0.0586 sec/batch
Epoch: 1/20...  Training Step: 483...  Training loss: 2.5270...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 484...  Training loss: 2.5655...  0.0520 sec/batch
Epoch: 1/20...  Training Step: 485...  Training loss: 2.5729...  0.0585 sec/batch
Epoch: 1/20...  Training Step: 486...  Training loss: 2.5488...  0.0561 sec/batch
Epoch: 1/20...  Training Step: 487...  Training loss: 2.6217...  0.0541 sec/batch
Epoch: 1/20...  Training Step: 488...  Training loss: 2.5896...  0.0567 sec/batch
Epoch: 1/20...  Training Step: 489...  Training loss: 2.5927...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 490...  Training loss: 2.6012...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 491...  Training loss: 2.6139...  0.0561 sec/batch
Epoch: 1/20...  Training Step: 492...  Training loss: 2.6245...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 493...  Training loss: 2.6046...  0.0558 sec/batch
Epoch: 1/20...  Training Step: 494...  Training loss: 2.5970...  0.0556 sec/batch
Epoch: 1/20...  Training Step: 495...  Training loss: 2.5272...  0.0556 sec/batch
Epoch: 1/20...  Training Step: 496...  Training loss: 2.5531...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 497...  Training loss: 2.5418...  0.0534 sec/batch
Epoch: 1/20...  Training Step: 498...  Training loss: 2.5436...  0.0547 sec/batch
Epoch: 1/20...  Training Step: 499...  Training loss: 2.5325...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 500...  Training loss: 2.5363...  0.0575 sec/batch
Epoch: 1/20...  Training Step: 501...  Training loss: 2.5306...  0.0576 sec/batch
Epoch: 1/20...  Training Step: 502...  Training loss: 2.5896...  0.0544 sec/batch
Epoch: 1/20...  Training Step: 503...  Training loss: 2.5970...  0.0575 sec/batch
Epoch: 1/20...  Training Step: 504...  Training loss: 2.5490...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 505...  Training loss: 2.5432...  0.0577 sec/batch
Epoch: 1/20...  Training Step: 506...  Training loss: 2.4832...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 507...  Training loss: 2.5578...  0.0574 sec/batch
Epoch: 1/20...  Training Step: 508...  Training loss: 2.5307...  0.0602 sec/batch
Epoch: 1/20...  Training Step: 509...  Training loss: 2.5446...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 510...  Training loss: 2.5604...  0.0583 sec/batch
Epoch: 1/20...  Training Step: 511...  Training loss: 2.5563...  0.0547 sec/batch
Epoch: 1/20...  Training Step: 512...  Training loss: 2.4947...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 513...  Training loss: 2.6403...  0.0587 sec/batch
Epoch: 1/20...  Training Step: 514...  Training loss: 2.6023...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 515...  Training loss: 2.5628...  0.0587 sec/batch
Epoch: 1/20...  Training Step: 516...  Training loss: 2.5322...  0.0593 sec/batch
Epoch: 1/20...  Training Step: 517...  Training loss: 2.5253...  0.0594 sec/batch
Epoch: 1/20...  Training Step: 518...  Training loss: 2.5427...  0.0592 sec/batch
Epoch: 1/20...  Training Step: 519...  Training loss: 2.5231...  0.0566 sec/batch
Epoch: 1/20...  Training Step: 520...  Training loss: 2.5220...  0.0540 sec/batch
Epoch: 1/20...  Training Step: 521...  Training loss: 2.5039...  0.0592 sec/batch
Epoch: 1/20...  Training Step: 522...  Training loss: 2.5048...  0.0608 sec/batch
Epoch: 1/20...  Training Step: 523...  Training loss: 2.5368...  0.0561 sec/batch
Epoch: 1/20...  Training Step: 524...  Training loss: 2.4795...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 525...  Training loss: 2.5084...  0.0560 sec/batch
Epoch: 1/20...  Training Step: 526...  Training loss: 2.5440...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 527...  Training loss: 2.5278...  0.0588 sec/batch
Epoch: 1/20...  Training Step: 528...  Training loss: 2.5618...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 529...  Training loss: 2.5112...  0.0588 sec/batch
Epoch: 1/20...  Training Step: 530...  Training loss: 2.5009...  0.0527 sec/batch
Epoch: 1/20...  Training Step: 531...  Training loss: 2.5241...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 532...  Training loss: 2.4774...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 533...  Training loss: 2.5382...  0.0542 sec/batch
Epoch: 1/20...  Training Step: 534...  Training loss: 2.4925...  0.0541 sec/batch
Epoch: 1/20...  Training Step: 535...  Training loss: 2.4978...  0.0551 sec/batch
Epoch: 1/20...  Training Step: 536...  Training loss: 2.5011...  0.0537 sec/batch
Epoch: 1/20...  Training Step: 537...  Training loss: 2.4977...  0.0595 sec/batch
Epoch: 1/20...  Training Step: 538...  Training loss: 2.5623...  0.0585 sec/batch
Epoch: 1/20...  Training Step: 539...  Training loss: 2.4895...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 540...  Training loss: 2.5197...  0.0546 sec/batch
Epoch: 1/20...  Training Step: 541...  Training loss: 2.5266...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 542...  Training loss: 2.5188...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 543...  Training loss: 2.4836...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 544...  Training loss: 2.5031...  0.0596 sec/batch
Epoch: 1/20...  Training Step: 545...  Training loss: 2.5236...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 546...  Training loss: 2.5251...  0.0550 sec/batch
Epoch: 1/20...  Training Step: 547...  Training loss: 2.5005...  0.0558 sec/batch
Epoch: 1/20...  Training Step: 548...  Training loss: 2.5459...  0.0524 sec/batch
Epoch: 1/20...  Training Step: 549...  Training loss: 2.5398...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 550...  Training loss: 2.5240...  0.0547 sec/batch
Epoch: 1/20...  Training Step: 551...  Training loss: 2.4839...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 552...  Training loss: 2.5208...  0.0573 sec/batch
Epoch: 1/20...  Training Step: 553...  Training loss: 2.4980...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 554...  Training loss: 2.5211...  0.0522 sec/batch
Epoch: 1/20...  Training Step: 555...  Training loss: 2.5022...  0.0531 sec/batch
Epoch: 1/20...  Training Step: 556...  Training loss: 2.4592...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 557...  Training loss: 2.4806...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 558...  Training loss: 2.5146...  0.0578 sec/batch
Epoch: 1/20...  Training Step: 559...  Training loss: 2.4979...  0.0559 sec/batch
Epoch: 1/20...  Training Step: 560...  Training loss: 2.5107...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 561...  Training loss: 2.4668...  0.0587 sec/batch
Epoch: 1/20...  Training Step: 562...  Training loss: 2.5123...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 563...  Training loss: 2.4974...  0.0565 sec/batch
Epoch: 1/20...  Training Step: 564...  Training loss: 2.5079...  0.0556 sec/batch
Epoch: 1/20...  Training Step: 565...  Training loss: 2.5454...  0.0559 sec/batch
Epoch: 1/20...  Training Step: 566...  Training loss: 2.5048...  0.0525 sec/batch
Epoch: 1/20...  Training Step: 567...  Training loss: 2.5453...  0.0581 sec/batch
Epoch: 1/20...  Training Step: 568...  Training loss: 2.5598...  0.0557 sec/batch
Epoch: 1/20...  Training Step: 569...  Training loss: 2.5426...  0.0533 sec/batch
Epoch: 1/20...  Training Step: 570...  Training loss: 2.5049...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 571...  Training loss: 2.4709...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 572...  Training loss: 2.5464...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 573...  Training loss: 2.4865...  0.0533 sec/batch
Epoch: 1/20...  Training Step: 574...  Training loss: 2.4907...  0.0575 sec/batch
Epoch: 1/20...  Training Step: 575...  Training loss: 2.5025...  0.0544 sec/batch
Epoch: 1/20...  Training Step: 576...  Training loss: 2.5584...  0.0559 sec/batch
Epoch: 1/20...  Training Step: 577...  Training loss: 2.5109...  0.0524 sec/batch
Epoch: 1/20...  Training Step: 578...  Training loss: 2.4988...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 579...  Training loss: 2.5517...  0.0524 sec/batch
Epoch: 1/20...  Training Step: 580...  Training loss: 2.5387...  0.0557 sec/batch
Epoch: 1/20...  Training Step: 581...  Training loss: 2.5005...  0.0577 sec/batch
Epoch: 1/20...  Training Step: 582...  Training loss: 2.4925...  0.0526 sec/batch
Epoch: 1/20...  Training Step: 583...  Training loss: 2.4887...  0.0585 sec/batch
Epoch: 1/20...  Training Step: 584...  Training loss: 2.5285...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 585...  Training loss: 2.5082...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 586...  Training loss: 2.4660...  0.0523 sec/batch
Epoch: 1/20...  Training Step: 587...  Training loss: 2.4890...  0.0523 sec/batch
Epoch: 1/20...  Training Step: 588...  Training loss: 2.5125...  0.0543 sec/batch
Epoch: 1/20...  Training Step: 589...  Training loss: 2.4472...  0.0549 sec/batch
Epoch: 1/20...  Training Step: 590...  Training loss: 2.5471...  0.0559 sec/batch
Epoch: 1/20...  Training Step: 591...  Training loss: 2.4506...  0.0574 sec/batch
Epoch: 1/20...  Training Step: 592...  Training loss: 2.4955...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 593...  Training loss: 2.4829...  0.0538 sec/batch
Epoch: 1/20...  Training Step: 594...  Training loss: 2.4597...  0.0595 sec/batch
Epoch: 1/20...  Training Step: 595...  Training loss: 2.4578...  0.0525 sec/batch
Epoch: 1/20...  Training Step: 596...  Training loss: 2.4756...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 597...  Training loss: 2.4560...  0.0563 sec/batch
Epoch: 1/20...  Training Step: 598...  Training loss: 2.4607...  0.0535 sec/batch
Epoch: 1/20...  Training Step: 599...  Training loss: 2.4873...  0.0528 sec/batch
Epoch: 1/20...  Training Step: 600...  Training loss: 2.5227...  0.0554 sec/batch
Epoch: 1/20...  Training Step: 601...  Training loss: 2.4849...  0.0532 sec/batch
Epoch: 1/20...  Training Step: 602...  Training loss: 2.5049...  0.0584 sec/batch
Epoch: 1/20...  Training Step: 603...  Training loss: 2.5313...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 604...  Training loss: 2.4529...  0.0604 sec/batch
Epoch: 1/20...  Training Step: 605...  Training loss: 2.4762...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 606...  Training loss: 2.4682...  0.0529 sec/batch
Epoch: 1/20...  Training Step: 607...  Training loss: 2.4414...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 608...  Training loss: 2.4718...  0.0548 sec/batch
Epoch: 1/20...  Training Step: 609...  Training loss: 2.4387...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 610...  Training loss: 2.4874...  0.0555 sec/batch
Epoch: 1/20...  Training Step: 611...  Training loss: 2.4799...  0.0534 sec/batch
Epoch: 1/20...  Training Step: 612...  Training loss: 2.4928...  0.0550 sec/batch
Epoch: 1/20...  Training Step: 613...  Training loss: 2.4592...  0.0596 sec/batch
Epoch: 1/20...  Training Step: 614...  Training loss: 2.4616...  0.0550 sec/batch
Epoch: 1/20...  Training Step: 615...  Training loss: 2.4409...  0.0552 sec/batch
Epoch: 1/20...  Training Step: 616...  Training loss: 2.4979...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 617...  Training loss: 2.5088...  0.0553 sec/batch
Epoch: 1/20...  Training Step: 618...  Training loss: 2.4500...  0.0591 sec/batch
Epoch: 1/20...  Training Step: 619...  Training loss: 2.4533...  0.0530 sec/batch
Epoch: 1/20...  Training Step: 620...  Training loss: 2.4528...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 621...  Training loss: 2.6068...  0.0548 sec/batch
Epoch: 2/20...  Training Step: 622...  Training loss: 2.5003...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 623...  Training loss: 2.4887...  0.0562 sec/batch
Epoch: 2/20...  Training Step: 624...  Training loss: 2.4515...  0.0536 sec/batch
Epoch: 2/20...  Training Step: 625...  Training loss: 2.4628...  0.0558 sec/batch
Epoch: 2/20...  Training Step: 626...  Training loss: 2.4944...  0.0533 sec/batch
Epoch: 2/20...  Training Step: 627...  Training loss: 2.4526...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 628...  Training loss: 2.4134...  0.0551 sec/batch
Epoch: 2/20...  Training Step: 629...  Training loss: 2.4245...  0.0563 sec/batch
Epoch: 2/20...  Training Step: 630...  Training loss: 2.4795...  0.0531 sec/batch
Epoch: 2/20...  Training Step: 631...  Training loss: 2.4526...  0.0546 sec/batch
Epoch: 2/20...  Training Step: 632...  Training loss: 2.4488...  0.0550 sec/batch
Epoch: 2/20...  Training Step: 633...  Training loss: 2.5133...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 634...  Training loss: 2.4158...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 635...  Training loss: 2.4525...  0.0553 sec/batch
Epoch: 2/20...  Training Step: 636...  Training loss: 2.4708...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 637...  Training loss: 2.4957...  0.0583 sec/batch
Epoch: 2/20...  Training Step: 638...  Training loss: 2.4799...  0.0549 sec/batch
Epoch: 2/20...  Training Step: 639...  Training loss: 2.4305...  0.0673 sec/batch
Epoch: 2/20...  Training Step: 640...  Training loss: 2.4616...  0.0607 sec/batch
Epoch: 2/20...  Training Step: 641...  Training loss: 2.4869...  0.0559 sec/batch
Epoch: 2/20...  Training Step: 642...  Training loss: 2.4288...  0.0550 sec/batch
Epoch: 2/20...  Training Step: 643...  Training loss: 2.4539...  0.0572 sec/batch
Epoch: 2/20...  Training Step: 644...  Training loss: 2.4581...  0.0550 sec/batch
Epoch: 2/20...  Training Step: 645...  Training loss: 2.4799...  0.0541 sec/batch
Epoch: 2/20...  Training Step: 646...  Training loss: 2.4670...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 647...  Training loss: 2.4716...  0.0551 sec/batch
Epoch: 2/20...  Training Step: 648...  Training loss: 2.4684...  0.0598 sec/batch
Epoch: 2/20...  Training Step: 649...  Training loss: 2.5176...  0.0531 sec/batch
Epoch: 2/20...  Training Step: 650...  Training loss: 2.4326...  0.0553 sec/batch
Epoch: 2/20...  Training Step: 651...  Training loss: 2.4265...  0.0558 sec/batch
Epoch: 2/20...  Training Step: 652...  Training loss: 2.4763...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 653...  Training loss: 2.4425...  0.0559 sec/batch
Epoch: 2/20...  Training Step: 654...  Training loss: 2.4561...  0.0584 sec/batch
Epoch: 2/20...  Training Step: 655...  Training loss: 2.4514...  0.0549 sec/batch
Epoch: 2/20...  Training Step: 656...  Training loss: 2.4770...  0.0530 sec/batch
Epoch: 2/20...  Training Step: 657...  Training loss: 2.4453...  0.0602 sec/batch
Epoch: 2/20...  Training Step: 658...  Training loss: 2.4570...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 659...  Training loss: 2.4444...  0.0579 sec/batch
Epoch: 2/20...  Training Step: 660...  Training loss: 2.4789...  0.0551 sec/batch
Epoch: 2/20...  Training Step: 661...  Training loss: 2.4311...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 662...  Training loss: 2.4479...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 663...  Training loss: 2.4224...  0.0545 sec/batch
Epoch: 2/20...  Training Step: 664...  Training loss: 2.4492...  0.0530 sec/batch
Epoch: 2/20...  Training Step: 665...  Training loss: 2.4488...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 666...  Training loss: 2.4384...  0.0548 sec/batch
Epoch: 2/20...  Training Step: 667...  Training loss: 2.4135...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 668...  Training loss: 2.4735...  0.0553 sec/batch
Epoch: 2/20...  Training Step: 669...  Training loss: 2.4833...  0.0525 sec/batch
Epoch: 2/20...  Training Step: 670...  Training loss: 2.4484...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 671...  Training loss: 2.3935...  0.0559 sec/batch
Epoch: 2/20...  Training Step: 672...  Training loss: 2.4383...  0.0547 sec/batch
Epoch: 2/20...  Training Step: 673...  Training loss: 2.4586...  0.0593 sec/batch
Epoch: 2/20...  Training Step: 674...  Training loss: 2.4958...  0.0546 sec/batch
Epoch: 2/20...  Training Step: 675...  Training loss: 2.4959...  0.0583 sec/batch
Epoch: 2/20...  Training Step: 676...  Training loss: 2.4326...  0.0571 sec/batch
Epoch: 2/20...  Training Step: 677...  Training loss: 2.4276...  0.0530 sec/batch
Epoch: 2/20...  Training Step: 678...  Training loss: 2.4711...  0.0548 sec/batch
Epoch: 2/20...  Training Step: 679...  Training loss: 2.4228...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 680...  Training loss: 2.4789...  0.0555 sec/batch
Epoch: 2/20...  Training Step: 681...  Training loss: 2.4611...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 682...  Training loss: 2.4351...  0.0569 sec/batch
Epoch: 2/20...  Training Step: 683...  Training loss: 2.4627...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 684...  Training loss: 2.4305...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 685...  Training loss: 2.4075...  0.0589 sec/batch
Epoch: 2/20...  Training Step: 686...  Training loss: 2.4119...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 687...  Training loss: 2.3929...  0.0531 sec/batch
Epoch: 2/20...  Training Step: 688...  Training loss: 2.4030...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 689...  Training loss: 2.4525...  0.0525 sec/batch
Epoch: 2/20...  Training Step: 690...  Training loss: 2.4176...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 691...  Training loss: 2.4236...  0.0523 sec/batch
Epoch: 2/20...  Training Step: 692...  Training loss: 2.4460...  0.0549 sec/batch
Epoch: 2/20...  Training Step: 693...  Training loss: 2.4427...  0.0582 sec/batch
Epoch: 2/20...  Training Step: 694...  Training loss: 2.4264...  0.0573 sec/batch
Epoch: 2/20...  Training Step: 695...  Training loss: 2.4649...  0.0570 sec/batch
Epoch: 2/20...  Training Step: 696...  Training loss: 2.4511...  0.0575 sec/batch
Epoch: 2/20...  Training Step: 697...  Training loss: 2.4916...  0.0549 sec/batch
Epoch: 2/20...  Training Step: 698...  Training loss: 2.4242...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 699...  Training loss: 2.4627...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 700...  Training loss: 2.4688...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 701...  Training loss: 2.4601...  0.0531 sec/batch
Epoch: 2/20...  Training Step: 702...  Training loss: 2.4072...  0.0527 sec/batch
Epoch: 2/20...  Training Step: 703...  Training loss: 2.4271...  0.0523 sec/batch
Epoch: 2/20...  Training Step: 704...  Training loss: 2.4624...  0.0561 sec/batch
Epoch: 2/20...  Training Step: 705...  Training loss: 2.4474...  0.0587 sec/batch
Epoch: 2/20...  Training Step: 706...  Training loss: 2.4332...  0.0558 sec/batch
Epoch: 2/20...  Training Step: 707...  Training loss: 2.4310...  0.0522 sec/batch
Epoch: 2/20...  Training Step: 708...  Training loss: 2.5048...  0.0581 sec/batch
Epoch: 2/20...  Training Step: 709...  Training loss: 2.4331...  0.0576 sec/batch
Epoch: 2/20...  Training Step: 710...  Training loss: 2.4370...  0.0590 sec/batch
Epoch: 2/20...  Training Step: 711...  Training loss: 2.4099...  0.0540 sec/batch
Epoch: 2/20...  Training Step: 712...  Training loss: 2.4816...  0.0612 sec/batch
Epoch: 2/20...  Training Step: 713...  Training loss: 2.4454...  0.0533 sec/batch
Epoch: 2/20...  Training Step: 714...  Training loss: 2.4161...  0.0523 sec/batch
Epoch: 2/20...  Training Step: 715...  Training loss: 2.4583...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 716...  Training loss: 2.4312...  0.0522 sec/batch
Epoch: 2/20...  Training Step: 717...  Training loss: 2.4608...  0.0552 sec/batch
Epoch: 2/20...  Training Step: 718...  Training loss: 2.4233...  0.0591 sec/batch
Epoch: 2/20...  Training Step: 719...  Training loss: 2.4855...  0.0588 sec/batch
Epoch: 2/20...  Training Step: 720...  Training loss: 2.4321...  0.0548 sec/batch
Epoch: 2/20...  Training Step: 721...  Training loss: 2.4276...  0.0531 sec/batch
Epoch: 2/20...  Training Step: 722...  Training loss: 2.4484...  0.0583 sec/batch
Epoch: 2/20...  Training Step: 723...  Training loss: 2.4311...  0.0589 sec/batch
Epoch: 2/20...  Training Step: 724...  Training loss: 2.3922...  0.0564 sec/batch
Epoch: 2/20...  Training Step: 725...  Training loss: 2.4438...  0.0572 sec/batch
Epoch: 2/20...  Training Step: 726...  Training loss: 2.3969...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 727...  Training loss: 2.4620...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 728...  Training loss: 2.4257...  0.0577 sec/batch
Epoch: 2/20...  Training Step: 729...  Training loss: 2.3981...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 730...  Training loss: 2.4054...  0.0553 sec/batch
Epoch: 2/20...  Training Step: 731...  Training loss: 2.3947...  0.0588 sec/batch
Epoch: 2/20...  Training Step: 732...  Training loss: 2.4604...  0.0548 sec/batch
Epoch: 2/20...  Training Step: 733...  Training loss: 2.4293...  0.0565 sec/batch
Epoch: 2/20...  Training Step: 734...  Training loss: 2.4285...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 735...  Training loss: 2.4562...  0.0581 sec/batch
Epoch: 2/20...  Training Step: 736...  Training loss: 2.4438...  0.0550 sec/batch
Epoch: 2/20...  Training Step: 737...  Training loss: 2.4218...  0.0580 sec/batch
Epoch: 2/20...  Training Step: 738...  Training loss: 2.4471...  0.0527 sec/batch
Epoch: 2/20...  Training Step: 739...  Training loss: 2.4072...  0.0598 sec/batch
Epoch: 2/20...  Training Step: 740...  Training loss: 2.4257...  0.0548 sec/batch
Epoch: 2/20...  Training Step: 741...  Training loss: 2.3930...  0.0555 sec/batch
Epoch: 2/20...  Training Step: 742...  Training loss: 2.3653...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 743...  Training loss: 2.4196...  0.0552 sec/batch
Epoch: 2/20...  Training Step: 744...  Training loss: 2.4212...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 745...  Training loss: 2.4303...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 746...  Training loss: 2.4759...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 747...  Training loss: 2.4543...  0.0551 sec/batch
Epoch: 2/20...  Training Step: 748...  Training loss: 2.4146...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 749...  Training loss: 2.3890...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 750...  Training loss: 2.4353...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 751...  Training loss: 2.3827...  0.0522 sec/batch
Epoch: 2/20...  Training Step: 752...  Training loss: 2.4481...  0.0536 sec/batch
Epoch: 2/20...  Training Step: 753...  Training loss: 2.4597...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 754...  Training loss: 2.4285...  0.0561 sec/batch
Epoch: 2/20...  Training Step: 755...  Training loss: 2.3895...  0.0563 sec/batch
Epoch: 2/20...  Training Step: 756...  Training loss: 2.4161...  0.0581 sec/batch
Epoch: 2/20...  Training Step: 757...  Training loss: 2.4146...  0.0538 sec/batch
Epoch: 2/20...  Training Step: 758...  Training loss: 2.4292...  0.0551 sec/batch
Epoch: 2/20...  Training Step: 759...  Training loss: 2.4386...  0.0545 sec/batch
Epoch: 2/20...  Training Step: 760...  Training loss: 2.3922...  0.0527 sec/batch
Epoch: 2/20...  Training Step: 761...  Training loss: 2.4018...  0.0536 sec/batch
Epoch: 2/20...  Training Step: 762...  Training loss: 2.4245...  0.0527 sec/batch
Epoch: 2/20...  Training Step: 763...  Training loss: 2.4121...  0.0547 sec/batch
Epoch: 2/20...  Training Step: 764...  Training loss: 2.4197...  0.0525 sec/batch
Epoch: 2/20...  Training Step: 765...  Training loss: 2.3923...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 766...  Training loss: 2.4349...  0.0569 sec/batch
Epoch: 2/20...  Training Step: 767...  Training loss: 2.3695...  0.0550 sec/batch
Epoch: 2/20...  Training Step: 768...  Training loss: 2.4527...  0.0525 sec/batch
Epoch: 2/20...  Training Step: 769...  Training loss: 2.3951...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 770...  Training loss: 2.4309...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 771...  Training loss: 2.4311...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 772...  Training loss: 2.4382...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 773...  Training loss: 2.3830...  0.0553 sec/batch
Epoch: 2/20...  Training Step: 774...  Training loss: 2.4420...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 775...  Training loss: 2.4009...  0.0552 sec/batch
Epoch: 2/20...  Training Step: 776...  Training loss: 2.4182...  0.0550 sec/batch
Epoch: 2/20...  Training Step: 777...  Training loss: 2.3731...  0.0562 sec/batch
Epoch: 2/20...  Training Step: 778...  Training loss: 2.4403...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 779...  Training loss: 2.4581...  0.0595 sec/batch
Epoch: 2/20...  Training Step: 780...  Training loss: 2.3708...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 781...  Training loss: 2.4064...  0.0572 sec/batch
Epoch: 2/20...  Training Step: 782...  Training loss: 2.3976...  0.0571 sec/batch
Epoch: 2/20...  Training Step: 783...  Training loss: 2.4106...  0.0585 sec/batch
Epoch: 2/20...  Training Step: 784...  Training loss: 2.3877...  0.0559 sec/batch
Epoch: 2/20...  Training Step: 785...  Training loss: 2.4377...  0.0539 sec/batch
Epoch: 2/20...  Training Step: 786...  Training loss: 2.3589...  0.0534 sec/batch
Epoch: 2/20...  Training Step: 787...  Training loss: 2.4501...  0.0586 sec/batch
Epoch: 2/20...  Training Step: 788...  Training loss: 2.3855...  0.0603 sec/batch
Epoch: 2/20...  Training Step: 789...  Training loss: 2.3941...  0.0594 sec/batch
Epoch: 2/20...  Training Step: 790...  Training loss: 2.3936...  0.0593 sec/batch
Epoch: 2/20...  Training Step: 791...  Training loss: 2.3842...  0.0580 sec/batch
Epoch: 2/20...  Training Step: 792...  Training loss: 2.4013...  0.0535 sec/batch
Epoch: 2/20...  Training Step: 793...  Training loss: 2.4369...  0.0563 sec/batch
Epoch: 2/20...  Training Step: 794...  Training loss: 2.4184...  0.0575 sec/batch
Epoch: 2/20...  Training Step: 795...  Training loss: 2.3985...  0.0596 sec/batch
Epoch: 2/20...  Training Step: 796...  Training loss: 2.4336...  0.0551 sec/batch
Epoch: 2/20...  Training Step: 797...  Training loss: 2.4119...  0.0540 sec/batch
Epoch: 2/20...  Training Step: 798...  Training loss: 2.4479...  0.0530 sec/batch
Epoch: 2/20...  Training Step: 799...  Training loss: 2.3817...  0.0597 sec/batch
Epoch: 2/20...  Training Step: 800...  Training loss: 2.3866...  0.0578 sec/batch
Epoch: 2/20...  Training Step: 801...  Training loss: 2.4047...  0.0582 sec/batch
Epoch: 2/20...  Training Step: 802...  Training loss: 2.4132...  0.0551 sec/batch
Epoch: 2/20...  Training Step: 803...  Training loss: 2.4334...  0.0537 sec/batch
Epoch: 2/20...  Training Step: 804...  Training loss: 2.3557...  0.0527 sec/batch
Epoch: 2/20...  Training Step: 805...  Training loss: 2.3811...  0.0578 sec/batch
Epoch: 2/20...  Training Step: 806...  Training loss: 2.4054...  0.0536 sec/batch
Epoch: 2/20...  Training Step: 807...  Training loss: 2.3657...  0.0595 sec/batch
Epoch: 2/20...  Training Step: 808...  Training loss: 2.3687...  0.0536 sec/batch
Epoch: 2/20...  Training Step: 809...  Training loss: 2.3852...  0.0566 sec/batch
Epoch: 2/20...  Training Step: 810...  Training loss: 2.4511...  0.0533 sec/batch
Epoch: 2/20...  Training Step: 811...  Training loss: 2.4869...  0.0537 sec/batch
Epoch: 2/20...  Training Step: 812...  Training loss: 2.4617...  0.0563 sec/batch
Epoch: 2/20...  Training Step: 813...  Training loss: 2.4216...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 814...  Training loss: 2.3869...  0.0585 sec/batch
Epoch: 2/20...  Training Step: 815...  Training loss: 2.4299...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 816...  Training loss: 2.4498...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 817...  Training loss: 2.4271...  0.0575 sec/batch
Epoch: 2/20...  Training Step: 818...  Training loss: 2.4167...  0.0562 sec/batch
Epoch: 2/20...  Training Step: 819...  Training loss: 2.3889...  0.0599 sec/batch
Epoch: 2/20...  Training Step: 820...  Training loss: 2.3830...  0.0525 sec/batch
Epoch: 2/20...  Training Step: 821...  Training loss: 2.3930...  0.0563 sec/batch
Epoch: 2/20...  Training Step: 822...  Training loss: 2.3864...  0.0569 sec/batch
Epoch: 2/20...  Training Step: 823...  Training loss: 2.3611...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 824...  Training loss: 2.3806...  0.0547 sec/batch
Epoch: 2/20...  Training Step: 825...  Training loss: 2.4007...  0.0541 sec/batch
Epoch: 2/20...  Training Step: 826...  Training loss: 2.3747...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 827...  Training loss: 2.3925...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 828...  Training loss: 2.4027...  0.0597 sec/batch
Epoch: 2/20...  Training Step: 829...  Training loss: 2.4179...  0.0536 sec/batch
Epoch: 2/20...  Training Step: 830...  Training loss: 2.3841...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 831...  Training loss: 2.3879...  0.0558 sec/batch
Epoch: 2/20...  Training Step: 832...  Training loss: 2.4233...  0.0555 sec/batch
Epoch: 2/20...  Training Step: 833...  Training loss: 2.4110...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 834...  Training loss: 2.4163...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 835...  Training loss: 2.4089...  0.0551 sec/batch
Epoch: 2/20...  Training Step: 836...  Training loss: 2.4144...  0.0589 sec/batch
Epoch: 2/20...  Training Step: 837...  Training loss: 2.3666...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 838...  Training loss: 2.3700...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 839...  Training loss: 2.4512...  0.0521 sec/batch
Epoch: 2/20...  Training Step: 840...  Training loss: 2.4229...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 841...  Training loss: 2.3664...  0.0561 sec/batch
Epoch: 2/20...  Training Step: 842...  Training loss: 2.3726...  0.0536 sec/batch
Epoch: 2/20...  Training Step: 843...  Training loss: 2.4294...  0.0597 sec/batch
Epoch: 2/20...  Training Step: 844...  Training loss: 2.3747...  0.0533 sec/batch
Epoch: 2/20...  Training Step: 845...  Training loss: 2.3930...  0.0563 sec/batch
Epoch: 2/20...  Training Step: 846...  Training loss: 2.4365...  0.0553 sec/batch
Epoch: 2/20...  Training Step: 847...  Training loss: 2.4215...  0.0546 sec/batch
Epoch: 2/20...  Training Step: 848...  Training loss: 2.3717...  0.0587 sec/batch
Epoch: 2/20...  Training Step: 849...  Training loss: 2.4393...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 850...  Training loss: 2.3872...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 851...  Training loss: 2.4072...  0.0530 sec/batch
Epoch: 2/20...  Training Step: 852...  Training loss: 2.4203...  0.0555 sec/batch
Epoch: 2/20...  Training Step: 853...  Training loss: 2.3924...  0.0552 sec/batch
Epoch: 2/20...  Training Step: 854...  Training loss: 2.3797...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 855...  Training loss: 2.3945...  0.0590 sec/batch
Epoch: 2/20...  Training Step: 856...  Training loss: 2.4140...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 857...  Training loss: 2.3859...  0.0563 sec/batch
Epoch: 2/20...  Training Step: 858...  Training loss: 2.3381...  0.0600 sec/batch
Epoch: 2/20...  Training Step: 859...  Training loss: 2.3664...  0.0551 sec/batch
Epoch: 2/20...  Training Step: 860...  Training loss: 2.4124...  0.0561 sec/batch
Epoch: 2/20...  Training Step: 861...  Training loss: 2.4060...  0.0547 sec/batch
Epoch: 2/20...  Training Step: 862...  Training loss: 2.3748...  0.0535 sec/batch
Epoch: 2/20...  Training Step: 863...  Training loss: 2.3827...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 864...  Training loss: 2.3937...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 865...  Training loss: 2.3532...  0.0564 sec/batch
Epoch: 2/20...  Training Step: 866...  Training loss: 2.4003...  0.0522 sec/batch
Epoch: 2/20...  Training Step: 867...  Training loss: 2.3915...  0.0670 sec/batch
Epoch: 2/20...  Training Step: 868...  Training loss: 2.3956...  0.0555 sec/batch
Epoch: 2/20...  Training Step: 869...  Training loss: 2.3591...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 870...  Training loss: 2.3853...  0.0549 sec/batch
Epoch: 2/20...  Training Step: 871...  Training loss: 2.3731...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 872...  Training loss: 2.3391...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 873...  Training loss: 2.3971...  0.0559 sec/batch
Epoch: 2/20...  Training Step: 874...  Training loss: 2.3969...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 875...  Training loss: 2.4099...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 876...  Training loss: 2.3974...  0.0544 sec/batch
Epoch: 2/20...  Training Step: 877...  Training loss: 2.3958...  0.0572 sec/batch
Epoch: 2/20...  Training Step: 878...  Training loss: 2.4074...  0.0534 sec/batch
Epoch: 2/20...  Training Step: 879...  Training loss: 2.3932...  0.0590 sec/batch
Epoch: 2/20...  Training Step: 880...  Training loss: 2.3417...  0.0534 sec/batch
Epoch: 2/20...  Training Step: 881...  Training loss: 2.3736...  0.0525 sec/batch
Epoch: 2/20...  Training Step: 882...  Training loss: 2.3706...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 883...  Training loss: 2.3829...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 884...  Training loss: 2.4202...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 885...  Training loss: 2.4176...  0.0582 sec/batch
Epoch: 2/20...  Training Step: 886...  Training loss: 2.3347...  0.0610 sec/batch
Epoch: 2/20...  Training Step: 887...  Training loss: 2.4060...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 888...  Training loss: 2.3783...  0.0555 sec/batch
Epoch: 2/20...  Training Step: 889...  Training loss: 2.3894...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 890...  Training loss: 2.3824...  0.0559 sec/batch
Epoch: 2/20...  Training Step: 891...  Training loss: 2.3920...  0.0552 sec/batch
Epoch: 2/20...  Training Step: 892...  Training loss: 2.3634...  0.0546 sec/batch
Epoch: 2/20...  Training Step: 893...  Training loss: 2.3746...  0.0542 sec/batch
Epoch: 2/20...  Training Step: 894...  Training loss: 2.3522...  0.0593 sec/batch
Epoch: 2/20...  Training Step: 895...  Training loss: 2.3741...  0.0539 sec/batch
Epoch: 2/20...  Training Step: 896...  Training loss: 2.3972...  0.0562 sec/batch
Epoch: 2/20...  Training Step: 897...  Training loss: 2.3944...  0.0541 sec/batch
Epoch: 2/20...  Training Step: 898...  Training loss: 2.3543...  0.0545 sec/batch
Epoch: 2/20...  Training Step: 899...  Training loss: 2.4024...  0.0531 sec/batch
Epoch: 2/20...  Training Step: 900...  Training loss: 2.4325...  0.0558 sec/batch
Epoch: 2/20...  Training Step: 901...  Training loss: 2.3618...  0.0538 sec/batch
Epoch: 2/20...  Training Step: 902...  Training loss: 2.3317...  0.0523 sec/batch
Epoch: 2/20...  Training Step: 903...  Training loss: 2.3852...  0.0573 sec/batch
Epoch: 2/20...  Training Step: 904...  Training loss: 2.3466...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 905...  Training loss: 2.3243...  0.0534 sec/batch
Epoch: 2/20...  Training Step: 906...  Training loss: 2.3438...  0.0533 sec/batch
Epoch: 2/20...  Training Step: 907...  Training loss: 2.3414...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 908...  Training loss: 2.3627...  0.0533 sec/batch
Epoch: 2/20...  Training Step: 909...  Training loss: 2.3803...  0.0551 sec/batch
Epoch: 2/20...  Training Step: 910...  Training loss: 2.3880...  0.0575 sec/batch
Epoch: 2/20...  Training Step: 911...  Training loss: 2.3792...  0.0531 sec/batch
Epoch: 2/20...  Training Step: 912...  Training loss: 2.3861...  0.0565 sec/batch
Epoch: 2/20...  Training Step: 913...  Training loss: 2.4007...  0.0547 sec/batch
Epoch: 2/20...  Training Step: 914...  Training loss: 2.3498...  0.0602 sec/batch
Epoch: 2/20...  Training Step: 915...  Training loss: 2.3576...  0.0538 sec/batch
Epoch: 2/20...  Training Step: 916...  Training loss: 2.3551...  0.0561 sec/batch
Epoch: 2/20...  Training Step: 917...  Training loss: 2.3872...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 918...  Training loss: 2.3784...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 919...  Training loss: 2.4209...  0.0574 sec/batch
Epoch: 2/20...  Training Step: 920...  Training loss: 2.3690...  0.0550 sec/batch
Epoch: 2/20...  Training Step: 921...  Training loss: 2.3560...  0.0570 sec/batch
Epoch: 2/20...  Training Step: 922...  Training loss: 2.4055...  0.0562 sec/batch
Epoch: 2/20...  Training Step: 923...  Training loss: 2.3477...  0.0601 sec/batch
Epoch: 2/20...  Training Step: 924...  Training loss: 2.3789...  0.0530 sec/batch
Epoch: 2/20...  Training Step: 925...  Training loss: 2.3760...  0.0544 sec/batch
Epoch: 2/20...  Training Step: 926...  Training loss: 2.4077...  0.0552 sec/batch
Epoch: 2/20...  Training Step: 927...  Training loss: 2.3697...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 928...  Training loss: 2.3299...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 929...  Training loss: 2.3827...  0.0602 sec/batch
Epoch: 2/20...  Training Step: 930...  Training loss: 2.3157...  0.0575 sec/batch
Epoch: 2/20...  Training Step: 931...  Training loss: 2.3555...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 932...  Training loss: 2.3753...  0.0550 sec/batch
Epoch: 2/20...  Training Step: 933...  Training loss: 2.3578...  0.0582 sec/batch
Epoch: 2/20...  Training Step: 934...  Training loss: 2.3463...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 935...  Training loss: 2.3766...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 936...  Training loss: 2.3676...  0.0558 sec/batch
Epoch: 2/20...  Training Step: 937...  Training loss: 2.3204...  0.0534 sec/batch
Epoch: 2/20...  Training Step: 938...  Training loss: 2.3447...  0.0559 sec/batch
Epoch: 2/20...  Training Step: 939...  Training loss: 2.3715...  0.0652 sec/batch
Epoch: 2/20...  Training Step: 940...  Training loss: 2.4027...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 941...  Training loss: 2.3460...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 942...  Training loss: 2.3313...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 943...  Training loss: 2.3537...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 944...  Training loss: 2.3409...  0.0531 sec/batch
Epoch: 2/20...  Training Step: 945...  Training loss: 2.3338...  0.0548 sec/batch
Epoch: 2/20...  Training Step: 946...  Training loss: 2.3546...  0.0592 sec/batch
Epoch: 2/20...  Training Step: 947...  Training loss: 2.3239...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 948...  Training loss: 2.3084...  0.0577 sec/batch
Epoch: 2/20...  Training Step: 949...  Training loss: 2.3666...  0.0542 sec/batch
Epoch: 2/20...  Training Step: 950...  Training loss: 2.3100...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 951...  Training loss: 2.3655...  0.0559 sec/batch
Epoch: 2/20...  Training Step: 952...  Training loss: 2.3440...  0.0594 sec/batch
Epoch: 2/20...  Training Step: 953...  Training loss: 2.3112...  0.0536 sec/batch
Epoch: 2/20...  Training Step: 954...  Training loss: 2.3187...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 955...  Training loss: 2.3394...  0.0576 sec/batch
Epoch: 2/20...  Training Step: 956...  Training loss: 2.3571...  0.0549 sec/batch
Epoch: 2/20...  Training Step: 957...  Training loss: 2.3314...  0.0567 sec/batch
Epoch: 2/20...  Training Step: 958...  Training loss: 2.3490...  0.0606 sec/batch
Epoch: 2/20...  Training Step: 959...  Training loss: 2.3383...  0.0583 sec/batch
Epoch: 2/20...  Training Step: 960...  Training loss: 2.3695...  0.0569 sec/batch
Epoch: 2/20...  Training Step: 961...  Training loss: 2.3666...  0.0540 sec/batch
Epoch: 2/20...  Training Step: 962...  Training loss: 2.3534...  0.0541 sec/batch
Epoch: 2/20...  Training Step: 963...  Training loss: 2.3583...  0.0547 sec/batch
Epoch: 2/20...  Training Step: 964...  Training loss: 2.3389...  0.0559 sec/batch
Epoch: 2/20...  Training Step: 965...  Training loss: 2.3263...  0.0609 sec/batch
Epoch: 2/20...  Training Step: 966...  Training loss: 2.4011...  0.0596 sec/batch
Epoch: 2/20...  Training Step: 967...  Training loss: 2.3486...  0.0594 sec/batch
Epoch: 2/20...  Training Step: 968...  Training loss: 2.3260...  0.0566 sec/batch
Epoch: 2/20...  Training Step: 969...  Training loss: 2.3256...  0.0533 sec/batch
Epoch: 2/20...  Training Step: 970...  Training loss: 2.2957...  0.0535 sec/batch
Epoch: 2/20...  Training Step: 971...  Training loss: 2.3452...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 972...  Training loss: 2.3271...  0.0562 sec/batch
Epoch: 2/20...  Training Step: 973...  Training loss: 2.3710...  0.0601 sec/batch
Epoch: 2/20...  Training Step: 974...  Training loss: 2.3215...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 975...  Training loss: 2.3339...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 976...  Training loss: 2.3971...  0.0551 sec/batch
Epoch: 2/20...  Training Step: 977...  Training loss: 2.4300...  0.0592 sec/batch
Epoch: 2/20...  Training Step: 978...  Training loss: 2.3855...  0.0566 sec/batch
Epoch: 2/20...  Training Step: 979...  Training loss: 2.3316...  0.0593 sec/batch
Epoch: 2/20...  Training Step: 980...  Training loss: 2.3566...  0.0583 sec/batch
Epoch: 2/20...  Training Step: 981...  Training loss: 2.3962...  0.0573 sec/batch
Epoch: 2/20...  Training Step: 982...  Training loss: 2.3594...  0.0550 sec/batch
Epoch: 2/20...  Training Step: 983...  Training loss: 2.2905...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 984...  Training loss: 2.3046...  0.0572 sec/batch
Epoch: 2/20...  Training Step: 985...  Training loss: 2.3524...  0.0549 sec/batch
Epoch: 2/20...  Training Step: 986...  Training loss: 2.3681...  0.0531 sec/batch
Epoch: 2/20...  Training Step: 987...  Training loss: 2.3497...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 988...  Training loss: 2.3855...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 989...  Training loss: 2.3622...  0.0562 sec/batch
Epoch: 2/20...  Training Step: 990...  Training loss: 2.3500...  0.0534 sec/batch
Epoch: 2/20...  Training Step: 991...  Training loss: 2.3866...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 992...  Training loss: 2.4063...  0.0539 sec/batch
Epoch: 2/20...  Training Step: 993...  Training loss: 2.3663...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 994...  Training loss: 2.3523...  0.0533 sec/batch
Epoch: 2/20...  Training Step: 995...  Training loss: 2.3280...  0.0536 sec/batch
Epoch: 2/20...  Training Step: 996...  Training loss: 2.3735...  0.0533 sec/batch
Epoch: 2/20...  Training Step: 997...  Training loss: 2.3421...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 998...  Training loss: 2.3806...  0.0540 sec/batch
Epoch: 2/20...  Training Step: 999...  Training loss: 2.3831...  0.0567 sec/batch
Epoch: 2/20...  Training Step: 1000...  Training loss: 2.3150...  0.0550 sec/batch
Epoch: 2/20...  Training Step: 1001...  Training loss: 2.2941...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 1002...  Training loss: 2.3782...  0.0580 sec/batch
Epoch: 2/20...  Training Step: 1003...  Training loss: 2.3148...  0.0572 sec/batch
Epoch: 2/20...  Training Step: 1004...  Training loss: 2.3541...  0.0605 sec/batch
Epoch: 2/20...  Training Step: 1005...  Training loss: 2.3561...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 1006...  Training loss: 2.3090...  0.0527 sec/batch
Epoch: 2/20...  Training Step: 1007...  Training loss: 2.3014...  0.0596 sec/batch
Epoch: 2/20...  Training Step: 1008...  Training loss: 2.3603...  0.0552 sec/batch
Epoch: 2/20...  Training Step: 1009...  Training loss: 2.2715...  0.0569 sec/batch
Epoch: 2/20...  Training Step: 1010...  Training loss: 2.3030...  0.0553 sec/batch
Epoch: 2/20...  Training Step: 1011...  Training loss: 2.3737...  0.0525 sec/batch
Epoch: 2/20...  Training Step: 1012...  Training loss: 2.2827...  0.0583 sec/batch
Epoch: 2/20...  Training Step: 1013...  Training loss: 2.3358...  0.0592 sec/batch
Epoch: 2/20...  Training Step: 1014...  Training loss: 2.3317...  0.0583 sec/batch
Epoch: 2/20...  Training Step: 1015...  Training loss: 2.3329...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 1016...  Training loss: 2.3214...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 1017...  Training loss: 2.3281...  0.0570 sec/batch
Epoch: 2/20...  Training Step: 1018...  Training loss: 2.3502...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 1019...  Training loss: 2.3193...  0.0594 sec/batch
Epoch: 2/20...  Training Step: 1020...  Training loss: 2.3484...  0.0530 sec/batch
Epoch: 2/20...  Training Step: 1021...  Training loss: 2.3493...  0.0587 sec/batch
Epoch: 2/20...  Training Step: 1022...  Training loss: 2.3361...  0.0567 sec/batch
Epoch: 2/20...  Training Step: 1023...  Training loss: 2.3564...  0.0635 sec/batch
Epoch: 2/20...  Training Step: 1024...  Training loss: 2.3467...  0.0565 sec/batch
Epoch: 2/20...  Training Step: 1025...  Training loss: 2.3691...  0.0537 sec/batch
Epoch: 2/20...  Training Step: 1026...  Training loss: 2.3728...  0.0530 sec/batch
Epoch: 2/20...  Training Step: 1027...  Training loss: 2.3840...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 1028...  Training loss: 2.3152...  0.0598 sec/batch
Epoch: 2/20...  Training Step: 1029...  Training loss: 2.3728...  0.0558 sec/batch
Epoch: 2/20...  Training Step: 1030...  Training loss: 2.3317...  0.0521 sec/batch
Epoch: 2/20...  Training Step: 1031...  Training loss: 2.3255...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 1032...  Training loss: 2.3682...  0.0620 sec/batch
Epoch: 2/20...  Training Step: 1033...  Training loss: 2.3256...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 1034...  Training loss: 2.3464...  0.0595 sec/batch
Epoch: 2/20...  Training Step: 1035...  Training loss: 2.2893...  0.0547 sec/batch
Epoch: 2/20...  Training Step: 1036...  Training loss: 2.2992...  0.0533 sec/batch
Epoch: 2/20...  Training Step: 1037...  Training loss: 2.3172...  0.0540 sec/batch
Epoch: 2/20...  Training Step: 1038...  Training loss: 2.3559...  0.0555 sec/batch
Epoch: 2/20...  Training Step: 1039...  Training loss: 2.3564...  0.0564 sec/batch
Epoch: 2/20...  Training Step: 1040...  Training loss: 2.3555...  0.0533 sec/batch
Epoch: 2/20...  Training Step: 1041...  Training loss: 2.2957...  0.0547 sec/batch
Epoch: 2/20...  Training Step: 1042...  Training loss: 2.3184...  0.0592 sec/batch
Epoch: 2/20...  Training Step: 1043...  Training loss: 2.3541...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 1044...  Training loss: 2.3510...  0.0565 sec/batch
Epoch: 2/20...  Training Step: 1045...  Training loss: 2.3631...  0.0559 sec/batch
Epoch: 2/20...  Training Step: 1046...  Training loss: 2.3567...  0.0550 sec/batch
Epoch: 2/20...  Training Step: 1047...  Training loss: 2.3299...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 1048...  Training loss: 2.2919...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 1049...  Training loss: 2.3320...  0.0562 sec/batch
Epoch: 2/20...  Training Step: 1050...  Training loss: 2.3057...  0.0574 sec/batch
Epoch: 2/20...  Training Step: 1051...  Training loss: 2.3230...  0.0535 sec/batch
Epoch: 2/20...  Training Step: 1052...  Training loss: 2.3705...  0.0535 sec/batch
Epoch: 2/20...  Training Step: 1053...  Training loss: 2.3502...  0.0558 sec/batch
Epoch: 2/20...  Training Step: 1054...  Training loss: 2.3126...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 1055...  Training loss: 2.3185...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 1056...  Training loss: 2.3329...  0.0555 sec/batch
Epoch: 2/20...  Training Step: 1057...  Training loss: 2.2864...  0.0635 sec/batch
Epoch: 2/20...  Training Step: 1058...  Training loss: 2.3509...  0.0543 sec/batch
Epoch: 2/20...  Training Step: 1059...  Training loss: 2.3277...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 1060...  Training loss: 2.2924...  0.0555 sec/batch
Epoch: 2/20...  Training Step: 1061...  Training loss: 2.3216...  0.0535 sec/batch
Epoch: 2/20...  Training Step: 1062...  Training loss: 2.2943...  0.0522 sec/batch
Epoch: 2/20...  Training Step: 1063...  Training loss: 2.3663...  0.0593 sec/batch
Epoch: 2/20...  Training Step: 1064...  Training loss: 2.3180...  0.0579 sec/batch
Epoch: 2/20...  Training Step: 1065...  Training loss: 2.3282...  0.0563 sec/batch
Epoch: 2/20...  Training Step: 1066...  Training loss: 2.3094...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 1067...  Training loss: 2.3329...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 1068...  Training loss: 2.3092...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 1069...  Training loss: 2.3295...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 1070...  Training loss: 2.3514...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 1071...  Training loss: 2.3979...  0.0568 sec/batch
Epoch: 2/20...  Training Step: 1072...  Training loss: 2.3222...  0.0535 sec/batch
Epoch: 2/20...  Training Step: 1073...  Training loss: 2.2986...  0.0568 sec/batch
Epoch: 2/20...  Training Step: 1074...  Training loss: 2.3147...  0.0581 sec/batch
Epoch: 2/20...  Training Step: 1075...  Training loss: 2.2875...  0.0555 sec/batch
Epoch: 2/20...  Training Step: 1076...  Training loss: 2.3544...  0.0530 sec/batch
Epoch: 2/20...  Training Step: 1077...  Training loss: 2.3124...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 1078...  Training loss: 2.3673...  0.0522 sec/batch
Epoch: 2/20...  Training Step: 1079...  Training loss: 2.3308...  0.0525 sec/batch
Epoch: 2/20...  Training Step: 1080...  Training loss: 2.3312...  0.0545 sec/batch
Epoch: 2/20...  Training Step: 1081...  Training loss: 2.2996...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 1082...  Training loss: 2.3429...  0.0558 sec/batch
Epoch: 2/20...  Training Step: 1083...  Training loss: 2.3099...  0.0552 sec/batch
Epoch: 2/20...  Training Step: 1084...  Training loss: 2.3242...  0.0555 sec/batch
Epoch: 2/20...  Training Step: 1085...  Training loss: 2.3521...  0.0576 sec/batch
Epoch: 2/20...  Training Step: 1086...  Training loss: 2.3321...  0.0533 sec/batch
Epoch: 2/20...  Training Step: 1087...  Training loss: 2.3187...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 1088...  Training loss: 2.3752...  0.0573 sec/batch
Epoch: 2/20...  Training Step: 1089...  Training loss: 2.4386...  0.0525 sec/batch
Epoch: 2/20...  Training Step: 1090...  Training loss: 2.4109...  0.0547 sec/batch
Epoch: 2/20...  Training Step: 1091...  Training loss: 2.3991...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 1092...  Training loss: 2.3545...  0.0555 sec/batch
Epoch: 2/20...  Training Step: 1093...  Training loss: 2.3541...  0.0591 sec/batch
Epoch: 2/20...  Training Step: 1094...  Training loss: 2.3397...  0.0527 sec/batch
Epoch: 2/20...  Training Step: 1095...  Training loss: 2.4067...  0.0553 sec/batch
Epoch: 2/20...  Training Step: 1096...  Training loss: 2.4074...  0.0576 sec/batch
Epoch: 2/20...  Training Step: 1097...  Training loss: 2.3644...  0.0536 sec/batch
Epoch: 2/20...  Training Step: 1098...  Training loss: 2.4216...  0.0520 sec/batch
Epoch: 2/20...  Training Step: 1099...  Training loss: 2.3200...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 1100...  Training loss: 2.3851...  0.0590 sec/batch
Epoch: 2/20...  Training Step: 1101...  Training loss: 2.3663...  0.0590 sec/batch
Epoch: 2/20...  Training Step: 1102...  Training loss: 2.3381...  0.0559 sec/batch
Epoch: 2/20...  Training Step: 1103...  Training loss: 2.3548...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 1104...  Training loss: 2.3704...  0.0609 sec/batch
Epoch: 2/20...  Training Step: 1105...  Training loss: 2.3946...  0.0562 sec/batch
Epoch: 2/20...  Training Step: 1106...  Training loss: 2.3364...  0.0531 sec/batch
Epoch: 2/20...  Training Step: 1107...  Training loss: 2.3851...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 1108...  Training loss: 2.3523...  0.0562 sec/batch
Epoch: 2/20...  Training Step: 1109...  Training loss: 2.3721...  0.0530 sec/batch
Epoch: 2/20...  Training Step: 1110...  Training loss: 2.3509...  0.0530 sec/batch
Epoch: 2/20...  Training Step: 1111...  Training loss: 2.3638...  0.0576 sec/batch
Epoch: 2/20...  Training Step: 1112...  Training loss: 2.3992...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 1113...  Training loss: 2.3431...  0.0559 sec/batch
Epoch: 2/20...  Training Step: 1114...  Training loss: 2.3694...  0.0547 sec/batch
Epoch: 2/20...  Training Step: 1115...  Training loss: 2.3637...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 1116...  Training loss: 2.3633...  0.0552 sec/batch
Epoch: 2/20...  Training Step: 1117...  Training loss: 2.3230...  0.0540 sec/batch
Epoch: 2/20...  Training Step: 1118...  Training loss: 2.3479...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 1119...  Training loss: 2.3183...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 1120...  Training loss: 2.3394...  0.0546 sec/batch
Epoch: 2/20...  Training Step: 1121...  Training loss: 2.3342...  0.0588 sec/batch
Epoch: 2/20...  Training Step: 1122...  Training loss: 2.3795...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 1123...  Training loss: 2.4095...  0.0552 sec/batch
Epoch: 2/20...  Training Step: 1124...  Training loss: 2.3402...  0.0572 sec/batch
Epoch: 2/20...  Training Step: 1125...  Training loss: 2.3415...  0.0533 sec/batch
Epoch: 2/20...  Training Step: 1126...  Training loss: 2.3050...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 1127...  Training loss: 2.3524...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 1128...  Training loss: 2.3259...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 1129...  Training loss: 2.3413...  0.0581 sec/batch
Epoch: 2/20...  Training Step: 1130...  Training loss: 2.3297...  0.0555 sec/batch
Epoch: 2/20...  Training Step: 1131...  Training loss: 2.3391...  0.0594 sec/batch
Epoch: 2/20...  Training Step: 1132...  Training loss: 2.2946...  0.0551 sec/batch
Epoch: 2/20...  Training Step: 1133...  Training loss: 2.4094...  0.0582 sec/batch
Epoch: 2/20...  Training Step: 1134...  Training loss: 2.3695...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 1135...  Training loss: 2.3565...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 1136...  Training loss: 2.3463...  0.0589 sec/batch
Epoch: 2/20...  Training Step: 1137...  Training loss: 2.3092...  0.0592 sec/batch
Epoch: 2/20...  Training Step: 1138...  Training loss: 2.3321...  0.0546 sec/batch
Epoch: 2/20...  Training Step: 1139...  Training loss: 2.3155...  0.0593 sec/batch
Epoch: 2/20...  Training Step: 1140...  Training loss: 2.3176...  0.0558 sec/batch
Epoch: 2/20...  Training Step: 1141...  Training loss: 2.3159...  0.0536 sec/batch
Epoch: 2/20...  Training Step: 1142...  Training loss: 2.2937...  0.0548 sec/batch
Epoch: 2/20...  Training Step: 1143...  Training loss: 2.3518...  0.0553 sec/batch
Epoch: 2/20...  Training Step: 1144...  Training loss: 2.2346...  0.0543 sec/batch
Epoch: 2/20...  Training Step: 1145...  Training loss: 2.3066...  0.0585 sec/batch
Epoch: 2/20...  Training Step: 1146...  Training loss: 2.3190...  0.0583 sec/batch
Epoch: 2/20...  Training Step: 1147...  Training loss: 2.3295...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 1148...  Training loss: 2.3375...  0.0551 sec/batch
Epoch: 2/20...  Training Step: 1149...  Training loss: 2.3026...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 1150...  Training loss: 2.2956...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 1151...  Training loss: 2.3350...  0.0568 sec/batch
Epoch: 2/20...  Training Step: 1152...  Training loss: 2.2933...  0.0628 sec/batch
Epoch: 2/20...  Training Step: 1153...  Training loss: 2.3200...  0.0611 sec/batch
Epoch: 2/20...  Training Step: 1154...  Training loss: 2.2943...  0.0531 sec/batch
Epoch: 2/20...  Training Step: 1155...  Training loss: 2.3196...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 1156...  Training loss: 2.3243...  0.0552 sec/batch
Epoch: 2/20...  Training Step: 1157...  Training loss: 2.2752...  0.0561 sec/batch
Epoch: 2/20...  Training Step: 1158...  Training loss: 2.3725...  0.0527 sec/batch
Epoch: 2/20...  Training Step: 1159...  Training loss: 2.2747...  0.0522 sec/batch
Epoch: 2/20...  Training Step: 1160...  Training loss: 2.3624...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 1161...  Training loss: 2.3375...  0.0559 sec/batch
Epoch: 2/20...  Training Step: 1162...  Training loss: 2.3315...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 1163...  Training loss: 2.2990...  0.0534 sec/batch
Epoch: 2/20...  Training Step: 1164...  Training loss: 2.2868...  0.0535 sec/batch
Epoch: 2/20...  Training Step: 1165...  Training loss: 2.3241...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 1166...  Training loss: 2.3230...  0.0570 sec/batch
Epoch: 2/20...  Training Step: 1167...  Training loss: 2.3150...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 1168...  Training loss: 2.3660...  0.0558 sec/batch
Epoch: 2/20...  Training Step: 1169...  Training loss: 2.3624...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 1170...  Training loss: 2.3457...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 1171...  Training loss: 2.2904...  0.0552 sec/batch
Epoch: 2/20...  Training Step: 1172...  Training loss: 2.3119...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 1173...  Training loss: 2.3158...  0.0558 sec/batch
Epoch: 2/20...  Training Step: 1174...  Training loss: 2.3438...  0.0527 sec/batch
Epoch: 2/20...  Training Step: 1175...  Training loss: 2.3188...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 1176...  Training loss: 2.2842...  0.0600 sec/batch
Epoch: 2/20...  Training Step: 1177...  Training loss: 2.3102...  0.0558 sec/batch
Epoch: 2/20...  Training Step: 1178...  Training loss: 2.3142...  0.0530 sec/batch
Epoch: 2/20...  Training Step: 1179...  Training loss: 2.3219...  0.0527 sec/batch
Epoch: 2/20...  Training Step: 1180...  Training loss: 2.3119...  0.0527 sec/batch
Epoch: 2/20...  Training Step: 1181...  Training loss: 2.3118...  0.0553 sec/batch
Epoch: 2/20...  Training Step: 1182...  Training loss: 2.3294...  0.0557 sec/batch
Epoch: 2/20...  Training Step: 1183...  Training loss: 2.3240...  0.0600 sec/batch
Epoch: 2/20...  Training Step: 1184...  Training loss: 2.3491...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 1185...  Training loss: 2.3932...  0.0543 sec/batch
Epoch: 2/20...  Training Step: 1186...  Training loss: 2.3264...  0.0595 sec/batch
Epoch: 2/20...  Training Step: 1187...  Training loss: 2.3432...  0.0551 sec/batch
Epoch: 2/20...  Training Step: 1188...  Training loss: 2.3658...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 1189...  Training loss: 2.3453...  0.0566 sec/batch
Epoch: 2/20...  Training Step: 1190...  Training loss: 2.3235...  0.0534 sec/batch
Epoch: 2/20...  Training Step: 1191...  Training loss: 2.3099...  0.0524 sec/batch
Epoch: 2/20...  Training Step: 1192...  Training loss: 2.3619...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 1193...  Training loss: 2.3101...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 1194...  Training loss: 2.3003...  0.0535 sec/batch
Epoch: 2/20...  Training Step: 1195...  Training loss: 2.3084...  0.0539 sec/batch
Epoch: 2/20...  Training Step: 1196...  Training loss: 2.3847...  0.0529 sec/batch
Epoch: 2/20...  Training Step: 1197...  Training loss: 2.3116...  0.0592 sec/batch
Epoch: 2/20...  Training Step: 1198...  Training loss: 2.3297...  0.0523 sec/batch
Epoch: 2/20...  Training Step: 1199...  Training loss: 2.3681...  0.0553 sec/batch
Epoch: 2/20...  Training Step: 1200...  Training loss: 2.3573...  0.0605 sec/batch
Epoch: 2/20...  Training Step: 1201...  Training loss: 2.3372...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 1202...  Training loss: 2.3089...  0.0531 sec/batch
Epoch: 2/20...  Training Step: 1203...  Training loss: 2.3087...  0.0532 sec/batch
Epoch: 2/20...  Training Step: 1204...  Training loss: 2.3519...  0.0526 sec/batch
Epoch: 2/20...  Training Step: 1205...  Training loss: 2.3165...  0.0585 sec/batch
Epoch: 2/20...  Training Step: 1206...  Training loss: 2.3093...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 1207...  Training loss: 2.2724...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 1208...  Training loss: 2.3202...  0.0577 sec/batch
Epoch: 2/20...  Training Step: 1209...  Training loss: 2.2639...  0.0555 sec/batch
Epoch: 2/20...  Training Step: 1210...  Training loss: 2.3686...  0.0567 sec/batch
Epoch: 2/20...  Training Step: 1211...  Training loss: 2.2592...  0.0578 sec/batch
Epoch: 2/20...  Training Step: 1212...  Training loss: 2.3463...  0.0527 sec/batch
Epoch: 2/20...  Training Step: 1213...  Training loss: 2.2960...  0.0602 sec/batch
Epoch: 2/20...  Training Step: 1214...  Training loss: 2.2749...  0.0530 sec/batch
Epoch: 2/20...  Training Step: 1215...  Training loss: 2.2871...  0.0547 sec/batch
Epoch: 2/20...  Training Step: 1216...  Training loss: 2.2868...  0.0574 sec/batch
Epoch: 2/20...  Training Step: 1217...  Training loss: 2.2741...  0.0564 sec/batch
Epoch: 2/20...  Training Step: 1218...  Training loss: 2.3019...  0.0588 sec/batch
Epoch: 2/20...  Training Step: 1219...  Training loss: 2.3214...  0.0553 sec/batch
Epoch: 2/20...  Training Step: 1220...  Training loss: 2.3424...  0.0530 sec/batch
Epoch: 2/20...  Training Step: 1221...  Training loss: 2.3057...  0.0560 sec/batch
Epoch: 2/20...  Training Step: 1222...  Training loss: 2.3221...  0.0546 sec/batch
Epoch: 2/20...  Training Step: 1223...  Training loss: 2.3384...  0.0531 sec/batch
Epoch: 2/20...  Training Step: 1224...  Training loss: 2.2764...  0.0584 sec/batch
Epoch: 2/20...  Training Step: 1225...  Training loss: 2.3014...  0.0542 sec/batch
Epoch: 2/20...  Training Step: 1226...  Training loss: 2.2745...  0.0553 sec/batch
Epoch: 2/20...  Training Step: 1227...  Training loss: 2.2734...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 1228...  Training loss: 2.2975...  0.0554 sec/batch
Epoch: 2/20...  Training Step: 1229...  Training loss: 2.2791...  0.0548 sec/batch
Epoch: 2/20...  Training Step: 1230...  Training loss: 2.3138...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 1231...  Training loss: 2.3050...  0.0566 sec/batch
Epoch: 2/20...  Training Step: 1232...  Training loss: 2.3315...  0.0574 sec/batch
Epoch: 2/20...  Training Step: 1233...  Training loss: 2.2871...  0.0567 sec/batch
Epoch: 2/20...  Training Step: 1234...  Training loss: 2.3074...  0.0548 sec/batch
Epoch: 2/20...  Training Step: 1235...  Training loss: 2.2786...  0.0567 sec/batch
Epoch: 2/20...  Training Step: 1236...  Training loss: 2.3353...  0.0528 sec/batch
Epoch: 2/20...  Training Step: 1237...  Training loss: 2.3355...  0.0523 sec/batch
Epoch: 2/20...  Training Step: 1238...  Training loss: 2.2729...  0.0556 sec/batch
Epoch: 2/20...  Training Step: 1239...  Training loss: 2.2705...  0.0568 sec/batch
Epoch: 2/20...  Training Step: 1240...  Training loss: 2.2856...  0.0526 sec/batch
Epoch: 3/20...  Training Step: 1241...  Training loss: 2.4156...  0.0562 sec/batch
Epoch: 3/20...  Training Step: 1242...  Training loss: 2.3488...  0.0532 sec/batch
Epoch: 3/20...  Training Step: 1243...  Training loss: 2.3251...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1244...  Training loss: 2.2695...  0.0564 sec/batch
Epoch: 3/20...  Training Step: 1245...  Training loss: 2.3100...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1246...  Training loss: 2.2951...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1247...  Training loss: 2.2684...  0.0567 sec/batch
Epoch: 3/20...  Training Step: 1248...  Training loss: 2.2439...  0.0581 sec/batch
Epoch: 3/20...  Training Step: 1249...  Training loss: 2.2317...  0.0564 sec/batch
Epoch: 3/20...  Training Step: 1250...  Training loss: 2.2688...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1251...  Training loss: 2.2693...  0.0521 sec/batch
Epoch: 3/20...  Training Step: 1252...  Training loss: 2.2501...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1253...  Training loss: 2.3325...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1254...  Training loss: 2.2616...  0.0548 sec/batch
Epoch: 3/20...  Training Step: 1255...  Training loss: 2.2842...  0.0588 sec/batch
Epoch: 3/20...  Training Step: 1256...  Training loss: 2.3128...  0.0526 sec/batch
Epoch: 3/20...  Training Step: 1257...  Training loss: 2.3173...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1258...  Training loss: 2.3029...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1259...  Training loss: 2.2473...  0.0552 sec/batch
Epoch: 3/20...  Training Step: 1260...  Training loss: 2.2986...  0.0525 sec/batch
Epoch: 3/20...  Training Step: 1261...  Training loss: 2.3168...  0.0550 sec/batch
Epoch: 3/20...  Training Step: 1262...  Training loss: 2.2645...  0.0547 sec/batch
Epoch: 3/20...  Training Step: 1263...  Training loss: 2.2631...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1264...  Training loss: 2.2956...  0.0549 sec/batch
Epoch: 3/20...  Training Step: 1265...  Training loss: 2.2724...  0.0532 sec/batch
Epoch: 3/20...  Training Step: 1266...  Training loss: 2.2889...  0.0517 sec/batch
Epoch: 3/20...  Training Step: 1267...  Training loss: 2.2860...  0.0587 sec/batch
Epoch: 3/20...  Training Step: 1268...  Training loss: 2.2779...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1269...  Training loss: 2.3146...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1270...  Training loss: 2.2422...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1271...  Training loss: 2.2442...  0.0526 sec/batch
Epoch: 3/20...  Training Step: 1272...  Training loss: 2.2843...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1273...  Training loss: 2.2600...  0.0562 sec/batch
Epoch: 3/20...  Training Step: 1274...  Training loss: 2.2710...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1275...  Training loss: 2.2571...  0.0560 sec/batch
Epoch: 3/20...  Training Step: 1276...  Training loss: 2.2722...  0.0550 sec/batch
Epoch: 3/20...  Training Step: 1277...  Training loss: 2.2561...  0.0595 sec/batch
Epoch: 3/20...  Training Step: 1278...  Training loss: 2.2694...  0.0524 sec/batch
Epoch: 3/20...  Training Step: 1279...  Training loss: 2.2683...  0.0552 sec/batch
Epoch: 3/20...  Training Step: 1280...  Training loss: 2.2607...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1281...  Training loss: 2.2523...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1282...  Training loss: 2.2762...  0.0559 sec/batch
Epoch: 3/20...  Training Step: 1283...  Training loss: 2.2254...  0.0544 sec/batch
Epoch: 3/20...  Training Step: 1284...  Training loss: 2.2918...  0.0550 sec/batch
Epoch: 3/20...  Training Step: 1285...  Training loss: 2.2650...  0.0560 sec/batch
Epoch: 3/20...  Training Step: 1286...  Training loss: 2.2498...  0.0577 sec/batch
Epoch: 3/20...  Training Step: 1287...  Training loss: 2.1994...  0.0525 sec/batch
Epoch: 3/20...  Training Step: 1288...  Training loss: 2.2869...  0.0552 sec/batch
Epoch: 3/20...  Training Step: 1289...  Training loss: 2.2922...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1290...  Training loss: 2.2742...  0.0525 sec/batch
Epoch: 3/20...  Training Step: 1291...  Training loss: 2.2172...  0.0584 sec/batch
Epoch: 3/20...  Training Step: 1292...  Training loss: 2.2728...  0.0594 sec/batch
Epoch: 3/20...  Training Step: 1293...  Training loss: 2.2778...  0.0578 sec/batch
Epoch: 3/20...  Training Step: 1294...  Training loss: 2.3240...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1295...  Training loss: 2.3079...  0.0586 sec/batch
Epoch: 3/20...  Training Step: 1296...  Training loss: 2.2520...  0.0525 sec/batch
Epoch: 3/20...  Training Step: 1297...  Training loss: 2.2583...  0.0563 sec/batch
Epoch: 3/20...  Training Step: 1298...  Training loss: 2.2869...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1299...  Training loss: 2.2542...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1300...  Training loss: 2.2960...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1301...  Training loss: 2.2876...  0.0536 sec/batch
Epoch: 3/20...  Training Step: 1302...  Training loss: 2.2527...  0.0525 sec/batch
Epoch: 3/20...  Training Step: 1303...  Training loss: 2.2966...  0.0589 sec/batch
Epoch: 3/20...  Training Step: 1304...  Training loss: 2.2577...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1305...  Training loss: 2.2351...  0.0562 sec/batch
Epoch: 3/20...  Training Step: 1306...  Training loss: 2.2244...  0.0526 sec/batch
Epoch: 3/20...  Training Step: 1307...  Training loss: 2.2176...  0.0573 sec/batch
Epoch: 3/20...  Training Step: 1308...  Training loss: 2.2162...  0.0556 sec/batch
Epoch: 3/20...  Training Step: 1309...  Training loss: 2.2811...  0.0562 sec/batch
Epoch: 3/20...  Training Step: 1310...  Training loss: 2.2348...  0.0548 sec/batch
Epoch: 3/20...  Training Step: 1311...  Training loss: 2.2503...  0.0558 sec/batch
Epoch: 3/20...  Training Step: 1312...  Training loss: 2.2646...  0.0527 sec/batch
Epoch: 3/20...  Training Step: 1313...  Training loss: 2.2595...  0.0524 sec/batch
Epoch: 3/20...  Training Step: 1314...  Training loss: 2.2503...  0.0543 sec/batch
Epoch: 3/20...  Training Step: 1315...  Training loss: 2.2836...  0.0555 sec/batch
Epoch: 3/20...  Training Step: 1316...  Training loss: 2.2602...  0.0555 sec/batch
Epoch: 3/20...  Training Step: 1317...  Training loss: 2.3237...  0.0571 sec/batch
Epoch: 3/20...  Training Step: 1318...  Training loss: 2.2421...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1319...  Training loss: 2.2867...  0.0589 sec/batch
Epoch: 3/20...  Training Step: 1320...  Training loss: 2.2860...  0.0555 sec/batch
Epoch: 3/20...  Training Step: 1321...  Training loss: 2.2547...  0.0603 sec/batch
Epoch: 3/20...  Training Step: 1322...  Training loss: 2.2258...  0.0560 sec/batch
Epoch: 3/20...  Training Step: 1323...  Training loss: 2.2375...  0.0549 sec/batch
Epoch: 3/20...  Training Step: 1324...  Training loss: 2.2733...  0.0525 sec/batch
Epoch: 3/20...  Training Step: 1325...  Training loss: 2.2687...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1326...  Training loss: 2.2654...  0.0527 sec/batch
Epoch: 3/20...  Training Step: 1327...  Training loss: 2.2558...  0.0530 sec/batch
Epoch: 3/20...  Training Step: 1328...  Training loss: 2.3205...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1329...  Training loss: 2.2709...  0.0585 sec/batch
Epoch: 3/20...  Training Step: 1330...  Training loss: 2.2919...  0.0527 sec/batch
Epoch: 3/20...  Training Step: 1331...  Training loss: 2.2386...  0.0581 sec/batch
Epoch: 3/20...  Training Step: 1332...  Training loss: 2.3087...  0.0524 sec/batch
Epoch: 3/20...  Training Step: 1333...  Training loss: 2.2740...  0.0556 sec/batch
Epoch: 3/20...  Training Step: 1334...  Training loss: 2.2553...  0.0549 sec/batch
Epoch: 3/20...  Training Step: 1335...  Training loss: 2.2816...  0.0551 sec/batch
Epoch: 3/20...  Training Step: 1336...  Training loss: 2.2360...  0.0593 sec/batch
Epoch: 3/20...  Training Step: 1337...  Training loss: 2.2796...  0.0576 sec/batch
Epoch: 3/20...  Training Step: 1338...  Training loss: 2.2220...  0.0561 sec/batch
Epoch: 3/20...  Training Step: 1339...  Training loss: 2.3161...  0.0559 sec/batch
Epoch: 3/20...  Training Step: 1340...  Training loss: 2.2385...  0.0560 sec/batch
Epoch: 3/20...  Training Step: 1341...  Training loss: 2.2502...  0.0536 sec/batch
Epoch: 3/20...  Training Step: 1342...  Training loss: 2.2688...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1343...  Training loss: 2.2827...  0.0556 sec/batch
Epoch: 3/20...  Training Step: 1344...  Training loss: 2.2693...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1345...  Training loss: 2.2577...  0.0530 sec/batch
Epoch: 3/20...  Training Step: 1346...  Training loss: 2.2419...  0.0562 sec/batch
Epoch: 3/20...  Training Step: 1347...  Training loss: 2.2678...  0.0556 sec/batch
Epoch: 3/20...  Training Step: 1348...  Training loss: 2.2691...  0.0542 sec/batch
Epoch: 3/20...  Training Step: 1349...  Training loss: 2.2180...  0.0558 sec/batch
Epoch: 3/20...  Training Step: 1350...  Training loss: 2.2473...  0.0548 sec/batch
Epoch: 3/20...  Training Step: 1351...  Training loss: 2.2277...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1352...  Training loss: 2.2668...  0.0561 sec/batch
Epoch: 3/20...  Training Step: 1353...  Training loss: 2.2436...  0.0540 sec/batch
Epoch: 3/20...  Training Step: 1354...  Training loss: 2.2562...  0.0577 sec/batch
Epoch: 3/20...  Training Step: 1355...  Training loss: 2.2755...  0.0595 sec/batch
Epoch: 3/20...  Training Step: 1356...  Training loss: 2.2665...  0.0564 sec/batch
Epoch: 3/20...  Training Step: 1357...  Training loss: 2.2390...  0.0613 sec/batch
Epoch: 3/20...  Training Step: 1358...  Training loss: 2.2891...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1359...  Training loss: 2.2340...  0.0530 sec/batch
Epoch: 3/20...  Training Step: 1360...  Training loss: 2.2256...  0.0560 sec/batch
Epoch: 3/20...  Training Step: 1361...  Training loss: 2.2395...  0.0575 sec/batch
Epoch: 3/20...  Training Step: 1362...  Training loss: 2.2058...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1363...  Training loss: 2.2371...  0.0561 sec/batch
Epoch: 3/20...  Training Step: 1364...  Training loss: 2.2546...  0.0579 sec/batch
Epoch: 3/20...  Training Step: 1365...  Training loss: 2.2692...  0.0589 sec/batch
Epoch: 3/20...  Training Step: 1366...  Training loss: 2.3087...  0.0527 sec/batch
Epoch: 3/20...  Training Step: 1367...  Training loss: 2.2756...  0.0538 sec/batch
Epoch: 3/20...  Training Step: 1368...  Training loss: 2.2204...  0.0581 sec/batch
Epoch: 3/20...  Training Step: 1369...  Training loss: 2.1978...  0.0609 sec/batch
Epoch: 3/20...  Training Step: 1370...  Training loss: 2.2910...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1371...  Training loss: 2.2052...  0.0550 sec/batch
Epoch: 3/20...  Training Step: 1372...  Training loss: 2.2905...  0.0590 sec/batch
Epoch: 3/20...  Training Step: 1373...  Training loss: 2.2903...  0.0571 sec/batch
Epoch: 3/20...  Training Step: 1374...  Training loss: 2.2450...  0.0613 sec/batch
Epoch: 3/20...  Training Step: 1375...  Training loss: 2.1952...  0.0577 sec/batch
Epoch: 3/20...  Training Step: 1376...  Training loss: 2.2498...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1377...  Training loss: 2.2326...  0.0566 sec/batch
Epoch: 3/20...  Training Step: 1378...  Training loss: 2.2524...  0.0581 sec/batch
Epoch: 3/20...  Training Step: 1379...  Training loss: 2.2963...  0.0539 sec/batch
Epoch: 3/20...  Training Step: 1380...  Training loss: 2.2273...  0.0525 sec/batch
Epoch: 3/20...  Training Step: 1381...  Training loss: 2.2590...  0.0580 sec/batch
Epoch: 3/20...  Training Step: 1382...  Training loss: 2.2105...  0.0599 sec/batch
Epoch: 3/20...  Training Step: 1383...  Training loss: 2.2589...  0.0564 sec/batch
Epoch: 3/20...  Training Step: 1384...  Training loss: 2.2371...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1385...  Training loss: 2.2179...  0.0563 sec/batch
Epoch: 3/20...  Training Step: 1386...  Training loss: 2.2718...  0.0540 sec/batch
Epoch: 3/20...  Training Step: 1387...  Training loss: 2.2383...  0.0527 sec/batch
Epoch: 3/20...  Training Step: 1388...  Training loss: 2.2908...  0.0555 sec/batch
Epoch: 3/20...  Training Step: 1389...  Training loss: 2.2184...  0.0547 sec/batch
Epoch: 3/20...  Training Step: 1390...  Training loss: 2.2519...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1391...  Training loss: 2.2546...  0.0525 sec/batch
Epoch: 3/20...  Training Step: 1392...  Training loss: 2.2538...  0.0611 sec/batch
Epoch: 3/20...  Training Step: 1393...  Training loss: 2.2286...  0.0576 sec/batch
Epoch: 3/20...  Training Step: 1394...  Training loss: 2.2791...  0.0549 sec/batch
Epoch: 3/20...  Training Step: 1395...  Training loss: 2.2206...  0.0563 sec/batch
Epoch: 3/20...  Training Step: 1396...  Training loss: 2.2450...  0.0594 sec/batch
Epoch: 3/20...  Training Step: 1397...  Training loss: 2.2084...  0.0573 sec/batch
Epoch: 3/20...  Training Step: 1398...  Training loss: 2.2831...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1399...  Training loss: 2.2914...  0.0547 sec/batch
Epoch: 3/20...  Training Step: 1400...  Training loss: 2.2123...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1401...  Training loss: 2.2218...  0.0605 sec/batch
Epoch: 3/20...  Training Step: 1402...  Training loss: 2.2368...  0.0576 sec/batch
Epoch: 3/20...  Training Step: 1403...  Training loss: 2.2252...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1404...  Training loss: 2.2347...  0.0556 sec/batch
Epoch: 3/20...  Training Step: 1405...  Training loss: 2.2481...  0.0589 sec/batch
Epoch: 3/20...  Training Step: 1406...  Training loss: 2.1857...  0.0591 sec/batch
Epoch: 3/20...  Training Step: 1407...  Training loss: 2.2710...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1408...  Training loss: 2.2268...  0.0521 sec/batch
Epoch: 3/20...  Training Step: 1409...  Training loss: 2.2238...  0.0541 sec/batch
Epoch: 3/20...  Training Step: 1410...  Training loss: 2.2366...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1411...  Training loss: 2.2212...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1412...  Training loss: 2.2367...  0.0568 sec/batch
Epoch: 3/20...  Training Step: 1413...  Training loss: 2.2591...  0.0569 sec/batch
Epoch: 3/20...  Training Step: 1414...  Training loss: 2.2565...  0.0568 sec/batch
Epoch: 3/20...  Training Step: 1415...  Training loss: 2.2317...  0.0580 sec/batch
Epoch: 3/20...  Training Step: 1416...  Training loss: 2.2431...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1417...  Training loss: 2.2535...  0.0577 sec/batch
Epoch: 3/20...  Training Step: 1418...  Training loss: 2.2764...  0.0600 sec/batch
Epoch: 3/20...  Training Step: 1419...  Training loss: 2.2140...  0.0607 sec/batch
Epoch: 3/20...  Training Step: 1420...  Training loss: 2.2345...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1421...  Training loss: 2.2496...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1422...  Training loss: 2.2449...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1423...  Training loss: 2.2549...  0.0537 sec/batch
Epoch: 3/20...  Training Step: 1424...  Training loss: 2.1777...  0.0583 sec/batch
Epoch: 3/20...  Training Step: 1425...  Training loss: 2.2205...  0.0579 sec/batch
Epoch: 3/20...  Training Step: 1426...  Training loss: 2.2443...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1427...  Training loss: 2.2014...  0.0559 sec/batch
Epoch: 3/20...  Training Step: 1428...  Training loss: 2.2137...  0.0532 sec/batch
Epoch: 3/20...  Training Step: 1429...  Training loss: 2.2462...  0.0581 sec/batch
Epoch: 3/20...  Training Step: 1430...  Training loss: 2.2918...  0.0538 sec/batch
Epoch: 3/20...  Training Step: 1431...  Training loss: 2.3061...  0.0558 sec/batch
Epoch: 3/20...  Training Step: 1432...  Training loss: 2.3087...  0.0549 sec/batch
Epoch: 3/20...  Training Step: 1433...  Training loss: 2.2760...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1434...  Training loss: 2.2072...  0.0586 sec/batch
Epoch: 3/20...  Training Step: 1435...  Training loss: 2.2451...  0.0561 sec/batch
Epoch: 3/20...  Training Step: 1436...  Training loss: 2.3069...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1437...  Training loss: 2.2612...  0.0608 sec/batch
Epoch: 3/20...  Training Step: 1438...  Training loss: 2.2709...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1439...  Training loss: 2.2151...  0.0597 sec/batch
Epoch: 3/20...  Training Step: 1440...  Training loss: 2.2332...  0.0537 sec/batch
Epoch: 3/20...  Training Step: 1441...  Training loss: 2.2448...  0.0592 sec/batch
Epoch: 3/20...  Training Step: 1442...  Training loss: 2.2300...  0.0562 sec/batch
Epoch: 3/20...  Training Step: 1443...  Training loss: 2.2095...  0.0549 sec/batch
Epoch: 3/20...  Training Step: 1444...  Training loss: 2.2310...  0.0539 sec/batch
Epoch: 3/20...  Training Step: 1445...  Training loss: 2.2340...  0.0560 sec/batch
Epoch: 3/20...  Training Step: 1446...  Training loss: 2.2019...  0.0530 sec/batch
Epoch: 3/20...  Training Step: 1447...  Training loss: 2.2537...  0.0539 sec/batch
Epoch: 3/20...  Training Step: 1448...  Training loss: 2.2236...  0.0559 sec/batch
Epoch: 3/20...  Training Step: 1449...  Training loss: 2.2349...  0.0547 sec/batch
Epoch: 3/20...  Training Step: 1450...  Training loss: 2.2300...  0.0593 sec/batch
Epoch: 3/20...  Training Step: 1451...  Training loss: 2.2347...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1452...  Training loss: 2.2441...  0.0530 sec/batch
Epoch: 3/20...  Training Step: 1453...  Training loss: 2.2585...  0.0618 sec/batch
Epoch: 3/20...  Training Step: 1454...  Training loss: 2.2788...  0.0596 sec/batch
Epoch: 3/20...  Training Step: 1455...  Training loss: 2.2483...  0.0573 sec/batch
Epoch: 3/20...  Training Step: 1456...  Training loss: 2.2307...  0.0562 sec/batch
Epoch: 3/20...  Training Step: 1457...  Training loss: 2.2234...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1458...  Training loss: 2.2054...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1459...  Training loss: 2.2990...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1460...  Training loss: 2.2486...  0.0561 sec/batch
Epoch: 3/20...  Training Step: 1461...  Training loss: 2.2215...  0.0544 sec/batch
Epoch: 3/20...  Training Step: 1462...  Training loss: 2.2396...  0.0556 sec/batch
Epoch: 3/20...  Training Step: 1463...  Training loss: 2.2787...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1464...  Training loss: 2.2056...  0.0582 sec/batch
Epoch: 3/20...  Training Step: 1465...  Training loss: 2.2149...  0.0567 sec/batch
Epoch: 3/20...  Training Step: 1466...  Training loss: 2.2663...  0.0551 sec/batch
Epoch: 3/20...  Training Step: 1467...  Training loss: 2.2709...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1468...  Training loss: 2.1901...  0.0552 sec/batch
Epoch: 3/20...  Training Step: 1469...  Training loss: 2.2623...  0.0540 sec/batch
Epoch: 3/20...  Training Step: 1470...  Training loss: 2.2343...  0.0558 sec/batch
Epoch: 3/20...  Training Step: 1471...  Training loss: 2.2710...  0.0580 sec/batch
Epoch: 3/20...  Training Step: 1472...  Training loss: 2.2553...  0.0567 sec/batch
Epoch: 3/20...  Training Step: 1473...  Training loss: 2.2154...  0.0586 sec/batch
Epoch: 3/20...  Training Step: 1474...  Training loss: 2.2178...  0.0586 sec/batch
Epoch: 3/20...  Training Step: 1475...  Training loss: 2.2248...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1476...  Training loss: 2.2589...  0.0552 sec/batch
Epoch: 3/20...  Training Step: 1477...  Training loss: 2.2462...  0.0563 sec/batch
Epoch: 3/20...  Training Step: 1478...  Training loss: 2.1814...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1479...  Training loss: 2.1995...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1480...  Training loss: 2.2606...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1481...  Training loss: 2.2486...  0.0530 sec/batch
Epoch: 3/20...  Training Step: 1482...  Training loss: 2.2334...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1483...  Training loss: 2.2140...  0.0552 sec/batch
Epoch: 3/20...  Training Step: 1484...  Training loss: 2.2200...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1485...  Training loss: 2.2101...  0.0544 sec/batch
Epoch: 3/20...  Training Step: 1486...  Training loss: 2.2270...  0.0550 sec/batch
Epoch: 3/20...  Training Step: 1487...  Training loss: 2.2427...  0.0560 sec/batch
Epoch: 3/20...  Training Step: 1488...  Training loss: 2.2196...  0.0558 sec/batch
Epoch: 3/20...  Training Step: 1489...  Training loss: 2.1902...  0.0580 sec/batch
Epoch: 3/20...  Training Step: 1490...  Training loss: 2.2236...  0.0591 sec/batch
Epoch: 3/20...  Training Step: 1491...  Training loss: 2.2116...  0.0582 sec/batch
Epoch: 3/20...  Training Step: 1492...  Training loss: 2.1713...  0.0527 sec/batch
Epoch: 3/20...  Training Step: 1493...  Training loss: 2.2247...  0.0573 sec/batch
Epoch: 3/20...  Training Step: 1494...  Training loss: 2.2370...  0.0555 sec/batch
Epoch: 3/20...  Training Step: 1495...  Training loss: 2.2583...  0.0545 sec/batch
Epoch: 3/20...  Training Step: 1496...  Training loss: 2.2285...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1497...  Training loss: 2.2202...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1498...  Training loss: 2.2304...  0.0556 sec/batch
Epoch: 3/20...  Training Step: 1499...  Training loss: 2.2393...  0.0524 sec/batch
Epoch: 3/20...  Training Step: 1500...  Training loss: 2.1985...  0.0589 sec/batch
Epoch: 3/20...  Training Step: 1501...  Training loss: 2.2166...  0.0563 sec/batch
Epoch: 3/20...  Training Step: 1502...  Training loss: 2.2175...  0.0587 sec/batch
Epoch: 3/20...  Training Step: 1503...  Training loss: 2.2475...  0.0583 sec/batch
Epoch: 3/20...  Training Step: 1504...  Training loss: 2.2481...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1505...  Training loss: 2.2477...  0.0585 sec/batch
Epoch: 3/20...  Training Step: 1506...  Training loss: 2.1696...  0.0538 sec/batch
Epoch: 3/20...  Training Step: 1507...  Training loss: 2.2490...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1508...  Training loss: 2.2323...  0.0591 sec/batch
Epoch: 3/20...  Training Step: 1509...  Training loss: 2.2201...  0.0619 sec/batch
Epoch: 3/20...  Training Step: 1510...  Training loss: 2.2051...  0.0536 sec/batch
Epoch: 3/20...  Training Step: 1511...  Training loss: 2.2115...  0.0551 sec/batch
Epoch: 3/20...  Training Step: 1512...  Training loss: 2.2274...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1513...  Training loss: 2.2287...  0.0610 sec/batch
Epoch: 3/20...  Training Step: 1514...  Training loss: 2.1949...  0.0576 sec/batch
Epoch: 3/20...  Training Step: 1515...  Training loss: 2.2181...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1516...  Training loss: 2.2936...  0.0532 sec/batch
Epoch: 3/20...  Training Step: 1517...  Training loss: 2.2750...  0.0537 sec/batch
Epoch: 3/20...  Training Step: 1518...  Training loss: 2.2138...  0.0550 sec/batch
Epoch: 3/20...  Training Step: 1519...  Training loss: 2.2441...  0.0548 sec/batch
Epoch: 3/20...  Training Step: 1520...  Training loss: 2.2830...  0.0571 sec/batch
Epoch: 3/20...  Training Step: 1521...  Training loss: 2.2276...  0.0547 sec/batch
Epoch: 3/20...  Training Step: 1522...  Training loss: 2.1777...  0.0564 sec/batch
Epoch: 3/20...  Training Step: 1523...  Training loss: 2.2126...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1524...  Training loss: 2.2264...  0.0536 sec/batch
Epoch: 3/20...  Training Step: 1525...  Training loss: 2.1760...  0.0626 sec/batch
Epoch: 3/20...  Training Step: 1526...  Training loss: 2.2166...  0.0600 sec/batch
Epoch: 3/20...  Training Step: 1527...  Training loss: 2.1940...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1528...  Training loss: 2.2080...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1529...  Training loss: 2.2348...  0.0542 sec/batch
Epoch: 3/20...  Training Step: 1530...  Training loss: 2.2381...  0.0532 sec/batch
Epoch: 3/20...  Training Step: 1531...  Training loss: 2.2152...  0.0593 sec/batch
Epoch: 3/20...  Training Step: 1532...  Training loss: 2.2220...  0.0559 sec/batch
Epoch: 3/20...  Training Step: 1533...  Training loss: 2.2322...  0.0563 sec/batch
Epoch: 3/20...  Training Step: 1534...  Training loss: 2.2158...  0.0537 sec/batch
Epoch: 3/20...  Training Step: 1535...  Training loss: 2.1903...  0.0542 sec/batch
Epoch: 3/20...  Training Step: 1536...  Training loss: 2.2036...  0.0615 sec/batch
Epoch: 3/20...  Training Step: 1537...  Training loss: 2.2409...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1538...  Training loss: 2.2306...  0.0574 sec/batch
Epoch: 3/20...  Training Step: 1539...  Training loss: 2.2617...  0.0541 sec/batch
Epoch: 3/20...  Training Step: 1540...  Training loss: 2.2125...  0.0559 sec/batch
Epoch: 3/20...  Training Step: 1541...  Training loss: 2.1955...  0.0590 sec/batch
Epoch: 3/20...  Training Step: 1542...  Training loss: 2.2650...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1543...  Training loss: 2.1885...  0.0639 sec/batch
Epoch: 3/20...  Training Step: 1544...  Training loss: 2.2109...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1545...  Training loss: 2.2187...  0.0608 sec/batch
Epoch: 3/20...  Training Step: 1546...  Training loss: 2.2302...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1547...  Training loss: 2.2060...  0.0576 sec/batch
Epoch: 3/20...  Training Step: 1548...  Training loss: 2.1731...  0.0579 sec/batch
Epoch: 3/20...  Training Step: 1549...  Training loss: 2.2383...  0.0539 sec/batch
Epoch: 3/20...  Training Step: 1550...  Training loss: 2.1788...  0.0536 sec/batch
Epoch: 3/20...  Training Step: 1551...  Training loss: 2.1921...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1552...  Training loss: 2.2309...  0.0573 sec/batch
Epoch: 3/20...  Training Step: 1553...  Training loss: 2.2161...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1554...  Training loss: 2.2006...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1555...  Training loss: 2.2164...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1556...  Training loss: 2.2257...  0.0555 sec/batch
Epoch: 3/20...  Training Step: 1557...  Training loss: 2.1743...  0.0594 sec/batch
Epoch: 3/20...  Training Step: 1558...  Training loss: 2.1847...  0.0532 sec/batch
Epoch: 3/20...  Training Step: 1559...  Training loss: 2.2180...  0.0527 sec/batch
Epoch: 3/20...  Training Step: 1560...  Training loss: 2.2660...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1561...  Training loss: 2.2163...  0.0618 sec/batch
Epoch: 3/20...  Training Step: 1562...  Training loss: 2.1672...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1563...  Training loss: 2.2095...  0.0571 sec/batch
Epoch: 3/20...  Training Step: 1564...  Training loss: 2.1977...  0.0565 sec/batch
Epoch: 3/20...  Training Step: 1565...  Training loss: 2.1662...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1566...  Training loss: 2.1894...  0.0568 sec/batch
Epoch: 3/20...  Training Step: 1567...  Training loss: 2.1613...  0.0558 sec/batch
Epoch: 3/20...  Training Step: 1568...  Training loss: 2.1581...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1569...  Training loss: 2.2261...  0.0592 sec/batch
Epoch: 3/20...  Training Step: 1570...  Training loss: 2.1717...  0.0555 sec/batch
Epoch: 3/20...  Training Step: 1571...  Training loss: 2.2230...  0.0634 sec/batch
Epoch: 3/20...  Training Step: 1572...  Training loss: 2.1703...  0.0550 sec/batch
Epoch: 3/20...  Training Step: 1573...  Training loss: 2.1652...  0.0546 sec/batch
Epoch: 3/20...  Training Step: 1574...  Training loss: 2.1866...  0.0549 sec/batch
Epoch: 3/20...  Training Step: 1575...  Training loss: 2.2103...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1576...  Training loss: 2.2105...  0.0559 sec/batch
Epoch: 3/20...  Training Step: 1577...  Training loss: 2.1961...  0.0566 sec/batch
Epoch: 3/20...  Training Step: 1578...  Training loss: 2.1797...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1579...  Training loss: 2.1784...  0.0564 sec/batch
Epoch: 3/20...  Training Step: 1580...  Training loss: 2.2180...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1581...  Training loss: 2.1991...  0.0561 sec/batch
Epoch: 3/20...  Training Step: 1582...  Training loss: 2.2245...  0.0561 sec/batch
Epoch: 3/20...  Training Step: 1583...  Training loss: 2.1961...  0.0558 sec/batch
Epoch: 3/20...  Training Step: 1584...  Training loss: 2.1903...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1585...  Training loss: 2.1950...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1586...  Training loss: 2.2268...  0.0532 sec/batch
Epoch: 3/20...  Training Step: 1587...  Training loss: 2.2167...  0.0524 sec/batch
Epoch: 3/20...  Training Step: 1588...  Training loss: 2.1801...  0.0562 sec/batch
Epoch: 3/20...  Training Step: 1589...  Training loss: 2.1750...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1590...  Training loss: 2.1508...  0.0588 sec/batch
Epoch: 3/20...  Training Step: 1591...  Training loss: 2.1979...  0.0538 sec/batch
Epoch: 3/20...  Training Step: 1592...  Training loss: 2.1967...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1593...  Training loss: 2.2220...  0.0530 sec/batch
Epoch: 3/20...  Training Step: 1594...  Training loss: 2.1694...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1595...  Training loss: 2.2104...  0.0570 sec/batch
Epoch: 3/20...  Training Step: 1596...  Training loss: 2.2566...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1597...  Training loss: 2.2950...  0.0622 sec/batch
Epoch: 3/20...  Training Step: 1598...  Training loss: 2.2520...  0.0589 sec/batch
Epoch: 3/20...  Training Step: 1599...  Training loss: 2.1977...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1600...  Training loss: 2.2200...  0.0566 sec/batch
Epoch: 3/20...  Training Step: 1601...  Training loss: 2.2243...  0.0569 sec/batch
Epoch: 3/20...  Training Step: 1602...  Training loss: 2.2040...  0.0530 sec/batch
Epoch: 3/20...  Training Step: 1603...  Training loss: 2.1484...  0.0538 sec/batch
Epoch: 3/20...  Training Step: 1604...  Training loss: 2.1464...  0.0550 sec/batch
Epoch: 3/20...  Training Step: 1605...  Training loss: 2.1865...  0.0562 sec/batch
Epoch: 3/20...  Training Step: 1606...  Training loss: 2.2115...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1607...  Training loss: 2.1901...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1608...  Training loss: 2.2573...  0.0539 sec/batch
Epoch: 3/20...  Training Step: 1609...  Training loss: 2.2002...  0.0537 sec/batch
Epoch: 3/20...  Training Step: 1610...  Training loss: 2.1800...  0.0594 sec/batch
Epoch: 3/20...  Training Step: 1611...  Training loss: 2.2399...  0.0539 sec/batch
Epoch: 3/20...  Training Step: 1612...  Training loss: 2.2596...  0.0561 sec/batch
Epoch: 3/20...  Training Step: 1613...  Training loss: 2.2314...  0.0597 sec/batch
Epoch: 3/20...  Training Step: 1614...  Training loss: 2.2189...  0.0561 sec/batch
Epoch: 3/20...  Training Step: 1615...  Training loss: 2.1705...  0.0540 sec/batch
Epoch: 3/20...  Training Step: 1616...  Training loss: 2.2313...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1617...  Training loss: 2.1914...  0.0577 sec/batch
Epoch: 3/20...  Training Step: 1618...  Training loss: 2.2663...  0.0542 sec/batch
Epoch: 3/20...  Training Step: 1619...  Training loss: 2.2201...  0.0589 sec/batch
Epoch: 3/20...  Training Step: 1620...  Training loss: 2.2018...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1621...  Training loss: 2.1545...  0.0581 sec/batch
Epoch: 3/20...  Training Step: 1622...  Training loss: 2.2533...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1623...  Training loss: 2.1591...  0.0558 sec/batch
Epoch: 3/20...  Training Step: 1624...  Training loss: 2.2193...  0.0532 sec/batch
Epoch: 3/20...  Training Step: 1625...  Training loss: 2.2032...  0.0556 sec/batch
Epoch: 3/20...  Training Step: 1626...  Training loss: 2.1614...  0.0571 sec/batch
Epoch: 3/20...  Training Step: 1627...  Training loss: 2.1713...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1628...  Training loss: 2.2561...  0.0602 sec/batch
Epoch: 3/20...  Training Step: 1629...  Training loss: 2.1482...  0.0565 sec/batch
Epoch: 3/20...  Training Step: 1630...  Training loss: 2.1705...  0.0582 sec/batch
Epoch: 3/20...  Training Step: 1631...  Training loss: 2.2188...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1632...  Training loss: 2.1403...  0.0573 sec/batch
Epoch: 3/20...  Training Step: 1633...  Training loss: 2.1861...  0.0538 sec/batch
Epoch: 3/20...  Training Step: 1634...  Training loss: 2.1739...  0.0552 sec/batch
Epoch: 3/20...  Training Step: 1635...  Training loss: 2.1687...  0.0569 sec/batch
Epoch: 3/20...  Training Step: 1636...  Training loss: 2.1846...  0.0571 sec/batch
Epoch: 3/20...  Training Step: 1637...  Training loss: 2.1940...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1638...  Training loss: 2.1981...  0.0526 sec/batch
Epoch: 3/20...  Training Step: 1639...  Training loss: 2.1811...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1640...  Training loss: 2.2058...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1641...  Training loss: 2.2010...  0.0539 sec/batch
Epoch: 3/20...  Training Step: 1642...  Training loss: 2.2128...  0.0587 sec/batch
Epoch: 3/20...  Training Step: 1643...  Training loss: 2.1889...  0.0525 sec/batch
Epoch: 3/20...  Training Step: 1644...  Training loss: 2.2305...  0.0539 sec/batch
Epoch: 3/20...  Training Step: 1645...  Training loss: 2.2358...  0.0591 sec/batch
Epoch: 3/20...  Training Step: 1646...  Training loss: 2.2349...  0.0565 sec/batch
Epoch: 3/20...  Training Step: 1647...  Training loss: 2.2322...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1648...  Training loss: 2.1849...  0.0559 sec/batch
Epoch: 3/20...  Training Step: 1649...  Training loss: 2.2129...  0.0538 sec/batch
Epoch: 3/20...  Training Step: 1650...  Training loss: 2.2122...  0.0556 sec/batch
Epoch: 3/20...  Training Step: 1651...  Training loss: 2.1790...  0.0564 sec/batch
Epoch: 3/20...  Training Step: 1652...  Training loss: 2.2186...  0.0532 sec/batch
Epoch: 3/20...  Training Step: 1653...  Training loss: 2.2014...  0.0564 sec/batch
Epoch: 3/20...  Training Step: 1654...  Training loss: 2.2083...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1655...  Training loss: 2.1382...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1656...  Training loss: 2.1505...  0.0565 sec/batch
Epoch: 3/20...  Training Step: 1657...  Training loss: 2.1728...  0.0628 sec/batch
Epoch: 3/20...  Training Step: 1658...  Training loss: 2.2027...  0.0564 sec/batch
Epoch: 3/20...  Training Step: 1659...  Training loss: 2.2123...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1660...  Training loss: 2.2025...  0.0584 sec/batch
Epoch: 3/20...  Training Step: 1661...  Training loss: 2.1624...  0.0536 sec/batch
Epoch: 3/20...  Training Step: 1662...  Training loss: 2.1887...  0.0594 sec/batch
Epoch: 3/20...  Training Step: 1663...  Training loss: 2.2370...  0.0602 sec/batch
Epoch: 3/20...  Training Step: 1664...  Training loss: 2.1973...  0.0624 sec/batch
Epoch: 3/20...  Training Step: 1665...  Training loss: 2.2326...  0.0580 sec/batch
Epoch: 3/20...  Training Step: 1666...  Training loss: 2.2109...  0.0593 sec/batch
Epoch: 3/20...  Training Step: 1667...  Training loss: 2.1762...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1668...  Training loss: 2.2049...  0.0556 sec/batch
Epoch: 3/20...  Training Step: 1669...  Training loss: 2.1946...  0.0555 sec/batch
Epoch: 3/20...  Training Step: 1670...  Training loss: 2.1474...  0.0563 sec/batch
Epoch: 3/20...  Training Step: 1671...  Training loss: 2.1668...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1672...  Training loss: 2.2135...  0.0522 sec/batch
Epoch: 3/20...  Training Step: 1673...  Training loss: 2.1929...  0.0599 sec/batch
Epoch: 3/20...  Training Step: 1674...  Training loss: 2.1625...  0.0526 sec/batch
Epoch: 3/20...  Training Step: 1675...  Training loss: 2.1882...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1676...  Training loss: 2.1966...  0.0549 sec/batch
Epoch: 3/20...  Training Step: 1677...  Training loss: 2.1467...  0.0552 sec/batch
Epoch: 3/20...  Training Step: 1678...  Training loss: 2.1968...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1679...  Training loss: 2.2082...  0.0536 sec/batch
Epoch: 3/20...  Training Step: 1680...  Training loss: 2.1831...  0.0537 sec/batch
Epoch: 3/20...  Training Step: 1681...  Training loss: 2.1758...  0.0544 sec/batch
Epoch: 3/20...  Training Step: 1682...  Training loss: 2.1700...  0.0538 sec/batch
Epoch: 3/20...  Training Step: 1683...  Training loss: 2.2204...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1684...  Training loss: 2.1827...  0.0532 sec/batch
Epoch: 3/20...  Training Step: 1685...  Training loss: 2.1761...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1686...  Training loss: 2.1614...  0.0588 sec/batch
Epoch: 3/20...  Training Step: 1687...  Training loss: 2.1704...  0.0564 sec/batch
Epoch: 3/20...  Training Step: 1688...  Training loss: 2.1611...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1689...  Training loss: 2.2012...  0.0558 sec/batch
Epoch: 3/20...  Training Step: 1690...  Training loss: 2.2354...  0.0564 sec/batch
Epoch: 3/20...  Training Step: 1691...  Training loss: 2.2541...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1692...  Training loss: 2.1997...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1693...  Training loss: 2.1742...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1694...  Training loss: 2.1905...  0.0561 sec/batch
Epoch: 3/20...  Training Step: 1695...  Training loss: 2.1418...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1696...  Training loss: 2.2032...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1697...  Training loss: 2.1755...  0.0580 sec/batch
Epoch: 3/20...  Training Step: 1698...  Training loss: 2.2228...  0.0538 sec/batch
Epoch: 3/20...  Training Step: 1699...  Training loss: 2.1652...  0.0568 sec/batch
Epoch: 3/20...  Training Step: 1700...  Training loss: 2.2016...  0.0611 sec/batch
Epoch: 3/20...  Training Step: 1701...  Training loss: 2.1607...  0.0562 sec/batch
Epoch: 3/20...  Training Step: 1702...  Training loss: 2.1920...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1703...  Training loss: 2.1713...  0.0560 sec/batch
Epoch: 3/20...  Training Step: 1704...  Training loss: 2.1717...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1705...  Training loss: 2.2131...  0.0537 sec/batch
Epoch: 3/20...  Training Step: 1706...  Training loss: 2.1807...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1707...  Training loss: 2.1761...  0.0555 sec/batch
Epoch: 3/20...  Training Step: 1708...  Training loss: 2.1527...  0.0552 sec/batch
Epoch: 3/20...  Training Step: 1709...  Training loss: 2.2178...  0.0537 sec/batch
Epoch: 3/20...  Training Step: 1710...  Training loss: 2.1851...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1711...  Training loss: 2.1915...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1712...  Training loss: 2.1530...  0.0537 sec/batch
Epoch: 3/20...  Training Step: 1713...  Training loss: 2.1556...  0.0597 sec/batch
Epoch: 3/20...  Training Step: 1714...  Training loss: 2.1219...  0.0556 sec/batch
Epoch: 3/20...  Training Step: 1715...  Training loss: 2.2280...  0.0579 sec/batch
Epoch: 3/20...  Training Step: 1716...  Training loss: 2.2135...  0.0546 sec/batch
Epoch: 3/20...  Training Step: 1717...  Training loss: 2.1831...  0.0577 sec/batch
Epoch: 3/20...  Training Step: 1718...  Training loss: 2.2422...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1719...  Training loss: 2.1601...  0.0575 sec/batch
Epoch: 3/20...  Training Step: 1720...  Training loss: 2.2199...  0.0581 sec/batch
Epoch: 3/20...  Training Step: 1721...  Training loss: 2.2136...  0.0527 sec/batch
Epoch: 3/20...  Training Step: 1722...  Training loss: 2.1699...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1723...  Training loss: 2.1864...  0.0586 sec/batch
Epoch: 3/20...  Training Step: 1724...  Training loss: 2.1809...  0.0551 sec/batch
Epoch: 3/20...  Training Step: 1725...  Training loss: 2.2316...  0.0582 sec/batch
Epoch: 3/20...  Training Step: 1726...  Training loss: 2.1713...  0.0573 sec/batch
Epoch: 3/20...  Training Step: 1727...  Training loss: 2.2245...  0.0555 sec/batch
Epoch: 3/20...  Training Step: 1728...  Training loss: 2.1901...  0.0550 sec/batch
Epoch: 3/20...  Training Step: 1729...  Training loss: 2.1894...  0.0560 sec/batch
Epoch: 3/20...  Training Step: 1730...  Training loss: 2.1884...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1731...  Training loss: 2.1800...  0.0587 sec/batch
Epoch: 3/20...  Training Step: 1732...  Training loss: 2.2293...  0.0525 sec/batch
Epoch: 3/20...  Training Step: 1733...  Training loss: 2.1907...  0.0532 sec/batch
Epoch: 3/20...  Training Step: 1734...  Training loss: 2.1914...  0.0561 sec/batch
Epoch: 3/20...  Training Step: 1735...  Training loss: 2.1742...  0.0591 sec/batch
Epoch: 3/20...  Training Step: 1736...  Training loss: 2.2029...  0.0590 sec/batch
Epoch: 3/20...  Training Step: 1737...  Training loss: 2.1662...  0.0537 sec/batch
Epoch: 3/20...  Training Step: 1738...  Training loss: 2.1879...  0.0564 sec/batch
Epoch: 3/20...  Training Step: 1739...  Training loss: 2.1551...  0.0582 sec/batch
Epoch: 3/20...  Training Step: 1740...  Training loss: 2.1875...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1741...  Training loss: 2.1885...  0.0582 sec/batch
Epoch: 3/20...  Training Step: 1742...  Training loss: 2.2123...  0.0560 sec/batch
Epoch: 3/20...  Training Step: 1743...  Training loss: 2.2862...  0.0524 sec/batch
Epoch: 3/20...  Training Step: 1744...  Training loss: 2.1881...  0.0530 sec/batch
Epoch: 3/20...  Training Step: 1745...  Training loss: 2.1821...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1746...  Training loss: 2.1314...  0.0528 sec/batch
Epoch: 3/20...  Training Step: 1747...  Training loss: 2.2235...  0.0527 sec/batch
Epoch: 3/20...  Training Step: 1748...  Training loss: 2.1409...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1749...  Training loss: 2.2085...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1750...  Training loss: 2.1936...  0.0559 sec/batch
Epoch: 3/20...  Training Step: 1751...  Training loss: 2.1747...  0.0534 sec/batch
Epoch: 3/20...  Training Step: 1752...  Training loss: 2.1658...  0.0561 sec/batch
Epoch: 3/20...  Training Step: 1753...  Training loss: 2.2715...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1754...  Training loss: 2.2412...  0.0556 sec/batch
Epoch: 3/20...  Training Step: 1755...  Training loss: 2.1936...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1756...  Training loss: 2.1767...  0.0530 sec/batch
Epoch: 3/20...  Training Step: 1757...  Training loss: 2.1769...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1758...  Training loss: 2.1607...  0.0546 sec/batch
Epoch: 3/20...  Training Step: 1759...  Training loss: 2.1611...  0.0524 sec/batch
Epoch: 3/20...  Training Step: 1760...  Training loss: 2.1653...  0.0569 sec/batch
Epoch: 3/20...  Training Step: 1761...  Training loss: 2.1764...  0.0548 sec/batch
Epoch: 3/20...  Training Step: 1762...  Training loss: 2.1548...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1763...  Training loss: 2.1801...  0.0524 sec/batch
Epoch: 3/20...  Training Step: 1764...  Training loss: 2.1068...  0.0550 sec/batch
Epoch: 3/20...  Training Step: 1765...  Training loss: 2.1551...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1766...  Training loss: 2.2023...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1767...  Training loss: 2.2055...  0.0543 sec/batch
Epoch: 3/20...  Training Step: 1768...  Training loss: 2.1868...  0.0548 sec/batch
Epoch: 3/20...  Training Step: 1769...  Training loss: 2.1727...  0.0523 sec/batch
Epoch: 3/20...  Training Step: 1770...  Training loss: 2.1403...  0.0590 sec/batch
Epoch: 3/20...  Training Step: 1771...  Training loss: 2.1764...  0.0527 sec/batch
Epoch: 3/20...  Training Step: 1772...  Training loss: 2.1404...  0.0596 sec/batch
Epoch: 3/20...  Training Step: 1773...  Training loss: 2.1827...  0.0567 sec/batch
Epoch: 3/20...  Training Step: 1774...  Training loss: 2.1570...  0.0549 sec/batch
Epoch: 3/20...  Training Step: 1775...  Training loss: 2.1745...  0.0530 sec/batch
Epoch: 3/20...  Training Step: 1776...  Training loss: 2.1707...  0.0530 sec/batch
Epoch: 3/20...  Training Step: 1777...  Training loss: 2.1333...  0.0581 sec/batch
Epoch: 3/20...  Training Step: 1778...  Training loss: 2.2137...  0.0526 sec/batch
Epoch: 3/20...  Training Step: 1779...  Training loss: 2.1145...  0.0582 sec/batch
Epoch: 3/20...  Training Step: 1780...  Training loss: 2.2018...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1781...  Training loss: 2.1901...  0.0564 sec/batch
Epoch: 3/20...  Training Step: 1782...  Training loss: 2.1608...  0.0542 sec/batch
Epoch: 3/20...  Training Step: 1783...  Training loss: 2.1390...  0.0536 sec/batch
Epoch: 3/20...  Training Step: 1784...  Training loss: 2.1413...  0.0537 sec/batch
Epoch: 3/20...  Training Step: 1785...  Training loss: 2.1925...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1786...  Training loss: 2.1582...  0.0560 sec/batch
Epoch: 3/20...  Training Step: 1787...  Training loss: 2.1949...  0.0603 sec/batch
Epoch: 3/20...  Training Step: 1788...  Training loss: 2.2256...  0.0561 sec/batch
Epoch: 3/20...  Training Step: 1789...  Training loss: 2.2297...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1790...  Training loss: 2.1754...  0.0592 sec/batch
Epoch: 3/20...  Training Step: 1791...  Training loss: 2.1805...  0.0569 sec/batch
Epoch: 3/20...  Training Step: 1792...  Training loss: 2.1661...  0.0597 sec/batch
Epoch: 3/20...  Training Step: 1793...  Training loss: 2.1668...  0.0551 sec/batch
Epoch: 3/20...  Training Step: 1794...  Training loss: 2.1938...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1795...  Training loss: 2.1823...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1796...  Training loss: 2.1520...  0.0611 sec/batch
Epoch: 3/20...  Training Step: 1797...  Training loss: 2.1746...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1798...  Training loss: 2.1624...  0.0533 sec/batch
Epoch: 3/20...  Training Step: 1799...  Training loss: 2.1872...  0.0551 sec/batch
Epoch: 3/20...  Training Step: 1800...  Training loss: 2.1819...  0.0562 sec/batch
Epoch: 3/20...  Training Step: 1801...  Training loss: 2.1912...  0.0619 sec/batch
Epoch: 3/20...  Training Step: 1802...  Training loss: 2.2025...  0.0535 sec/batch
Epoch: 3/20...  Training Step: 1803...  Training loss: 2.1780...  0.0587 sec/batch
Epoch: 3/20...  Training Step: 1804...  Training loss: 2.2129...  0.0572 sec/batch
Epoch: 3/20...  Training Step: 1805...  Training loss: 2.2626...  0.0551 sec/batch
Epoch: 3/20...  Training Step: 1806...  Training loss: 2.1983...  0.0536 sec/batch
Epoch: 3/20...  Training Step: 1807...  Training loss: 2.1795...  0.0558 sec/batch
Epoch: 3/20...  Training Step: 1808...  Training loss: 2.2219...  0.0571 sec/batch
Epoch: 3/20...  Training Step: 1809...  Training loss: 2.1824...  0.0577 sec/batch
Epoch: 3/20...  Training Step: 1810...  Training loss: 2.1767...  0.0575 sec/batch
Epoch: 3/20...  Training Step: 1811...  Training loss: 2.1707...  0.0616 sec/batch
Epoch: 3/20...  Training Step: 1812...  Training loss: 2.2412...  0.0596 sec/batch
Epoch: 3/20...  Training Step: 1813...  Training loss: 2.1619...  0.0577 sec/batch
Epoch: 3/20...  Training Step: 1814...  Training loss: 2.1717...  0.0586 sec/batch
Epoch: 3/20...  Training Step: 1815...  Training loss: 2.1734...  0.0568 sec/batch
Epoch: 3/20...  Training Step: 1816...  Training loss: 2.2447...  0.0577 sec/batch
Epoch: 3/20...  Training Step: 1817...  Training loss: 2.1319...  0.0573 sec/batch
Epoch: 3/20...  Training Step: 1818...  Training loss: 2.1774...  0.0634 sec/batch
Epoch: 3/20...  Training Step: 1819...  Training loss: 2.2320...  0.0568 sec/batch
Epoch: 3/20...  Training Step: 1820...  Training loss: 2.2124...  0.0552 sec/batch
Epoch: 3/20...  Training Step: 1821...  Training loss: 2.1882...  0.0632 sec/batch
Epoch: 3/20...  Training Step: 1822...  Training loss: 2.1684...  0.0568 sec/batch
Epoch: 3/20...  Training Step: 1823...  Training loss: 2.1670...  0.0531 sec/batch
Epoch: 3/20...  Training Step: 1824...  Training loss: 2.2163...  0.0556 sec/batch
Epoch: 3/20...  Training Step: 1825...  Training loss: 2.1698...  0.0604 sec/batch
Epoch: 3/20...  Training Step: 1826...  Training loss: 2.1684...  0.0591 sec/batch
Epoch: 3/20...  Training Step: 1827...  Training loss: 2.1359...  0.0541 sec/batch
Epoch: 3/20...  Training Step: 1828...  Training loss: 2.1818...  0.0601 sec/batch
Epoch: 3/20...  Training Step: 1829...  Training loss: 2.1179...  0.0571 sec/batch
Epoch: 3/20...  Training Step: 1830...  Training loss: 2.2134...  0.0568 sec/batch
Epoch: 3/20...  Training Step: 1831...  Training loss: 2.1341...  0.0591 sec/batch
Epoch: 3/20...  Training Step: 1832...  Training loss: 2.2072...  0.0567 sec/batch
Epoch: 3/20...  Training Step: 1833...  Training loss: 2.1604...  0.0536 sec/batch
Epoch: 3/20...  Training Step: 1834...  Training loss: 2.1319...  0.0588 sec/batch
Epoch: 3/20...  Training Step: 1835...  Training loss: 2.1551...  0.0620 sec/batch
Epoch: 3/20...  Training Step: 1836...  Training loss: 2.1446...  0.0566 sec/batch
Epoch: 3/20...  Training Step: 1837...  Training loss: 2.1244...  0.0572 sec/batch
Epoch: 3/20...  Training Step: 1838...  Training loss: 2.1468...  0.0573 sec/batch
Epoch: 3/20...  Training Step: 1839...  Training loss: 2.1881...  0.0557 sec/batch
Epoch: 3/20...  Training Step: 1840...  Training loss: 2.1904...  0.0537 sec/batch
Epoch: 3/20...  Training Step: 1841...  Training loss: 2.1571...  0.0624 sec/batch
Epoch: 3/20...  Training Step: 1842...  Training loss: 2.1888...  0.0537 sec/batch
Epoch: 3/20...  Training Step: 1843...  Training loss: 2.1900...  0.0561 sec/batch
Epoch: 3/20...  Training Step: 1844...  Training loss: 2.1273...  0.0579 sec/batch
Epoch: 3/20...  Training Step: 1845...  Training loss: 2.1486...  0.0553 sec/batch
Epoch: 3/20...  Training Step: 1846...  Training loss: 2.1553...  0.0551 sec/batch
Epoch: 3/20...  Training Step: 1847...  Training loss: 2.1043...  0.0554 sec/batch
Epoch: 3/20...  Training Step: 1848...  Training loss: 2.1331...  0.0562 sec/batch
Epoch: 3/20...  Training Step: 1849...  Training loss: 2.1265...  0.0539 sec/batch
Epoch: 3/20...  Training Step: 1850...  Training loss: 2.1919...  0.0564 sec/batch
Epoch: 3/20...  Training Step: 1851...  Training loss: 2.1928...  0.0591 sec/batch
Epoch: 3/20...  Training Step: 1852...  Training loss: 2.1933...  0.0604 sec/batch
Epoch: 3/20...  Training Step: 1853...  Training loss: 2.1303...  0.0578 sec/batch
Epoch: 3/20...  Training Step: 1854...  Training loss: 2.1655...  0.0606 sec/batch
Epoch: 3/20...  Training Step: 1855...  Training loss: 2.1212...  0.0579 sec/batch
Epoch: 3/20...  Training Step: 1856...  Training loss: 2.1847...  0.0529 sec/batch
Epoch: 3/20...  Training Step: 1857...  Training loss: 2.2049...  0.0562 sec/batch
Epoch: 3/20...  Training Step: 1858...  Training loss: 2.1468...  0.0583 sec/batch
Epoch: 3/20...  Training Step: 1859...  Training loss: 2.1227...  0.0571 sec/batch
Epoch: 3/20...  Training Step: 1860...  Training loss: 2.1390...  0.0537 sec/batch
Epoch: 4/20...  Training Step: 1861...  Training loss: 2.2332...  0.0575 sec/batch
Epoch: 4/20...  Training Step: 1862...  Training loss: 2.2261...  0.0564 sec/batch
Epoch: 4/20...  Training Step: 1863...  Training loss: 2.1967...  0.0565 sec/batch
Epoch: 4/20...  Training Step: 1864...  Training loss: 2.1299...  0.0600 sec/batch
Epoch: 4/20...  Training Step: 1865...  Training loss: 2.1605...  0.0572 sec/batch
Epoch: 4/20...  Training Step: 1866...  Training loss: 2.1574...  0.0536 sec/batch
Epoch: 4/20...  Training Step: 1867...  Training loss: 2.1523...  0.0540 sec/batch
Epoch: 4/20...  Training Step: 1868...  Training loss: 2.1222...  0.0586 sec/batch
Epoch: 4/20...  Training Step: 1869...  Training loss: 2.1086...  0.0580 sec/batch
Epoch: 4/20...  Training Step: 1870...  Training loss: 2.1450...  0.0571 sec/batch
Epoch: 4/20...  Training Step: 1871...  Training loss: 2.1536...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 1872...  Training loss: 2.1280...  0.0546 sec/batch
Epoch: 4/20...  Training Step: 1873...  Training loss: 2.1794...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 1874...  Training loss: 2.1242...  0.0571 sec/batch
Epoch: 4/20...  Training Step: 1875...  Training loss: 2.1673...  0.0567 sec/batch
Epoch: 4/20...  Training Step: 1876...  Training loss: 2.2010...  0.0601 sec/batch
Epoch: 4/20...  Training Step: 1877...  Training loss: 2.1754...  0.0568 sec/batch
Epoch: 4/20...  Training Step: 1878...  Training loss: 2.1843...  0.0564 sec/batch
Epoch: 4/20...  Training Step: 1879...  Training loss: 2.1267...  0.0545 sec/batch
Epoch: 4/20...  Training Step: 1880...  Training loss: 2.1560...  0.0572 sec/batch
Epoch: 4/20...  Training Step: 1881...  Training loss: 2.1960...  0.0564 sec/batch
Epoch: 4/20...  Training Step: 1882...  Training loss: 2.1417...  0.0573 sec/batch
Epoch: 4/20...  Training Step: 1883...  Training loss: 2.1217...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 1884...  Training loss: 2.1599...  0.0539 sec/batch
Epoch: 4/20...  Training Step: 1885...  Training loss: 2.1603...  0.0616 sec/batch
Epoch: 4/20...  Training Step: 1886...  Training loss: 2.1389...  0.0557 sec/batch
Epoch: 4/20...  Training Step: 1887...  Training loss: 2.1555...  0.0604 sec/batch
Epoch: 4/20...  Training Step: 1888...  Training loss: 2.1438...  0.0587 sec/batch
Epoch: 4/20...  Training Step: 1889...  Training loss: 2.1800...  0.0565 sec/batch
Epoch: 4/20...  Training Step: 1890...  Training loss: 2.0974...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 1891...  Training loss: 2.1371...  0.0550 sec/batch
Epoch: 4/20...  Training Step: 1892...  Training loss: 2.1687...  0.0550 sec/batch
Epoch: 4/20...  Training Step: 1893...  Training loss: 2.1398...  0.0571 sec/batch
Epoch: 4/20...  Training Step: 1894...  Training loss: 2.1341...  0.0585 sec/batch
Epoch: 4/20...  Training Step: 1895...  Training loss: 2.1562...  0.0566 sec/batch
Epoch: 4/20...  Training Step: 1896...  Training loss: 2.1553...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 1897...  Training loss: 2.1491...  0.0603 sec/batch
Epoch: 4/20...  Training Step: 1898...  Training loss: 2.1276...  0.0575 sec/batch
Epoch: 4/20...  Training Step: 1899...  Training loss: 2.1537...  0.0591 sec/batch
Epoch: 4/20...  Training Step: 1900...  Training loss: 2.1317...  0.0570 sec/batch
Epoch: 4/20...  Training Step: 1901...  Training loss: 2.1309...  0.0560 sec/batch
Epoch: 4/20...  Training Step: 1902...  Training loss: 2.1476...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 1903...  Training loss: 2.1387...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 1904...  Training loss: 2.1715...  0.0542 sec/batch
Epoch: 4/20...  Training Step: 1905...  Training loss: 2.1487...  0.0600 sec/batch
Epoch: 4/20...  Training Step: 1906...  Training loss: 2.1255...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 1907...  Training loss: 2.0526...  0.0535 sec/batch
Epoch: 4/20...  Training Step: 1908...  Training loss: 2.1674...  0.0598 sec/batch
Epoch: 4/20...  Training Step: 1909...  Training loss: 2.1525...  0.0569 sec/batch
Epoch: 4/20...  Training Step: 1910...  Training loss: 2.1548...  0.0562 sec/batch
Epoch: 4/20...  Training Step: 1911...  Training loss: 2.1114...  0.0578 sec/batch
Epoch: 4/20...  Training Step: 1912...  Training loss: 2.1231...  0.0547 sec/batch
Epoch: 4/20...  Training Step: 1913...  Training loss: 2.1397...  0.0568 sec/batch
Epoch: 4/20...  Training Step: 1914...  Training loss: 2.2108...  0.0572 sec/batch
Epoch: 4/20...  Training Step: 1915...  Training loss: 2.1870...  0.0569 sec/batch
Epoch: 4/20...  Training Step: 1916...  Training loss: 2.1301...  0.0561 sec/batch
Epoch: 4/20...  Training Step: 1917...  Training loss: 2.1113...  0.0533 sec/batch
Epoch: 4/20...  Training Step: 1918...  Training loss: 2.1553...  0.0614 sec/batch
Epoch: 4/20...  Training Step: 1919...  Training loss: 2.1353...  0.0538 sec/batch
Epoch: 4/20...  Training Step: 1920...  Training loss: 2.1877...  0.0601 sec/batch
Epoch: 4/20...  Training Step: 1921...  Training loss: 2.1528...  0.0552 sec/batch
Epoch: 4/20...  Training Step: 1922...  Training loss: 2.1492...  0.0566 sec/batch
Epoch: 4/20...  Training Step: 1923...  Training loss: 2.1717...  0.0589 sec/batch
Epoch: 4/20...  Training Step: 1924...  Training loss: 2.1222...  0.0545 sec/batch
Epoch: 4/20...  Training Step: 1925...  Training loss: 2.1123...  0.0575 sec/batch
Epoch: 4/20...  Training Step: 1926...  Training loss: 2.0876...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 1927...  Training loss: 2.1051...  0.0536 sec/batch
Epoch: 4/20...  Training Step: 1928...  Training loss: 2.0963...  0.0535 sec/batch
Epoch: 4/20...  Training Step: 1929...  Training loss: 2.1640...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 1930...  Training loss: 2.1492...  0.0578 sec/batch
Epoch: 4/20...  Training Step: 1931...  Training loss: 2.1583...  0.0560 sec/batch
Epoch: 4/20...  Training Step: 1932...  Training loss: 2.1572...  0.0560 sec/batch
Epoch: 4/20...  Training Step: 1933...  Training loss: 2.1155...  0.0575 sec/batch
Epoch: 4/20...  Training Step: 1934...  Training loss: 2.1492...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 1935...  Training loss: 2.1862...  0.0524 sec/batch
Epoch: 4/20...  Training Step: 1936...  Training loss: 2.1495...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 1937...  Training loss: 2.1717...  0.0524 sec/batch
Epoch: 4/20...  Training Step: 1938...  Training loss: 2.1449...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 1939...  Training loss: 2.1461...  0.0571 sec/batch
Epoch: 4/20...  Training Step: 1940...  Training loss: 2.1650...  0.0614 sec/batch
Epoch: 4/20...  Training Step: 1941...  Training loss: 2.1293...  0.0607 sec/batch
Epoch: 4/20...  Training Step: 1942...  Training loss: 2.1191...  0.0566 sec/batch
Epoch: 4/20...  Training Step: 1943...  Training loss: 2.1079...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 1944...  Training loss: 2.1213...  0.0602 sec/batch
Epoch: 4/20...  Training Step: 1945...  Training loss: 2.1404...  0.0563 sec/batch
Epoch: 4/20...  Training Step: 1946...  Training loss: 2.1610...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 1947...  Training loss: 2.1098...  0.0557 sec/batch
Epoch: 4/20...  Training Step: 1948...  Training loss: 2.1858...  0.0553 sec/batch
Epoch: 4/20...  Training Step: 1949...  Training loss: 2.1357...  0.0543 sec/batch
Epoch: 4/20...  Training Step: 1950...  Training loss: 2.1367...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 1951...  Training loss: 2.1245...  0.0522 sec/batch
Epoch: 4/20...  Training Step: 1952...  Training loss: 2.1921...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 1953...  Training loss: 2.1444...  0.0525 sec/batch
Epoch: 4/20...  Training Step: 1954...  Training loss: 2.1344...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 1955...  Training loss: 2.1631...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 1956...  Training loss: 2.1365...  0.0532 sec/batch
Epoch: 4/20...  Training Step: 1957...  Training loss: 2.1682...  0.0561 sec/batch
Epoch: 4/20...  Training Step: 1958...  Training loss: 2.0951...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 1959...  Training loss: 2.1779...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 1960...  Training loss: 2.1378...  0.0561 sec/batch
Epoch: 4/20...  Training Step: 1961...  Training loss: 2.1426...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 1962...  Training loss: 2.1267...  0.0524 sec/batch
Epoch: 4/20...  Training Step: 1963...  Training loss: 2.1661...  0.0590 sec/batch
Epoch: 4/20...  Training Step: 1964...  Training loss: 2.1692...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 1965...  Training loss: 2.1363...  0.0542 sec/batch
Epoch: 4/20...  Training Step: 1966...  Training loss: 2.1119...  0.0560 sec/batch
Epoch: 4/20...  Training Step: 1967...  Training loss: 2.1534...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 1968...  Training loss: 2.1522...  0.0524 sec/batch
Epoch: 4/20...  Training Step: 1969...  Training loss: 2.1141...  0.0553 sec/batch
Epoch: 4/20...  Training Step: 1970...  Training loss: 2.1138...  0.0586 sec/batch
Epoch: 4/20...  Training Step: 1971...  Training loss: 2.1029...  0.0576 sec/batch
Epoch: 4/20...  Training Step: 1972...  Training loss: 2.1352...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 1973...  Training loss: 2.1374...  0.0559 sec/batch
Epoch: 4/20...  Training Step: 1974...  Training loss: 2.1460...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 1975...  Training loss: 2.1603...  0.0594 sec/batch
Epoch: 4/20...  Training Step: 1976...  Training loss: 2.1651...  0.0585 sec/batch
Epoch: 4/20...  Training Step: 1977...  Training loss: 2.1059...  0.0561 sec/batch
Epoch: 4/20...  Training Step: 1978...  Training loss: 2.1485...  0.0559 sec/batch
Epoch: 4/20...  Training Step: 1979...  Training loss: 2.1119...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 1980...  Training loss: 2.1218...  0.0571 sec/batch
Epoch: 4/20...  Training Step: 1981...  Training loss: 2.1130...  0.0553 sec/batch
Epoch: 4/20...  Training Step: 1982...  Training loss: 2.0822...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 1983...  Training loss: 2.1322...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 1984...  Training loss: 2.1460...  0.0548 sec/batch
Epoch: 4/20...  Training Step: 1985...  Training loss: 2.1416...  0.0566 sec/batch
Epoch: 4/20...  Training Step: 1986...  Training loss: 2.1680...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 1987...  Training loss: 2.1593...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 1988...  Training loss: 2.0875...  0.0590 sec/batch
Epoch: 4/20...  Training Step: 1989...  Training loss: 2.1007...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 1990...  Training loss: 2.1753...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 1991...  Training loss: 2.1082...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 1992...  Training loss: 2.1990...  0.0525 sec/batch
Epoch: 4/20...  Training Step: 1993...  Training loss: 2.1776...  0.0589 sec/batch
Epoch: 4/20...  Training Step: 1994...  Training loss: 2.1500...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 1995...  Training loss: 2.1064...  0.0547 sec/batch
Epoch: 4/20...  Training Step: 1996...  Training loss: 2.1306...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 1997...  Training loss: 2.1276...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 1998...  Training loss: 2.1209...  0.0550 sec/batch
Epoch: 4/20...  Training Step: 1999...  Training loss: 2.1772...  0.0533 sec/batch
Epoch: 4/20...  Training Step: 2000...  Training loss: 2.1166...  0.0574 sec/batch
Epoch: 4/20...  Training Step: 2001...  Training loss: 2.1475...  0.0576 sec/batch
Epoch: 4/20...  Training Step: 2002...  Training loss: 2.0796...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 2003...  Training loss: 2.1342...  0.0562 sec/batch
Epoch: 4/20...  Training Step: 2004...  Training loss: 2.1046...  0.0584 sec/batch
Epoch: 4/20...  Training Step: 2005...  Training loss: 2.0927...  0.0559 sec/batch
Epoch: 4/20...  Training Step: 2006...  Training loss: 2.1324...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 2007...  Training loss: 2.1199...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 2008...  Training loss: 2.1535...  0.0526 sec/batch
Epoch: 4/20...  Training Step: 2009...  Training loss: 2.1072...  0.0574 sec/batch
Epoch: 4/20...  Training Step: 2010...  Training loss: 2.1246...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2011...  Training loss: 2.1437...  0.0568 sec/batch
Epoch: 4/20...  Training Step: 2012...  Training loss: 2.1317...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 2013...  Training loss: 2.1252...  0.0549 sec/batch
Epoch: 4/20...  Training Step: 2014...  Training loss: 2.1655...  0.0523 sec/batch
Epoch: 4/20...  Training Step: 2015...  Training loss: 2.1009...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 2016...  Training loss: 2.1371...  0.0525 sec/batch
Epoch: 4/20...  Training Step: 2017...  Training loss: 2.1057...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2018...  Training loss: 2.1517...  0.0576 sec/batch
Epoch: 4/20...  Training Step: 2019...  Training loss: 2.1617...  0.0544 sec/batch
Epoch: 4/20...  Training Step: 2020...  Training loss: 2.1085...  0.0562 sec/batch
Epoch: 4/20...  Training Step: 2021...  Training loss: 2.0885...  0.0572 sec/batch
Epoch: 4/20...  Training Step: 2022...  Training loss: 2.1011...  0.0542 sec/batch
Epoch: 4/20...  Training Step: 2023...  Training loss: 2.1123...  0.0550 sec/batch
Epoch: 4/20...  Training Step: 2024...  Training loss: 2.1260...  0.0525 sec/batch
Epoch: 4/20...  Training Step: 2025...  Training loss: 2.1454...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2026...  Training loss: 2.1025...  0.0573 sec/batch
Epoch: 4/20...  Training Step: 2027...  Training loss: 2.1681...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 2028...  Training loss: 2.1194...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 2029...  Training loss: 2.1148...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2030...  Training loss: 2.1154...  0.0590 sec/batch
Epoch: 4/20...  Training Step: 2031...  Training loss: 2.1145...  0.0552 sec/batch
Epoch: 4/20...  Training Step: 2032...  Training loss: 2.1161...  0.0525 sec/batch
Epoch: 4/20...  Training Step: 2033...  Training loss: 2.1166...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 2034...  Training loss: 2.1406...  0.0533 sec/batch
Epoch: 4/20...  Training Step: 2035...  Training loss: 2.1309...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 2036...  Training loss: 2.1325...  0.0552 sec/batch
Epoch: 4/20...  Training Step: 2037...  Training loss: 2.1427...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2038...  Training loss: 2.1465...  0.0580 sec/batch
Epoch: 4/20...  Training Step: 2039...  Training loss: 2.0980...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2040...  Training loss: 2.1083...  0.0547 sec/batch
Epoch: 4/20...  Training Step: 2041...  Training loss: 2.1139...  0.0606 sec/batch
Epoch: 4/20...  Training Step: 2042...  Training loss: 2.1242...  0.0568 sec/batch
Epoch: 4/20...  Training Step: 2043...  Training loss: 2.1469...  0.0526 sec/batch
Epoch: 4/20...  Training Step: 2044...  Training loss: 2.0572...  0.0553 sec/batch
Epoch: 4/20...  Training Step: 2045...  Training loss: 2.0860...  0.0543 sec/batch
Epoch: 4/20...  Training Step: 2046...  Training loss: 2.1255...  0.0595 sec/batch
Epoch: 4/20...  Training Step: 2047...  Training loss: 2.0998...  0.0539 sec/batch
Epoch: 4/20...  Training Step: 2048...  Training loss: 2.1011...  0.0562 sec/batch
Epoch: 4/20...  Training Step: 2049...  Training loss: 2.1049...  0.0541 sec/batch
Epoch: 4/20...  Training Step: 2050...  Training loss: 2.1817...  0.0563 sec/batch
Epoch: 4/20...  Training Step: 2051...  Training loss: 2.1763...  0.0585 sec/batch
Epoch: 4/20...  Training Step: 2052...  Training loss: 2.1704...  0.0524 sec/batch
Epoch: 4/20...  Training Step: 2053...  Training loss: 2.1516...  0.0605 sec/batch
Epoch: 4/20...  Training Step: 2054...  Training loss: 2.0921...  0.0535 sec/batch
Epoch: 4/20...  Training Step: 2055...  Training loss: 2.1381...  0.0537 sec/batch
Epoch: 4/20...  Training Step: 2056...  Training loss: 2.2018...  0.0525 sec/batch
Epoch: 4/20...  Training Step: 2057...  Training loss: 2.1441...  0.0583 sec/batch
Epoch: 4/20...  Training Step: 2058...  Training loss: 2.1744...  0.0610 sec/batch
Epoch: 4/20...  Training Step: 2059...  Training loss: 2.0958...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2060...  Training loss: 2.1045...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2061...  Training loss: 2.1123...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 2062...  Training loss: 2.1244...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 2063...  Training loss: 2.0920...  0.0570 sec/batch
Epoch: 4/20...  Training Step: 2064...  Training loss: 2.1002...  0.0591 sec/batch
Epoch: 4/20...  Training Step: 2065...  Training loss: 2.1282...  0.0594 sec/batch
Epoch: 4/20...  Training Step: 2066...  Training loss: 2.0784...  0.0548 sec/batch
Epoch: 4/20...  Training Step: 2067...  Training loss: 2.1373...  0.0537 sec/batch
Epoch: 4/20...  Training Step: 2068...  Training loss: 2.1384...  0.0562 sec/batch
Epoch: 4/20...  Training Step: 2069...  Training loss: 2.1178...  0.0533 sec/batch
Epoch: 4/20...  Training Step: 2070...  Training loss: 2.0999...  0.0573 sec/batch
Epoch: 4/20...  Training Step: 2071...  Training loss: 2.1342...  0.0552 sec/batch
Epoch: 4/20...  Training Step: 2072...  Training loss: 2.1444...  0.0576 sec/batch
Epoch: 4/20...  Training Step: 2073...  Training loss: 2.1502...  0.0557 sec/batch
Epoch: 4/20...  Training Step: 2074...  Training loss: 2.1553...  0.0583 sec/batch
Epoch: 4/20...  Training Step: 2075...  Training loss: 2.1269...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 2076...  Training loss: 2.1381...  0.0600 sec/batch
Epoch: 4/20...  Training Step: 2077...  Training loss: 2.1248...  0.0548 sec/batch
Epoch: 4/20...  Training Step: 2078...  Training loss: 2.0952...  0.0548 sec/batch
Epoch: 4/20...  Training Step: 2079...  Training loss: 2.2111...  0.0570 sec/batch
Epoch: 4/20...  Training Step: 2080...  Training loss: 2.1359...  0.0587 sec/batch
Epoch: 4/20...  Training Step: 2081...  Training loss: 2.1180...  0.0578 sec/batch
Epoch: 4/20...  Training Step: 2082...  Training loss: 2.1401...  0.0573 sec/batch
Epoch: 4/20...  Training Step: 2083...  Training loss: 2.1615...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2084...  Training loss: 2.1131...  0.0526 sec/batch
Epoch: 4/20...  Training Step: 2085...  Training loss: 2.1089...  0.0532 sec/batch
Epoch: 4/20...  Training Step: 2086...  Training loss: 2.1651...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2087...  Training loss: 2.1763...  0.0577 sec/batch
Epoch: 4/20...  Training Step: 2088...  Training loss: 2.0753...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 2089...  Training loss: 2.1482...  0.0550 sec/batch
Epoch: 4/20...  Training Step: 2090...  Training loss: 2.1143...  0.0553 sec/batch
Epoch: 4/20...  Training Step: 2091...  Training loss: 2.1510...  0.0550 sec/batch
Epoch: 4/20...  Training Step: 2092...  Training loss: 2.1206...  0.0590 sec/batch
Epoch: 4/20...  Training Step: 2093...  Training loss: 2.1046...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 2094...  Training loss: 2.0952...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 2095...  Training loss: 2.1068...  0.0573 sec/batch
Epoch: 4/20...  Training Step: 2096...  Training loss: 2.1369...  0.0538 sec/batch
Epoch: 4/20...  Training Step: 2097...  Training loss: 2.1220...  0.0526 sec/batch
Epoch: 4/20...  Training Step: 2098...  Training loss: 2.0748...  0.0550 sec/batch
Epoch: 4/20...  Training Step: 2099...  Training loss: 2.0925...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2100...  Training loss: 2.1461...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2101...  Training loss: 2.1244...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2102...  Training loss: 2.1016...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2103...  Training loss: 2.0969...  0.0580 sec/batch
Epoch: 4/20...  Training Step: 2104...  Training loss: 2.1257...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 2105...  Training loss: 2.0944...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 2106...  Training loss: 2.1404...  0.0589 sec/batch
Epoch: 4/20...  Training Step: 2107...  Training loss: 2.0982...  0.0550 sec/batch
Epoch: 4/20...  Training Step: 2108...  Training loss: 2.1115...  0.0533 sec/batch
Epoch: 4/20...  Training Step: 2109...  Training loss: 2.0715...  0.0524 sec/batch
Epoch: 4/20...  Training Step: 2110...  Training loss: 2.1187...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 2111...  Training loss: 2.1075...  0.0540 sec/batch
Epoch: 4/20...  Training Step: 2112...  Training loss: 2.0683...  0.0541 sec/batch
Epoch: 4/20...  Training Step: 2113...  Training loss: 2.1309...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 2114...  Training loss: 2.1293...  0.0586 sec/batch
Epoch: 4/20...  Training Step: 2115...  Training loss: 2.1459...  0.0526 sec/batch
Epoch: 4/20...  Training Step: 2116...  Training loss: 2.1131...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2117...  Training loss: 2.1215...  0.0544 sec/batch
Epoch: 4/20...  Training Step: 2118...  Training loss: 2.1279...  0.0608 sec/batch
Epoch: 4/20...  Training Step: 2119...  Training loss: 2.1164...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 2120...  Training loss: 2.1032...  0.0549 sec/batch
Epoch: 4/20...  Training Step: 2121...  Training loss: 2.1281...  0.0546 sec/batch
Epoch: 4/20...  Training Step: 2122...  Training loss: 2.0966...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2123...  Training loss: 2.1368...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 2124...  Training loss: 2.1226...  0.0548 sec/batch
Epoch: 4/20...  Training Step: 2125...  Training loss: 2.1424...  0.0571 sec/batch
Epoch: 4/20...  Training Step: 2126...  Training loss: 2.0627...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 2127...  Training loss: 2.1261...  0.0592 sec/batch
Epoch: 4/20...  Training Step: 2128...  Training loss: 2.1228...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 2129...  Training loss: 2.0940...  0.0573 sec/batch
Epoch: 4/20...  Training Step: 2130...  Training loss: 2.0797...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 2131...  Training loss: 2.0915...  0.0581 sec/batch
Epoch: 4/20...  Training Step: 2132...  Training loss: 2.1081...  0.0557 sec/batch
Epoch: 4/20...  Training Step: 2133...  Training loss: 2.1294...  0.0536 sec/batch
Epoch: 4/20...  Training Step: 2134...  Training loss: 2.0955...  0.0526 sec/batch
Epoch: 4/20...  Training Step: 2135...  Training loss: 2.1269...  0.0597 sec/batch
Epoch: 4/20...  Training Step: 2136...  Training loss: 2.1460...  0.0535 sec/batch
Epoch: 4/20...  Training Step: 2137...  Training loss: 2.1669...  0.0581 sec/batch
Epoch: 4/20...  Training Step: 2138...  Training loss: 2.1109...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2139...  Training loss: 2.1473...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2140...  Training loss: 2.1633...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 2141...  Training loss: 2.1116...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 2142...  Training loss: 2.0661...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2143...  Training loss: 2.0873...  0.0545 sec/batch
Epoch: 4/20...  Training Step: 2144...  Training loss: 2.1147...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 2145...  Training loss: 2.0816...  0.0548 sec/batch
Epoch: 4/20...  Training Step: 2146...  Training loss: 2.1070...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 2147...  Training loss: 2.0899...  0.0629 sec/batch
Epoch: 4/20...  Training Step: 2148...  Training loss: 2.1072...  0.0549 sec/batch
Epoch: 4/20...  Training Step: 2149...  Training loss: 2.1414...  0.0565 sec/batch
Epoch: 4/20...  Training Step: 2150...  Training loss: 2.1577...  0.0522 sec/batch
Epoch: 4/20...  Training Step: 2151...  Training loss: 2.1091...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 2152...  Training loss: 2.1185...  0.0526 sec/batch
Epoch: 4/20...  Training Step: 2153...  Training loss: 2.1196...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2154...  Training loss: 2.1129...  0.0576 sec/batch
Epoch: 4/20...  Training Step: 2155...  Training loss: 2.0782...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 2156...  Training loss: 2.0861...  0.0540 sec/batch
Epoch: 4/20...  Training Step: 2157...  Training loss: 2.1488...  0.0564 sec/batch
Epoch: 4/20...  Training Step: 2158...  Training loss: 2.1265...  0.0588 sec/batch
Epoch: 4/20...  Training Step: 2159...  Training loss: 2.1668...  0.0548 sec/batch
Epoch: 4/20...  Training Step: 2160...  Training loss: 2.1191...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2161...  Training loss: 2.1172...  0.0559 sec/batch
Epoch: 4/20...  Training Step: 2162...  Training loss: 2.1612...  0.0569 sec/batch
Epoch: 4/20...  Training Step: 2163...  Training loss: 2.0493...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 2164...  Training loss: 2.1239...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 2165...  Training loss: 2.1097...  0.0582 sec/batch
Epoch: 4/20...  Training Step: 2166...  Training loss: 2.1197...  0.0533 sec/batch
Epoch: 4/20...  Training Step: 2167...  Training loss: 2.0853...  0.0536 sec/batch
Epoch: 4/20...  Training Step: 2168...  Training loss: 2.0829...  0.0553 sec/batch
Epoch: 4/20...  Training Step: 2169...  Training loss: 2.1277...  0.0582 sec/batch
Epoch: 4/20...  Training Step: 2170...  Training loss: 2.0662...  0.0553 sec/batch
Epoch: 4/20...  Training Step: 2171...  Training loss: 2.0910...  0.0553 sec/batch
Epoch: 4/20...  Training Step: 2172...  Training loss: 2.1012...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2173...  Training loss: 2.0985...  0.0587 sec/batch
Epoch: 4/20...  Training Step: 2174...  Training loss: 2.0701...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 2175...  Training loss: 2.1198...  0.0553 sec/batch
Epoch: 4/20...  Training Step: 2176...  Training loss: 2.1376...  0.0568 sec/batch
Epoch: 4/20...  Training Step: 2177...  Training loss: 2.0660...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 2178...  Training loss: 2.0760...  0.0559 sec/batch
Epoch: 4/20...  Training Step: 2179...  Training loss: 2.1085...  0.0568 sec/batch
Epoch: 4/20...  Training Step: 2180...  Training loss: 2.1499...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 2181...  Training loss: 2.0995...  0.0545 sec/batch
Epoch: 4/20...  Training Step: 2182...  Training loss: 2.0574...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 2183...  Training loss: 2.1178...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 2184...  Training loss: 2.0965...  0.0532 sec/batch
Epoch: 4/20...  Training Step: 2185...  Training loss: 2.0738...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2186...  Training loss: 2.0781...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 2187...  Training loss: 2.0556...  0.0548 sec/batch
Epoch: 4/20...  Training Step: 2188...  Training loss: 2.0666...  0.0546 sec/batch
Epoch: 4/20...  Training Step: 2189...  Training loss: 2.1061...  0.0567 sec/batch
Epoch: 4/20...  Training Step: 2190...  Training loss: 2.0787...  0.0547 sec/batch
Epoch: 4/20...  Training Step: 2191...  Training loss: 2.1231...  0.0549 sec/batch
Epoch: 4/20...  Training Step: 2192...  Training loss: 2.0791...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 2193...  Training loss: 2.0609...  0.0569 sec/batch
Epoch: 4/20...  Training Step: 2194...  Training loss: 2.0838...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 2195...  Training loss: 2.1156...  0.0553 sec/batch
Epoch: 4/20...  Training Step: 2196...  Training loss: 2.0956...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 2197...  Training loss: 2.0821...  0.0564 sec/batch
Epoch: 4/20...  Training Step: 2198...  Training loss: 2.0758...  0.0542 sec/batch
Epoch: 4/20...  Training Step: 2199...  Training loss: 2.0700...  0.0576 sec/batch
Epoch: 4/20...  Training Step: 2200...  Training loss: 2.1013...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 2201...  Training loss: 2.0965...  0.0560 sec/batch
Epoch: 4/20...  Training Step: 2202...  Training loss: 2.0916...  0.0591 sec/batch
Epoch: 4/20...  Training Step: 2203...  Training loss: 2.0999...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 2204...  Training loss: 2.0804...  0.0570 sec/batch
Epoch: 4/20...  Training Step: 2205...  Training loss: 2.0872...  0.0559 sec/batch
Epoch: 4/20...  Training Step: 2206...  Training loss: 2.1185...  0.0604 sec/batch
Epoch: 4/20...  Training Step: 2207...  Training loss: 2.1117...  0.0561 sec/batch
Epoch: 4/20...  Training Step: 2208...  Training loss: 2.0837...  0.0572 sec/batch
Epoch: 4/20...  Training Step: 2209...  Training loss: 2.0823...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 2210...  Training loss: 2.0826...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 2211...  Training loss: 2.1009...  0.0533 sec/batch
Epoch: 4/20...  Training Step: 2212...  Training loss: 2.0947...  0.0549 sec/batch
Epoch: 4/20...  Training Step: 2213...  Training loss: 2.1154...  0.0610 sec/batch
Epoch: 4/20...  Training Step: 2214...  Training loss: 2.0836...  0.0640 sec/batch
Epoch: 4/20...  Training Step: 2215...  Training loss: 2.0956...  0.0525 sec/batch
Epoch: 4/20...  Training Step: 2216...  Training loss: 2.1478...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 2217...  Training loss: 2.2096...  0.0576 sec/batch
Epoch: 4/20...  Training Step: 2218...  Training loss: 2.1305...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 2219...  Training loss: 2.0857...  0.0523 sec/batch
Epoch: 4/20...  Training Step: 2220...  Training loss: 2.1119...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 2221...  Training loss: 2.1216...  0.0533 sec/batch
Epoch: 4/20...  Training Step: 2222...  Training loss: 2.0834...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2223...  Training loss: 2.0486...  0.0561 sec/batch
Epoch: 4/20...  Training Step: 2224...  Training loss: 2.0343...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 2225...  Training loss: 2.0603...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 2226...  Training loss: 2.1257...  0.0526 sec/batch
Epoch: 4/20...  Training Step: 2227...  Training loss: 2.0914...  0.0582 sec/batch
Epoch: 4/20...  Training Step: 2228...  Training loss: 2.1469...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2229...  Training loss: 2.1020...  0.0560 sec/batch
Epoch: 4/20...  Training Step: 2230...  Training loss: 2.0800...  0.0568 sec/batch
Epoch: 4/20...  Training Step: 2231...  Training loss: 2.1297...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 2232...  Training loss: 2.1720...  0.0588 sec/batch
Epoch: 4/20...  Training Step: 2233...  Training loss: 2.1298...  0.0543 sec/batch
Epoch: 4/20...  Training Step: 2234...  Training loss: 2.1207...  0.0537 sec/batch
Epoch: 4/20...  Training Step: 2235...  Training loss: 2.0885...  0.0552 sec/batch
Epoch: 4/20...  Training Step: 2236...  Training loss: 2.1168...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 2237...  Training loss: 2.0898...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 2238...  Training loss: 2.1395...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 2239...  Training loss: 2.1214...  0.0593 sec/batch
Epoch: 4/20...  Training Step: 2240...  Training loss: 2.1010...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 2241...  Training loss: 2.0334...  0.0533 sec/batch
Epoch: 4/20...  Training Step: 2242...  Training loss: 2.1439...  0.0590 sec/batch
Epoch: 4/20...  Training Step: 2243...  Training loss: 2.0499...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2244...  Training loss: 2.1029...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2245...  Training loss: 2.1229...  0.0569 sec/batch
Epoch: 4/20...  Training Step: 2246...  Training loss: 2.0432...  0.0563 sec/batch
Epoch: 4/20...  Training Step: 2247...  Training loss: 2.0466...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 2248...  Training loss: 2.1229...  0.0585 sec/batch
Epoch: 4/20...  Training Step: 2249...  Training loss: 2.0489...  0.0620 sec/batch
Epoch: 4/20...  Training Step: 2250...  Training loss: 2.0637...  0.0577 sec/batch
Epoch: 4/20...  Training Step: 2251...  Training loss: 2.1190...  0.0523 sec/batch
Epoch: 4/20...  Training Step: 2252...  Training loss: 2.0351...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 2253...  Training loss: 2.1017...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 2254...  Training loss: 2.0824...  0.0535 sec/batch
Epoch: 4/20...  Training Step: 2255...  Training loss: 2.0646...  0.0522 sec/batch
Epoch: 4/20...  Training Step: 2256...  Training loss: 2.0874...  0.0580 sec/batch
Epoch: 4/20...  Training Step: 2257...  Training loss: 2.0861...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 2258...  Training loss: 2.1087...  0.0537 sec/batch
Epoch: 4/20...  Training Step: 2259...  Training loss: 2.0804...  0.0522 sec/batch
Epoch: 4/20...  Training Step: 2260...  Training loss: 2.0978...  0.0547 sec/batch
Epoch: 4/20...  Training Step: 2261...  Training loss: 2.1271...  0.0550 sec/batch
Epoch: 4/20...  Training Step: 2262...  Training loss: 2.1019...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 2263...  Training loss: 2.0851...  0.0532 sec/batch
Epoch: 4/20...  Training Step: 2264...  Training loss: 2.1021...  0.0541 sec/batch
Epoch: 4/20...  Training Step: 2265...  Training loss: 2.1441...  0.0560 sec/batch
Epoch: 4/20...  Training Step: 2266...  Training loss: 2.1175...  0.0588 sec/batch
Epoch: 4/20...  Training Step: 2267...  Training loss: 2.1487...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 2268...  Training loss: 2.0926...  0.0539 sec/batch
Epoch: 4/20...  Training Step: 2269...  Training loss: 2.1447...  0.0582 sec/batch
Epoch: 4/20...  Training Step: 2270...  Training loss: 2.1077...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2271...  Training loss: 2.0832...  0.0546 sec/batch
Epoch: 4/20...  Training Step: 2272...  Training loss: 2.1231...  0.0562 sec/batch
Epoch: 4/20...  Training Step: 2273...  Training loss: 2.0903...  0.0590 sec/batch
Epoch: 4/20...  Training Step: 2274...  Training loss: 2.1003...  0.0595 sec/batch
Epoch: 4/20...  Training Step: 2275...  Training loss: 2.0497...  0.0526 sec/batch
Epoch: 4/20...  Training Step: 2276...  Training loss: 2.0321...  0.0562 sec/batch
Epoch: 4/20...  Training Step: 2277...  Training loss: 2.0880...  0.0580 sec/batch
Epoch: 4/20...  Training Step: 2278...  Training loss: 2.1067...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 2279...  Training loss: 2.1498...  0.0552 sec/batch
Epoch: 4/20...  Training Step: 2280...  Training loss: 2.0946...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2281...  Training loss: 2.0548...  0.0591 sec/batch
Epoch: 4/20...  Training Step: 2282...  Training loss: 2.0554...  0.0553 sec/batch
Epoch: 4/20...  Training Step: 2283...  Training loss: 2.1261...  0.0590 sec/batch
Epoch: 4/20...  Training Step: 2284...  Training loss: 2.0868...  0.0525 sec/batch
Epoch: 4/20...  Training Step: 2285...  Training loss: 2.1188...  0.0539 sec/batch
Epoch: 4/20...  Training Step: 2286...  Training loss: 2.1274...  0.0539 sec/batch
Epoch: 4/20...  Training Step: 2287...  Training loss: 2.0675...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2288...  Training loss: 2.1037...  0.0593 sec/batch
Epoch: 4/20...  Training Step: 2289...  Training loss: 2.0928...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2290...  Training loss: 2.0589...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2291...  Training loss: 2.0785...  0.0587 sec/batch
Epoch: 4/20...  Training Step: 2292...  Training loss: 2.1243...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2293...  Training loss: 2.1062...  0.0538 sec/batch
Epoch: 4/20...  Training Step: 2294...  Training loss: 2.0617...  0.0595 sec/batch
Epoch: 4/20...  Training Step: 2295...  Training loss: 2.0741...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 2296...  Training loss: 2.0998...  0.0523 sec/batch
Epoch: 4/20...  Training Step: 2297...  Training loss: 2.0566...  0.0532 sec/batch
Epoch: 4/20...  Training Step: 2298...  Training loss: 2.0919...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2299...  Training loss: 2.0754...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2300...  Training loss: 2.0776...  0.0552 sec/batch
Epoch: 4/20...  Training Step: 2301...  Training loss: 2.0793...  0.0563 sec/batch
Epoch: 4/20...  Training Step: 2302...  Training loss: 2.0909...  0.0563 sec/batch
Epoch: 4/20...  Training Step: 2303...  Training loss: 2.1191...  0.0572 sec/batch
Epoch: 4/20...  Training Step: 2304...  Training loss: 2.0878...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2305...  Training loss: 2.0447...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 2306...  Training loss: 2.0592...  0.0572 sec/batch
Epoch: 4/20...  Training Step: 2307...  Training loss: 2.0633...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 2308...  Training loss: 2.0486...  0.0525 sec/batch
Epoch: 4/20...  Training Step: 2309...  Training loss: 2.1130...  0.0537 sec/batch
Epoch: 4/20...  Training Step: 2310...  Training loss: 2.1351...  0.0536 sec/batch
Epoch: 4/20...  Training Step: 2311...  Training loss: 2.1446...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 2312...  Training loss: 2.0973...  0.0548 sec/batch
Epoch: 4/20...  Training Step: 2313...  Training loss: 2.0543...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2314...  Training loss: 2.0569...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2315...  Training loss: 2.0697...  0.0561 sec/batch
Epoch: 4/20...  Training Step: 2316...  Training loss: 2.0987...  0.0585 sec/batch
Epoch: 4/20...  Training Step: 2317...  Training loss: 2.0592...  0.0536 sec/batch
Epoch: 4/20...  Training Step: 2318...  Training loss: 2.0982...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 2319...  Training loss: 2.0683...  0.0547 sec/batch
Epoch: 4/20...  Training Step: 2320...  Training loss: 2.0798...  0.0568 sec/batch
Epoch: 4/20...  Training Step: 2321...  Training loss: 2.0332...  0.0601 sec/batch
Epoch: 4/20...  Training Step: 2322...  Training loss: 2.1070...  0.0585 sec/batch
Epoch: 4/20...  Training Step: 2323...  Training loss: 2.0838...  0.0524 sec/batch
Epoch: 4/20...  Training Step: 2324...  Training loss: 2.0777...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2325...  Training loss: 2.1034...  0.0538 sec/batch
Epoch: 4/20...  Training Step: 2326...  Training loss: 2.0939...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2327...  Training loss: 2.0645...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2328...  Training loss: 2.0645...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2329...  Training loss: 2.1154...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2330...  Training loss: 2.0874...  0.0560 sec/batch
Epoch: 4/20...  Training Step: 2331...  Training loss: 2.0802...  0.0582 sec/batch
Epoch: 4/20...  Training Step: 2332...  Training loss: 2.0763...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 2333...  Training loss: 2.0565...  0.0557 sec/batch
Epoch: 4/20...  Training Step: 2334...  Training loss: 2.0341...  0.0532 sec/batch
Epoch: 4/20...  Training Step: 2335...  Training loss: 2.1341...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 2336...  Training loss: 2.1299...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 2337...  Training loss: 2.0943...  0.0569 sec/batch
Epoch: 4/20...  Training Step: 2338...  Training loss: 2.1577...  0.0567 sec/batch
Epoch: 4/20...  Training Step: 2339...  Training loss: 2.0467...  0.0576 sec/batch
Epoch: 4/20...  Training Step: 2340...  Training loss: 2.1298...  0.0553 sec/batch
Epoch: 4/20...  Training Step: 2341...  Training loss: 2.0987...  0.0552 sec/batch
Epoch: 4/20...  Training Step: 2342...  Training loss: 2.0513...  0.0568 sec/batch
Epoch: 4/20...  Training Step: 2343...  Training loss: 2.0907...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2344...  Training loss: 2.0972...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2345...  Training loss: 2.1324...  0.0567 sec/batch
Epoch: 4/20...  Training Step: 2346...  Training loss: 2.0819...  0.0537 sec/batch
Epoch: 4/20...  Training Step: 2347...  Training loss: 2.1096...  0.0557 sec/batch
Epoch: 4/20...  Training Step: 2348...  Training loss: 2.0914...  0.0549 sec/batch
Epoch: 4/20...  Training Step: 2349...  Training loss: 2.0999...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 2350...  Training loss: 2.0926...  0.0573 sec/batch
Epoch: 4/20...  Training Step: 2351...  Training loss: 2.0770...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 2352...  Training loss: 2.1252...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 2353...  Training loss: 2.0767...  0.0563 sec/batch
Epoch: 4/20...  Training Step: 2354...  Training loss: 2.0793...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2355...  Training loss: 2.0814...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 2356...  Training loss: 2.0885...  0.0521 sec/batch
Epoch: 4/20...  Training Step: 2357...  Training loss: 2.0402...  0.0543 sec/batch
Epoch: 4/20...  Training Step: 2358...  Training loss: 2.1124...  0.0563 sec/batch
Epoch: 4/20...  Training Step: 2359...  Training loss: 2.0396...  0.0537 sec/batch
Epoch: 4/20...  Training Step: 2360...  Training loss: 2.0966...  0.0571 sec/batch
Epoch: 4/20...  Training Step: 2361...  Training loss: 2.0955...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 2362...  Training loss: 2.1374...  0.0557 sec/batch
Epoch: 4/20...  Training Step: 2363...  Training loss: 2.1429...  0.0555 sec/batch
Epoch: 4/20...  Training Step: 2364...  Training loss: 2.1180...  0.0570 sec/batch
Epoch: 4/20...  Training Step: 2365...  Training loss: 2.0927...  0.0564 sec/batch
Epoch: 4/20...  Training Step: 2366...  Training loss: 2.0451...  0.0552 sec/batch
Epoch: 4/20...  Training Step: 2367...  Training loss: 2.1000...  0.0584 sec/batch
Epoch: 4/20...  Training Step: 2368...  Training loss: 2.0591...  0.0561 sec/batch
Epoch: 4/20...  Training Step: 2369...  Training loss: 2.1208...  0.0546 sec/batch
Epoch: 4/20...  Training Step: 2370...  Training loss: 2.1245...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 2371...  Training loss: 2.1214...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 2372...  Training loss: 2.0533...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2373...  Training loss: 2.1530...  0.0535 sec/batch
Epoch: 4/20...  Training Step: 2374...  Training loss: 2.1152...  0.0543 sec/batch
Epoch: 4/20...  Training Step: 2375...  Training loss: 2.0924...  0.0559 sec/batch
Epoch: 4/20...  Training Step: 2376...  Training loss: 2.0754...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 2377...  Training loss: 2.0690...  0.0532 sec/batch
Epoch: 4/20...  Training Step: 2378...  Training loss: 2.0968...  0.0569 sec/batch
Epoch: 4/20...  Training Step: 2379...  Training loss: 2.0720...  0.0523 sec/batch
Epoch: 4/20...  Training Step: 2380...  Training loss: 2.0696...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2381...  Training loss: 2.0707...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 2382...  Training loss: 2.0416...  0.0553 sec/batch
Epoch: 4/20...  Training Step: 2383...  Training loss: 2.0940...  0.0537 sec/batch
Epoch: 4/20...  Training Step: 2384...  Training loss: 1.9849...  0.0586 sec/batch
Epoch: 4/20...  Training Step: 2385...  Training loss: 2.0701...  0.0549 sec/batch
Epoch: 4/20...  Training Step: 2386...  Training loss: 2.1236...  0.0546 sec/batch
Epoch: 4/20...  Training Step: 2387...  Training loss: 2.1195...  0.0559 sec/batch
Epoch: 4/20...  Training Step: 2388...  Training loss: 2.0894...  0.0595 sec/batch
Epoch: 4/20...  Training Step: 2389...  Training loss: 2.0733...  0.0544 sec/batch
Epoch: 4/20...  Training Step: 2390...  Training loss: 2.0296...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2391...  Training loss: 2.0866...  0.0532 sec/batch
Epoch: 4/20...  Training Step: 2392...  Training loss: 2.0424...  0.0532 sec/batch
Epoch: 4/20...  Training Step: 2393...  Training loss: 2.0730...  0.0573 sec/batch
Epoch: 4/20...  Training Step: 2394...  Training loss: 2.0541...  0.0524 sec/batch
Epoch: 4/20...  Training Step: 2395...  Training loss: 2.0868...  0.0548 sec/batch
Epoch: 4/20...  Training Step: 2396...  Training loss: 2.0700...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 2397...  Training loss: 2.0389...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 2398...  Training loss: 2.1116...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2399...  Training loss: 2.0233...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2400...  Training loss: 2.1173...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 2401...  Training loss: 2.0927...  0.0570 sec/batch
Epoch: 4/20...  Training Step: 2402...  Training loss: 2.0611...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 2403...  Training loss: 2.0530...  0.0544 sec/batch
Epoch: 4/20...  Training Step: 2404...  Training loss: 2.0550...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2405...  Training loss: 2.1047...  0.0604 sec/batch
Epoch: 4/20...  Training Step: 2406...  Training loss: 2.0704...  0.0599 sec/batch
Epoch: 4/20...  Training Step: 2407...  Training loss: 2.0929...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 2408...  Training loss: 2.1169...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 2409...  Training loss: 2.1337...  0.0564 sec/batch
Epoch: 4/20...  Training Step: 2410...  Training loss: 2.0911...  0.0533 sec/batch
Epoch: 4/20...  Training Step: 2411...  Training loss: 2.0647...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2412...  Training loss: 2.0451...  0.0594 sec/batch
Epoch: 4/20...  Training Step: 2413...  Training loss: 2.0760...  0.0528 sec/batch
Epoch: 4/20...  Training Step: 2414...  Training loss: 2.0993...  0.0551 sec/batch
Epoch: 4/20...  Training Step: 2415...  Training loss: 2.0612...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2416...  Training loss: 2.0457...  0.0522 sec/batch
Epoch: 4/20...  Training Step: 2417...  Training loss: 2.0715...  0.0532 sec/batch
Epoch: 4/20...  Training Step: 2418...  Training loss: 2.0520...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 2419...  Training loss: 2.0850...  0.0522 sec/batch
Epoch: 4/20...  Training Step: 2420...  Training loss: 2.0843...  0.0526 sec/batch
Epoch: 4/20...  Training Step: 2421...  Training loss: 2.0810...  0.0550 sec/batch
Epoch: 4/20...  Training Step: 2422...  Training loss: 2.1229...  0.0532 sec/batch
Epoch: 4/20...  Training Step: 2423...  Training loss: 2.0782...  0.0529 sec/batch
Epoch: 4/20...  Training Step: 2424...  Training loss: 2.1314...  0.0597 sec/batch
Epoch: 4/20...  Training Step: 2425...  Training loss: 2.2001...  0.0584 sec/batch
Epoch: 4/20...  Training Step: 2426...  Training loss: 2.1006...  0.0583 sec/batch
Epoch: 4/20...  Training Step: 2427...  Training loss: 2.1055...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2428...  Training loss: 2.1415...  0.0524 sec/batch
Epoch: 4/20...  Training Step: 2429...  Training loss: 2.0907...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 2430...  Training loss: 2.0759...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2431...  Training loss: 2.0932...  0.0578 sec/batch
Epoch: 4/20...  Training Step: 2432...  Training loss: 2.1264...  0.0586 sec/batch
Epoch: 4/20...  Training Step: 2433...  Training loss: 2.0667...  0.0541 sec/batch
Epoch: 4/20...  Training Step: 2434...  Training loss: 2.0824...  0.0577 sec/batch
Epoch: 4/20...  Training Step: 2435...  Training loss: 2.0663...  0.0564 sec/batch
Epoch: 4/20...  Training Step: 2436...  Training loss: 2.1356...  0.0573 sec/batch
Epoch: 4/20...  Training Step: 2437...  Training loss: 2.0179...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2438...  Training loss: 2.0910...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 2439...  Training loss: 2.1413...  0.0571 sec/batch
Epoch: 4/20...  Training Step: 2440...  Training loss: 2.1175...  0.0536 sec/batch
Epoch: 4/20...  Training Step: 2441...  Training loss: 2.1028...  0.0542 sec/batch
Epoch: 4/20...  Training Step: 2442...  Training loss: 2.0686...  0.0568 sec/batch
Epoch: 4/20...  Training Step: 2443...  Training loss: 2.0780...  0.0530 sec/batch
Epoch: 4/20...  Training Step: 2444...  Training loss: 2.1411...  0.0567 sec/batch
Epoch: 4/20...  Training Step: 2445...  Training loss: 2.0957...  0.0556 sec/batch
Epoch: 4/20...  Training Step: 2446...  Training loss: 2.0660...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 2447...  Training loss: 2.0495...  0.0560 sec/batch
Epoch: 4/20...  Training Step: 2448...  Training loss: 2.1037...  0.0587 sec/batch
Epoch: 4/20...  Training Step: 2449...  Training loss: 2.0396...  0.0582 sec/batch
Epoch: 4/20...  Training Step: 2450...  Training loss: 2.1238...  0.0552 sec/batch
Epoch: 4/20...  Training Step: 2451...  Training loss: 2.0256...  0.0560 sec/batch
Epoch: 4/20...  Training Step: 2452...  Training loss: 2.1302...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 2453...  Training loss: 2.0398...  0.0571 sec/batch
Epoch: 4/20...  Training Step: 2454...  Training loss: 2.0517...  0.0534 sec/batch
Epoch: 4/20...  Training Step: 2455...  Training loss: 2.0283...  0.0531 sec/batch
Epoch: 4/20...  Training Step: 2456...  Training loss: 2.0408...  0.0581 sec/batch
Epoch: 4/20...  Training Step: 2457...  Training loss: 2.0324...  0.0537 sec/batch
Epoch: 4/20...  Training Step: 2458...  Training loss: 2.0588...  0.0527 sec/batch
Epoch: 4/20...  Training Step: 2459...  Training loss: 2.0915...  0.0554 sec/batch
Epoch: 4/20...  Training Step: 2460...  Training loss: 2.1080...  0.0589 sec/batch
Epoch: 4/20...  Training Step: 2461...  Training loss: 2.0902...  0.0552 sec/batch
Epoch: 4/20...  Training Step: 2462...  Training loss: 2.1005...  0.0594 sec/batch
Epoch: 4/20...  Training Step: 2463...  Training loss: 2.0930...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2464...  Training loss: 2.0301...  0.0584 sec/batch
Epoch: 4/20...  Training Step: 2465...  Training loss: 2.0672...  0.0588 sec/batch
Epoch: 4/20...  Training Step: 2466...  Training loss: 2.0739...  0.0538 sec/batch
Epoch: 4/20...  Training Step: 2467...  Training loss: 2.0118...  0.0577 sec/batch
Epoch: 4/20...  Training Step: 2468...  Training loss: 2.0529...  0.0595 sec/batch
Epoch: 4/20...  Training Step: 2469...  Training loss: 2.0335...  0.0569 sec/batch
Epoch: 4/20...  Training Step: 2470...  Training loss: 2.0956...  0.0558 sec/batch
Epoch: 4/20...  Training Step: 2471...  Training loss: 2.1091...  0.0569 sec/batch
Epoch: 4/20...  Training Step: 2472...  Training loss: 2.0966...  0.0535 sec/batch
Epoch: 4/20...  Training Step: 2473...  Training loss: 2.0335...  0.0598 sec/batch
Epoch: 4/20...  Training Step: 2474...  Training loss: 2.0769...  0.0533 sec/batch
Epoch: 4/20...  Training Step: 2475...  Training loss: 2.0284...  0.0563 sec/batch
Epoch: 4/20...  Training Step: 2476...  Training loss: 2.0957...  0.0524 sec/batch
Epoch: 4/20...  Training Step: 2477...  Training loss: 2.1009...  0.0564 sec/batch
Epoch: 4/20...  Training Step: 2478...  Training loss: 2.0453...  0.0565 sec/batch
Epoch: 4/20...  Training Step: 2479...  Training loss: 2.0056...  0.0588 sec/batch
Epoch: 4/20...  Training Step: 2480...  Training loss: 2.0581...  0.0526 sec/batch
Epoch: 5/20...  Training Step: 2481...  Training loss: 2.1695...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 2482...  Training loss: 2.1368...  0.0536 sec/batch
Epoch: 5/20...  Training Step: 2483...  Training loss: 2.0952...  0.0559 sec/batch
Epoch: 5/20...  Training Step: 2484...  Training loss: 2.0274...  0.0549 sec/batch
Epoch: 5/20...  Training Step: 2485...  Training loss: 2.0771...  0.0536 sec/batch
Epoch: 5/20...  Training Step: 2486...  Training loss: 2.0799...  0.0533 sec/batch
Epoch: 5/20...  Training Step: 2487...  Training loss: 2.0520...  0.0534 sec/batch
Epoch: 5/20...  Training Step: 2488...  Training loss: 2.0292...  0.0534 sec/batch
Epoch: 5/20...  Training Step: 2489...  Training loss: 2.0161...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2490...  Training loss: 2.0599...  0.0538 sec/batch
Epoch: 5/20...  Training Step: 2491...  Training loss: 2.0649...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 2492...  Training loss: 2.0426...  0.0524 sec/batch
Epoch: 5/20...  Training Step: 2493...  Training loss: 2.0823...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2494...  Training loss: 2.0432...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 2495...  Training loss: 2.0832...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2496...  Training loss: 2.1089...  0.0545 sec/batch
Epoch: 5/20...  Training Step: 2497...  Training loss: 2.0919...  0.0571 sec/batch
Epoch: 5/20...  Training Step: 2498...  Training loss: 2.0934...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 2499...  Training loss: 2.0531...  0.0537 sec/batch
Epoch: 5/20...  Training Step: 2500...  Training loss: 2.0909...  0.0563 sec/batch
Epoch: 5/20...  Training Step: 2501...  Training loss: 2.1269...  0.0560 sec/batch
Epoch: 5/20...  Training Step: 2502...  Training loss: 2.0660...  0.0533 sec/batch
Epoch: 5/20...  Training Step: 2503...  Training loss: 2.0257...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2504...  Training loss: 2.0747...  0.0591 sec/batch
Epoch: 5/20...  Training Step: 2505...  Training loss: 2.0591...  0.0545 sec/batch
Epoch: 5/20...  Training Step: 2506...  Training loss: 2.0381...  0.0534 sec/batch
Epoch: 5/20...  Training Step: 2507...  Training loss: 2.0644...  0.0573 sec/batch
Epoch: 5/20...  Training Step: 2508...  Training loss: 2.0459...  0.0574 sec/batch
Epoch: 5/20...  Training Step: 2509...  Training loss: 2.0927...  0.0573 sec/batch
Epoch: 5/20...  Training Step: 2510...  Training loss: 2.0235...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 2511...  Training loss: 2.0283...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2512...  Training loss: 2.0799...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2513...  Training loss: 2.0468...  0.0611 sec/batch
Epoch: 5/20...  Training Step: 2514...  Training loss: 2.0300...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2515...  Training loss: 2.0495...  0.0533 sec/batch
Epoch: 5/20...  Training Step: 2516...  Training loss: 2.0521...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2517...  Training loss: 2.0602...  0.0573 sec/batch
Epoch: 5/20...  Training Step: 2518...  Training loss: 2.0676...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2519...  Training loss: 2.0714...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2520...  Training loss: 2.0358...  0.0557 sec/batch
Epoch: 5/20...  Training Step: 2521...  Training loss: 2.0546...  0.0520 sec/batch
Epoch: 5/20...  Training Step: 2522...  Training loss: 2.0821...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2523...  Training loss: 2.0345...  0.0572 sec/batch
Epoch: 5/20...  Training Step: 2524...  Training loss: 2.0787...  0.0552 sec/batch
Epoch: 5/20...  Training Step: 2525...  Training loss: 2.0473...  0.0592 sec/batch
Epoch: 5/20...  Training Step: 2526...  Training loss: 2.0351...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 2527...  Training loss: 1.9660...  0.0534 sec/batch
Epoch: 5/20...  Training Step: 2528...  Training loss: 2.0652...  0.0551 sec/batch
Epoch: 5/20...  Training Step: 2529...  Training loss: 2.0631...  0.0562 sec/batch
Epoch: 5/20...  Training Step: 2530...  Training loss: 2.0633...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2531...  Training loss: 2.0224...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 2532...  Training loss: 2.0486...  0.0575 sec/batch
Epoch: 5/20...  Training Step: 2533...  Training loss: 2.0792...  0.0608 sec/batch
Epoch: 5/20...  Training Step: 2534...  Training loss: 2.0835...  0.0564 sec/batch
Epoch: 5/20...  Training Step: 2535...  Training loss: 2.1138...  0.0618 sec/batch
Epoch: 5/20...  Training Step: 2536...  Training loss: 2.0316...  0.0562 sec/batch
Epoch: 5/20...  Training Step: 2537...  Training loss: 2.0153...  0.0563 sec/batch
Epoch: 5/20...  Training Step: 2538...  Training loss: 2.0538...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2539...  Training loss: 2.0293...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2540...  Training loss: 2.1005...  0.0559 sec/batch
Epoch: 5/20...  Training Step: 2541...  Training loss: 2.0785...  0.0544 sec/batch
Epoch: 5/20...  Training Step: 2542...  Training loss: 2.0576...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 2543...  Training loss: 2.0645...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2544...  Training loss: 2.0333...  0.0523 sec/batch
Epoch: 5/20...  Training Step: 2545...  Training loss: 2.0199...  0.0603 sec/batch
Epoch: 5/20...  Training Step: 2546...  Training loss: 1.9847...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2547...  Training loss: 2.0156...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2548...  Training loss: 1.9962...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2549...  Training loss: 2.0897...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2550...  Training loss: 2.0674...  0.0584 sec/batch
Epoch: 5/20...  Training Step: 2551...  Training loss: 2.0641...  0.0546 sec/batch
Epoch: 5/20...  Training Step: 2552...  Training loss: 2.0678...  0.0542 sec/batch
Epoch: 5/20...  Training Step: 2553...  Training loss: 2.0421...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 2554...  Training loss: 2.0383...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 2555...  Training loss: 2.0946...  0.0546 sec/batch
Epoch: 5/20...  Training Step: 2556...  Training loss: 2.0668...  0.0557 sec/batch
Epoch: 5/20...  Training Step: 2557...  Training loss: 2.0813...  0.0526 sec/batch
Epoch: 5/20...  Training Step: 2558...  Training loss: 2.0572...  0.0536 sec/batch
Epoch: 5/20...  Training Step: 2559...  Training loss: 2.0619...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2560...  Training loss: 2.0881...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 2561...  Training loss: 2.0021...  0.0589 sec/batch
Epoch: 5/20...  Training Step: 2562...  Training loss: 2.0419...  0.0546 sec/batch
Epoch: 5/20...  Training Step: 2563...  Training loss: 2.0108...  0.0562 sec/batch
Epoch: 5/20...  Training Step: 2564...  Training loss: 2.0307...  0.0566 sec/batch
Epoch: 5/20...  Training Step: 2565...  Training loss: 2.0551...  0.0563 sec/batch
Epoch: 5/20...  Training Step: 2566...  Training loss: 2.0632...  0.0550 sec/batch
Epoch: 5/20...  Training Step: 2567...  Training loss: 2.0360...  0.0584 sec/batch
Epoch: 5/20...  Training Step: 2568...  Training loss: 2.0963...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2569...  Training loss: 2.0476...  0.0578 sec/batch
Epoch: 5/20...  Training Step: 2570...  Training loss: 2.0765...  0.0540 sec/batch
Epoch: 5/20...  Training Step: 2571...  Training loss: 2.0228...  0.0589 sec/batch
Epoch: 5/20...  Training Step: 2572...  Training loss: 2.1057...  0.0559 sec/batch
Epoch: 5/20...  Training Step: 2573...  Training loss: 2.0608...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 2574...  Training loss: 2.0558...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 2575...  Training loss: 2.0658...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2576...  Training loss: 2.0725...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2577...  Training loss: 2.0765...  0.0525 sec/batch
Epoch: 5/20...  Training Step: 2578...  Training loss: 2.0188...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2579...  Training loss: 2.1145...  0.0541 sec/batch
Epoch: 5/20...  Training Step: 2580...  Training loss: 2.0504...  0.0547 sec/batch
Epoch: 5/20...  Training Step: 2581...  Training loss: 2.0294...  0.0563 sec/batch
Epoch: 5/20...  Training Step: 2582...  Training loss: 2.0386...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2583...  Training loss: 2.0882...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2584...  Training loss: 2.0749...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2585...  Training loss: 2.0310...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2586...  Training loss: 2.0114...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2587...  Training loss: 2.0526...  0.0549 sec/batch
Epoch: 5/20...  Training Step: 2588...  Training loss: 2.0226...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 2589...  Training loss: 2.0272...  0.0523 sec/batch
Epoch: 5/20...  Training Step: 2590...  Training loss: 2.0328...  0.0546 sec/batch
Epoch: 5/20...  Training Step: 2591...  Training loss: 2.0096...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 2592...  Training loss: 2.0401...  0.0563 sec/batch
Epoch: 5/20...  Training Step: 2593...  Training loss: 2.0402...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 2594...  Training loss: 2.0372...  0.0526 sec/batch
Epoch: 5/20...  Training Step: 2595...  Training loss: 2.0659...  0.0524 sec/batch
Epoch: 5/20...  Training Step: 2596...  Training loss: 2.0791...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2597...  Training loss: 2.0048...  0.0550 sec/batch
Epoch: 5/20...  Training Step: 2598...  Training loss: 2.0782...  0.0584 sec/batch
Epoch: 5/20...  Training Step: 2599...  Training loss: 2.0269...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2600...  Training loss: 2.0025...  0.0523 sec/batch
Epoch: 5/20...  Training Step: 2601...  Training loss: 2.0236...  0.0592 sec/batch
Epoch: 5/20...  Training Step: 2602...  Training loss: 2.0176...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2603...  Training loss: 2.0219...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2604...  Training loss: 2.0423...  0.0589 sec/batch
Epoch: 5/20...  Training Step: 2605...  Training loss: 2.0768...  0.0587 sec/batch
Epoch: 5/20...  Training Step: 2606...  Training loss: 2.0953...  0.0547 sec/batch
Epoch: 5/20...  Training Step: 2607...  Training loss: 2.0763...  0.0526 sec/batch
Epoch: 5/20...  Training Step: 2608...  Training loss: 2.0058...  0.0526 sec/batch
Epoch: 5/20...  Training Step: 2609...  Training loss: 2.0252...  0.0597 sec/batch
Epoch: 5/20...  Training Step: 2610...  Training loss: 2.0813...  0.0582 sec/batch
Epoch: 5/20...  Training Step: 2611...  Training loss: 2.0306...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2612...  Training loss: 2.0973...  0.0521 sec/batch
Epoch: 5/20...  Training Step: 2613...  Training loss: 2.0862...  0.0543 sec/batch
Epoch: 5/20...  Training Step: 2614...  Training loss: 2.0393...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 2615...  Training loss: 1.9946...  0.0525 sec/batch
Epoch: 5/20...  Training Step: 2616...  Training loss: 2.0381...  0.0601 sec/batch
Epoch: 5/20...  Training Step: 2617...  Training loss: 2.0320...  0.0590 sec/batch
Epoch: 5/20...  Training Step: 2618...  Training loss: 2.0325...  0.0584 sec/batch
Epoch: 5/20...  Training Step: 2619...  Training loss: 2.0991...  0.0535 sec/batch
Epoch: 5/20...  Training Step: 2620...  Training loss: 2.0244...  0.0546 sec/batch
Epoch: 5/20...  Training Step: 2621...  Training loss: 2.0549...  0.0541 sec/batch
Epoch: 5/20...  Training Step: 2622...  Training loss: 2.0005...  0.0552 sec/batch
Epoch: 5/20...  Training Step: 2623...  Training loss: 2.0448...  0.0588 sec/batch
Epoch: 5/20...  Training Step: 2624...  Training loss: 2.0142...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2625...  Training loss: 2.0178...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2626...  Training loss: 2.0722...  0.0525 sec/batch
Epoch: 5/20...  Training Step: 2627...  Training loss: 2.0530...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2628...  Training loss: 2.0820...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 2629...  Training loss: 2.0231...  0.0536 sec/batch
Epoch: 5/20...  Training Step: 2630...  Training loss: 2.0656...  0.0551 sec/batch
Epoch: 5/20...  Training Step: 2631...  Training loss: 2.0759...  0.0533 sec/batch
Epoch: 5/20...  Training Step: 2632...  Training loss: 2.0425...  0.0568 sec/batch
Epoch: 5/20...  Training Step: 2633...  Training loss: 2.0147...  0.0562 sec/batch
Epoch: 5/20...  Training Step: 2634...  Training loss: 2.0654...  0.0576 sec/batch
Epoch: 5/20...  Training Step: 2635...  Training loss: 2.0340...  0.0551 sec/batch
Epoch: 5/20...  Training Step: 2636...  Training loss: 2.0695...  0.0548 sec/batch
Epoch: 5/20...  Training Step: 2637...  Training loss: 2.0404...  0.0587 sec/batch
Epoch: 5/20...  Training Step: 2638...  Training loss: 2.0826...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2639...  Training loss: 2.0748...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2640...  Training loss: 2.0199...  0.0522 sec/batch
Epoch: 5/20...  Training Step: 2641...  Training loss: 2.0002...  0.0563 sec/batch
Epoch: 5/20...  Training Step: 2642...  Training loss: 2.0269...  0.0559 sec/batch
Epoch: 5/20...  Training Step: 2643...  Training loss: 2.0236...  0.0578 sec/batch
Epoch: 5/20...  Training Step: 2644...  Training loss: 2.0376...  0.0587 sec/batch
Epoch: 5/20...  Training Step: 2645...  Training loss: 2.0352...  0.0586 sec/batch
Epoch: 5/20...  Training Step: 2646...  Training loss: 2.0341...  0.0584 sec/batch
Epoch: 5/20...  Training Step: 2647...  Training loss: 2.0648...  0.0541 sec/batch
Epoch: 5/20...  Training Step: 2648...  Training loss: 2.0491...  0.0559 sec/batch
Epoch: 5/20...  Training Step: 2649...  Training loss: 2.0091...  0.0533 sec/batch
Epoch: 5/20...  Training Step: 2650...  Training loss: 2.0052...  0.0573 sec/batch
Epoch: 5/20...  Training Step: 2651...  Training loss: 2.0124...  0.0605 sec/batch
Epoch: 5/20...  Training Step: 2652...  Training loss: 2.0501...  0.0559 sec/batch
Epoch: 5/20...  Training Step: 2653...  Training loss: 2.0437...  0.0565 sec/batch
Epoch: 5/20...  Training Step: 2654...  Training loss: 2.0304...  0.0591 sec/batch
Epoch: 5/20...  Training Step: 2655...  Training loss: 2.0294...  0.0552 sec/batch
Epoch: 5/20...  Training Step: 2656...  Training loss: 2.0532...  0.0590 sec/batch
Epoch: 5/20...  Training Step: 2657...  Training loss: 2.0438...  0.0559 sec/batch
Epoch: 5/20...  Training Step: 2658...  Training loss: 2.0342...  0.0545 sec/batch
Epoch: 5/20...  Training Step: 2659...  Training loss: 2.0268...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 2660...  Training loss: 2.0179...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2661...  Training loss: 2.0241...  0.0575 sec/batch
Epoch: 5/20...  Training Step: 2662...  Training loss: 2.0546...  0.0590 sec/batch
Epoch: 5/20...  Training Step: 2663...  Training loss: 2.0365...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 2664...  Training loss: 1.9967...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 2665...  Training loss: 1.9880...  0.0533 sec/batch
Epoch: 5/20...  Training Step: 2666...  Training loss: 2.0417...  0.0574 sec/batch
Epoch: 5/20...  Training Step: 2667...  Training loss: 2.0050...  0.0535 sec/batch
Epoch: 5/20...  Training Step: 2668...  Training loss: 2.0289...  0.0533 sec/batch
Epoch: 5/20...  Training Step: 2669...  Training loss: 2.0474...  0.0578 sec/batch
Epoch: 5/20...  Training Step: 2670...  Training loss: 2.1160...  0.0587 sec/batch
Epoch: 5/20...  Training Step: 2671...  Training loss: 2.0822...  0.0576 sec/batch
Epoch: 5/20...  Training Step: 2672...  Training loss: 2.1106...  0.0537 sec/batch
Epoch: 5/20...  Training Step: 2673...  Training loss: 2.0615...  0.0536 sec/batch
Epoch: 5/20...  Training Step: 2674...  Training loss: 2.0105...  0.0525 sec/batch
Epoch: 5/20...  Training Step: 2675...  Training loss: 2.0464...  0.0535 sec/batch
Epoch: 5/20...  Training Step: 2676...  Training loss: 2.1049...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2677...  Training loss: 2.0500...  0.0572 sec/batch
Epoch: 5/20...  Training Step: 2678...  Training loss: 2.0972...  0.0563 sec/batch
Epoch: 5/20...  Training Step: 2679...  Training loss: 2.0190...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2680...  Training loss: 2.0417...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 2681...  Training loss: 2.0539...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2682...  Training loss: 2.0358...  0.0562 sec/batch
Epoch: 5/20...  Training Step: 2683...  Training loss: 2.0189...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2684...  Training loss: 2.0207...  0.0547 sec/batch
Epoch: 5/20...  Training Step: 2685...  Training loss: 2.0449...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2686...  Training loss: 1.9940...  0.0564 sec/batch
Epoch: 5/20...  Training Step: 2687...  Training loss: 2.0620...  0.0617 sec/batch
Epoch: 5/20...  Training Step: 2688...  Training loss: 2.0389...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2689...  Training loss: 2.0429...  0.0536 sec/batch
Epoch: 5/20...  Training Step: 2690...  Training loss: 2.0268...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2691...  Training loss: 2.0359...  0.0552 sec/batch
Epoch: 5/20...  Training Step: 2692...  Training loss: 2.0545...  0.0588 sec/batch
Epoch: 5/20...  Training Step: 2693...  Training loss: 2.0662...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2694...  Training loss: 2.0793...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2695...  Training loss: 2.0576...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2696...  Training loss: 2.0644...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2697...  Training loss: 2.0497...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2698...  Training loss: 2.0056...  0.0566 sec/batch
Epoch: 5/20...  Training Step: 2699...  Training loss: 2.1337...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2700...  Training loss: 2.0838...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2701...  Training loss: 2.0359...  0.0549 sec/batch
Epoch: 5/20...  Training Step: 2702...  Training loss: 2.0524...  0.0538 sec/batch
Epoch: 5/20...  Training Step: 2703...  Training loss: 2.0992...  0.0557 sec/batch
Epoch: 5/20...  Training Step: 2704...  Training loss: 2.0059...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 2705...  Training loss: 2.0306...  0.0606 sec/batch
Epoch: 5/20...  Training Step: 2706...  Training loss: 2.0722...  0.0548 sec/batch
Epoch: 5/20...  Training Step: 2707...  Training loss: 2.0847...  0.0557 sec/batch
Epoch: 5/20...  Training Step: 2708...  Training loss: 2.0117...  0.0545 sec/batch
Epoch: 5/20...  Training Step: 2709...  Training loss: 2.0587...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2710...  Training loss: 2.0375...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2711...  Training loss: 2.0865...  0.0580 sec/batch
Epoch: 5/20...  Training Step: 2712...  Training loss: 2.0198...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2713...  Training loss: 2.0220...  0.0557 sec/batch
Epoch: 5/20...  Training Step: 2714...  Training loss: 2.0048...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 2715...  Training loss: 2.0250...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2716...  Training loss: 2.0606...  0.0562 sec/batch
Epoch: 5/20...  Training Step: 2717...  Training loss: 2.0448...  0.0581 sec/batch
Epoch: 5/20...  Training Step: 2718...  Training loss: 1.9851...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2719...  Training loss: 1.9956...  0.0577 sec/batch
Epoch: 5/20...  Training Step: 2720...  Training loss: 2.0772...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2721...  Training loss: 2.0420...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2722...  Training loss: 2.0283...  0.0535 sec/batch
Epoch: 5/20...  Training Step: 2723...  Training loss: 2.0113...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 2724...  Training loss: 2.0281...  0.0524 sec/batch
Epoch: 5/20...  Training Step: 2725...  Training loss: 2.0188...  0.0573 sec/batch
Epoch: 5/20...  Training Step: 2726...  Training loss: 2.0250...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 2727...  Training loss: 2.0329...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 2728...  Training loss: 2.0554...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2729...  Training loss: 2.0050...  0.0534 sec/batch
Epoch: 5/20...  Training Step: 2730...  Training loss: 2.0411...  0.0591 sec/batch
Epoch: 5/20...  Training Step: 2731...  Training loss: 2.0173...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 2732...  Training loss: 1.9794...  0.0524 sec/batch
Epoch: 5/20...  Training Step: 2733...  Training loss: 2.0478...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 2734...  Training loss: 2.0476...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2735...  Training loss: 2.0735...  0.0574 sec/batch
Epoch: 5/20...  Training Step: 2736...  Training loss: 2.0335...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2737...  Training loss: 2.0339...  0.0566 sec/batch
Epoch: 5/20...  Training Step: 2738...  Training loss: 2.0512...  0.0537 sec/batch
Epoch: 5/20...  Training Step: 2739...  Training loss: 2.0481...  0.0564 sec/batch
Epoch: 5/20...  Training Step: 2740...  Training loss: 2.0348...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2741...  Training loss: 2.0545...  0.0564 sec/batch
Epoch: 5/20...  Training Step: 2742...  Training loss: 2.0302...  0.0536 sec/batch
Epoch: 5/20...  Training Step: 2743...  Training loss: 2.0557...  0.0678 sec/batch
Epoch: 5/20...  Training Step: 2744...  Training loss: 2.0408...  0.0720 sec/batch
Epoch: 5/20...  Training Step: 2745...  Training loss: 2.0645...  0.0535 sec/batch
Epoch: 5/20...  Training Step: 2746...  Training loss: 1.9728...  0.0525 sec/batch
Epoch: 5/20...  Training Step: 2747...  Training loss: 2.0571...  0.0524 sec/batch
Epoch: 5/20...  Training Step: 2748...  Training loss: 2.0332...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 2749...  Training loss: 2.0294...  0.0546 sec/batch
Epoch: 5/20...  Training Step: 2750...  Training loss: 2.0210...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 2751...  Training loss: 1.9981...  0.0559 sec/batch
Epoch: 5/20...  Training Step: 2752...  Training loss: 2.0397...  0.0563 sec/batch
Epoch: 5/20...  Training Step: 2753...  Training loss: 2.0199...  0.0585 sec/batch
Epoch: 5/20...  Training Step: 2754...  Training loss: 2.0196...  0.0584 sec/batch
Epoch: 5/20...  Training Step: 2755...  Training loss: 2.0538...  0.0560 sec/batch
Epoch: 5/20...  Training Step: 2756...  Training loss: 2.0636...  0.0583 sec/batch
Epoch: 5/20...  Training Step: 2757...  Training loss: 2.0935...  0.0592 sec/batch
Epoch: 5/20...  Training Step: 2758...  Training loss: 2.0429...  0.0606 sec/batch
Epoch: 5/20...  Training Step: 2759...  Training loss: 2.0672...  0.0534 sec/batch
Epoch: 5/20...  Training Step: 2760...  Training loss: 2.0783...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2761...  Training loss: 2.0411...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2762...  Training loss: 1.9783...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2763...  Training loss: 2.0165...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2764...  Training loss: 2.0361...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 2765...  Training loss: 2.0019...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 2766...  Training loss: 2.0521...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2767...  Training loss: 2.0179...  0.0581 sec/batch
Epoch: 5/20...  Training Step: 2768...  Training loss: 2.0181...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2769...  Training loss: 2.0380...  0.0541 sec/batch
Epoch: 5/20...  Training Step: 2770...  Training loss: 2.0877...  0.0560 sec/batch
Epoch: 5/20...  Training Step: 2771...  Training loss: 2.0156...  0.0533 sec/batch
Epoch: 5/20...  Training Step: 2772...  Training loss: 2.0437...  0.0560 sec/batch
Epoch: 5/20...  Training Step: 2773...  Training loss: 2.0274...  0.0547 sec/batch
Epoch: 5/20...  Training Step: 2774...  Training loss: 2.0329...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2775...  Training loss: 2.0044...  0.0593 sec/batch
Epoch: 5/20...  Training Step: 2776...  Training loss: 2.0183...  0.0624 sec/batch
Epoch: 5/20...  Training Step: 2777...  Training loss: 2.0547...  0.0535 sec/batch
Epoch: 5/20...  Training Step: 2778...  Training loss: 2.0542...  0.0563 sec/batch
Epoch: 5/20...  Training Step: 2779...  Training loss: 2.0924...  0.0526 sec/batch
Epoch: 5/20...  Training Step: 2780...  Training loss: 2.0230...  0.0567 sec/batch
Epoch: 5/20...  Training Step: 2781...  Training loss: 2.0437...  0.0567 sec/batch
Epoch: 5/20...  Training Step: 2782...  Training loss: 2.0898...  0.0539 sec/batch
Epoch: 5/20...  Training Step: 2783...  Training loss: 1.9815...  0.0602 sec/batch
Epoch: 5/20...  Training Step: 2784...  Training loss: 2.0566...  0.0540 sec/batch
Epoch: 5/20...  Training Step: 2785...  Training loss: 2.0260...  0.0539 sec/batch
Epoch: 5/20...  Training Step: 2786...  Training loss: 2.0391...  0.0552 sec/batch
Epoch: 5/20...  Training Step: 2787...  Training loss: 2.0314...  0.0584 sec/batch
Epoch: 5/20...  Training Step: 2788...  Training loss: 2.0097...  0.0547 sec/batch
Epoch: 5/20...  Training Step: 2789...  Training loss: 2.0492...  0.0580 sec/batch
Epoch: 5/20...  Training Step: 2790...  Training loss: 1.9834...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 2791...  Training loss: 2.0053...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 2792...  Training loss: 2.0204...  0.0557 sec/batch
Epoch: 5/20...  Training Step: 2793...  Training loss: 2.0061...  0.0590 sec/batch
Epoch: 5/20...  Training Step: 2794...  Training loss: 1.9878...  0.0565 sec/batch
Epoch: 5/20...  Training Step: 2795...  Training loss: 2.0171...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2796...  Training loss: 2.0400...  0.0548 sec/batch
Epoch: 5/20...  Training Step: 2797...  Training loss: 1.9941...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 2798...  Training loss: 1.9882...  0.0541 sec/batch
Epoch: 5/20...  Training Step: 2799...  Training loss: 2.0400...  0.0576 sec/batch
Epoch: 5/20...  Training Step: 2800...  Training loss: 2.0835...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2801...  Training loss: 2.0298...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 2802...  Training loss: 1.9802...  0.0557 sec/batch
Epoch: 5/20...  Training Step: 2803...  Training loss: 2.0307...  0.0545 sec/batch
Epoch: 5/20...  Training Step: 2804...  Training loss: 2.0187...  0.0571 sec/batch
Epoch: 5/20...  Training Step: 2805...  Training loss: 1.9803...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 2806...  Training loss: 2.0047...  0.0579 sec/batch
Epoch: 5/20...  Training Step: 2807...  Training loss: 1.9958...  0.0585 sec/batch
Epoch: 5/20...  Training Step: 2808...  Training loss: 1.9718...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2809...  Training loss: 2.0269...  0.0574 sec/batch
Epoch: 5/20...  Training Step: 2810...  Training loss: 2.0017...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2811...  Training loss: 2.0310...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2812...  Training loss: 2.0110...  0.0589 sec/batch
Epoch: 5/20...  Training Step: 2813...  Training loss: 1.9760...  0.0562 sec/batch
Epoch: 5/20...  Training Step: 2814...  Training loss: 2.0153...  0.0549 sec/batch
Epoch: 5/20...  Training Step: 2815...  Training loss: 2.0290...  0.0523 sec/batch
Epoch: 5/20...  Training Step: 2816...  Training loss: 2.0425...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2817...  Training loss: 1.9883...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 2818...  Training loss: 2.0125...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 2819...  Training loss: 2.0169...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2820...  Training loss: 2.0481...  0.0566 sec/batch
Epoch: 5/20...  Training Step: 2821...  Training loss: 2.0253...  0.0594 sec/batch
Epoch: 5/20...  Training Step: 2822...  Training loss: 2.0009...  0.0574 sec/batch
Epoch: 5/20...  Training Step: 2823...  Training loss: 2.0011...  0.0557 sec/batch
Epoch: 5/20...  Training Step: 2824...  Training loss: 2.0091...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2825...  Training loss: 2.0217...  0.0535 sec/batch
Epoch: 5/20...  Training Step: 2826...  Training loss: 2.0438...  0.0557 sec/batch
Epoch: 5/20...  Training Step: 2827...  Training loss: 2.0332...  0.0534 sec/batch
Epoch: 5/20...  Training Step: 2828...  Training loss: 2.0136...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2829...  Training loss: 2.0166...  0.0560 sec/batch
Epoch: 5/20...  Training Step: 2830...  Training loss: 1.9992...  0.0552 sec/batch
Epoch: 5/20...  Training Step: 2831...  Training loss: 2.0447...  0.0526 sec/batch
Epoch: 5/20...  Training Step: 2832...  Training loss: 2.0050...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2833...  Training loss: 2.0514...  0.0536 sec/batch
Epoch: 5/20...  Training Step: 2834...  Training loss: 2.0066...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2835...  Training loss: 1.9978...  0.0535 sec/batch
Epoch: 5/20...  Training Step: 2836...  Training loss: 2.0675...  0.0563 sec/batch
Epoch: 5/20...  Training Step: 2837...  Training loss: 2.1150...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2838...  Training loss: 2.0404...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2839...  Training loss: 2.0439...  0.0564 sec/batch
Epoch: 5/20...  Training Step: 2840...  Training loss: 2.0549...  0.0564 sec/batch
Epoch: 5/20...  Training Step: 2841...  Training loss: 2.0501...  0.0585 sec/batch
Epoch: 5/20...  Training Step: 2842...  Training loss: 2.0001...  0.0572 sec/batch
Epoch: 5/20...  Training Step: 2843...  Training loss: 1.9734...  0.0588 sec/batch
Epoch: 5/20...  Training Step: 2844...  Training loss: 1.9425...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2845...  Training loss: 1.9971...  0.0590 sec/batch
Epoch: 5/20...  Training Step: 2846...  Training loss: 2.0387...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2847...  Training loss: 2.0071...  0.0550 sec/batch
Epoch: 5/20...  Training Step: 2848...  Training loss: 2.0884...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2849...  Training loss: 2.0456...  0.0533 sec/batch
Epoch: 5/20...  Training Step: 2850...  Training loss: 2.0165...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 2851...  Training loss: 2.0505...  0.0559 sec/batch
Epoch: 5/20...  Training Step: 2852...  Training loss: 2.0928...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 2853...  Training loss: 2.0461...  0.0538 sec/batch
Epoch: 5/20...  Training Step: 2854...  Training loss: 2.0325...  0.0567 sec/batch
Epoch: 5/20...  Training Step: 2855...  Training loss: 2.0098...  0.0544 sec/batch
Epoch: 5/20...  Training Step: 2856...  Training loss: 2.0461...  0.0526 sec/batch
Epoch: 5/20...  Training Step: 2857...  Training loss: 2.0115...  0.0563 sec/batch
Epoch: 5/20...  Training Step: 2858...  Training loss: 2.0843...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2859...  Training loss: 2.0436...  0.0594 sec/batch
Epoch: 5/20...  Training Step: 2860...  Training loss: 2.0056...  0.0525 sec/batch
Epoch: 5/20...  Training Step: 2861...  Training loss: 1.9680...  0.0538 sec/batch
Epoch: 5/20...  Training Step: 2862...  Training loss: 2.0832...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 2863...  Training loss: 1.9719...  0.0588 sec/batch
Epoch: 5/20...  Training Step: 2864...  Training loss: 2.0441...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2865...  Training loss: 2.0304...  0.0551 sec/batch
Epoch: 5/20...  Training Step: 2866...  Training loss: 1.9607...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2867...  Training loss: 1.9801...  0.0552 sec/batch
Epoch: 5/20...  Training Step: 2868...  Training loss: 2.0216...  0.0547 sec/batch
Epoch: 5/20...  Training Step: 2869...  Training loss: 1.9573...  0.0597 sec/batch
Epoch: 5/20...  Training Step: 2870...  Training loss: 1.9790...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2871...  Training loss: 2.0520...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 2872...  Training loss: 1.9529...  0.0547 sec/batch
Epoch: 5/20...  Training Step: 2873...  Training loss: 2.0118...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 2874...  Training loss: 2.0204...  0.0536 sec/batch
Epoch: 5/20...  Training Step: 2875...  Training loss: 1.9901...  0.0539 sec/batch
Epoch: 5/20...  Training Step: 2876...  Training loss: 2.0252...  0.0595 sec/batch
Epoch: 5/20...  Training Step: 2877...  Training loss: 2.0149...  0.0599 sec/batch
Epoch: 5/20...  Training Step: 2878...  Training loss: 2.0333...  0.0580 sec/batch
Epoch: 5/20...  Training Step: 2879...  Training loss: 2.0159...  0.0616 sec/batch
Epoch: 5/20...  Training Step: 2880...  Training loss: 2.0236...  0.0586 sec/batch
Epoch: 5/20...  Training Step: 2881...  Training loss: 2.0522...  0.0560 sec/batch
Epoch: 5/20...  Training Step: 2882...  Training loss: 2.0340...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2883...  Training loss: 2.0111...  0.0564 sec/batch
Epoch: 5/20...  Training Step: 2884...  Training loss: 2.0527...  0.0562 sec/batch
Epoch: 5/20...  Training Step: 2885...  Training loss: 2.0663...  0.0536 sec/batch
Epoch: 5/20...  Training Step: 2886...  Training loss: 2.0355...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2887...  Training loss: 2.0900...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 2888...  Training loss: 2.0102...  0.0578 sec/batch
Epoch: 5/20...  Training Step: 2889...  Training loss: 2.0661...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2890...  Training loss: 2.0349...  0.0552 sec/batch
Epoch: 5/20...  Training Step: 2891...  Training loss: 2.0117...  0.0563 sec/batch
Epoch: 5/20...  Training Step: 2892...  Training loss: 2.0587...  0.0551 sec/batch
Epoch: 5/20...  Training Step: 2893...  Training loss: 2.0372...  0.0563 sec/batch
Epoch: 5/20...  Training Step: 2894...  Training loss: 2.0161...  0.0548 sec/batch
Epoch: 5/20...  Training Step: 2895...  Training loss: 1.9809...  0.0572 sec/batch
Epoch: 5/20...  Training Step: 2896...  Training loss: 1.9773...  0.0570 sec/batch
Epoch: 5/20...  Training Step: 2897...  Training loss: 2.0051...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2898...  Training loss: 2.0301...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2899...  Training loss: 2.0568...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2900...  Training loss: 2.0186...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 2901...  Training loss: 1.9740...  0.0559 sec/batch
Epoch: 5/20...  Training Step: 2902...  Training loss: 2.0090...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 2903...  Training loss: 2.0436...  0.0598 sec/batch
Epoch: 5/20...  Training Step: 2904...  Training loss: 1.9999...  0.0526 sec/batch
Epoch: 5/20...  Training Step: 2905...  Training loss: 2.0568...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 2906...  Training loss: 2.0454...  0.0523 sec/batch
Epoch: 5/20...  Training Step: 2907...  Training loss: 1.9957...  0.0592 sec/batch
Epoch: 5/20...  Training Step: 2908...  Training loss: 2.0217...  0.0551 sec/batch
Epoch: 5/20...  Training Step: 2909...  Training loss: 2.0291...  0.0538 sec/batch
Epoch: 5/20...  Training Step: 2910...  Training loss: 1.9733...  0.0534 sec/batch
Epoch: 5/20...  Training Step: 2911...  Training loss: 2.0149...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2912...  Training loss: 2.0706...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2913...  Training loss: 2.0253...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 2914...  Training loss: 1.9967...  0.0533 sec/batch
Epoch: 5/20...  Training Step: 2915...  Training loss: 1.9910...  0.0546 sec/batch
Epoch: 5/20...  Training Step: 2916...  Training loss: 2.0317...  0.0536 sec/batch
Epoch: 5/20...  Training Step: 2917...  Training loss: 1.9757...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2918...  Training loss: 2.0365...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2919...  Training loss: 2.0341...  0.0589 sec/batch
Epoch: 5/20...  Training Step: 2920...  Training loss: 1.9875...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2921...  Training loss: 2.0072...  0.0546 sec/batch
Epoch: 5/20...  Training Step: 2922...  Training loss: 2.0038...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 2923...  Training loss: 2.0579...  0.0526 sec/batch
Epoch: 5/20...  Training Step: 2924...  Training loss: 1.9951...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2925...  Training loss: 1.9519...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2926...  Training loss: 2.0071...  0.0525 sec/batch
Epoch: 5/20...  Training Step: 2927...  Training loss: 1.9909...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 2928...  Training loss: 1.9739...  0.0549 sec/batch
Epoch: 5/20...  Training Step: 2929...  Training loss: 2.0298...  0.0572 sec/batch
Epoch: 5/20...  Training Step: 2930...  Training loss: 2.0755...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2931...  Training loss: 2.0937...  0.0564 sec/batch
Epoch: 5/20...  Training Step: 2932...  Training loss: 2.0357...  0.0560 sec/batch
Epoch: 5/20...  Training Step: 2933...  Training loss: 1.9836...  0.0571 sec/batch
Epoch: 5/20...  Training Step: 2934...  Training loss: 1.9997...  0.0523 sec/batch
Epoch: 5/20...  Training Step: 2935...  Training loss: 1.9992...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2936...  Training loss: 2.0233...  0.0562 sec/batch
Epoch: 5/20...  Training Step: 2937...  Training loss: 2.0087...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2938...  Training loss: 2.0352...  0.0547 sec/batch
Epoch: 5/20...  Training Step: 2939...  Training loss: 2.0027...  0.0559 sec/batch
Epoch: 5/20...  Training Step: 2940...  Training loss: 2.0237...  0.0533 sec/batch
Epoch: 5/20...  Training Step: 2941...  Training loss: 1.9788...  0.0539 sec/batch
Epoch: 5/20...  Training Step: 2942...  Training loss: 2.0147...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 2943...  Training loss: 1.9916...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 2944...  Training loss: 1.9953...  0.0551 sec/batch
Epoch: 5/20...  Training Step: 2945...  Training loss: 2.0516...  0.0582 sec/batch
Epoch: 5/20...  Training Step: 2946...  Training loss: 2.0189...  0.0551 sec/batch
Epoch: 5/20...  Training Step: 2947...  Training loss: 2.0038...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 2948...  Training loss: 1.9963...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 2949...  Training loss: 2.0266...  0.0594 sec/batch
Epoch: 5/20...  Training Step: 2950...  Training loss: 2.0140...  0.0552 sec/batch
Epoch: 5/20...  Training Step: 2951...  Training loss: 2.0087...  0.0567 sec/batch
Epoch: 5/20...  Training Step: 2952...  Training loss: 2.0202...  0.0564 sec/batch
Epoch: 5/20...  Training Step: 2953...  Training loss: 1.9766...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 2954...  Training loss: 1.9499...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2955...  Training loss: 2.0609...  0.0522 sec/batch
Epoch: 5/20...  Training Step: 2956...  Training loss: 2.0646...  0.0564 sec/batch
Epoch: 5/20...  Training Step: 2957...  Training loss: 2.0174...  0.0557 sec/batch
Epoch: 5/20...  Training Step: 2958...  Training loss: 2.0667...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 2959...  Training loss: 1.9907...  0.0577 sec/batch
Epoch: 5/20...  Training Step: 2960...  Training loss: 2.0555...  0.0590 sec/batch
Epoch: 5/20...  Training Step: 2961...  Training loss: 2.0302...  0.0549 sec/batch
Epoch: 5/20...  Training Step: 2962...  Training loss: 1.9714...  0.0533 sec/batch
Epoch: 5/20...  Training Step: 2963...  Training loss: 2.0476...  0.0536 sec/batch
Epoch: 5/20...  Training Step: 2964...  Training loss: 2.0349...  0.0577 sec/batch
Epoch: 5/20...  Training Step: 2965...  Training loss: 2.0680...  0.0538 sec/batch
Epoch: 5/20...  Training Step: 2966...  Training loss: 1.9889...  0.0593 sec/batch
Epoch: 5/20...  Training Step: 2967...  Training loss: 2.0524...  0.0570 sec/batch
Epoch: 5/20...  Training Step: 2968...  Training loss: 2.0230...  0.0552 sec/batch
Epoch: 5/20...  Training Step: 2969...  Training loss: 2.0279...  0.0591 sec/batch
Epoch: 5/20...  Training Step: 2970...  Training loss: 2.0110...  0.0551 sec/batch
Epoch: 5/20...  Training Step: 2971...  Training loss: 2.0151...  0.0541 sec/batch
Epoch: 5/20...  Training Step: 2972...  Training loss: 2.0656...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2973...  Training loss: 2.0034...  0.0526 sec/batch
Epoch: 5/20...  Training Step: 2974...  Training loss: 2.0077...  0.0536 sec/batch
Epoch: 5/20...  Training Step: 2975...  Training loss: 1.9894...  0.0585 sec/batch
Epoch: 5/20...  Training Step: 2976...  Training loss: 2.0278...  0.0584 sec/batch
Epoch: 5/20...  Training Step: 2977...  Training loss: 2.0106...  0.0551 sec/batch
Epoch: 5/20...  Training Step: 2978...  Training loss: 2.0454...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 2979...  Training loss: 1.9611...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 2980...  Training loss: 2.0319...  0.0587 sec/batch
Epoch: 5/20...  Training Step: 2981...  Training loss: 2.0237...  0.0560 sec/batch
Epoch: 5/20...  Training Step: 2982...  Training loss: 2.0472...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 2983...  Training loss: 2.0783...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 2984...  Training loss: 2.0296...  0.0535 sec/batch
Epoch: 5/20...  Training Step: 2985...  Training loss: 2.0080...  0.0565 sec/batch
Epoch: 5/20...  Training Step: 2986...  Training loss: 1.9580...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 2987...  Training loss: 2.0340...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 2988...  Training loss: 2.0015...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 2989...  Training loss: 2.0221...  0.0534 sec/batch
Epoch: 5/20...  Training Step: 2990...  Training loss: 2.0219...  0.0565 sec/batch
Epoch: 5/20...  Training Step: 2991...  Training loss: 2.0324...  0.0571 sec/batch
Epoch: 5/20...  Training Step: 2992...  Training loss: 2.0154...  0.0582 sec/batch
Epoch: 5/20...  Training Step: 2993...  Training loss: 2.0846...  0.0579 sec/batch
Epoch: 5/20...  Training Step: 2994...  Training loss: 2.0392...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2995...  Training loss: 2.0283...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 2996...  Training loss: 2.0108...  0.0549 sec/batch
Epoch: 5/20...  Training Step: 2997...  Training loss: 1.9970...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 2998...  Training loss: 1.9970...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 2999...  Training loss: 1.9892...  0.0548 sec/batch
Epoch: 5/20...  Training Step: 3000...  Training loss: 1.9872...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 3001...  Training loss: 1.9982...  0.0537 sec/batch
Epoch: 5/20...  Training Step: 3002...  Training loss: 1.9784...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 3003...  Training loss: 1.9874...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 3004...  Training loss: 1.9104...  0.0550 sec/batch
Epoch: 5/20...  Training Step: 3005...  Training loss: 2.0033...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 3006...  Training loss: 2.0532...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 3007...  Training loss: 2.0406...  0.0533 sec/batch
Epoch: 5/20...  Training Step: 3008...  Training loss: 2.0278...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 3009...  Training loss: 2.0059...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 3010...  Training loss: 1.9803...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 3011...  Training loss: 2.0164...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 3012...  Training loss: 1.9805...  0.0535 sec/batch
Epoch: 5/20...  Training Step: 3013...  Training loss: 1.9973...  0.0552 sec/batch
Epoch: 5/20...  Training Step: 3014...  Training loss: 1.9794...  0.0534 sec/batch
Epoch: 5/20...  Training Step: 3015...  Training loss: 2.0066...  0.0537 sec/batch
Epoch: 5/20...  Training Step: 3016...  Training loss: 2.0143...  0.0581 sec/batch
Epoch: 5/20...  Training Step: 3017...  Training loss: 1.9668...  0.0547 sec/batch
Epoch: 5/20...  Training Step: 3018...  Training loss: 2.0254...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 3019...  Training loss: 1.9461...  0.0552 sec/batch
Epoch: 5/20...  Training Step: 3020...  Training loss: 2.0366...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 3021...  Training loss: 2.0261...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 3022...  Training loss: 2.0041...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 3023...  Training loss: 1.9887...  0.0594 sec/batch
Epoch: 5/20...  Training Step: 3024...  Training loss: 1.9671...  0.0550 sec/batch
Epoch: 5/20...  Training Step: 3025...  Training loss: 2.0332...  0.0540 sec/batch
Epoch: 5/20...  Training Step: 3026...  Training loss: 2.0078...  0.0525 sec/batch
Epoch: 5/20...  Training Step: 3027...  Training loss: 2.0489...  0.0526 sec/batch
Epoch: 5/20...  Training Step: 3028...  Training loss: 2.0743...  0.0590 sec/batch
Epoch: 5/20...  Training Step: 3029...  Training loss: 2.0585...  0.0563 sec/batch
Epoch: 5/20...  Training Step: 3030...  Training loss: 2.0186...  0.0556 sec/batch
Epoch: 5/20...  Training Step: 3031...  Training loss: 2.0220...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 3032...  Training loss: 1.9702...  0.0564 sec/batch
Epoch: 5/20...  Training Step: 3033...  Training loss: 2.0178...  0.0526 sec/batch
Epoch: 5/20...  Training Step: 3034...  Training loss: 2.0344...  0.0573 sec/batch
Epoch: 5/20...  Training Step: 3035...  Training loss: 1.9863...  0.0568 sec/batch
Epoch: 5/20...  Training Step: 3036...  Training loss: 1.9964...  0.0570 sec/batch
Epoch: 5/20...  Training Step: 3037...  Training loss: 1.9911...  0.0593 sec/batch
Epoch: 5/20...  Training Step: 3038...  Training loss: 1.9719...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 3039...  Training loss: 2.0371...  0.0560 sec/batch
Epoch: 5/20...  Training Step: 3040...  Training loss: 2.0236...  0.0543 sec/batch
Epoch: 5/20...  Training Step: 3041...  Training loss: 2.0381...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 3042...  Training loss: 2.0460...  0.0524 sec/batch
Epoch: 5/20...  Training Step: 3043...  Training loss: 2.0358...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 3044...  Training loss: 2.0713...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 3045...  Training loss: 2.1089...  0.0547 sec/batch
Epoch: 5/20...  Training Step: 3046...  Training loss: 2.0470...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 3047...  Training loss: 2.0257...  0.0557 sec/batch
Epoch: 5/20...  Training Step: 3048...  Training loss: 2.0750...  0.0595 sec/batch
Epoch: 5/20...  Training Step: 3049...  Training loss: 1.9868...  0.0535 sec/batch
Epoch: 5/20...  Training Step: 3050...  Training loss: 1.9976...  0.0547 sec/batch
Epoch: 5/20...  Training Step: 3051...  Training loss: 2.0155...  0.0524 sec/batch
Epoch: 5/20...  Training Step: 3052...  Training loss: 2.0667...  0.0593 sec/batch
Epoch: 5/20...  Training Step: 3053...  Training loss: 1.9999...  0.0597 sec/batch
Epoch: 5/20...  Training Step: 3054...  Training loss: 1.9758...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 3055...  Training loss: 1.9919...  0.0527 sec/batch
Epoch: 5/20...  Training Step: 3056...  Training loss: 2.0697...  0.0528 sec/batch
Epoch: 5/20...  Training Step: 3057...  Training loss: 1.9663...  0.0585 sec/batch
Epoch: 5/20...  Training Step: 3058...  Training loss: 2.0139...  0.0530 sec/batch
Epoch: 5/20...  Training Step: 3059...  Training loss: 2.0951...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 3060...  Training loss: 2.0440...  0.0551 sec/batch
Epoch: 5/20...  Training Step: 3061...  Training loss: 2.0292...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 3062...  Training loss: 2.0033...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 3063...  Training loss: 2.0261...  0.0529 sec/batch
Epoch: 5/20...  Training Step: 3064...  Training loss: 2.0645...  0.0557 sec/batch
Epoch: 5/20...  Training Step: 3065...  Training loss: 2.0366...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 3066...  Training loss: 2.0059...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 3067...  Training loss: 1.9704...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 3068...  Training loss: 2.0160...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 3069...  Training loss: 1.9745...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 3070...  Training loss: 2.0422...  0.0621 sec/batch
Epoch: 5/20...  Training Step: 3071...  Training loss: 1.9534...  0.0547 sec/batch
Epoch: 5/20...  Training Step: 3072...  Training loss: 2.0408...  0.0548 sec/batch
Epoch: 5/20...  Training Step: 3073...  Training loss: 1.9854...  0.0535 sec/batch
Epoch: 5/20...  Training Step: 3074...  Training loss: 1.9734...  0.0557 sec/batch
Epoch: 5/20...  Training Step: 3075...  Training loss: 1.9790...  0.0585 sec/batch
Epoch: 5/20...  Training Step: 3076...  Training loss: 1.9788...  0.0550 sec/batch
Epoch: 5/20...  Training Step: 3077...  Training loss: 1.9689...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 3078...  Training loss: 2.0103...  0.0557 sec/batch
Epoch: 5/20...  Training Step: 3079...  Training loss: 2.0095...  0.0531 sec/batch
Epoch: 5/20...  Training Step: 3080...  Training loss: 2.0487...  0.0559 sec/batch
Epoch: 5/20...  Training Step: 3081...  Training loss: 2.0149...  0.0554 sec/batch
Epoch: 5/20...  Training Step: 3082...  Training loss: 2.0178...  0.0523 sec/batch
Epoch: 5/20...  Training Step: 3083...  Training loss: 2.0249...  0.0558 sec/batch
Epoch: 5/20...  Training Step: 3084...  Training loss: 1.9823...  0.0555 sec/batch
Epoch: 5/20...  Training Step: 3085...  Training loss: 2.0215...  0.0552 sec/batch
Epoch: 5/20...  Training Step: 3086...  Training loss: 2.0048...  0.0581 sec/batch
Epoch: 5/20...  Training Step: 3087...  Training loss: 1.9684...  0.0551 sec/batch
Epoch: 5/20...  Training Step: 3088...  Training loss: 1.9909...  0.0565 sec/batch
Epoch: 5/20...  Training Step: 3089...  Training loss: 1.9808...  0.0560 sec/batch
Epoch: 5/20...  Training Step: 3090...  Training loss: 2.0614...  0.0532 sec/batch
Epoch: 5/20...  Training Step: 3091...  Training loss: 2.0326...  0.0588 sec/batch
Epoch: 5/20...  Training Step: 3092...  Training loss: 2.0448...  0.0553 sec/batch
Epoch: 5/20...  Training Step: 3093...  Training loss: 1.9692...  0.0536 sec/batch
Epoch: 5/20...  Training Step: 3094...  Training loss: 2.0110...  0.0581 sec/batch
Epoch: 5/20...  Training Step: 3095...  Training loss: 1.9543...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 3096...  Training loss: 2.0275...  0.0597 sec/batch
Epoch: 5/20...  Training Step: 3097...  Training loss: 2.0350...  0.0542 sec/batch
Epoch: 5/20...  Training Step: 3098...  Training loss: 1.9795...  0.0534 sec/batch
Epoch: 5/20...  Training Step: 3099...  Training loss: 1.9358...  0.0561 sec/batch
Epoch: 5/20...  Training Step: 3100...  Training loss: 2.0082...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3101...  Training loss: 2.0826...  0.0550 sec/batch
Epoch: 6/20...  Training Step: 3102...  Training loss: 2.0875...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3103...  Training loss: 2.0583...  0.0559 sec/batch
Epoch: 6/20...  Training Step: 3104...  Training loss: 1.9699...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3105...  Training loss: 2.0061...  0.0549 sec/batch
Epoch: 6/20...  Training Step: 3106...  Training loss: 2.0171...  0.0602 sec/batch
Epoch: 6/20...  Training Step: 3107...  Training loss: 1.9765...  0.0554 sec/batch
Epoch: 6/20...  Training Step: 3108...  Training loss: 1.9670...  0.0585 sec/batch
Epoch: 6/20...  Training Step: 3109...  Training loss: 1.9571...  0.0633 sec/batch
Epoch: 6/20...  Training Step: 3110...  Training loss: 1.9838...  0.0533 sec/batch
Epoch: 6/20...  Training Step: 3111...  Training loss: 2.0116...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3112...  Training loss: 1.9510...  0.0579 sec/batch
Epoch: 6/20...  Training Step: 3113...  Training loss: 2.0327...  0.0566 sec/batch
Epoch: 6/20...  Training Step: 3114...  Training loss: 1.9830...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3115...  Training loss: 2.0377...  0.0589 sec/batch
Epoch: 6/20...  Training Step: 3116...  Training loss: 2.0528...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3117...  Training loss: 2.0313...  0.0550 sec/batch
Epoch: 6/20...  Training Step: 3118...  Training loss: 2.0124...  0.0575 sec/batch
Epoch: 6/20...  Training Step: 3119...  Training loss: 1.9684...  0.0535 sec/batch
Epoch: 6/20...  Training Step: 3120...  Training loss: 2.0067...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3121...  Training loss: 2.0591...  0.0558 sec/batch
Epoch: 6/20...  Training Step: 3122...  Training loss: 1.9890...  0.0550 sec/batch
Epoch: 6/20...  Training Step: 3123...  Training loss: 1.9755...  0.0570 sec/batch
Epoch: 6/20...  Training Step: 3124...  Training loss: 1.9963...  0.0572 sec/batch
Epoch: 6/20...  Training Step: 3125...  Training loss: 1.9853...  0.0590 sec/batch
Epoch: 6/20...  Training Step: 3126...  Training loss: 1.9805...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3127...  Training loss: 2.0032...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3128...  Training loss: 1.9778...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3129...  Training loss: 2.0264...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3130...  Training loss: 1.9688...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3131...  Training loss: 1.9580...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3132...  Training loss: 2.0095...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3133...  Training loss: 1.9856...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3134...  Training loss: 2.0042...  0.0525 sec/batch
Epoch: 6/20...  Training Step: 3135...  Training loss: 2.0127...  0.0548 sec/batch
Epoch: 6/20...  Training Step: 3136...  Training loss: 1.9920...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3137...  Training loss: 1.9720...  0.0525 sec/batch
Epoch: 6/20...  Training Step: 3138...  Training loss: 1.9948...  0.0549 sec/batch
Epoch: 6/20...  Training Step: 3139...  Training loss: 2.0076...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3140...  Training loss: 1.9505...  0.0569 sec/batch
Epoch: 6/20...  Training Step: 3141...  Training loss: 1.9926...  0.0596 sec/batch
Epoch: 6/20...  Training Step: 3142...  Training loss: 2.0170...  0.0570 sec/batch
Epoch: 6/20...  Training Step: 3143...  Training loss: 1.9846...  0.0524 sec/batch
Epoch: 6/20...  Training Step: 3144...  Training loss: 2.0295...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3145...  Training loss: 1.9998...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3146...  Training loss: 1.9727...  0.0544 sec/batch
Epoch: 6/20...  Training Step: 3147...  Training loss: 1.8922...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3148...  Training loss: 2.0085...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3149...  Training loss: 2.0028...  0.0535 sec/batch
Epoch: 6/20...  Training Step: 3150...  Training loss: 1.9855...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3151...  Training loss: 1.9703...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3152...  Training loss: 1.9769...  0.0575 sec/batch
Epoch: 6/20...  Training Step: 3153...  Training loss: 1.9982...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3154...  Training loss: 2.0398...  0.0558 sec/batch
Epoch: 6/20...  Training Step: 3155...  Training loss: 2.0354...  0.0570 sec/batch
Epoch: 6/20...  Training Step: 3156...  Training loss: 1.9916...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3157...  Training loss: 1.9643...  0.0607 sec/batch
Epoch: 6/20...  Training Step: 3158...  Training loss: 2.0131...  0.0585 sec/batch
Epoch: 6/20...  Training Step: 3159...  Training loss: 1.9787...  0.0576 sec/batch
Epoch: 6/20...  Training Step: 3160...  Training loss: 2.0474...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3161...  Training loss: 1.9854...  0.0540 sec/batch
Epoch: 6/20...  Training Step: 3162...  Training loss: 1.9723...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3163...  Training loss: 2.0182...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3164...  Training loss: 1.9942...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3165...  Training loss: 1.9644...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3166...  Training loss: 1.9323...  0.0555 sec/batch
Epoch: 6/20...  Training Step: 3167...  Training loss: 1.9477...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3168...  Training loss: 1.9597...  0.0556 sec/batch
Epoch: 6/20...  Training Step: 3169...  Training loss: 2.0166...  0.0561 sec/batch
Epoch: 6/20...  Training Step: 3170...  Training loss: 1.9813...  0.0554 sec/batch
Epoch: 6/20...  Training Step: 3171...  Training loss: 2.0081...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3172...  Training loss: 2.0145...  0.0539 sec/batch
Epoch: 6/20...  Training Step: 3173...  Training loss: 1.9518...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3174...  Training loss: 1.9935...  0.0557 sec/batch
Epoch: 6/20...  Training Step: 3175...  Training loss: 2.0445...  0.0562 sec/batch
Epoch: 6/20...  Training Step: 3176...  Training loss: 1.9915...  0.0532 sec/batch
Epoch: 6/20...  Training Step: 3177...  Training loss: 2.0236...  0.0574 sec/batch
Epoch: 6/20...  Training Step: 3178...  Training loss: 1.9771...  0.0601 sec/batch
Epoch: 6/20...  Training Step: 3179...  Training loss: 1.9931...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3180...  Training loss: 2.0064...  0.0586 sec/batch
Epoch: 6/20...  Training Step: 3181...  Training loss: 1.9469...  0.0555 sec/batch
Epoch: 6/20...  Training Step: 3182...  Training loss: 1.9864...  0.0548 sec/batch
Epoch: 6/20...  Training Step: 3183...  Training loss: 1.9433...  0.0524 sec/batch
Epoch: 6/20...  Training Step: 3184...  Training loss: 1.9689...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3185...  Training loss: 1.9816...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3186...  Training loss: 2.0314...  0.0555 sec/batch
Epoch: 6/20...  Training Step: 3187...  Training loss: 1.9680...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3188...  Training loss: 2.0343...  0.0554 sec/batch
Epoch: 6/20...  Training Step: 3189...  Training loss: 1.9781...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3190...  Training loss: 2.0219...  0.0591 sec/batch
Epoch: 6/20...  Training Step: 3191...  Training loss: 1.9737...  0.0546 sec/batch
Epoch: 6/20...  Training Step: 3192...  Training loss: 2.0778...  0.0586 sec/batch
Epoch: 6/20...  Training Step: 3193...  Training loss: 1.9814...  0.0548 sec/batch
Epoch: 6/20...  Training Step: 3194...  Training loss: 2.0029...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3195...  Training loss: 2.0061...  0.0592 sec/batch
Epoch: 6/20...  Training Step: 3196...  Training loss: 2.0210...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3197...  Training loss: 2.0151...  0.0558 sec/batch
Epoch: 6/20...  Training Step: 3198...  Training loss: 1.9433...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3199...  Training loss: 2.0604...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3200...  Training loss: 1.9771...  0.0522 sec/batch
Epoch: 6/20...  Training Step: 3201...  Training loss: 1.9622...  0.0595 sec/batch
Epoch: 6/20...  Training Step: 3202...  Training loss: 1.9741...  0.0591 sec/batch
Epoch: 6/20...  Training Step: 3203...  Training loss: 2.0206...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3204...  Training loss: 2.0127...  0.0556 sec/batch
Epoch: 6/20...  Training Step: 3205...  Training loss: 1.9608...  0.0555 sec/batch
Epoch: 6/20...  Training Step: 3206...  Training loss: 1.9414...  0.0562 sec/batch
Epoch: 6/20...  Training Step: 3207...  Training loss: 2.0121...  0.0574 sec/batch
Epoch: 6/20...  Training Step: 3208...  Training loss: 1.9760...  0.0562 sec/batch
Epoch: 6/20...  Training Step: 3209...  Training loss: 1.9690...  0.0533 sec/batch
Epoch: 6/20...  Training Step: 3210...  Training loss: 1.9673...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3211...  Training loss: 1.9515...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3212...  Training loss: 1.9851...  0.0524 sec/batch
Epoch: 6/20...  Training Step: 3213...  Training loss: 1.9911...  0.0569 sec/batch
Epoch: 6/20...  Training Step: 3214...  Training loss: 1.9560...  0.0522 sec/batch
Epoch: 6/20...  Training Step: 3215...  Training loss: 2.0090...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3216...  Training loss: 2.0090...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3217...  Training loss: 1.9515...  0.0576 sec/batch
Epoch: 6/20...  Training Step: 3218...  Training loss: 2.0350...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3219...  Training loss: 1.9690...  0.0555 sec/batch
Epoch: 6/20...  Training Step: 3220...  Training loss: 1.9766...  0.0599 sec/batch
Epoch: 6/20...  Training Step: 3221...  Training loss: 1.9716...  0.0540 sec/batch
Epoch: 6/20...  Training Step: 3222...  Training loss: 1.9365...  0.0559 sec/batch
Epoch: 6/20...  Training Step: 3223...  Training loss: 1.9715...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3224...  Training loss: 1.9906...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3225...  Training loss: 1.9933...  0.0550 sec/batch
Epoch: 6/20...  Training Step: 3226...  Training loss: 2.0105...  0.0542 sec/batch
Epoch: 6/20...  Training Step: 3227...  Training loss: 2.0191...  0.0599 sec/batch
Epoch: 6/20...  Training Step: 3228...  Training loss: 1.9378...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3229...  Training loss: 1.9688...  0.0555 sec/batch
Epoch: 6/20...  Training Step: 3230...  Training loss: 2.0466...  0.0572 sec/batch
Epoch: 6/20...  Training Step: 3231...  Training loss: 1.9612...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3232...  Training loss: 2.0275...  0.0547 sec/batch
Epoch: 6/20...  Training Step: 3233...  Training loss: 2.0158...  0.0557 sec/batch
Epoch: 6/20...  Training Step: 3234...  Training loss: 1.9750...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3235...  Training loss: 1.9522...  0.0584 sec/batch
Epoch: 6/20...  Training Step: 3236...  Training loss: 1.9736...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3237...  Training loss: 1.9828...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3238...  Training loss: 1.9883...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3239...  Training loss: 2.0366...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3240...  Training loss: 1.9815...  0.0550 sec/batch
Epoch: 6/20...  Training Step: 3241...  Training loss: 2.0117...  0.0524 sec/batch
Epoch: 6/20...  Training Step: 3242...  Training loss: 1.9236...  0.0580 sec/batch
Epoch: 6/20...  Training Step: 3243...  Training loss: 1.9826...  0.0590 sec/batch
Epoch: 6/20...  Training Step: 3244...  Training loss: 1.9519...  0.0540 sec/batch
Epoch: 6/20...  Training Step: 3245...  Training loss: 1.9442...  0.0571 sec/batch
Epoch: 6/20...  Training Step: 3246...  Training loss: 1.9947...  0.0523 sec/batch
Epoch: 6/20...  Training Step: 3247...  Training loss: 1.9882...  0.0587 sec/batch
Epoch: 6/20...  Training Step: 3248...  Training loss: 1.9983...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3249...  Training loss: 1.9671...  0.0584 sec/batch
Epoch: 6/20...  Training Step: 3250...  Training loss: 2.0166...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3251...  Training loss: 2.0017...  0.0544 sec/batch
Epoch: 6/20...  Training Step: 3252...  Training loss: 1.9845...  0.0546 sec/batch
Epoch: 6/20...  Training Step: 3253...  Training loss: 1.9662...  0.0524 sec/batch
Epoch: 6/20...  Training Step: 3254...  Training loss: 2.0098...  0.0558 sec/batch
Epoch: 6/20...  Training Step: 3255...  Training loss: 1.9707...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3256...  Training loss: 2.0097...  0.0592 sec/batch
Epoch: 6/20...  Training Step: 3257...  Training loss: 1.9604...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3258...  Training loss: 2.0264...  0.0563 sec/batch
Epoch: 6/20...  Training Step: 3259...  Training loss: 2.0239...  0.0567 sec/batch
Epoch: 6/20...  Training Step: 3260...  Training loss: 1.9642...  0.0525 sec/batch
Epoch: 6/20...  Training Step: 3261...  Training loss: 1.9363...  0.0599 sec/batch
Epoch: 6/20...  Training Step: 3262...  Training loss: 1.9665...  0.0566 sec/batch
Epoch: 6/20...  Training Step: 3263...  Training loss: 1.9903...  0.0564 sec/batch
Epoch: 6/20...  Training Step: 3264...  Training loss: 1.9814...  0.0533 sec/batch
Epoch: 6/20...  Training Step: 3265...  Training loss: 1.9879...  0.0542 sec/batch
Epoch: 6/20...  Training Step: 3266...  Training loss: 1.9784...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3267...  Training loss: 2.0123...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3268...  Training loss: 1.9690...  0.0520 sec/batch
Epoch: 6/20...  Training Step: 3269...  Training loss: 1.9540...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3270...  Training loss: 1.9331...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3271...  Training loss: 1.9525...  0.0557 sec/batch
Epoch: 6/20...  Training Step: 3272...  Training loss: 1.9712...  0.0555 sec/batch
Epoch: 6/20...  Training Step: 3273...  Training loss: 1.9816...  0.0569 sec/batch
Epoch: 6/20...  Training Step: 3274...  Training loss: 1.9628...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3275...  Training loss: 1.9636...  0.0554 sec/batch
Epoch: 6/20...  Training Step: 3276...  Training loss: 1.9883...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3277...  Training loss: 1.9949...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3278...  Training loss: 1.9541...  0.0580 sec/batch
Epoch: 6/20...  Training Step: 3279...  Training loss: 1.9496...  0.0550 sec/batch
Epoch: 6/20...  Training Step: 3280...  Training loss: 1.9710...  0.0548 sec/batch
Epoch: 6/20...  Training Step: 3281...  Training loss: 1.9717...  0.0533 sec/batch
Epoch: 6/20...  Training Step: 3282...  Training loss: 1.9977...  0.0587 sec/batch
Epoch: 6/20...  Training Step: 3283...  Training loss: 1.9995...  0.0573 sec/batch
Epoch: 6/20...  Training Step: 3284...  Training loss: 1.9240...  0.0556 sec/batch
Epoch: 6/20...  Training Step: 3285...  Training loss: 1.9311...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3286...  Training loss: 1.9814...  0.0564 sec/batch
Epoch: 6/20...  Training Step: 3287...  Training loss: 1.9665...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3288...  Training loss: 1.9848...  0.0570 sec/batch
Epoch: 6/20...  Training Step: 3289...  Training loss: 1.9704...  0.0523 sec/batch
Epoch: 6/20...  Training Step: 3290...  Training loss: 2.0602...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3291...  Training loss: 2.0068...  0.0594 sec/batch
Epoch: 6/20...  Training Step: 3292...  Training loss: 2.0447...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3293...  Training loss: 2.0061...  0.0572 sec/batch
Epoch: 6/20...  Training Step: 3294...  Training loss: 1.9458...  0.0532 sec/batch
Epoch: 6/20...  Training Step: 3295...  Training loss: 1.9732...  0.0522 sec/batch
Epoch: 6/20...  Training Step: 3296...  Training loss: 2.0709...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3297...  Training loss: 1.9819...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3298...  Training loss: 2.0502...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3299...  Training loss: 1.9620...  0.0549 sec/batch
Epoch: 6/20...  Training Step: 3300...  Training loss: 1.9864...  0.0544 sec/batch
Epoch: 6/20...  Training Step: 3301...  Training loss: 1.9724...  0.0587 sec/batch
Epoch: 6/20...  Training Step: 3302...  Training loss: 1.9761...  0.0583 sec/batch
Epoch: 6/20...  Training Step: 3303...  Training loss: 1.9741...  0.0554 sec/batch
Epoch: 6/20...  Training Step: 3304...  Training loss: 1.9644...  0.0555 sec/batch
Epoch: 6/20...  Training Step: 3305...  Training loss: 1.9875...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3306...  Training loss: 1.9304...  0.0594 sec/batch
Epoch: 6/20...  Training Step: 3307...  Training loss: 1.9920...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3308...  Training loss: 1.9792...  0.0560 sec/batch
Epoch: 6/20...  Training Step: 3309...  Training loss: 1.9816...  0.0564 sec/batch
Epoch: 6/20...  Training Step: 3310...  Training loss: 1.9689...  0.0532 sec/batch
Epoch: 6/20...  Training Step: 3311...  Training loss: 1.9778...  0.0535 sec/batch
Epoch: 6/20...  Training Step: 3312...  Training loss: 1.9818...  0.0571 sec/batch
Epoch: 6/20...  Training Step: 3313...  Training loss: 2.0187...  0.0574 sec/batch
Epoch: 6/20...  Training Step: 3314...  Training loss: 2.0197...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3315...  Training loss: 1.9909...  0.0579 sec/batch
Epoch: 6/20...  Training Step: 3316...  Training loss: 2.0191...  0.0580 sec/batch
Epoch: 6/20...  Training Step: 3317...  Training loss: 1.9881...  0.0562 sec/batch
Epoch: 6/20...  Training Step: 3318...  Training loss: 1.9407...  0.0593 sec/batch
Epoch: 6/20...  Training Step: 3319...  Training loss: 2.0720...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3320...  Training loss: 2.0031...  0.0534 sec/batch
Epoch: 6/20...  Training Step: 3321...  Training loss: 1.9656...  0.0577 sec/batch
Epoch: 6/20...  Training Step: 3322...  Training loss: 1.9988...  0.0537 sec/batch
Epoch: 6/20...  Training Step: 3323...  Training loss: 2.0572...  0.0556 sec/batch
Epoch: 6/20...  Training Step: 3324...  Training loss: 1.9420...  0.0594 sec/batch
Epoch: 6/20...  Training Step: 3325...  Training loss: 1.9702...  0.0571 sec/batch
Epoch: 6/20...  Training Step: 3326...  Training loss: 2.0195...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3327...  Training loss: 2.0209...  0.0558 sec/batch
Epoch: 6/20...  Training Step: 3328...  Training loss: 1.9457...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3329...  Training loss: 1.9999...  0.0557 sec/batch
Epoch: 6/20...  Training Step: 3330...  Training loss: 1.9752...  0.0524 sec/batch
Epoch: 6/20...  Training Step: 3331...  Training loss: 2.0266...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3332...  Training loss: 1.9758...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3333...  Training loss: 1.9414...  0.0557 sec/batch
Epoch: 6/20...  Training Step: 3334...  Training loss: 1.9511...  0.0609 sec/batch
Epoch: 6/20...  Training Step: 3335...  Training loss: 1.9596...  0.0535 sec/batch
Epoch: 6/20...  Training Step: 3336...  Training loss: 2.0223...  0.0525 sec/batch
Epoch: 6/20...  Training Step: 3337...  Training loss: 1.9772...  0.0536 sec/batch
Epoch: 6/20...  Training Step: 3338...  Training loss: 1.9481...  0.0549 sec/batch
Epoch: 6/20...  Training Step: 3339...  Training loss: 1.9701...  0.0546 sec/batch
Epoch: 6/20...  Training Step: 3340...  Training loss: 2.0145...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3341...  Training loss: 1.9755...  0.0570 sec/batch
Epoch: 6/20...  Training Step: 3342...  Training loss: 1.9604...  0.0548 sec/batch
Epoch: 6/20...  Training Step: 3343...  Training loss: 1.9430...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3344...  Training loss: 1.9725...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3345...  Training loss: 1.9794...  0.0554 sec/batch
Epoch: 6/20...  Training Step: 3346...  Training loss: 1.9619...  0.0561 sec/batch
Epoch: 6/20...  Training Step: 3347...  Training loss: 1.9918...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3348...  Training loss: 2.0065...  0.0547 sec/batch
Epoch: 6/20...  Training Step: 3349...  Training loss: 1.9318...  0.0548 sec/batch
Epoch: 6/20...  Training Step: 3350...  Training loss: 1.9612...  0.0548 sec/batch
Epoch: 6/20...  Training Step: 3351...  Training loss: 1.9869...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3352...  Training loss: 1.9554...  0.0545 sec/batch
Epoch: 6/20...  Training Step: 3353...  Training loss: 1.9971...  0.0587 sec/batch
Epoch: 6/20...  Training Step: 3354...  Training loss: 1.9970...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3355...  Training loss: 2.0125...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3356...  Training loss: 1.9732...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3357...  Training loss: 1.9584...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3358...  Training loss: 1.9873...  0.0565 sec/batch
Epoch: 6/20...  Training Step: 3359...  Training loss: 1.9885...  0.0582 sec/batch
Epoch: 6/20...  Training Step: 3360...  Training loss: 1.9707...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3361...  Training loss: 1.9791...  0.0538 sec/batch
Epoch: 6/20...  Training Step: 3362...  Training loss: 1.9545...  0.0562 sec/batch
Epoch: 6/20...  Training Step: 3363...  Training loss: 1.9900...  0.0555 sec/batch
Epoch: 6/20...  Training Step: 3364...  Training loss: 1.9785...  0.0538 sec/batch
Epoch: 6/20...  Training Step: 3365...  Training loss: 1.9937...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3366...  Training loss: 1.9263...  0.0557 sec/batch
Epoch: 6/20...  Training Step: 3367...  Training loss: 1.9866...  0.0522 sec/batch
Epoch: 6/20...  Training Step: 3368...  Training loss: 1.9966...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3369...  Training loss: 1.9663...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3370...  Training loss: 1.9437...  0.0616 sec/batch
Epoch: 6/20...  Training Step: 3371...  Training loss: 1.9215...  0.0561 sec/batch
Epoch: 6/20...  Training Step: 3372...  Training loss: 1.9753...  0.0537 sec/batch
Epoch: 6/20...  Training Step: 3373...  Training loss: 1.9631...  0.0578 sec/batch
Epoch: 6/20...  Training Step: 3374...  Training loss: 1.9524...  0.0556 sec/batch
Epoch: 6/20...  Training Step: 3375...  Training loss: 1.9829...  0.0592 sec/batch
Epoch: 6/20...  Training Step: 3376...  Training loss: 2.0058...  0.0525 sec/batch
Epoch: 6/20...  Training Step: 3377...  Training loss: 2.0436...  0.0547 sec/batch
Epoch: 6/20...  Training Step: 3378...  Training loss: 1.9872...  0.0556 sec/batch
Epoch: 6/20...  Training Step: 3379...  Training loss: 2.0151...  0.0522 sec/batch
Epoch: 6/20...  Training Step: 3380...  Training loss: 2.0339...  0.0560 sec/batch
Epoch: 6/20...  Training Step: 3381...  Training loss: 1.9749...  0.0540 sec/batch
Epoch: 6/20...  Training Step: 3382...  Training loss: 1.9130...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3383...  Training loss: 1.9508...  0.0533 sec/batch
Epoch: 6/20...  Training Step: 3384...  Training loss: 1.9824...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3385...  Training loss: 1.9584...  0.0597 sec/batch
Epoch: 6/20...  Training Step: 3386...  Training loss: 1.9786...  0.0585 sec/batch
Epoch: 6/20...  Training Step: 3387...  Training loss: 1.9427...  0.0556 sec/batch
Epoch: 6/20...  Training Step: 3388...  Training loss: 1.9523...  0.0548 sec/batch
Epoch: 6/20...  Training Step: 3389...  Training loss: 1.9802...  0.0571 sec/batch
Epoch: 6/20...  Training Step: 3390...  Training loss: 1.9992...  0.0523 sec/batch
Epoch: 6/20...  Training Step: 3391...  Training loss: 1.9595...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3392...  Training loss: 1.9842...  0.0554 sec/batch
Epoch: 6/20...  Training Step: 3393...  Training loss: 1.9879...  0.0585 sec/batch
Epoch: 6/20...  Training Step: 3394...  Training loss: 1.9904...  0.0548 sec/batch
Epoch: 6/20...  Training Step: 3395...  Training loss: 1.9570...  0.0522 sec/batch
Epoch: 6/20...  Training Step: 3396...  Training loss: 1.9361...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3397...  Training loss: 2.0037...  0.0550 sec/batch
Epoch: 6/20...  Training Step: 3398...  Training loss: 2.0165...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3399...  Training loss: 2.0334...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3400...  Training loss: 2.0005...  0.0556 sec/batch
Epoch: 6/20...  Training Step: 3401...  Training loss: 1.9930...  0.0574 sec/batch
Epoch: 6/20...  Training Step: 3402...  Training loss: 2.0388...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3403...  Training loss: 1.9308...  0.0576 sec/batch
Epoch: 6/20...  Training Step: 3404...  Training loss: 1.9886...  0.0525 sec/batch
Epoch: 6/20...  Training Step: 3405...  Training loss: 1.9800...  0.0594 sec/batch
Epoch: 6/20...  Training Step: 3406...  Training loss: 1.9934...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3407...  Training loss: 1.9701...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3408...  Training loss: 1.9606...  0.0567 sec/batch
Epoch: 6/20...  Training Step: 3409...  Training loss: 1.9858...  0.0523 sec/batch
Epoch: 6/20...  Training Step: 3410...  Training loss: 1.9416...  0.0570 sec/batch
Epoch: 6/20...  Training Step: 3411...  Training loss: 1.9347...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3412...  Training loss: 1.9631...  0.0522 sec/batch
Epoch: 6/20...  Training Step: 3413...  Training loss: 1.9410...  0.0571 sec/batch
Epoch: 6/20...  Training Step: 3414...  Training loss: 1.9355...  0.0543 sec/batch
Epoch: 6/20...  Training Step: 3415...  Training loss: 1.9655...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3416...  Training loss: 1.9984...  0.0534 sec/batch
Epoch: 6/20...  Training Step: 3417...  Training loss: 1.9393...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3418...  Training loss: 1.9163...  0.0554 sec/batch
Epoch: 6/20...  Training Step: 3419...  Training loss: 1.9541...  0.0606 sec/batch
Epoch: 6/20...  Training Step: 3420...  Training loss: 2.0169...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3421...  Training loss: 1.9682...  0.0570 sec/batch
Epoch: 6/20...  Training Step: 3422...  Training loss: 1.9119...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3423...  Training loss: 1.9892...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3424...  Training loss: 1.9686...  0.0558 sec/batch
Epoch: 6/20...  Training Step: 3425...  Training loss: 1.9374...  0.0569 sec/batch
Epoch: 6/20...  Training Step: 3426...  Training loss: 1.9484...  0.0545 sec/batch
Epoch: 6/20...  Training Step: 3427...  Training loss: 1.9335...  0.0549 sec/batch
Epoch: 6/20...  Training Step: 3428...  Training loss: 1.9296...  0.0532 sec/batch
Epoch: 6/20...  Training Step: 3429...  Training loss: 1.9808...  0.0549 sec/batch
Epoch: 6/20...  Training Step: 3430...  Training loss: 1.9486...  0.0549 sec/batch
Epoch: 6/20...  Training Step: 3431...  Training loss: 1.9596...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3432...  Training loss: 1.9510...  0.0524 sec/batch
Epoch: 6/20...  Training Step: 3433...  Training loss: 1.9263...  0.0594 sec/batch
Epoch: 6/20...  Training Step: 3434...  Training loss: 1.9736...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3435...  Training loss: 1.9886...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3436...  Training loss: 1.9747...  0.0564 sec/batch
Epoch: 6/20...  Training Step: 3437...  Training loss: 1.9566...  0.0603 sec/batch
Epoch: 6/20...  Training Step: 3438...  Training loss: 1.9411...  0.0532 sec/batch
Epoch: 6/20...  Training Step: 3439...  Training loss: 1.9408...  0.0524 sec/batch
Epoch: 6/20...  Training Step: 3440...  Training loss: 1.9617...  0.0573 sec/batch
Epoch: 6/20...  Training Step: 3441...  Training loss: 1.9938...  0.0578 sec/batch
Epoch: 6/20...  Training Step: 3442...  Training loss: 1.9489...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3443...  Training loss: 1.9447...  0.0559 sec/batch
Epoch: 6/20...  Training Step: 3444...  Training loss: 1.9449...  0.0574 sec/batch
Epoch: 6/20...  Training Step: 3445...  Training loss: 1.9783...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3446...  Training loss: 1.9674...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3447...  Training loss: 1.9732...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3448...  Training loss: 1.9627...  0.0549 sec/batch
Epoch: 6/20...  Training Step: 3449...  Training loss: 1.9502...  0.0561 sec/batch
Epoch: 6/20...  Training Step: 3450...  Training loss: 1.9386...  0.0546 sec/batch
Epoch: 6/20...  Training Step: 3451...  Training loss: 1.9956...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3452...  Training loss: 1.9521...  0.0524 sec/batch
Epoch: 6/20...  Training Step: 3453...  Training loss: 1.9836...  0.0581 sec/batch
Epoch: 6/20...  Training Step: 3454...  Training loss: 1.9530...  0.0558 sec/batch
Epoch: 6/20...  Training Step: 3455...  Training loss: 1.9534...  0.0597 sec/batch
Epoch: 6/20...  Training Step: 3456...  Training loss: 1.9992...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3457...  Training loss: 2.0438...  0.0559 sec/batch
Epoch: 6/20...  Training Step: 3458...  Training loss: 2.0099...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3459...  Training loss: 1.9808...  0.0556 sec/batch
Epoch: 6/20...  Training Step: 3460...  Training loss: 1.9752...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3461...  Training loss: 2.0029...  0.0564 sec/batch
Epoch: 6/20...  Training Step: 3462...  Training loss: 1.9405...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3463...  Training loss: 1.9045...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3464...  Training loss: 1.9070...  0.0580 sec/batch
Epoch: 6/20...  Training Step: 3465...  Training loss: 1.9423...  0.0533 sec/batch
Epoch: 6/20...  Training Step: 3466...  Training loss: 1.9616...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3467...  Training loss: 1.9522...  0.0535 sec/batch
Epoch: 6/20...  Training Step: 3468...  Training loss: 2.0281...  0.0564 sec/batch
Epoch: 6/20...  Training Step: 3469...  Training loss: 1.9876...  0.0557 sec/batch
Epoch: 6/20...  Training Step: 3470...  Training loss: 1.9434...  0.0584 sec/batch
Epoch: 6/20...  Training Step: 3471...  Training loss: 1.9973...  0.0572 sec/batch
Epoch: 6/20...  Training Step: 3472...  Training loss: 2.0624...  0.0579 sec/batch
Epoch: 6/20...  Training Step: 3473...  Training loss: 1.9849...  0.0557 sec/batch
Epoch: 6/20...  Training Step: 3474...  Training loss: 1.9658...  0.0592 sec/batch
Epoch: 6/20...  Training Step: 3475...  Training loss: 1.9725...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3476...  Training loss: 1.9816...  0.0596 sec/batch
Epoch: 6/20...  Training Step: 3477...  Training loss: 1.9383...  0.0561 sec/batch
Epoch: 6/20...  Training Step: 3478...  Training loss: 2.0130...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3479...  Training loss: 1.9736...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3480...  Training loss: 1.9585...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3481...  Training loss: 1.8936...  0.0532 sec/batch
Epoch: 6/20...  Training Step: 3482...  Training loss: 2.0209...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3483...  Training loss: 1.9288...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3484...  Training loss: 1.9695...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3485...  Training loss: 1.9749...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3486...  Training loss: 1.8960...  0.0534 sec/batch
Epoch: 6/20...  Training Step: 3487...  Training loss: 1.9122...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3488...  Training loss: 1.9620...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3489...  Training loss: 1.8968...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3490...  Training loss: 1.9453...  0.0586 sec/batch
Epoch: 6/20...  Training Step: 3491...  Training loss: 1.9977...  0.0573 sec/batch
Epoch: 6/20...  Training Step: 3492...  Training loss: 1.9027...  0.0556 sec/batch
Epoch: 6/20...  Training Step: 3493...  Training loss: 1.9709...  0.0594 sec/batch
Epoch: 6/20...  Training Step: 3494...  Training loss: 1.9788...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3495...  Training loss: 1.9433...  0.0593 sec/batch
Epoch: 6/20...  Training Step: 3496...  Training loss: 1.9668...  0.0550 sec/batch
Epoch: 6/20...  Training Step: 3497...  Training loss: 1.9643...  0.0532 sec/batch
Epoch: 6/20...  Training Step: 3498...  Training loss: 1.9876...  0.0585 sec/batch
Epoch: 6/20...  Training Step: 3499...  Training loss: 1.9470...  0.0564 sec/batch
Epoch: 6/20...  Training Step: 3500...  Training loss: 1.9687...  0.0566 sec/batch
Epoch: 6/20...  Training Step: 3501...  Training loss: 2.0083...  0.0538 sec/batch
Epoch: 6/20...  Training Step: 3502...  Training loss: 1.9589...  0.0554 sec/batch
Epoch: 6/20...  Training Step: 3503...  Training loss: 1.9374...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3504...  Training loss: 2.0083...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3505...  Training loss: 1.9954...  0.0579 sec/batch
Epoch: 6/20...  Training Step: 3506...  Training loss: 2.0022...  0.0567 sec/batch
Epoch: 6/20...  Training Step: 3507...  Training loss: 2.0255...  0.0536 sec/batch
Epoch: 6/20...  Training Step: 3508...  Training loss: 1.9680...  0.0533 sec/batch
Epoch: 6/20...  Training Step: 3509...  Training loss: 2.0289...  0.0525 sec/batch
Epoch: 6/20...  Training Step: 3510...  Training loss: 1.9927...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3511...  Training loss: 1.9526...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3512...  Training loss: 1.9846...  0.0560 sec/batch
Epoch: 6/20...  Training Step: 3513...  Training loss: 1.9684...  0.0612 sec/batch
Epoch: 6/20...  Training Step: 3514...  Training loss: 1.9504...  0.0557 sec/batch
Epoch: 6/20...  Training Step: 3515...  Training loss: 1.9201...  0.0558 sec/batch
Epoch: 6/20...  Training Step: 3516...  Training loss: 1.9101...  0.0555 sec/batch
Epoch: 6/20...  Training Step: 3517...  Training loss: 1.9676...  0.0602 sec/batch
Epoch: 6/20...  Training Step: 3518...  Training loss: 1.9720...  0.0520 sec/batch
Epoch: 6/20...  Training Step: 3519...  Training loss: 2.0032...  0.0548 sec/batch
Epoch: 6/20...  Training Step: 3520...  Training loss: 1.9628...  0.0558 sec/batch
Epoch: 6/20...  Training Step: 3521...  Training loss: 1.9307...  0.0537 sec/batch
Epoch: 6/20...  Training Step: 3522...  Training loss: 1.9424...  0.0532 sec/batch
Epoch: 6/20...  Training Step: 3523...  Training loss: 1.9837...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3524...  Training loss: 1.9466...  0.0548 sec/batch
Epoch: 6/20...  Training Step: 3525...  Training loss: 1.9829...  0.0534 sec/batch
Epoch: 6/20...  Training Step: 3526...  Training loss: 1.9926...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3527...  Training loss: 1.9456...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3528...  Training loss: 1.9663...  0.0562 sec/batch
Epoch: 6/20...  Training Step: 3529...  Training loss: 1.9668...  0.0533 sec/batch
Epoch: 6/20...  Training Step: 3530...  Training loss: 1.9227...  0.0543 sec/batch
Epoch: 6/20...  Training Step: 3531...  Training loss: 1.9524...  0.0562 sec/batch
Epoch: 6/20...  Training Step: 3532...  Training loss: 2.0087...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3533...  Training loss: 1.9767...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3534...  Training loss: 1.9270...  0.0532 sec/batch
Epoch: 6/20...  Training Step: 3535...  Training loss: 1.9501...  0.0564 sec/batch
Epoch: 6/20...  Training Step: 3536...  Training loss: 1.9709...  0.0604 sec/batch
Epoch: 6/20...  Training Step: 3537...  Training loss: 1.9164...  0.0570 sec/batch
Epoch: 6/20...  Training Step: 3538...  Training loss: 1.9596...  0.0588 sec/batch
Epoch: 6/20...  Training Step: 3539...  Training loss: 1.9862...  0.0555 sec/batch
Epoch: 6/20...  Training Step: 3540...  Training loss: 1.9349...  0.0560 sec/batch
Epoch: 6/20...  Training Step: 3541...  Training loss: 1.9508...  0.0533 sec/batch
Epoch: 6/20...  Training Step: 3542...  Training loss: 1.9404...  0.0578 sec/batch
Epoch: 6/20...  Training Step: 3543...  Training loss: 1.9981...  0.0532 sec/batch
Epoch: 6/20...  Training Step: 3544...  Training loss: 1.9497...  0.0598 sec/batch
Epoch: 6/20...  Training Step: 3545...  Training loss: 1.9076...  0.0539 sec/batch
Epoch: 6/20...  Training Step: 3546...  Training loss: 1.9505...  0.0584 sec/batch
Epoch: 6/20...  Training Step: 3547...  Training loss: 1.9271...  0.0560 sec/batch
Epoch: 6/20...  Training Step: 3548...  Training loss: 1.9134...  0.0538 sec/batch
Epoch: 6/20...  Training Step: 3549...  Training loss: 1.9616...  0.0572 sec/batch
Epoch: 6/20...  Training Step: 3550...  Training loss: 1.9940...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3551...  Training loss: 2.0154...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3552...  Training loss: 1.9779...  0.0576 sec/batch
Epoch: 6/20...  Training Step: 3553...  Training loss: 1.9286...  0.0536 sec/batch
Epoch: 6/20...  Training Step: 3554...  Training loss: 1.9470...  0.0522 sec/batch
Epoch: 6/20...  Training Step: 3555...  Training loss: 1.9283...  0.0586 sec/batch
Epoch: 6/20...  Training Step: 3556...  Training loss: 1.9737...  0.0594 sec/batch
Epoch: 6/20...  Training Step: 3557...  Training loss: 1.9546...  0.0536 sec/batch
Epoch: 6/20...  Training Step: 3558...  Training loss: 1.9784...  0.0583 sec/batch
Epoch: 6/20...  Training Step: 3559...  Training loss: 1.9516...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3560...  Training loss: 1.9573...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3561...  Training loss: 1.9049...  0.0565 sec/batch
Epoch: 6/20...  Training Step: 3562...  Training loss: 1.9774...  0.0606 sec/batch
Epoch: 6/20...  Training Step: 3563...  Training loss: 1.9415...  0.0534 sec/batch
Epoch: 6/20...  Training Step: 3564...  Training loss: 1.9348...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3565...  Training loss: 1.9936...  0.0558 sec/batch
Epoch: 6/20...  Training Step: 3566...  Training loss: 1.9588...  0.0561 sec/batch
Epoch: 6/20...  Training Step: 3567...  Training loss: 1.9438...  0.0534 sec/batch
Epoch: 6/20...  Training Step: 3568...  Training loss: 1.9305...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3569...  Training loss: 1.9741...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3570...  Training loss: 1.9599...  0.0521 sec/batch
Epoch: 6/20...  Training Step: 3571...  Training loss: 1.9690...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3572...  Training loss: 1.9534...  0.0581 sec/batch
Epoch: 6/20...  Training Step: 3573...  Training loss: 1.9233...  0.0575 sec/batch
Epoch: 6/20...  Training Step: 3574...  Training loss: 1.9060...  0.0588 sec/batch
Epoch: 6/20...  Training Step: 3575...  Training loss: 2.0077...  0.0534 sec/batch
Epoch: 6/20...  Training Step: 3576...  Training loss: 1.9991...  0.0584 sec/batch
Epoch: 6/20...  Training Step: 3577...  Training loss: 1.9693...  0.0582 sec/batch
Epoch: 6/20...  Training Step: 3578...  Training loss: 2.0200...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3579...  Training loss: 1.9299...  0.0526 sec/batch
Epoch: 6/20...  Training Step: 3580...  Training loss: 2.0111...  0.0617 sec/batch
Epoch: 6/20...  Training Step: 3581...  Training loss: 1.9612...  0.0570 sec/batch
Epoch: 6/20...  Training Step: 3582...  Training loss: 1.9424...  0.0580 sec/batch
Epoch: 6/20...  Training Step: 3583...  Training loss: 1.9988...  0.0536 sec/batch
Epoch: 6/20...  Training Step: 3584...  Training loss: 1.9779...  0.0537 sec/batch
Epoch: 6/20...  Training Step: 3585...  Training loss: 2.0188...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3586...  Training loss: 1.9464...  0.0563 sec/batch
Epoch: 6/20...  Training Step: 3587...  Training loss: 1.9845...  0.0563 sec/batch
Epoch: 6/20...  Training Step: 3588...  Training loss: 1.9532...  0.0582 sec/batch
Epoch: 6/20...  Training Step: 3589...  Training loss: 1.9697...  0.0596 sec/batch
Epoch: 6/20...  Training Step: 3590...  Training loss: 1.9574...  0.0524 sec/batch
Epoch: 6/20...  Training Step: 3591...  Training loss: 1.9442...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3592...  Training loss: 1.9976...  0.0567 sec/batch
Epoch: 6/20...  Training Step: 3593...  Training loss: 1.9605...  0.0553 sec/batch
Epoch: 6/20...  Training Step: 3594...  Training loss: 1.9565...  0.0561 sec/batch
Epoch: 6/20...  Training Step: 3595...  Training loss: 1.9316...  0.0537 sec/batch
Epoch: 6/20...  Training Step: 3596...  Training loss: 1.9785...  0.0566 sec/batch
Epoch: 6/20...  Training Step: 3597...  Training loss: 1.9558...  0.0557 sec/batch
Epoch: 6/20...  Training Step: 3598...  Training loss: 1.9805...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3599...  Training loss: 1.8859...  0.0538 sec/batch
Epoch: 6/20...  Training Step: 3600...  Training loss: 1.9686...  0.0555 sec/batch
Epoch: 6/20...  Training Step: 3601...  Training loss: 1.9745...  0.0609 sec/batch
Epoch: 6/20...  Training Step: 3602...  Training loss: 1.9943...  0.0567 sec/batch
Epoch: 6/20...  Training Step: 3603...  Training loss: 2.0341...  0.0580 sec/batch
Epoch: 6/20...  Training Step: 3604...  Training loss: 1.9763...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3605...  Training loss: 1.9609...  0.0539 sec/batch
Epoch: 6/20...  Training Step: 3606...  Training loss: 1.9257...  0.0545 sec/batch
Epoch: 6/20...  Training Step: 3607...  Training loss: 1.9763...  0.0537 sec/batch
Epoch: 6/20...  Training Step: 3608...  Training loss: 1.9355...  0.0617 sec/batch
Epoch: 6/20...  Training Step: 3609...  Training loss: 1.9729...  0.0550 sec/batch
Epoch: 6/20...  Training Step: 3610...  Training loss: 1.9913...  0.0614 sec/batch
Epoch: 6/20...  Training Step: 3611...  Training loss: 1.9919...  0.0558 sec/batch
Epoch: 6/20...  Training Step: 3612...  Training loss: 1.9685...  0.0609 sec/batch
Epoch: 6/20...  Training Step: 3613...  Training loss: 2.0127...  0.0573 sec/batch
Epoch: 6/20...  Training Step: 3614...  Training loss: 1.9897...  0.0541 sec/batch
Epoch: 6/20...  Training Step: 3615...  Training loss: 1.9864...  0.0543 sec/batch
Epoch: 6/20...  Training Step: 3616...  Training loss: 1.9472...  0.0568 sec/batch
Epoch: 6/20...  Training Step: 3617...  Training loss: 1.9447...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3618...  Training loss: 1.9609...  0.0585 sec/batch
Epoch: 6/20...  Training Step: 3619...  Training loss: 1.9420...  0.0541 sec/batch
Epoch: 6/20...  Training Step: 3620...  Training loss: 1.9385...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3621...  Training loss: 1.9312...  0.0560 sec/batch
Epoch: 6/20...  Training Step: 3622...  Training loss: 1.9205...  0.0566 sec/batch
Epoch: 6/20...  Training Step: 3623...  Training loss: 1.9531...  0.0562 sec/batch
Epoch: 6/20...  Training Step: 3624...  Training loss: 1.8564...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3625...  Training loss: 1.9660...  0.0555 sec/batch
Epoch: 6/20...  Training Step: 3626...  Training loss: 2.0020...  0.0580 sec/batch
Epoch: 6/20...  Training Step: 3627...  Training loss: 2.0006...  0.0562 sec/batch
Epoch: 6/20...  Training Step: 3628...  Training loss: 1.9821...  0.0534 sec/batch
Epoch: 6/20...  Training Step: 3629...  Training loss: 1.9617...  0.0566 sec/batch
Epoch: 6/20...  Training Step: 3630...  Training loss: 1.9193...  0.0534 sec/batch
Epoch: 6/20...  Training Step: 3631...  Training loss: 1.9431...  0.0579 sec/batch
Epoch: 6/20...  Training Step: 3632...  Training loss: 1.9253...  0.0561 sec/batch
Epoch: 6/20...  Training Step: 3633...  Training loss: 1.9657...  0.0562 sec/batch
Epoch: 6/20...  Training Step: 3634...  Training loss: 1.9467...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3635...  Training loss: 1.9661...  0.0588 sec/batch
Epoch: 6/20...  Training Step: 3636...  Training loss: 1.9602...  0.0532 sec/batch
Epoch: 6/20...  Training Step: 3637...  Training loss: 1.9282...  0.0579 sec/batch
Epoch: 6/20...  Training Step: 3638...  Training loss: 1.9953...  0.0533 sec/batch
Epoch: 6/20...  Training Step: 3639...  Training loss: 1.8879...  0.0566 sec/batch
Epoch: 6/20...  Training Step: 3640...  Training loss: 1.9860...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3641...  Training loss: 1.9766...  0.0580 sec/batch
Epoch: 6/20...  Training Step: 3642...  Training loss: 1.9240...  0.0533 sec/batch
Epoch: 6/20...  Training Step: 3643...  Training loss: 1.9365...  0.0562 sec/batch
Epoch: 6/20...  Training Step: 3644...  Training loss: 1.9276...  0.0561 sec/batch
Epoch: 6/20...  Training Step: 3645...  Training loss: 1.9856...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3646...  Training loss: 1.9687...  0.0550 sec/batch
Epoch: 6/20...  Training Step: 3647...  Training loss: 1.9634...  0.0574 sec/batch
Epoch: 6/20...  Training Step: 3648...  Training loss: 2.0113...  0.0525 sec/batch
Epoch: 6/20...  Training Step: 3649...  Training loss: 2.0036...  0.0533 sec/batch
Epoch: 6/20...  Training Step: 3650...  Training loss: 1.9318...  0.0548 sec/batch
Epoch: 6/20...  Training Step: 3651...  Training loss: 1.9736...  0.0537 sec/batch
Epoch: 6/20...  Training Step: 3652...  Training loss: 1.9084...  0.0525 sec/batch
Epoch: 6/20...  Training Step: 3653...  Training loss: 1.9458...  0.0535 sec/batch
Epoch: 6/20...  Training Step: 3654...  Training loss: 1.9607...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3655...  Training loss: 1.9286...  0.0560 sec/batch
Epoch: 6/20...  Training Step: 3656...  Training loss: 1.9388...  0.0596 sec/batch
Epoch: 6/20...  Training Step: 3657...  Training loss: 1.9603...  0.0550 sec/batch
Epoch: 6/20...  Training Step: 3658...  Training loss: 1.9314...  0.0587 sec/batch
Epoch: 6/20...  Training Step: 3659...  Training loss: 1.9579...  0.0536 sec/batch
Epoch: 6/20...  Training Step: 3660...  Training loss: 1.9612...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3661...  Training loss: 1.9739...  0.0589 sec/batch
Epoch: 6/20...  Training Step: 3662...  Training loss: 1.9714...  0.0560 sec/batch
Epoch: 6/20...  Training Step: 3663...  Training loss: 1.9675...  0.0557 sec/batch
Epoch: 6/20...  Training Step: 3664...  Training loss: 2.0092...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3665...  Training loss: 2.0537...  0.0535 sec/batch
Epoch: 6/20...  Training Step: 3666...  Training loss: 2.0097...  0.0569 sec/batch
Epoch: 6/20...  Training Step: 3667...  Training loss: 1.9553...  0.0560 sec/batch
Epoch: 6/20...  Training Step: 3668...  Training loss: 2.0471...  0.0557 sec/batch
Epoch: 6/20...  Training Step: 3669...  Training loss: 1.9585...  0.0566 sec/batch
Epoch: 6/20...  Training Step: 3670...  Training loss: 1.9683...  0.0581 sec/batch
Epoch: 6/20...  Training Step: 3671...  Training loss: 1.9634...  0.0554 sec/batch
Epoch: 6/20...  Training Step: 3672...  Training loss: 2.0173...  0.0556 sec/batch
Epoch: 6/20...  Training Step: 3673...  Training loss: 1.9538...  0.0570 sec/batch
Epoch: 6/20...  Training Step: 3674...  Training loss: 1.9391...  0.0564 sec/batch
Epoch: 6/20...  Training Step: 3675...  Training loss: 1.9399...  0.0570 sec/batch
Epoch: 6/20...  Training Step: 3676...  Training loss: 2.0039...  0.0578 sec/batch
Epoch: 6/20...  Training Step: 3677...  Training loss: 1.9188...  0.0546 sec/batch
Epoch: 6/20...  Training Step: 3678...  Training loss: 1.9657...  0.0533 sec/batch
Epoch: 6/20...  Training Step: 3679...  Training loss: 2.0136...  0.0575 sec/batch
Epoch: 6/20...  Training Step: 3680...  Training loss: 1.9792...  0.0534 sec/batch
Epoch: 6/20...  Training Step: 3681...  Training loss: 1.9867...  0.0545 sec/batch
Epoch: 6/20...  Training Step: 3682...  Training loss: 1.9740...  0.0532 sec/batch
Epoch: 6/20...  Training Step: 3683...  Training loss: 1.9512...  0.0560 sec/batch
Epoch: 6/20...  Training Step: 3684...  Training loss: 2.0035...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3685...  Training loss: 1.9513...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3686...  Training loss: 1.9715...  0.0525 sec/batch
Epoch: 6/20...  Training Step: 3687...  Training loss: 1.9384...  0.0579 sec/batch
Epoch: 6/20...  Training Step: 3688...  Training loss: 1.9749...  0.0554 sec/batch
Epoch: 6/20...  Training Step: 3689...  Training loss: 1.9262...  0.0557 sec/batch
Epoch: 6/20...  Training Step: 3690...  Training loss: 1.9877...  0.0558 sec/batch
Epoch: 6/20...  Training Step: 3691...  Training loss: 1.9121...  0.0550 sec/batch
Epoch: 6/20...  Training Step: 3692...  Training loss: 1.9807...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3693...  Training loss: 1.9263...  0.0556 sec/batch
Epoch: 6/20...  Training Step: 3694...  Training loss: 1.9271...  0.0528 sec/batch
Epoch: 6/20...  Training Step: 3695...  Training loss: 1.9325...  0.0576 sec/batch
Epoch: 6/20...  Training Step: 3696...  Training loss: 1.9406...  0.0529 sec/batch
Epoch: 6/20...  Training Step: 3697...  Training loss: 1.9001...  0.0595 sec/batch
Epoch: 6/20...  Training Step: 3698...  Training loss: 1.9517...  0.0588 sec/batch
Epoch: 6/20...  Training Step: 3699...  Training loss: 1.9482...  0.0527 sec/batch
Epoch: 6/20...  Training Step: 3700...  Training loss: 1.9706...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3701...  Training loss: 1.9504...  0.0579 sec/batch
Epoch: 6/20...  Training Step: 3702...  Training loss: 1.9728...  0.0556 sec/batch
Epoch: 6/20...  Training Step: 3703...  Training loss: 1.9818...  0.0540 sec/batch
Epoch: 6/20...  Training Step: 3704...  Training loss: 1.9205...  0.0550 sec/batch
Epoch: 6/20...  Training Step: 3705...  Training loss: 1.9608...  0.0530 sec/batch
Epoch: 6/20...  Training Step: 3706...  Training loss: 1.9411...  0.0567 sec/batch
Epoch: 6/20...  Training Step: 3707...  Training loss: 1.9102...  0.0542 sec/batch
Epoch: 6/20...  Training Step: 3708...  Training loss: 1.9358...  0.0555 sec/batch
Epoch: 6/20...  Training Step: 3709...  Training loss: 1.9367...  0.0576 sec/batch
Epoch: 6/20...  Training Step: 3710...  Training loss: 1.9849...  0.0560 sec/batch
Epoch: 6/20...  Training Step: 3711...  Training loss: 1.9951...  0.0556 sec/batch
Epoch: 6/20...  Training Step: 3712...  Training loss: 1.9752...  0.0532 sec/batch
Epoch: 6/20...  Training Step: 3713...  Training loss: 1.9099...  0.0531 sec/batch
Epoch: 6/20...  Training Step: 3714...  Training loss: 1.9803...  0.0552 sec/batch
Epoch: 6/20...  Training Step: 3715...  Training loss: 1.9248...  0.0566 sec/batch
Epoch: 6/20...  Training Step: 3716...  Training loss: 1.9783...  0.0551 sec/batch
Epoch: 6/20...  Training Step: 3717...  Training loss: 1.9824...  0.0577 sec/batch
Epoch: 6/20...  Training Step: 3718...  Training loss: 1.9279...  0.0554 sec/batch
Epoch: 6/20...  Training Step: 3719...  Training loss: 1.9134...  0.0563 sec/batch
Epoch: 6/20...  Training Step: 3720...  Training loss: 1.9245...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 3721...  Training loss: 2.0344...  0.0562 sec/batch
Epoch: 7/20...  Training Step: 3722...  Training loss: 2.0289...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 3723...  Training loss: 1.9909...  0.0556 sec/batch
Epoch: 7/20...  Training Step: 3724...  Training loss: 1.9216...  0.0571 sec/batch
Epoch: 7/20...  Training Step: 3725...  Training loss: 1.9576...  0.0564 sec/batch
Epoch: 7/20...  Training Step: 3726...  Training loss: 1.9338...  0.0552 sec/batch
Epoch: 7/20...  Training Step: 3727...  Training loss: 1.9282...  0.0584 sec/batch
Epoch: 7/20...  Training Step: 3728...  Training loss: 1.9088...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 3729...  Training loss: 1.8917...  0.0551 sec/batch
Epoch: 7/20...  Training Step: 3730...  Training loss: 1.9245...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 3731...  Training loss: 1.9586...  0.0558 sec/batch
Epoch: 7/20...  Training Step: 3732...  Training loss: 1.9001...  0.0564 sec/batch
Epoch: 7/20...  Training Step: 3733...  Training loss: 1.9746...  0.0624 sec/batch
Epoch: 7/20...  Training Step: 3734...  Training loss: 1.9341...  0.0550 sec/batch
Epoch: 7/20...  Training Step: 3735...  Training loss: 1.9608...  0.0597 sec/batch
Epoch: 7/20...  Training Step: 3736...  Training loss: 1.9940...  0.0592 sec/batch
Epoch: 7/20...  Training Step: 3737...  Training loss: 1.9817...  0.0562 sec/batch
Epoch: 7/20...  Training Step: 3738...  Training loss: 1.9654...  0.0534 sec/batch
Epoch: 7/20...  Training Step: 3739...  Training loss: 1.9123...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 3740...  Training loss: 1.9583...  0.0555 sec/batch
Epoch: 7/20...  Training Step: 3741...  Training loss: 2.0153...  0.0525 sec/batch
Epoch: 7/20...  Training Step: 3742...  Training loss: 1.9378...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 3743...  Training loss: 1.9244...  0.0573 sec/batch
Epoch: 7/20...  Training Step: 3744...  Training loss: 1.9429...  0.0576 sec/batch
Epoch: 7/20...  Training Step: 3745...  Training loss: 1.9383...  0.0605 sec/batch
Epoch: 7/20...  Training Step: 3746...  Training loss: 1.9321...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 3747...  Training loss: 1.9415...  0.0586 sec/batch
Epoch: 7/20...  Training Step: 3748...  Training loss: 1.9541...  0.0550 sec/batch
Epoch: 7/20...  Training Step: 3749...  Training loss: 1.9517...  0.0563 sec/batch
Epoch: 7/20...  Training Step: 3750...  Training loss: 1.9005...  0.0561 sec/batch
Epoch: 7/20...  Training Step: 3751...  Training loss: 1.9104...  0.0536 sec/batch
Epoch: 7/20...  Training Step: 3752...  Training loss: 1.9660...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 3753...  Training loss: 1.9389...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 3754...  Training loss: 1.9194...  0.0588 sec/batch
Epoch: 7/20...  Training Step: 3755...  Training loss: 1.9333...  0.0535 sec/batch
Epoch: 7/20...  Training Step: 3756...  Training loss: 1.9596...  0.0526 sec/batch
Epoch: 7/20...  Training Step: 3757...  Training loss: 1.9461...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 3758...  Training loss: 1.9360...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 3759...  Training loss: 1.9526...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 3760...  Training loss: 1.9057...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 3761...  Training loss: 1.9389...  0.0541 sec/batch
Epoch: 7/20...  Training Step: 3762...  Training loss: 1.9802...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 3763...  Training loss: 1.9445...  0.0535 sec/batch
Epoch: 7/20...  Training Step: 3764...  Training loss: 1.9662...  0.0534 sec/batch
Epoch: 7/20...  Training Step: 3765...  Training loss: 1.9510...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 3766...  Training loss: 1.9256...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 3767...  Training loss: 1.8464...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 3768...  Training loss: 1.9472...  0.0590 sec/batch
Epoch: 7/20...  Training Step: 3769...  Training loss: 1.9298...  0.0567 sec/batch
Epoch: 7/20...  Training Step: 3770...  Training loss: 1.9586...  0.0536 sec/batch
Epoch: 7/20...  Training Step: 3771...  Training loss: 1.9129...  0.0563 sec/batch
Epoch: 7/20...  Training Step: 3772...  Training loss: 1.9134...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 3773...  Training loss: 1.9544...  0.0542 sec/batch
Epoch: 7/20...  Training Step: 3774...  Training loss: 1.9680...  0.0576 sec/batch
Epoch: 7/20...  Training Step: 3775...  Training loss: 1.9766...  0.0561 sec/batch
Epoch: 7/20...  Training Step: 3776...  Training loss: 1.9311...  0.0563 sec/batch
Epoch: 7/20...  Training Step: 3777...  Training loss: 1.9047...  0.0536 sec/batch
Epoch: 7/20...  Training Step: 3778...  Training loss: 1.9470...  0.0605 sec/batch
Epoch: 7/20...  Training Step: 3779...  Training loss: 1.9351...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 3780...  Training loss: 1.9927...  0.0558 sec/batch
Epoch: 7/20...  Training Step: 3781...  Training loss: 1.9525...  0.0535 sec/batch
Epoch: 7/20...  Training Step: 3782...  Training loss: 1.9270...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 3783...  Training loss: 1.9584...  0.0538 sec/batch
Epoch: 7/20...  Training Step: 3784...  Training loss: 1.9136...  0.0585 sec/batch
Epoch: 7/20...  Training Step: 3785...  Training loss: 1.9040...  0.0590 sec/batch
Epoch: 7/20...  Training Step: 3786...  Training loss: 1.8601...  0.0602 sec/batch
Epoch: 7/20...  Training Step: 3787...  Training loss: 1.9095...  0.0601 sec/batch
Epoch: 7/20...  Training Step: 3788...  Training loss: 1.9112...  0.0540 sec/batch
Epoch: 7/20...  Training Step: 3789...  Training loss: 1.9741...  0.0541 sec/batch
Epoch: 7/20...  Training Step: 3790...  Training loss: 1.9447...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 3791...  Training loss: 1.9800...  0.0535 sec/batch
Epoch: 7/20...  Training Step: 3792...  Training loss: 1.9580...  0.0562 sec/batch
Epoch: 7/20...  Training Step: 3793...  Training loss: 1.9014...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 3794...  Training loss: 1.9343...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 3795...  Training loss: 1.9748...  0.0568 sec/batch
Epoch: 7/20...  Training Step: 3796...  Training loss: 1.9630...  0.0590 sec/batch
Epoch: 7/20...  Training Step: 3797...  Training loss: 1.9560...  0.0541 sec/batch
Epoch: 7/20...  Training Step: 3798...  Training loss: 1.9266...  0.0535 sec/batch
Epoch: 7/20...  Training Step: 3799...  Training loss: 1.9327...  0.0566 sec/batch
Epoch: 7/20...  Training Step: 3800...  Training loss: 1.9571...  0.0587 sec/batch
Epoch: 7/20...  Training Step: 3801...  Training loss: 1.9100...  0.0602 sec/batch
Epoch: 7/20...  Training Step: 3802...  Training loss: 1.9412...  0.0564 sec/batch
Epoch: 7/20...  Training Step: 3803...  Training loss: 1.8936...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 3804...  Training loss: 1.9399...  0.0537 sec/batch
Epoch: 7/20...  Training Step: 3805...  Training loss: 1.9291...  0.0573 sec/batch
Epoch: 7/20...  Training Step: 3806...  Training loss: 1.9763...  0.0556 sec/batch
Epoch: 7/20...  Training Step: 3807...  Training loss: 1.8999...  0.0559 sec/batch
Epoch: 7/20...  Training Step: 3808...  Training loss: 1.9807...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 3809...  Training loss: 1.9626...  0.0545 sec/batch
Epoch: 7/20...  Training Step: 3810...  Training loss: 1.9556...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 3811...  Training loss: 1.9387...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 3812...  Training loss: 1.9844...  0.0551 sec/batch
Epoch: 7/20...  Training Step: 3813...  Training loss: 1.9573...  0.0607 sec/batch
Epoch: 7/20...  Training Step: 3814...  Training loss: 1.9349...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 3815...  Training loss: 1.9532...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 3816...  Training loss: 1.9652...  0.0536 sec/batch
Epoch: 7/20...  Training Step: 3817...  Training loss: 1.9670...  0.0603 sec/batch
Epoch: 7/20...  Training Step: 3818...  Training loss: 1.8988...  0.0569 sec/batch
Epoch: 7/20...  Training Step: 3819...  Training loss: 1.9973...  0.0560 sec/batch
Epoch: 7/20...  Training Step: 3820...  Training loss: 1.9161...  0.0588 sec/batch
Epoch: 7/20...  Training Step: 3821...  Training loss: 1.9365...  0.0566 sec/batch
Epoch: 7/20...  Training Step: 3822...  Training loss: 1.9275...  0.0591 sec/batch
Epoch: 7/20...  Training Step: 3823...  Training loss: 1.9779...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 3824...  Training loss: 1.9629...  0.0549 sec/batch
Epoch: 7/20...  Training Step: 3825...  Training loss: 1.9445...  0.0598 sec/batch
Epoch: 7/20...  Training Step: 3826...  Training loss: 1.8939...  0.0527 sec/batch
Epoch: 7/20...  Training Step: 3827...  Training loss: 1.9560...  0.0549 sec/batch
Epoch: 7/20...  Training Step: 3828...  Training loss: 1.9440...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 3829...  Training loss: 1.9171...  0.0560 sec/batch
Epoch: 7/20...  Training Step: 3830...  Training loss: 1.9006...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 3831...  Training loss: 1.9121...  0.0596 sec/batch
Epoch: 7/20...  Training Step: 3832...  Training loss: 1.9232...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 3833...  Training loss: 1.9492...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 3834...  Training loss: 1.9282...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 3835...  Training loss: 1.9480...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 3836...  Training loss: 1.9632...  0.0535 sec/batch
Epoch: 7/20...  Training Step: 3837...  Training loss: 1.8951...  0.0539 sec/batch
Epoch: 7/20...  Training Step: 3838...  Training loss: 1.9696...  0.0536 sec/batch
Epoch: 7/20...  Training Step: 3839...  Training loss: 1.9198...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 3840...  Training loss: 1.9238...  0.0556 sec/batch
Epoch: 7/20...  Training Step: 3841...  Training loss: 1.9007...  0.0588 sec/batch
Epoch: 7/20...  Training Step: 3842...  Training loss: 1.8839...  0.0578 sec/batch
Epoch: 7/20...  Training Step: 3843...  Training loss: 1.9042...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 3844...  Training loss: 1.9524...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 3845...  Training loss: 1.9395...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 3846...  Training loss: 1.9648...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 3847...  Training loss: 1.9856...  0.0573 sec/batch
Epoch: 7/20...  Training Step: 3848...  Training loss: 1.9010...  0.0573 sec/batch
Epoch: 7/20...  Training Step: 3849...  Training loss: 1.9196...  0.0590 sec/batch
Epoch: 7/20...  Training Step: 3850...  Training loss: 1.9936...  0.0555 sec/batch
Epoch: 7/20...  Training Step: 3851...  Training loss: 1.9265...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 3852...  Training loss: 1.9781...  0.0550 sec/batch
Epoch: 7/20...  Training Step: 3853...  Training loss: 1.9823...  0.0611 sec/batch
Epoch: 7/20...  Training Step: 3854...  Training loss: 1.9249...  0.0536 sec/batch
Epoch: 7/20...  Training Step: 3855...  Training loss: 1.8934...  0.0597 sec/batch
Epoch: 7/20...  Training Step: 3856...  Training loss: 1.9335...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 3857...  Training loss: 1.9318...  0.0539 sec/batch
Epoch: 7/20...  Training Step: 3858...  Training loss: 1.9381...  0.0561 sec/batch
Epoch: 7/20...  Training Step: 3859...  Training loss: 1.9899...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 3860...  Training loss: 1.9213...  0.0567 sec/batch
Epoch: 7/20...  Training Step: 3861...  Training loss: 1.9620...  0.0538 sec/batch
Epoch: 7/20...  Training Step: 3862...  Training loss: 1.8480...  0.0537 sec/batch
Epoch: 7/20...  Training Step: 3863...  Training loss: 1.9492...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 3864...  Training loss: 1.9168...  0.0563 sec/batch
Epoch: 7/20...  Training Step: 3865...  Training loss: 1.9104...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 3866...  Training loss: 1.9741...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 3867...  Training loss: 1.9522...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 3868...  Training loss: 1.9449...  0.0539 sec/batch
Epoch: 7/20...  Training Step: 3869...  Training loss: 1.9332...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 3870...  Training loss: 1.9557...  0.0600 sec/batch
Epoch: 7/20...  Training Step: 3871...  Training loss: 1.9549...  0.0547 sec/batch
Epoch: 7/20...  Training Step: 3872...  Training loss: 1.9104...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 3873...  Training loss: 1.9215...  0.0603 sec/batch
Epoch: 7/20...  Training Step: 3874...  Training loss: 1.9661...  0.0564 sec/batch
Epoch: 7/20...  Training Step: 3875...  Training loss: 1.9285...  0.0558 sec/batch
Epoch: 7/20...  Training Step: 3876...  Training loss: 1.9551...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 3877...  Training loss: 1.9296...  0.0534 sec/batch
Epoch: 7/20...  Training Step: 3878...  Training loss: 1.9615...  0.0584 sec/batch
Epoch: 7/20...  Training Step: 3879...  Training loss: 1.9610...  0.0563 sec/batch
Epoch: 7/20...  Training Step: 3880...  Training loss: 1.8864...  0.0556 sec/batch
Epoch: 7/20...  Training Step: 3881...  Training loss: 1.8955...  0.0546 sec/batch
Epoch: 7/20...  Training Step: 3882...  Training loss: 1.8905...  0.0562 sec/batch
Epoch: 7/20...  Training Step: 3883...  Training loss: 1.9326...  0.0537 sec/batch
Epoch: 7/20...  Training Step: 3884...  Training loss: 1.9268...  0.0541 sec/batch
Epoch: 7/20...  Training Step: 3885...  Training loss: 1.9579...  0.0552 sec/batch
Epoch: 7/20...  Training Step: 3886...  Training loss: 1.9395...  0.0536 sec/batch
Epoch: 7/20...  Training Step: 3887...  Training loss: 1.9532...  0.0558 sec/batch
Epoch: 7/20...  Training Step: 3888...  Training loss: 1.9311...  0.0538 sec/batch
Epoch: 7/20...  Training Step: 3889...  Training loss: 1.9301...  0.0612 sec/batch
Epoch: 7/20...  Training Step: 3890...  Training loss: 1.8973...  0.0552 sec/batch
Epoch: 7/20...  Training Step: 3891...  Training loss: 1.9120...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 3892...  Training loss: 1.9308...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 3893...  Training loss: 1.9377...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 3894...  Training loss: 1.9355...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 3895...  Training loss: 1.9091...  0.0562 sec/batch
Epoch: 7/20...  Training Step: 3896...  Training loss: 1.9392...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 3897...  Training loss: 1.9532...  0.0537 sec/batch
Epoch: 7/20...  Training Step: 3898...  Training loss: 1.9304...  0.0559 sec/batch
Epoch: 7/20...  Training Step: 3899...  Training loss: 1.9091...  0.0543 sec/batch
Epoch: 7/20...  Training Step: 3900...  Training loss: 1.9192...  0.0534 sec/batch
Epoch: 7/20...  Training Step: 3901...  Training loss: 1.9063...  0.0571 sec/batch
Epoch: 7/20...  Training Step: 3902...  Training loss: 1.9421...  0.0586 sec/batch
Epoch: 7/20...  Training Step: 3903...  Training loss: 1.9507...  0.0566 sec/batch
Epoch: 7/20...  Training Step: 3904...  Training loss: 1.8890...  0.0551 sec/batch
Epoch: 7/20...  Training Step: 3905...  Training loss: 1.8843...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 3906...  Training loss: 1.9265...  0.0542 sec/batch
Epoch: 7/20...  Training Step: 3907...  Training loss: 1.9227...  0.0591 sec/batch
Epoch: 7/20...  Training Step: 3908...  Training loss: 1.9197...  0.0600 sec/batch
Epoch: 7/20...  Training Step: 3909...  Training loss: 1.9266...  0.0603 sec/batch
Epoch: 7/20...  Training Step: 3910...  Training loss: 2.0080...  0.0550 sec/batch
Epoch: 7/20...  Training Step: 3911...  Training loss: 1.9616...  0.0603 sec/batch
Epoch: 7/20...  Training Step: 3912...  Training loss: 1.9719...  0.0584 sec/batch
Epoch: 7/20...  Training Step: 3913...  Training loss: 1.9604...  0.0558 sec/batch
Epoch: 7/20...  Training Step: 3914...  Training loss: 1.9139...  0.0591 sec/batch
Epoch: 7/20...  Training Step: 3915...  Training loss: 1.9320...  0.0566 sec/batch
Epoch: 7/20...  Training Step: 3916...  Training loss: 2.0060...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 3917...  Training loss: 1.9285...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 3918...  Training loss: 2.0011...  0.0564 sec/batch
Epoch: 7/20...  Training Step: 3919...  Training loss: 1.9002...  0.0590 sec/batch
Epoch: 7/20...  Training Step: 3920...  Training loss: 1.9498...  0.0565 sec/batch
Epoch: 7/20...  Training Step: 3921...  Training loss: 1.9298...  0.0549 sec/batch
Epoch: 7/20...  Training Step: 3922...  Training loss: 1.9056...  0.0549 sec/batch
Epoch: 7/20...  Training Step: 3923...  Training loss: 1.9312...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 3924...  Training loss: 1.9141...  0.0601 sec/batch
Epoch: 7/20...  Training Step: 3925...  Training loss: 1.9340...  0.0543 sec/batch
Epoch: 7/20...  Training Step: 3926...  Training loss: 1.8836...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 3927...  Training loss: 1.9444...  0.0567 sec/batch
Epoch: 7/20...  Training Step: 3928...  Training loss: 1.9448...  0.0593 sec/batch
Epoch: 7/20...  Training Step: 3929...  Training loss: 1.9177...  0.0534 sec/batch
Epoch: 7/20...  Training Step: 3930...  Training loss: 1.9200...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 3931...  Training loss: 1.9374...  0.0549 sec/batch
Epoch: 7/20...  Training Step: 3932...  Training loss: 1.9391...  0.0591 sec/batch
Epoch: 7/20...  Training Step: 3933...  Training loss: 1.9540...  0.0559 sec/batch
Epoch: 7/20...  Training Step: 3934...  Training loss: 1.9608...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 3935...  Training loss: 1.9609...  0.0551 sec/batch
Epoch: 7/20...  Training Step: 3936...  Training loss: 1.9499...  0.0575 sec/batch
Epoch: 7/20...  Training Step: 3937...  Training loss: 1.9329...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 3938...  Training loss: 1.9078...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 3939...  Training loss: 2.0275...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 3940...  Training loss: 1.9608...  0.0524 sec/batch
Epoch: 7/20...  Training Step: 3941...  Training loss: 1.9446...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 3942...  Training loss: 1.9502...  0.0564 sec/batch
Epoch: 7/20...  Training Step: 3943...  Training loss: 1.9774...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 3944...  Training loss: 1.9121...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 3945...  Training loss: 1.9225...  0.0534 sec/batch
Epoch: 7/20...  Training Step: 3946...  Training loss: 1.9739...  0.0597 sec/batch
Epoch: 7/20...  Training Step: 3947...  Training loss: 1.9893...  0.0581 sec/batch
Epoch: 7/20...  Training Step: 3948...  Training loss: 1.9006...  0.0561 sec/batch
Epoch: 7/20...  Training Step: 3949...  Training loss: 1.9696...  0.0561 sec/batch
Epoch: 7/20...  Training Step: 3950...  Training loss: 1.9108...  0.0559 sec/batch
Epoch: 7/20...  Training Step: 3951...  Training loss: 1.9966...  0.0585 sec/batch
Epoch: 7/20...  Training Step: 3952...  Training loss: 1.9157...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 3953...  Training loss: 1.9097...  0.0546 sec/batch
Epoch: 7/20...  Training Step: 3954...  Training loss: 1.9060...  0.0559 sec/batch
Epoch: 7/20...  Training Step: 3955...  Training loss: 1.9163...  0.0594 sec/batch
Epoch: 7/20...  Training Step: 3956...  Training loss: 1.9677...  0.0581 sec/batch
Epoch: 7/20...  Training Step: 3957...  Training loss: 1.9313...  0.0580 sec/batch
Epoch: 7/20...  Training Step: 3958...  Training loss: 1.8769...  0.0567 sec/batch
Epoch: 7/20...  Training Step: 3959...  Training loss: 1.9119...  0.0564 sec/batch
Epoch: 7/20...  Training Step: 3960...  Training loss: 1.9623...  0.0606 sec/batch
Epoch: 7/20...  Training Step: 3961...  Training loss: 1.9336...  0.0570 sec/batch
Epoch: 7/20...  Training Step: 3962...  Training loss: 1.9117...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 3963...  Training loss: 1.8996...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 3964...  Training loss: 1.9116...  0.0593 sec/batch
Epoch: 7/20...  Training Step: 3965...  Training loss: 1.9310...  0.0561 sec/batch
Epoch: 7/20...  Training Step: 3966...  Training loss: 1.9500...  0.0525 sec/batch
Epoch: 7/20...  Training Step: 3967...  Training loss: 1.9493...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 3968...  Training loss: 1.9326...  0.0578 sec/batch
Epoch: 7/20...  Training Step: 3969...  Training loss: 1.8944...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 3970...  Training loss: 1.9259...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 3971...  Training loss: 1.9228...  0.0539 sec/batch
Epoch: 7/20...  Training Step: 3972...  Training loss: 1.9181...  0.0577 sec/batch
Epoch: 7/20...  Training Step: 3973...  Training loss: 1.9320...  0.0558 sec/batch
Epoch: 7/20...  Training Step: 3974...  Training loss: 1.9440...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 3975...  Training loss: 1.9562...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 3976...  Training loss: 1.9282...  0.0535 sec/batch
Epoch: 7/20...  Training Step: 3977...  Training loss: 1.9306...  0.0596 sec/batch
Epoch: 7/20...  Training Step: 3978...  Training loss: 1.9244...  0.0536 sec/batch
Epoch: 7/20...  Training Step: 3979...  Training loss: 1.9356...  0.0560 sec/batch
Epoch: 7/20...  Training Step: 3980...  Training loss: 1.9161...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 3981...  Training loss: 1.9413...  0.0593 sec/batch
Epoch: 7/20...  Training Step: 3982...  Training loss: 1.8942...  0.0600 sec/batch
Epoch: 7/20...  Training Step: 3983...  Training loss: 1.9438...  0.0546 sec/batch
Epoch: 7/20...  Training Step: 3984...  Training loss: 1.9495...  0.0544 sec/batch
Epoch: 7/20...  Training Step: 3985...  Training loss: 1.9526...  0.0590 sec/batch
Epoch: 7/20...  Training Step: 3986...  Training loss: 1.8792...  0.0544 sec/batch
Epoch: 7/20...  Training Step: 3987...  Training loss: 1.9378...  0.0555 sec/batch
Epoch: 7/20...  Training Step: 3988...  Training loss: 1.9309...  0.0547 sec/batch
Epoch: 7/20...  Training Step: 3989...  Training loss: 1.9252...  0.0540 sec/batch
Epoch: 7/20...  Training Step: 3990...  Training loss: 1.8910...  0.0552 sec/batch
Epoch: 7/20...  Training Step: 3991...  Training loss: 1.9026...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 3992...  Training loss: 1.9277...  0.0539 sec/batch
Epoch: 7/20...  Training Step: 3993...  Training loss: 1.9262...  0.0567 sec/batch
Epoch: 7/20...  Training Step: 3994...  Training loss: 1.8943...  0.0538 sec/batch
Epoch: 7/20...  Training Step: 3995...  Training loss: 1.9572...  0.0597 sec/batch
Epoch: 7/20...  Training Step: 3996...  Training loss: 1.9754...  0.0551 sec/batch
Epoch: 7/20...  Training Step: 3997...  Training loss: 2.0107...  0.0575 sec/batch
Epoch: 7/20...  Training Step: 3998...  Training loss: 1.9344...  0.0595 sec/batch
Epoch: 7/20...  Training Step: 3999...  Training loss: 1.9699...  0.0575 sec/batch
Epoch: 7/20...  Training Step: 4000...  Training loss: 1.9763...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 4001...  Training loss: 1.9431...  0.0562 sec/batch
Epoch: 7/20...  Training Step: 4002...  Training loss: 1.8756...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 4003...  Training loss: 1.9051...  0.0524 sec/batch
Epoch: 7/20...  Training Step: 4004...  Training loss: 1.9348...  0.0535 sec/batch
Epoch: 7/20...  Training Step: 4005...  Training loss: 1.9221...  0.0574 sec/batch
Epoch: 7/20...  Training Step: 4006...  Training loss: 1.9557...  0.0559 sec/batch
Epoch: 7/20...  Training Step: 4007...  Training loss: 1.9204...  0.0584 sec/batch
Epoch: 7/20...  Training Step: 4008...  Training loss: 1.9238...  0.0576 sec/batch
Epoch: 7/20...  Training Step: 4009...  Training loss: 1.9436...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 4010...  Training loss: 1.9730...  0.0589 sec/batch
Epoch: 7/20...  Training Step: 4011...  Training loss: 1.9234...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 4012...  Training loss: 1.9406...  0.0522 sec/batch
Epoch: 7/20...  Training Step: 4013...  Training loss: 1.9437...  0.0555 sec/batch
Epoch: 7/20...  Training Step: 4014...  Training loss: 1.9469...  0.0570 sec/batch
Epoch: 7/20...  Training Step: 4015...  Training loss: 1.9084...  0.0555 sec/batch
Epoch: 7/20...  Training Step: 4016...  Training loss: 1.8885...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4017...  Training loss: 1.9503...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 4018...  Training loss: 1.9659...  0.0598 sec/batch
Epoch: 7/20...  Training Step: 4019...  Training loss: 1.9585...  0.0527 sec/batch
Epoch: 7/20...  Training Step: 4020...  Training loss: 1.9255...  0.0552 sec/batch
Epoch: 7/20...  Training Step: 4021...  Training loss: 1.9606...  0.0559 sec/batch
Epoch: 7/20...  Training Step: 4022...  Training loss: 2.0004...  0.0537 sec/batch
Epoch: 7/20...  Training Step: 4023...  Training loss: 1.8760...  0.0629 sec/batch
Epoch: 7/20...  Training Step: 4024...  Training loss: 1.9625...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 4025...  Training loss: 1.9276...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 4026...  Training loss: 1.9138...  0.0579 sec/batch
Epoch: 7/20...  Training Step: 4027...  Training loss: 1.9226...  0.0525 sec/batch
Epoch: 7/20...  Training Step: 4028...  Training loss: 1.9067...  0.0564 sec/batch
Epoch: 7/20...  Training Step: 4029...  Training loss: 1.9341...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 4030...  Training loss: 1.9005...  0.0600 sec/batch
Epoch: 7/20...  Training Step: 4031...  Training loss: 1.9035...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4032...  Training loss: 1.9009...  0.0551 sec/batch
Epoch: 7/20...  Training Step: 4033...  Training loss: 1.9159...  0.0563 sec/batch
Epoch: 7/20...  Training Step: 4034...  Training loss: 1.9002...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4035...  Training loss: 1.9346...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 4036...  Training loss: 1.9531...  0.0552 sec/batch
Epoch: 7/20...  Training Step: 4037...  Training loss: 1.8989...  0.0550 sec/batch
Epoch: 7/20...  Training Step: 4038...  Training loss: 1.8784...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 4039...  Training loss: 1.9164...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4040...  Training loss: 1.9785...  0.0527 sec/batch
Epoch: 7/20...  Training Step: 4041...  Training loss: 1.9149...  0.0588 sec/batch
Epoch: 7/20...  Training Step: 4042...  Training loss: 1.8842...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 4043...  Training loss: 1.9366...  0.0549 sec/batch
Epoch: 7/20...  Training Step: 4044...  Training loss: 1.9193...  0.0575 sec/batch
Epoch: 7/20...  Training Step: 4045...  Training loss: 1.8741...  0.0559 sec/batch
Epoch: 7/20...  Training Step: 4046...  Training loss: 1.9133...  0.0524 sec/batch
Epoch: 7/20...  Training Step: 4047...  Training loss: 1.9013...  0.0534 sec/batch
Epoch: 7/20...  Training Step: 4048...  Training loss: 1.8757...  0.0555 sec/batch
Epoch: 7/20...  Training Step: 4049...  Training loss: 1.9266...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4050...  Training loss: 1.8948...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4051...  Training loss: 1.9278...  0.0550 sec/batch
Epoch: 7/20...  Training Step: 4052...  Training loss: 1.8970...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4053...  Training loss: 1.8871...  0.0556 sec/batch
Epoch: 7/20...  Training Step: 4054...  Training loss: 1.9143...  0.0563 sec/batch
Epoch: 7/20...  Training Step: 4055...  Training loss: 1.9327...  0.0561 sec/batch
Epoch: 7/20...  Training Step: 4056...  Training loss: 1.9207...  0.0574 sec/batch
Epoch: 7/20...  Training Step: 4057...  Training loss: 1.9049...  0.0562 sec/batch
Epoch: 7/20...  Training Step: 4058...  Training loss: 1.8874...  0.0558 sec/batch
Epoch: 7/20...  Training Step: 4059...  Training loss: 1.9080...  0.0538 sec/batch
Epoch: 7/20...  Training Step: 4060...  Training loss: 1.9151...  0.0534 sec/batch
Epoch: 7/20...  Training Step: 4061...  Training loss: 1.9167...  0.0527 sec/batch
Epoch: 7/20...  Training Step: 4062...  Training loss: 1.9048...  0.0549 sec/batch
Epoch: 7/20...  Training Step: 4063...  Training loss: 1.9001...  0.0556 sec/batch
Epoch: 7/20...  Training Step: 4064...  Training loss: 1.8954...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 4065...  Training loss: 1.9128...  0.0584 sec/batch
Epoch: 7/20...  Training Step: 4066...  Training loss: 1.9307...  0.0524 sec/batch
Epoch: 7/20...  Training Step: 4067...  Training loss: 1.9268...  0.0584 sec/batch
Epoch: 7/20...  Training Step: 4068...  Training loss: 1.9164...  0.0526 sec/batch
Epoch: 7/20...  Training Step: 4069...  Training loss: 1.9178...  0.0555 sec/batch
Epoch: 7/20...  Training Step: 4070...  Training loss: 1.9048...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4071...  Training loss: 1.9557...  0.0571 sec/batch
Epoch: 7/20...  Training Step: 4072...  Training loss: 1.9017...  0.0525 sec/batch
Epoch: 7/20...  Training Step: 4073...  Training loss: 1.9356...  0.0551 sec/batch
Epoch: 7/20...  Training Step: 4074...  Training loss: 1.9080...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 4075...  Training loss: 1.8922...  0.0559 sec/batch
Epoch: 7/20...  Training Step: 4076...  Training loss: 1.9740...  0.0552 sec/batch
Epoch: 7/20...  Training Step: 4077...  Training loss: 2.0151...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 4078...  Training loss: 1.9641...  0.0552 sec/batch
Epoch: 7/20...  Training Step: 4079...  Training loss: 1.9318...  0.0562 sec/batch
Epoch: 7/20...  Training Step: 4080...  Training loss: 1.9346...  0.0540 sec/batch
Epoch: 7/20...  Training Step: 4081...  Training loss: 1.9499...  0.0591 sec/batch
Epoch: 7/20...  Training Step: 4082...  Training loss: 1.9015...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 4083...  Training loss: 1.8734...  0.0540 sec/batch
Epoch: 7/20...  Training Step: 4084...  Training loss: 1.8550...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 4085...  Training loss: 1.9083...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4086...  Training loss: 1.9308...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 4087...  Training loss: 1.8909...  0.0578 sec/batch
Epoch: 7/20...  Training Step: 4088...  Training loss: 1.9663...  0.0584 sec/batch
Epoch: 7/20...  Training Step: 4089...  Training loss: 1.9359...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 4090...  Training loss: 1.8979...  0.0588 sec/batch
Epoch: 7/20...  Training Step: 4091...  Training loss: 1.9258...  0.0550 sec/batch
Epoch: 7/20...  Training Step: 4092...  Training loss: 1.9995...  0.0537 sec/batch
Epoch: 7/20...  Training Step: 4093...  Training loss: 1.9409...  0.0608 sec/batch
Epoch: 7/20...  Training Step: 4094...  Training loss: 1.9283...  0.0539 sec/batch
Epoch: 7/20...  Training Step: 4095...  Training loss: 1.9043...  0.0577 sec/batch
Epoch: 7/20...  Training Step: 4096...  Training loss: 1.9274...  0.0566 sec/batch
Epoch: 7/20...  Training Step: 4097...  Training loss: 1.8930...  0.0582 sec/batch
Epoch: 7/20...  Training Step: 4098...  Training loss: 1.9765...  0.0563 sec/batch
Epoch: 7/20...  Training Step: 4099...  Training loss: 1.9364...  0.0545 sec/batch
Epoch: 7/20...  Training Step: 4100...  Training loss: 1.9101...  0.0559 sec/batch
Epoch: 7/20...  Training Step: 4101...  Training loss: 1.8509...  0.0570 sec/batch
Epoch: 7/20...  Training Step: 4102...  Training loss: 1.9809...  0.0586 sec/batch
Epoch: 7/20...  Training Step: 4103...  Training loss: 1.8841...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4104...  Training loss: 1.9139...  0.0525 sec/batch
Epoch: 7/20...  Training Step: 4105...  Training loss: 1.9260...  0.0562 sec/batch
Epoch: 7/20...  Training Step: 4106...  Training loss: 1.8514...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 4107...  Training loss: 1.8635...  0.0566 sec/batch
Epoch: 7/20...  Training Step: 4108...  Training loss: 1.9241...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 4109...  Training loss: 1.8634...  0.0537 sec/batch
Epoch: 7/20...  Training Step: 4110...  Training loss: 1.8984...  0.0586 sec/batch
Epoch: 7/20...  Training Step: 4111...  Training loss: 1.9464...  0.0565 sec/batch
Epoch: 7/20...  Training Step: 4112...  Training loss: 1.8847...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4113...  Training loss: 1.9233...  0.0590 sec/batch
Epoch: 7/20...  Training Step: 4114...  Training loss: 1.9368...  0.0526 sec/batch
Epoch: 7/20...  Training Step: 4115...  Training loss: 1.8916...  0.0555 sec/batch
Epoch: 7/20...  Training Step: 4116...  Training loss: 1.9291...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 4117...  Training loss: 1.9004...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 4118...  Training loss: 1.9284...  0.0580 sec/batch
Epoch: 7/20...  Training Step: 4119...  Training loss: 1.9071...  0.0534 sec/batch
Epoch: 7/20...  Training Step: 4120...  Training loss: 1.9325...  0.0534 sec/batch
Epoch: 7/20...  Training Step: 4121...  Training loss: 1.9386...  0.0565 sec/batch
Epoch: 7/20...  Training Step: 4122...  Training loss: 1.9174...  0.0560 sec/batch
Epoch: 7/20...  Training Step: 4123...  Training loss: 1.8999...  0.0555 sec/batch
Epoch: 7/20...  Training Step: 4124...  Training loss: 1.9452...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 4125...  Training loss: 1.9734...  0.0550 sec/batch
Epoch: 7/20...  Training Step: 4126...  Training loss: 1.9422...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 4127...  Training loss: 1.9829...  0.0526 sec/batch
Epoch: 7/20...  Training Step: 4128...  Training loss: 1.9234...  0.0556 sec/batch
Epoch: 7/20...  Training Step: 4129...  Training loss: 1.9828...  0.0524 sec/batch
Epoch: 7/20...  Training Step: 4130...  Training loss: 1.9409...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 4131...  Training loss: 1.9099...  0.0633 sec/batch
Epoch: 7/20...  Training Step: 4132...  Training loss: 1.9580...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 4133...  Training loss: 1.9350...  0.0573 sec/batch
Epoch: 7/20...  Training Step: 4134...  Training loss: 1.9124...  0.0566 sec/batch
Epoch: 7/20...  Training Step: 4135...  Training loss: 1.8706...  0.0550 sec/batch
Epoch: 7/20...  Training Step: 4136...  Training loss: 1.8774...  0.0555 sec/batch
Epoch: 7/20...  Training Step: 4137...  Training loss: 1.9242...  0.0590 sec/batch
Epoch: 7/20...  Training Step: 4138...  Training loss: 1.9299...  0.0540 sec/batch
Epoch: 7/20...  Training Step: 4139...  Training loss: 1.9564...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4140...  Training loss: 1.9264...  0.0526 sec/batch
Epoch: 7/20...  Training Step: 4141...  Training loss: 1.8994...  0.0526 sec/batch
Epoch: 7/20...  Training Step: 4142...  Training loss: 1.9018...  0.0550 sec/batch
Epoch: 7/20...  Training Step: 4143...  Training loss: 1.9319...  0.0560 sec/batch
Epoch: 7/20...  Training Step: 4144...  Training loss: 1.9144...  0.0592 sec/batch
Epoch: 7/20...  Training Step: 4145...  Training loss: 1.9718...  0.0586 sec/batch
Epoch: 7/20...  Training Step: 4146...  Training loss: 1.9519...  0.0590 sec/batch
Epoch: 7/20...  Training Step: 4147...  Training loss: 1.8797...  0.0526 sec/batch
Epoch: 7/20...  Training Step: 4148...  Training loss: 1.9085...  0.0545 sec/batch
Epoch: 7/20...  Training Step: 4149...  Training loss: 1.8964...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4150...  Training loss: 1.8858...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4151...  Training loss: 1.9111...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 4152...  Training loss: 1.9596...  0.0594 sec/batch
Epoch: 7/20...  Training Step: 4153...  Training loss: 1.9578...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4154...  Training loss: 1.8899...  0.0552 sec/batch
Epoch: 7/20...  Training Step: 4155...  Training loss: 1.8923...  0.0597 sec/batch
Epoch: 7/20...  Training Step: 4156...  Training loss: 1.9005...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4157...  Training loss: 1.8891...  0.0556 sec/batch
Epoch: 7/20...  Training Step: 4158...  Training loss: 1.9105...  0.0555 sec/batch
Epoch: 7/20...  Training Step: 4159...  Training loss: 1.9413...  0.0549 sec/batch
Epoch: 7/20...  Training Step: 4160...  Training loss: 1.9025...  0.0535 sec/batch
Epoch: 7/20...  Training Step: 4161...  Training loss: 1.9129...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 4162...  Training loss: 1.9231...  0.0548 sec/batch
Epoch: 7/20...  Training Step: 4163...  Training loss: 1.9556...  0.0547 sec/batch
Epoch: 7/20...  Training Step: 4164...  Training loss: 1.9371...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 4165...  Training loss: 1.8434...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 4166...  Training loss: 1.9051...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4167...  Training loss: 1.8733...  0.0569 sec/batch
Epoch: 7/20...  Training Step: 4168...  Training loss: 1.8803...  0.0560 sec/batch
Epoch: 7/20...  Training Step: 4169...  Training loss: 1.9367...  0.0608 sec/batch
Epoch: 7/20...  Training Step: 4170...  Training loss: 1.9629...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 4171...  Training loss: 1.9759...  0.0536 sec/batch
Epoch: 7/20...  Training Step: 4172...  Training loss: 1.9439...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 4173...  Training loss: 1.8849...  0.0559 sec/batch
Epoch: 7/20...  Training Step: 4174...  Training loss: 1.9164...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 4175...  Training loss: 1.8905...  0.0534 sec/batch
Epoch: 7/20...  Training Step: 4176...  Training loss: 1.9264...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 4177...  Training loss: 1.8948...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 4178...  Training loss: 1.9356...  0.0527 sec/batch
Epoch: 7/20...  Training Step: 4179...  Training loss: 1.8902...  0.0590 sec/batch
Epoch: 7/20...  Training Step: 4180...  Training loss: 1.9209...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 4181...  Training loss: 1.8902...  0.0558 sec/batch
Epoch: 7/20...  Training Step: 4182...  Training loss: 1.9192...  0.0604 sec/batch
Epoch: 7/20...  Training Step: 4183...  Training loss: 1.8880...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4184...  Training loss: 1.8939...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4185...  Training loss: 1.9600...  0.0579 sec/batch
Epoch: 7/20...  Training Step: 4186...  Training loss: 1.9367...  0.0525 sec/batch
Epoch: 7/20...  Training Step: 4187...  Training loss: 1.8984...  0.0570 sec/batch
Epoch: 7/20...  Training Step: 4188...  Training loss: 1.9179...  0.0549 sec/batch
Epoch: 7/20...  Training Step: 4189...  Training loss: 1.9519...  0.0575 sec/batch
Epoch: 7/20...  Training Step: 4190...  Training loss: 1.9188...  0.0580 sec/batch
Epoch: 7/20...  Training Step: 4191...  Training loss: 1.9061...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 4192...  Training loss: 1.9236...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 4193...  Training loss: 1.9087...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 4194...  Training loss: 1.8537...  0.0558 sec/batch
Epoch: 7/20...  Training Step: 4195...  Training loss: 1.9665...  0.0589 sec/batch
Epoch: 7/20...  Training Step: 4196...  Training loss: 1.9558...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4197...  Training loss: 1.9372...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 4198...  Training loss: 2.0031...  0.0591 sec/batch
Epoch: 7/20...  Training Step: 4199...  Training loss: 1.8840...  0.0550 sec/batch
Epoch: 7/20...  Training Step: 4200...  Training loss: 1.9761...  0.0548 sec/batch
Epoch: 7/20...  Training Step: 4201...  Training loss: 1.9205...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4202...  Training loss: 1.8754...  0.0527 sec/batch
Epoch: 7/20...  Training Step: 4203...  Training loss: 1.9562...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4204...  Training loss: 1.9405...  0.0584 sec/batch
Epoch: 7/20...  Training Step: 4205...  Training loss: 1.9778...  0.0539 sec/batch
Epoch: 7/20...  Training Step: 4206...  Training loss: 1.9174...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 4207...  Training loss: 1.9502...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 4208...  Training loss: 1.8909...  0.0573 sec/batch
Epoch: 7/20...  Training Step: 4209...  Training loss: 1.9269...  0.0565 sec/batch
Epoch: 7/20...  Training Step: 4210...  Training loss: 1.9294...  0.0522 sec/batch
Epoch: 7/20...  Training Step: 4211...  Training loss: 1.8948...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4212...  Training loss: 1.9329...  0.0524 sec/batch
Epoch: 7/20...  Training Step: 4213...  Training loss: 1.9229...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 4214...  Training loss: 1.9027...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 4215...  Training loss: 1.8971...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4216...  Training loss: 1.9173...  0.0585 sec/batch
Epoch: 7/20...  Training Step: 4217...  Training loss: 1.9220...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4218...  Training loss: 1.9444...  0.0561 sec/batch
Epoch: 7/20...  Training Step: 4219...  Training loss: 1.8528...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 4220...  Training loss: 1.9485...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4221...  Training loss: 1.9340...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4222...  Training loss: 1.9504...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 4223...  Training loss: 1.9938...  0.0524 sec/batch
Epoch: 7/20...  Training Step: 4224...  Training loss: 1.9348...  0.0591 sec/batch
Epoch: 7/20...  Training Step: 4225...  Training loss: 1.8924...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 4226...  Training loss: 1.8854...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 4227...  Training loss: 1.9398...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 4228...  Training loss: 1.9050...  0.0576 sec/batch
Epoch: 7/20...  Training Step: 4229...  Training loss: 1.9359...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 4230...  Training loss: 1.9484...  0.0567 sec/batch
Epoch: 7/20...  Training Step: 4231...  Training loss: 1.9607...  0.0535 sec/batch
Epoch: 7/20...  Training Step: 4232...  Training loss: 1.9321...  0.0577 sec/batch
Epoch: 7/20...  Training Step: 4233...  Training loss: 1.9982...  0.0569 sec/batch
Epoch: 7/20...  Training Step: 4234...  Training loss: 1.9462...  0.0522 sec/batch
Epoch: 7/20...  Training Step: 4235...  Training loss: 1.9588...  0.0561 sec/batch
Epoch: 7/20...  Training Step: 4236...  Training loss: 1.9165...  0.0669 sec/batch
Epoch: 7/20...  Training Step: 4237...  Training loss: 1.8988...  0.0555 sec/batch
Epoch: 7/20...  Training Step: 4238...  Training loss: 1.8899...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4239...  Training loss: 1.8978...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 4240...  Training loss: 1.9029...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 4241...  Training loss: 1.9145...  0.0556 sec/batch
Epoch: 7/20...  Training Step: 4242...  Training loss: 1.8675...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 4243...  Training loss: 1.9127...  0.0559 sec/batch
Epoch: 7/20...  Training Step: 4244...  Training loss: 1.8155...  0.0571 sec/batch
Epoch: 7/20...  Training Step: 4245...  Training loss: 1.9222...  0.0575 sec/batch
Epoch: 7/20...  Training Step: 4246...  Training loss: 1.9646...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 4247...  Training loss: 1.9614...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4248...  Training loss: 1.9424...  0.0607 sec/batch
Epoch: 7/20...  Training Step: 4249...  Training loss: 1.9241...  0.0566 sec/batch
Epoch: 7/20...  Training Step: 4250...  Training loss: 1.8940...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4251...  Training loss: 1.9143...  0.0550 sec/batch
Epoch: 7/20...  Training Step: 4252...  Training loss: 1.8920...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 4253...  Training loss: 1.9114...  0.0593 sec/batch
Epoch: 7/20...  Training Step: 4254...  Training loss: 1.8975...  0.0633 sec/batch
Epoch: 7/20...  Training Step: 4255...  Training loss: 1.9187...  0.0544 sec/batch
Epoch: 7/20...  Training Step: 4256...  Training loss: 1.9441...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 4257...  Training loss: 1.8773...  0.0593 sec/batch
Epoch: 7/20...  Training Step: 4258...  Training loss: 1.9341...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 4259...  Training loss: 1.8618...  0.0525 sec/batch
Epoch: 7/20...  Training Step: 4260...  Training loss: 1.9402...  0.0560 sec/batch
Epoch: 7/20...  Training Step: 4261...  Training loss: 1.9327...  0.0568 sec/batch
Epoch: 7/20...  Training Step: 4262...  Training loss: 1.8759...  0.0547 sec/batch
Epoch: 7/20...  Training Step: 4263...  Training loss: 1.8802...  0.0546 sec/batch
Epoch: 7/20...  Training Step: 4264...  Training loss: 1.8837...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 4265...  Training loss: 1.9293...  0.0561 sec/batch
Epoch: 7/20...  Training Step: 4266...  Training loss: 1.9157...  0.0527 sec/batch
Epoch: 7/20...  Training Step: 4267...  Training loss: 1.9461...  0.0561 sec/batch
Epoch: 7/20...  Training Step: 4268...  Training loss: 1.9529...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4269...  Training loss: 1.9482...  0.0556 sec/batch
Epoch: 7/20...  Training Step: 4270...  Training loss: 1.9080...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4271...  Training loss: 1.9239...  0.0555 sec/batch
Epoch: 7/20...  Training Step: 4272...  Training loss: 1.8637...  0.0630 sec/batch
Epoch: 7/20...  Training Step: 4273...  Training loss: 1.9301...  0.0591 sec/batch
Epoch: 7/20...  Training Step: 4274...  Training loss: 1.9436...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 4275...  Training loss: 1.9022...  0.0526 sec/batch
Epoch: 7/20...  Training Step: 4276...  Training loss: 1.8851...  0.0549 sec/batch
Epoch: 7/20...  Training Step: 4277...  Training loss: 1.8913...  0.0594 sec/batch
Epoch: 7/20...  Training Step: 4278...  Training loss: 1.8699...  0.0565 sec/batch
Epoch: 7/20...  Training Step: 4279...  Training loss: 1.9220...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 4280...  Training loss: 1.9053...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4281...  Training loss: 1.9431...  0.0535 sec/batch
Epoch: 7/20...  Training Step: 4282...  Training loss: 1.9505...  0.0549 sec/batch
Epoch: 7/20...  Training Step: 4283...  Training loss: 1.9276...  0.0528 sec/batch
Epoch: 7/20...  Training Step: 4284...  Training loss: 1.9935...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 4285...  Training loss: 2.0177...  0.0558 sec/batch
Epoch: 7/20...  Training Step: 4286...  Training loss: 1.9631...  0.0549 sec/batch
Epoch: 7/20...  Training Step: 4287...  Training loss: 1.9266...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4288...  Training loss: 1.9712...  0.0552 sec/batch
Epoch: 7/20...  Training Step: 4289...  Training loss: 1.9029...  0.0566 sec/batch
Epoch: 7/20...  Training Step: 4290...  Training loss: 1.9210...  0.0564 sec/batch
Epoch: 7/20...  Training Step: 4291...  Training loss: 1.9228...  0.0576 sec/batch
Epoch: 7/20...  Training Step: 4292...  Training loss: 1.9798...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 4293...  Training loss: 1.9142...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 4294...  Training loss: 1.9038...  0.0555 sec/batch
Epoch: 7/20...  Training Step: 4295...  Training loss: 1.8989...  0.0526 sec/batch
Epoch: 7/20...  Training Step: 4296...  Training loss: 1.9540...  0.0526 sec/batch
Epoch: 7/20...  Training Step: 4297...  Training loss: 1.8836...  0.0552 sec/batch
Epoch: 7/20...  Training Step: 4298...  Training loss: 1.9362...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 4299...  Training loss: 1.9937...  0.0534 sec/batch
Epoch: 7/20...  Training Step: 4300...  Training loss: 1.9213...  0.0521 sec/batch
Epoch: 7/20...  Training Step: 4301...  Training loss: 1.9495...  0.0584 sec/batch
Epoch: 7/20...  Training Step: 4302...  Training loss: 1.9222...  0.0527 sec/batch
Epoch: 7/20...  Training Step: 4303...  Training loss: 1.9390...  0.0559 sec/batch
Epoch: 7/20...  Training Step: 4304...  Training loss: 1.9617...  0.0531 sec/batch
Epoch: 7/20...  Training Step: 4305...  Training loss: 1.9402...  0.0581 sec/batch
Epoch: 7/20...  Training Step: 4306...  Training loss: 1.9060...  0.0523 sec/batch
Epoch: 7/20...  Training Step: 4307...  Training loss: 1.8700...  0.0568 sec/batch
Epoch: 7/20...  Training Step: 4308...  Training loss: 1.9274...  0.0588 sec/batch
Epoch: 7/20...  Training Step: 4309...  Training loss: 1.8980...  0.0568 sec/batch
Epoch: 7/20...  Training Step: 4310...  Training loss: 1.9524...  0.0527 sec/batch
Epoch: 7/20...  Training Step: 4311...  Training loss: 1.8731...  0.0549 sec/batch
Epoch: 7/20...  Training Step: 4312...  Training loss: 1.9576...  0.0533 sec/batch
Epoch: 7/20...  Training Step: 4313...  Training loss: 1.8981...  0.0583 sec/batch
Epoch: 7/20...  Training Step: 4314...  Training loss: 1.9031...  0.0548 sec/batch
Epoch: 7/20...  Training Step: 4315...  Training loss: 1.9003...  0.0588 sec/batch
Epoch: 7/20...  Training Step: 4316...  Training loss: 1.8917...  0.0549 sec/batch
Epoch: 7/20...  Training Step: 4317...  Training loss: 1.8610...  0.0588 sec/batch
Epoch: 7/20...  Training Step: 4318...  Training loss: 1.9117...  0.0565 sec/batch
Epoch: 7/20...  Training Step: 4319...  Training loss: 1.9062...  0.0586 sec/batch
Epoch: 7/20...  Training Step: 4320...  Training loss: 1.9298...  0.0560 sec/batch
Epoch: 7/20...  Training Step: 4321...  Training loss: 1.9248...  0.0527 sec/batch
Epoch: 7/20...  Training Step: 4322...  Training loss: 1.9206...  0.0527 sec/batch
Epoch: 7/20...  Training Step: 4323...  Training loss: 1.9193...  0.0578 sec/batch
Epoch: 7/20...  Training Step: 4324...  Training loss: 1.8825...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4325...  Training loss: 1.9169...  0.0560 sec/batch
Epoch: 7/20...  Training Step: 4326...  Training loss: 1.9070...  0.0532 sec/batch
Epoch: 7/20...  Training Step: 4327...  Training loss: 1.8735...  0.0595 sec/batch
Epoch: 7/20...  Training Step: 4328...  Training loss: 1.9116...  0.0530 sec/batch
Epoch: 7/20...  Training Step: 4329...  Training loss: 1.8968...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 4330...  Training loss: 1.9740...  0.0554 sec/batch
Epoch: 7/20...  Training Step: 4331...  Training loss: 1.9415...  0.0556 sec/batch
Epoch: 7/20...  Training Step: 4332...  Training loss: 1.9347...  0.0598 sec/batch
Epoch: 7/20...  Training Step: 4333...  Training loss: 1.8834...  0.0529 sec/batch
Epoch: 7/20...  Training Step: 4334...  Training loss: 1.9050...  0.0548 sec/batch
Epoch: 7/20...  Training Step: 4335...  Training loss: 1.8720...  0.0557 sec/batch
Epoch: 7/20...  Training Step: 4336...  Training loss: 1.9348...  0.0553 sec/batch
Epoch: 7/20...  Training Step: 4337...  Training loss: 1.9359...  0.0560 sec/batch
Epoch: 7/20...  Training Step: 4338...  Training loss: 1.8853...  0.0563 sec/batch
Epoch: 7/20...  Training Step: 4339...  Training loss: 1.8761...  0.0548 sec/batch
Epoch: 7/20...  Training Step: 4340...  Training loss: 1.8636...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4341...  Training loss: 1.9933...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4342...  Training loss: 1.9805...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4343...  Training loss: 1.9637...  0.0575 sec/batch
Epoch: 8/20...  Training Step: 4344...  Training loss: 1.8671...  0.0542 sec/batch
Epoch: 8/20...  Training Step: 4345...  Training loss: 1.9032...  0.0535 sec/batch
Epoch: 8/20...  Training Step: 4346...  Training loss: 1.9385...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4347...  Training loss: 1.8912...  0.0555 sec/batch
Epoch: 8/20...  Training Step: 4348...  Training loss: 1.8802...  0.0548 sec/batch
Epoch: 8/20...  Training Step: 4349...  Training loss: 1.8693...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4350...  Training loss: 1.8869...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4351...  Training loss: 1.9060...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4352...  Training loss: 1.8571...  0.0523 sec/batch
Epoch: 8/20...  Training Step: 4353...  Training loss: 1.9328...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4354...  Training loss: 1.9051...  0.0581 sec/batch
Epoch: 8/20...  Training Step: 4355...  Training loss: 1.9316...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4356...  Training loss: 1.9462...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4357...  Training loss: 1.9328...  0.0533 sec/batch
Epoch: 8/20...  Training Step: 4358...  Training loss: 1.9129...  0.0555 sec/batch
Epoch: 8/20...  Training Step: 4359...  Training loss: 1.8613...  0.0554 sec/batch
Epoch: 8/20...  Training Step: 4360...  Training loss: 1.9212...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4361...  Training loss: 1.9587...  0.0614 sec/batch
Epoch: 8/20...  Training Step: 4362...  Training loss: 1.8970...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4363...  Training loss: 1.8762...  0.0524 sec/batch
Epoch: 8/20...  Training Step: 4364...  Training loss: 1.9322...  0.0564 sec/batch
Epoch: 8/20...  Training Step: 4365...  Training loss: 1.8819...  0.0541 sec/batch
Epoch: 8/20...  Training Step: 4366...  Training loss: 1.8748...  0.0535 sec/batch
Epoch: 8/20...  Training Step: 4367...  Training loss: 1.9118...  0.0536 sec/batch
Epoch: 8/20...  Training Step: 4368...  Training loss: 1.9167...  0.0527 sec/batch
Epoch: 8/20...  Training Step: 4369...  Training loss: 1.9226...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4370...  Training loss: 1.8786...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4371...  Training loss: 1.8690...  0.0555 sec/batch
Epoch: 8/20...  Training Step: 4372...  Training loss: 1.9238...  0.0524 sec/batch
Epoch: 8/20...  Training Step: 4373...  Training loss: 1.8959...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4374...  Training loss: 1.8814...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4375...  Training loss: 1.9180...  0.0558 sec/batch
Epoch: 8/20...  Training Step: 4376...  Training loss: 1.9022...  0.0588 sec/batch
Epoch: 8/20...  Training Step: 4377...  Training loss: 1.8900...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4378...  Training loss: 1.9276...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4379...  Training loss: 1.9161...  0.0567 sec/batch
Epoch: 8/20...  Training Step: 4380...  Training loss: 1.8664...  0.0555 sec/batch
Epoch: 8/20...  Training Step: 4381...  Training loss: 1.8925...  0.0547 sec/batch
Epoch: 8/20...  Training Step: 4382...  Training loss: 1.9256...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4383...  Training loss: 1.9026...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4384...  Training loss: 1.9254...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4385...  Training loss: 1.8930...  0.0527 sec/batch
Epoch: 8/20...  Training Step: 4386...  Training loss: 1.8933...  0.0558 sec/batch
Epoch: 8/20...  Training Step: 4387...  Training loss: 1.7642...  0.0554 sec/batch
Epoch: 8/20...  Training Step: 4388...  Training loss: 1.9205...  0.0535 sec/batch
Epoch: 8/20...  Training Step: 4389...  Training loss: 1.8826...  0.0606 sec/batch
Epoch: 8/20...  Training Step: 4390...  Training loss: 1.8989...  0.0586 sec/batch
Epoch: 8/20...  Training Step: 4391...  Training loss: 1.8696...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4392...  Training loss: 1.8816...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4393...  Training loss: 1.9095...  0.0571 sec/batch
Epoch: 8/20...  Training Step: 4394...  Training loss: 1.9391...  0.0554 sec/batch
Epoch: 8/20...  Training Step: 4395...  Training loss: 1.9238...  0.0569 sec/batch
Epoch: 8/20...  Training Step: 4396...  Training loss: 1.9065...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4397...  Training loss: 1.8666...  0.0581 sec/batch
Epoch: 8/20...  Training Step: 4398...  Training loss: 1.9063...  0.0602 sec/batch
Epoch: 8/20...  Training Step: 4399...  Training loss: 1.8955...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4400...  Training loss: 1.9346...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4401...  Training loss: 1.9108...  0.0594 sec/batch
Epoch: 8/20...  Training Step: 4402...  Training loss: 1.8865...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4403...  Training loss: 1.9047...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4404...  Training loss: 1.9042...  0.0589 sec/batch
Epoch: 8/20...  Training Step: 4405...  Training loss: 1.8751...  0.0554 sec/batch
Epoch: 8/20...  Training Step: 4406...  Training loss: 1.8489...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4407...  Training loss: 1.8685...  0.0544 sec/batch
Epoch: 8/20...  Training Step: 4408...  Training loss: 1.8759...  0.0560 sec/batch
Epoch: 8/20...  Training Step: 4409...  Training loss: 1.9266...  0.0565 sec/batch
Epoch: 8/20...  Training Step: 4410...  Training loss: 1.9049...  0.0581 sec/batch
Epoch: 8/20...  Training Step: 4411...  Training loss: 1.9309...  0.0599 sec/batch
Epoch: 8/20...  Training Step: 4412...  Training loss: 1.9115...  0.0548 sec/batch
Epoch: 8/20...  Training Step: 4413...  Training loss: 1.8474...  0.0562 sec/batch
Epoch: 8/20...  Training Step: 4414...  Training loss: 1.8941...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4415...  Training loss: 1.9399...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4416...  Training loss: 1.9118...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4417...  Training loss: 1.9138...  0.0567 sec/batch
Epoch: 8/20...  Training Step: 4418...  Training loss: 1.8844...  0.0554 sec/batch
Epoch: 8/20...  Training Step: 4419...  Training loss: 1.9177...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4420...  Training loss: 1.9315...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4421...  Training loss: 1.8559...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4422...  Training loss: 1.9037...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4423...  Training loss: 1.8460...  0.0536 sec/batch
Epoch: 8/20...  Training Step: 4424...  Training loss: 1.8704...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4425...  Training loss: 1.8934...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4426...  Training loss: 1.9460...  0.0565 sec/batch
Epoch: 8/20...  Training Step: 4427...  Training loss: 1.8549...  0.0557 sec/batch
Epoch: 8/20...  Training Step: 4428...  Training loss: 1.9600...  0.0562 sec/batch
Epoch: 8/20...  Training Step: 4429...  Training loss: 1.9089...  0.0534 sec/batch
Epoch: 8/20...  Training Step: 4430...  Training loss: 1.9217...  0.0580 sec/batch
Epoch: 8/20...  Training Step: 4431...  Training loss: 1.8851...  0.0580 sec/batch
Epoch: 8/20...  Training Step: 4432...  Training loss: 1.9511...  0.0546 sec/batch
Epoch: 8/20...  Training Step: 4433...  Training loss: 1.8971...  0.0592 sec/batch
Epoch: 8/20...  Training Step: 4434...  Training loss: 1.8905...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4435...  Training loss: 1.9016...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4436...  Training loss: 1.9338...  0.0591 sec/batch
Epoch: 8/20...  Training Step: 4437...  Training loss: 1.9215...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4438...  Training loss: 1.8368...  0.0563 sec/batch
Epoch: 8/20...  Training Step: 4439...  Training loss: 1.9552...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4440...  Training loss: 1.8846...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4441...  Training loss: 1.8873...  0.0560 sec/batch
Epoch: 8/20...  Training Step: 4442...  Training loss: 1.8919...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4443...  Training loss: 1.9230...  0.0554 sec/batch
Epoch: 8/20...  Training Step: 4444...  Training loss: 1.9357...  0.0573 sec/batch
Epoch: 8/20...  Training Step: 4445...  Training loss: 1.8857...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4446...  Training loss: 1.8561...  0.0596 sec/batch
Epoch: 8/20...  Training Step: 4447...  Training loss: 1.9197...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4448...  Training loss: 1.8887...  0.0588 sec/batch
Epoch: 8/20...  Training Step: 4449...  Training loss: 1.8896...  0.0575 sec/batch
Epoch: 8/20...  Training Step: 4450...  Training loss: 1.8842...  0.0557 sec/batch
Epoch: 8/20...  Training Step: 4451...  Training loss: 1.8502...  0.0533 sec/batch
Epoch: 8/20...  Training Step: 4452...  Training loss: 1.8848...  0.0522 sec/batch
Epoch: 8/20...  Training Step: 4453...  Training loss: 1.8800...  0.0571 sec/batch
Epoch: 8/20...  Training Step: 4454...  Training loss: 1.8828...  0.0534 sec/batch
Epoch: 8/20...  Training Step: 4455...  Training loss: 1.9301...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4456...  Training loss: 1.9273...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4457...  Training loss: 1.8692...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4458...  Training loss: 1.9200...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4459...  Training loss: 1.8844...  0.0578 sec/batch
Epoch: 8/20...  Training Step: 4460...  Training loss: 1.8878...  0.0558 sec/batch
Epoch: 8/20...  Training Step: 4461...  Training loss: 1.8727...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4462...  Training loss: 1.8531...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4463...  Training loss: 1.8772...  0.0557 sec/batch
Epoch: 8/20...  Training Step: 4464...  Training loss: 1.9202...  0.0623 sec/batch
Epoch: 8/20...  Training Step: 4465...  Training loss: 1.9119...  0.0555 sec/batch
Epoch: 8/20...  Training Step: 4466...  Training loss: 1.9354...  0.0547 sec/batch
Epoch: 8/20...  Training Step: 4467...  Training loss: 1.9483...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4468...  Training loss: 1.8367...  0.0594 sec/batch
Epoch: 8/20...  Training Step: 4469...  Training loss: 1.8910...  0.0560 sec/batch
Epoch: 8/20...  Training Step: 4470...  Training loss: 1.9569...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4471...  Training loss: 1.8945...  0.0559 sec/batch
Epoch: 8/20...  Training Step: 4472...  Training loss: 1.9432...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4473...  Training loss: 1.9284...  0.0523 sec/batch
Epoch: 8/20...  Training Step: 4474...  Training loss: 1.8884...  0.0586 sec/batch
Epoch: 8/20...  Training Step: 4475...  Training loss: 1.8683...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4476...  Training loss: 1.8788...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4477...  Training loss: 1.8726...  0.0600 sec/batch
Epoch: 8/20...  Training Step: 4478...  Training loss: 1.9008...  0.0542 sec/batch
Epoch: 8/20...  Training Step: 4479...  Training loss: 1.9445...  0.0579 sec/batch
Epoch: 8/20...  Training Step: 4480...  Training loss: 1.8948...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4481...  Training loss: 1.9223...  0.0535 sec/batch
Epoch: 8/20...  Training Step: 4482...  Training loss: 1.8254...  0.0568 sec/batch
Epoch: 8/20...  Training Step: 4483...  Training loss: 1.9006...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4484...  Training loss: 1.8841...  0.0604 sec/batch
Epoch: 8/20...  Training Step: 4485...  Training loss: 1.8440...  0.0535 sec/batch
Epoch: 8/20...  Training Step: 4486...  Training loss: 1.9480...  0.0527 sec/batch
Epoch: 8/20...  Training Step: 4487...  Training loss: 1.9063...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4488...  Training loss: 1.9008...  0.0598 sec/batch
Epoch: 8/20...  Training Step: 4489...  Training loss: 1.9016...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4490...  Training loss: 1.9210...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4491...  Training loss: 1.9141...  0.0523 sec/batch
Epoch: 8/20...  Training Step: 4492...  Training loss: 1.8880...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4493...  Training loss: 1.8883...  0.0569 sec/batch
Epoch: 8/20...  Training Step: 4494...  Training loss: 1.9371...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4495...  Training loss: 1.8828...  0.0523 sec/batch
Epoch: 8/20...  Training Step: 4496...  Training loss: 1.9023...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4497...  Training loss: 1.8823...  0.0522 sec/batch
Epoch: 8/20...  Training Step: 4498...  Training loss: 1.9254...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4499...  Training loss: 1.9152...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4500...  Training loss: 1.8619...  0.0590 sec/batch
Epoch: 8/20...  Training Step: 4501...  Training loss: 1.8488...  0.0543 sec/batch
Epoch: 8/20...  Training Step: 4502...  Training loss: 1.8683...  0.0591 sec/batch
Epoch: 8/20...  Training Step: 4503...  Training loss: 1.9044...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4504...  Training loss: 1.8960...  0.0566 sec/batch
Epoch: 8/20...  Training Step: 4505...  Training loss: 1.8992...  0.0543 sec/batch
Epoch: 8/20...  Training Step: 4506...  Training loss: 1.9119...  0.0543 sec/batch
Epoch: 8/20...  Training Step: 4507...  Training loss: 1.9349...  0.0568 sec/batch
Epoch: 8/20...  Training Step: 4508...  Training loss: 1.8990...  0.0591 sec/batch
Epoch: 8/20...  Training Step: 4509...  Training loss: 1.8811...  0.0544 sec/batch
Epoch: 8/20...  Training Step: 4510...  Training loss: 1.8464...  0.0598 sec/batch
Epoch: 8/20...  Training Step: 4511...  Training loss: 1.8709...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4512...  Training loss: 1.9029...  0.0583 sec/batch
Epoch: 8/20...  Training Step: 4513...  Training loss: 1.8877...  0.0533 sec/batch
Epoch: 8/20...  Training Step: 4514...  Training loss: 1.9006...  0.0559 sec/batch
Epoch: 8/20...  Training Step: 4515...  Training loss: 1.8670...  0.0564 sec/batch
Epoch: 8/20...  Training Step: 4516...  Training loss: 1.8947...  0.0561 sec/batch
Epoch: 8/20...  Training Step: 4517...  Training loss: 1.8953...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4518...  Training loss: 1.8885...  0.0617 sec/batch
Epoch: 8/20...  Training Step: 4519...  Training loss: 1.8845...  0.0542 sec/batch
Epoch: 8/20...  Training Step: 4520...  Training loss: 1.8744...  0.0587 sec/batch
Epoch: 8/20...  Training Step: 4521...  Training loss: 1.8855...  0.0540 sec/batch
Epoch: 8/20...  Training Step: 4522...  Training loss: 1.9146...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4523...  Training loss: 1.8994...  0.0564 sec/batch
Epoch: 8/20...  Training Step: 4524...  Training loss: 1.8553...  0.0560 sec/batch
Epoch: 8/20...  Training Step: 4525...  Training loss: 1.8536...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4526...  Training loss: 1.8931...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4527...  Training loss: 1.8949...  0.0565 sec/batch
Epoch: 8/20...  Training Step: 4528...  Training loss: 1.8888...  0.0571 sec/batch
Epoch: 8/20...  Training Step: 4529...  Training loss: 1.8795...  0.0563 sec/batch
Epoch: 8/20...  Training Step: 4530...  Training loss: 1.9605...  0.0566 sec/batch
Epoch: 8/20...  Training Step: 4531...  Training loss: 1.8996...  0.0583 sec/batch
Epoch: 8/20...  Training Step: 4532...  Training loss: 1.9432...  0.0536 sec/batch
Epoch: 8/20...  Training Step: 4533...  Training loss: 1.9323...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4534...  Training loss: 1.8691...  0.0598 sec/batch
Epoch: 8/20...  Training Step: 4535...  Training loss: 1.9007...  0.0564 sec/batch
Epoch: 8/20...  Training Step: 4536...  Training loss: 1.9661...  0.0592 sec/batch
Epoch: 8/20...  Training Step: 4537...  Training loss: 1.8809...  0.0546 sec/batch
Epoch: 8/20...  Training Step: 4538...  Training loss: 1.9562...  0.0577 sec/batch
Epoch: 8/20...  Training Step: 4539...  Training loss: 1.8547...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4540...  Training loss: 1.9157...  0.0597 sec/batch
Epoch: 8/20...  Training Step: 4541...  Training loss: 1.8861...  0.0617 sec/batch
Epoch: 8/20...  Training Step: 4542...  Training loss: 1.8873...  0.0534 sec/batch
Epoch: 8/20...  Training Step: 4543...  Training loss: 1.8863...  0.0554 sec/batch
Epoch: 8/20...  Training Step: 4544...  Training loss: 1.8948...  0.0590 sec/batch
Epoch: 8/20...  Training Step: 4545...  Training loss: 1.9088...  0.0557 sec/batch
Epoch: 8/20...  Training Step: 4546...  Training loss: 1.8726...  0.0591 sec/batch
Epoch: 8/20...  Training Step: 4547...  Training loss: 1.9123...  0.0588 sec/batch
Epoch: 8/20...  Training Step: 4548...  Training loss: 1.8801...  0.0563 sec/batch
Epoch: 8/20...  Training Step: 4549...  Training loss: 1.8868...  0.0565 sec/batch
Epoch: 8/20...  Training Step: 4550...  Training loss: 1.8594...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4551...  Training loss: 1.8936...  0.0569 sec/batch
Epoch: 8/20...  Training Step: 4552...  Training loss: 1.9078...  0.0565 sec/batch
Epoch: 8/20...  Training Step: 4553...  Training loss: 1.9421...  0.0574 sec/batch
Epoch: 8/20...  Training Step: 4554...  Training loss: 1.9428...  0.0593 sec/batch
Epoch: 8/20...  Training Step: 4555...  Training loss: 1.9289...  0.0572 sec/batch
Epoch: 8/20...  Training Step: 4556...  Training loss: 1.9199...  0.0539 sec/batch
Epoch: 8/20...  Training Step: 4557...  Training loss: 1.9016...  0.0642 sec/batch
Epoch: 8/20...  Training Step: 4558...  Training loss: 1.8777...  0.0536 sec/batch
Epoch: 8/20...  Training Step: 4559...  Training loss: 1.9806...  0.0538 sec/batch
Epoch: 8/20...  Training Step: 4560...  Training loss: 1.9445...  0.0598 sec/batch
Epoch: 8/20...  Training Step: 4561...  Training loss: 1.9100...  0.0578 sec/batch
Epoch: 8/20...  Training Step: 4562...  Training loss: 1.9256...  0.0559 sec/batch
Epoch: 8/20...  Training Step: 4563...  Training loss: 1.9457...  0.0548 sec/batch
Epoch: 8/20...  Training Step: 4564...  Training loss: 1.8522...  0.0570 sec/batch
Epoch: 8/20...  Training Step: 4565...  Training loss: 1.8830...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4566...  Training loss: 1.9391...  0.0535 sec/batch
Epoch: 8/20...  Training Step: 4567...  Training loss: 1.9642...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4568...  Training loss: 1.8650...  0.0547 sec/batch
Epoch: 8/20...  Training Step: 4569...  Training loss: 1.9194...  0.0566 sec/batch
Epoch: 8/20...  Training Step: 4570...  Training loss: 1.8858...  0.0600 sec/batch
Epoch: 8/20...  Training Step: 4571...  Training loss: 1.9435...  0.0565 sec/batch
Epoch: 8/20...  Training Step: 4572...  Training loss: 1.8743...  0.0533 sec/batch
Epoch: 8/20...  Training Step: 4573...  Training loss: 1.8743...  0.0567 sec/batch
Epoch: 8/20...  Training Step: 4574...  Training loss: 1.8706...  0.0546 sec/batch
Epoch: 8/20...  Training Step: 4575...  Training loss: 1.8594...  0.0558 sec/batch
Epoch: 8/20...  Training Step: 4576...  Training loss: 1.9354...  0.0586 sec/batch
Epoch: 8/20...  Training Step: 4577...  Training loss: 1.8951...  0.0593 sec/batch
Epoch: 8/20...  Training Step: 4578...  Training loss: 1.8539...  0.0590 sec/batch
Epoch: 8/20...  Training Step: 4579...  Training loss: 1.8598...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4580...  Training loss: 1.9056...  0.0533 sec/batch
Epoch: 8/20...  Training Step: 4581...  Training loss: 1.8718...  0.0567 sec/batch
Epoch: 8/20...  Training Step: 4582...  Training loss: 1.8861...  0.0560 sec/batch
Epoch: 8/20...  Training Step: 4583...  Training loss: 1.8611...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4584...  Training loss: 1.8938...  0.0571 sec/batch
Epoch: 8/20...  Training Step: 4585...  Training loss: 1.9021...  0.0590 sec/batch
Epoch: 8/20...  Training Step: 4586...  Training loss: 1.8945...  0.0558 sec/batch
Epoch: 8/20...  Training Step: 4587...  Training loss: 1.8973...  0.0598 sec/batch
Epoch: 8/20...  Training Step: 4588...  Training loss: 1.9054...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4589...  Training loss: 1.8488...  0.0579 sec/batch
Epoch: 8/20...  Training Step: 4590...  Training loss: 1.8676...  0.0618 sec/batch
Epoch: 8/20...  Training Step: 4591...  Training loss: 1.8937...  0.0546 sec/batch
Epoch: 8/20...  Training Step: 4592...  Training loss: 1.8717...  0.0557 sec/batch
Epoch: 8/20...  Training Step: 4593...  Training loss: 1.9025...  0.0535 sec/batch
Epoch: 8/20...  Training Step: 4594...  Training loss: 1.9174...  0.0546 sec/batch
Epoch: 8/20...  Training Step: 4595...  Training loss: 1.9458...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4596...  Training loss: 1.9195...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4597...  Training loss: 1.8909...  0.0591 sec/batch
Epoch: 8/20...  Training Step: 4598...  Training loss: 1.8875...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4599...  Training loss: 1.8897...  0.0533 sec/batch
Epoch: 8/20...  Training Step: 4600...  Training loss: 1.8874...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4601...  Training loss: 1.9009...  0.0612 sec/batch
Epoch: 8/20...  Training Step: 4602...  Training loss: 1.8535...  0.0537 sec/batch
Epoch: 8/20...  Training Step: 4603...  Training loss: 1.9107...  0.0586 sec/batch
Epoch: 8/20...  Training Step: 4604...  Training loss: 1.9076...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4605...  Training loss: 1.9467...  0.0542 sec/batch
Epoch: 8/20...  Training Step: 4606...  Training loss: 1.8207...  0.0596 sec/batch
Epoch: 8/20...  Training Step: 4607...  Training loss: 1.9034...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4608...  Training loss: 1.9009...  0.0533 sec/batch
Epoch: 8/20...  Training Step: 4609...  Training loss: 1.8750...  0.0543 sec/batch
Epoch: 8/20...  Training Step: 4610...  Training loss: 1.8729...  0.0536 sec/batch
Epoch: 8/20...  Training Step: 4611...  Training loss: 1.8489...  0.0536 sec/batch
Epoch: 8/20...  Training Step: 4612...  Training loss: 1.8989...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4613...  Training loss: 1.8588...  0.0608 sec/batch
Epoch: 8/20...  Training Step: 4614...  Training loss: 1.8819...  0.0534 sec/batch
Epoch: 8/20...  Training Step: 4615...  Training loss: 1.9144...  0.0605 sec/batch
Epoch: 8/20...  Training Step: 4616...  Training loss: 1.9442...  0.0569 sec/batch
Epoch: 8/20...  Training Step: 4617...  Training loss: 1.9641...  0.0542 sec/batch
Epoch: 8/20...  Training Step: 4618...  Training loss: 1.9113...  0.0600 sec/batch
Epoch: 8/20...  Training Step: 4619...  Training loss: 1.9396...  0.0537 sec/batch
Epoch: 8/20...  Training Step: 4620...  Training loss: 1.9403...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4621...  Training loss: 1.8917...  0.0562 sec/batch
Epoch: 8/20...  Training Step: 4622...  Training loss: 1.8612...  0.0537 sec/batch
Epoch: 8/20...  Training Step: 4623...  Training loss: 1.8662...  0.0562 sec/batch
Epoch: 8/20...  Training Step: 4624...  Training loss: 1.9032...  0.0557 sec/batch
Epoch: 8/20...  Training Step: 4625...  Training loss: 1.8772...  0.0537 sec/batch
Epoch: 8/20...  Training Step: 4626...  Training loss: 1.8993...  0.0565 sec/batch
Epoch: 8/20...  Training Step: 4627...  Training loss: 1.8682...  0.0559 sec/batch
Epoch: 8/20...  Training Step: 4628...  Training loss: 1.8902...  0.0527 sec/batch
Epoch: 8/20...  Training Step: 4629...  Training loss: 1.8919...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4630...  Training loss: 1.9266...  0.0591 sec/batch
Epoch: 8/20...  Training Step: 4631...  Training loss: 1.8882...  0.0578 sec/batch
Epoch: 8/20...  Training Step: 4632...  Training loss: 1.8856...  0.0587 sec/batch
Epoch: 8/20...  Training Step: 4633...  Training loss: 1.8829...  0.0548 sec/batch
Epoch: 8/20...  Training Step: 4634...  Training loss: 1.9086...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4635...  Training loss: 1.8827...  0.0567 sec/batch
Epoch: 8/20...  Training Step: 4636...  Training loss: 1.8297...  0.0576 sec/batch
Epoch: 8/20...  Training Step: 4637...  Training loss: 1.9060...  0.0537 sec/batch
Epoch: 8/20...  Training Step: 4638...  Training loss: 1.9364...  0.0562 sec/batch
Epoch: 8/20...  Training Step: 4639...  Training loss: 1.9409...  0.0572 sec/batch
Epoch: 8/20...  Training Step: 4640...  Training loss: 1.9158...  0.0561 sec/batch
Epoch: 8/20...  Training Step: 4641...  Training loss: 1.9160...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4642...  Training loss: 1.9610...  0.0574 sec/batch
Epoch: 8/20...  Training Step: 4643...  Training loss: 1.8425...  0.0559 sec/batch
Epoch: 8/20...  Training Step: 4644...  Training loss: 1.9113...  0.0533 sec/batch
Epoch: 8/20...  Training Step: 4645...  Training loss: 1.8982...  0.0536 sec/batch
Epoch: 8/20...  Training Step: 4646...  Training loss: 1.8861...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4647...  Training loss: 1.8878...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4648...  Training loss: 1.8725...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4649...  Training loss: 1.8811...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4650...  Training loss: 1.8568...  0.0564 sec/batch
Epoch: 8/20...  Training Step: 4651...  Training loss: 1.8540...  0.0567 sec/batch
Epoch: 8/20...  Training Step: 4652...  Training loss: 1.8743...  0.0565 sec/batch
Epoch: 8/20...  Training Step: 4653...  Training loss: 1.8894...  0.0533 sec/batch
Epoch: 8/20...  Training Step: 4654...  Training loss: 1.8518...  0.0548 sec/batch
Epoch: 8/20...  Training Step: 4655...  Training loss: 1.8865...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4656...  Training loss: 1.9040...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4657...  Training loss: 1.8587...  0.0560 sec/batch
Epoch: 8/20...  Training Step: 4658...  Training loss: 1.8374...  0.0590 sec/batch
Epoch: 8/20...  Training Step: 4659...  Training loss: 1.8783...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4660...  Training loss: 1.9352...  0.0546 sec/batch
Epoch: 8/20...  Training Step: 4661...  Training loss: 1.8819...  0.0537 sec/batch
Epoch: 8/20...  Training Step: 4662...  Training loss: 1.8507...  0.0523 sec/batch
Epoch: 8/20...  Training Step: 4663...  Training loss: 1.8810...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4664...  Training loss: 1.8859...  0.0546 sec/batch
Epoch: 8/20...  Training Step: 4665...  Training loss: 1.8608...  0.0557 sec/batch
Epoch: 8/20...  Training Step: 4666...  Training loss: 1.8619...  0.0555 sec/batch
Epoch: 8/20...  Training Step: 4667...  Training loss: 1.8406...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4668...  Training loss: 1.8434...  0.0559 sec/batch
Epoch: 8/20...  Training Step: 4669...  Training loss: 1.8902...  0.0535 sec/batch
Epoch: 8/20...  Training Step: 4670...  Training loss: 1.8917...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4671...  Training loss: 1.8835...  0.0579 sec/batch
Epoch: 8/20...  Training Step: 4672...  Training loss: 1.8684...  0.0631 sec/batch
Epoch: 8/20...  Training Step: 4673...  Training loss: 1.8553...  0.0554 sec/batch
Epoch: 8/20...  Training Step: 4674...  Training loss: 1.8672...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4675...  Training loss: 1.8741...  0.0520 sec/batch
Epoch: 8/20...  Training Step: 4676...  Training loss: 1.8777...  0.0547 sec/batch
Epoch: 8/20...  Training Step: 4677...  Training loss: 1.8511...  0.0593 sec/batch
Epoch: 8/20...  Training Step: 4678...  Training loss: 1.8504...  0.0544 sec/batch
Epoch: 8/20...  Training Step: 4679...  Training loss: 1.8552...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4680...  Training loss: 1.8882...  0.0527 sec/batch
Epoch: 8/20...  Training Step: 4681...  Training loss: 1.8905...  0.0548 sec/batch
Epoch: 8/20...  Training Step: 4682...  Training loss: 1.8772...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4683...  Training loss: 1.8628...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4684...  Training loss: 1.8688...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4685...  Training loss: 1.8771...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4686...  Training loss: 1.8946...  0.0565 sec/batch
Epoch: 8/20...  Training Step: 4687...  Training loss: 1.8947...  0.0548 sec/batch
Epoch: 8/20...  Training Step: 4688...  Training loss: 1.8894...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4689...  Training loss: 1.8807...  0.0527 sec/batch
Epoch: 8/20...  Training Step: 4690...  Training loss: 1.8692...  0.0545 sec/batch
Epoch: 8/20...  Training Step: 4691...  Training loss: 1.8967...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4692...  Training loss: 1.8857...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4693...  Training loss: 1.9110...  0.0578 sec/batch
Epoch: 8/20...  Training Step: 4694...  Training loss: 1.8563...  0.0544 sec/batch
Epoch: 8/20...  Training Step: 4695...  Training loss: 1.8595...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4696...  Training loss: 1.9199...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4697...  Training loss: 1.9734...  0.0533 sec/batch
Epoch: 8/20...  Training Step: 4698...  Training loss: 1.9247...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4699...  Training loss: 1.8989...  0.0558 sec/batch
Epoch: 8/20...  Training Step: 4700...  Training loss: 1.8992...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4701...  Training loss: 1.9298...  0.0535 sec/batch
Epoch: 8/20...  Training Step: 4702...  Training loss: 1.8651...  0.0575 sec/batch
Epoch: 8/20...  Training Step: 4703...  Training loss: 1.8357...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4704...  Training loss: 1.8206...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4705...  Training loss: 1.8761...  0.0559 sec/batch
Epoch: 8/20...  Training Step: 4706...  Training loss: 1.8932...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4707...  Training loss: 1.8693...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4708...  Training loss: 1.9434...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4709...  Training loss: 1.9200...  0.0559 sec/batch
Epoch: 8/20...  Training Step: 4710...  Training loss: 1.8765...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4711...  Training loss: 1.9110...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4712...  Training loss: 1.9632...  0.0584 sec/batch
Epoch: 8/20...  Training Step: 4713...  Training loss: 1.8851...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4714...  Training loss: 1.8821...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4715...  Training loss: 1.8683...  0.0566 sec/batch
Epoch: 8/20...  Training Step: 4716...  Training loss: 1.8857...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4717...  Training loss: 1.8474...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4718...  Training loss: 1.9637...  0.0546 sec/batch
Epoch: 8/20...  Training Step: 4719...  Training loss: 1.8966...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4720...  Training loss: 1.8982...  0.0579 sec/batch
Epoch: 8/20...  Training Step: 4721...  Training loss: 1.8110...  0.0588 sec/batch
Epoch: 8/20...  Training Step: 4722...  Training loss: 1.9517...  0.0524 sec/batch
Epoch: 8/20...  Training Step: 4723...  Training loss: 1.8530...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4724...  Training loss: 1.8823...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4725...  Training loss: 1.8836...  0.0546 sec/batch
Epoch: 8/20...  Training Step: 4726...  Training loss: 1.8154...  0.0583 sec/batch
Epoch: 8/20...  Training Step: 4727...  Training loss: 1.8040...  0.0579 sec/batch
Epoch: 8/20...  Training Step: 4728...  Training loss: 1.8852...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4729...  Training loss: 1.8460...  0.0573 sec/batch
Epoch: 8/20...  Training Step: 4730...  Training loss: 1.8502...  0.0578 sec/batch
Epoch: 8/20...  Training Step: 4731...  Training loss: 1.9258...  0.0578 sec/batch
Epoch: 8/20...  Training Step: 4732...  Training loss: 1.8467...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4733...  Training loss: 1.8856...  0.0591 sec/batch
Epoch: 8/20...  Training Step: 4734...  Training loss: 1.8818...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4735...  Training loss: 1.8605...  0.0545 sec/batch
Epoch: 8/20...  Training Step: 4736...  Training loss: 1.8814...  0.0585 sec/batch
Epoch: 8/20...  Training Step: 4737...  Training loss: 1.8655...  0.0568 sec/batch
Epoch: 8/20...  Training Step: 4738...  Training loss: 1.8917...  0.0589 sec/batch
Epoch: 8/20...  Training Step: 4739...  Training loss: 1.8675...  0.0524 sec/batch
Epoch: 8/20...  Training Step: 4740...  Training loss: 1.8971...  0.0534 sec/batch
Epoch: 8/20...  Training Step: 4741...  Training loss: 1.9280...  0.0555 sec/batch
Epoch: 8/20...  Training Step: 4742...  Training loss: 1.8976...  0.0533 sec/batch
Epoch: 8/20...  Training Step: 4743...  Training loss: 1.8532...  0.0608 sec/batch
Epoch: 8/20...  Training Step: 4744...  Training loss: 1.9133...  0.0587 sec/batch
Epoch: 8/20...  Training Step: 4745...  Training loss: 1.9342...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4746...  Training loss: 1.9142...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4747...  Training loss: 1.9387...  0.0534 sec/batch
Epoch: 8/20...  Training Step: 4748...  Training loss: 1.8865...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4749...  Training loss: 1.9489...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4750...  Training loss: 1.9030...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4751...  Training loss: 1.8879...  0.0575 sec/batch
Epoch: 8/20...  Training Step: 4752...  Training loss: 1.9335...  0.0558 sec/batch
Epoch: 8/20...  Training Step: 4753...  Training loss: 1.9078...  0.0527 sec/batch
Epoch: 8/20...  Training Step: 4754...  Training loss: 1.8631...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4755...  Training loss: 1.8580...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4756...  Training loss: 1.8439...  0.0557 sec/batch
Epoch: 8/20...  Training Step: 4757...  Training loss: 1.8646...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4758...  Training loss: 1.8828...  0.0533 sec/batch
Epoch: 8/20...  Training Step: 4759...  Training loss: 1.9253...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4760...  Training loss: 1.8631...  0.0568 sec/batch
Epoch: 8/20...  Training Step: 4761...  Training loss: 1.8486...  0.0574 sec/batch
Epoch: 8/20...  Training Step: 4762...  Training loss: 1.8932...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4763...  Training loss: 1.9135...  0.0523 sec/batch
Epoch: 8/20...  Training Step: 4764...  Training loss: 1.8592...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4765...  Training loss: 1.9155...  0.0527 sec/batch
Epoch: 8/20...  Training Step: 4766...  Training loss: 1.9085...  0.0603 sec/batch
Epoch: 8/20...  Training Step: 4767...  Training loss: 1.8700...  0.0539 sec/batch
Epoch: 8/20...  Training Step: 4768...  Training loss: 1.8965...  0.0523 sec/batch
Epoch: 8/20...  Training Step: 4769...  Training loss: 1.8617...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4770...  Training loss: 1.8357...  0.0523 sec/batch
Epoch: 8/20...  Training Step: 4771...  Training loss: 1.8632...  0.0561 sec/batch
Epoch: 8/20...  Training Step: 4772...  Training loss: 1.9090...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4773...  Training loss: 1.9030...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4774...  Training loss: 1.8545...  0.0577 sec/batch
Epoch: 8/20...  Training Step: 4775...  Training loss: 1.8436...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4776...  Training loss: 1.8764...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4777...  Training loss: 1.8449...  0.0588 sec/batch
Epoch: 8/20...  Training Step: 4778...  Training loss: 1.8887...  0.0570 sec/batch
Epoch: 8/20...  Training Step: 4779...  Training loss: 1.8712...  0.0640 sec/batch
Epoch: 8/20...  Training Step: 4780...  Training loss: 1.8756...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4781...  Training loss: 1.8639...  0.0559 sec/batch
Epoch: 8/20...  Training Step: 4782...  Training loss: 1.8943...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4783...  Training loss: 1.9142...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4784...  Training loss: 1.8805...  0.0524 sec/batch
Epoch: 8/20...  Training Step: 4785...  Training loss: 1.7860...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4786...  Training loss: 1.8941...  0.0542 sec/batch
Epoch: 8/20...  Training Step: 4787...  Training loss: 1.8477...  0.0527 sec/batch
Epoch: 8/20...  Training Step: 4788...  Training loss: 1.8166...  0.0546 sec/batch
Epoch: 8/20...  Training Step: 4789...  Training loss: 1.9202...  0.0545 sec/batch
Epoch: 8/20...  Training Step: 4790...  Training loss: 1.9288...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4791...  Training loss: 1.9449...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4792...  Training loss: 1.9228...  0.0524 sec/batch
Epoch: 8/20...  Training Step: 4793...  Training loss: 1.8609...  0.0572 sec/batch
Epoch: 8/20...  Training Step: 4794...  Training loss: 1.8893...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4795...  Training loss: 1.8555...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4796...  Training loss: 1.8934...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4797...  Training loss: 1.8916...  0.0584 sec/batch
Epoch: 8/20...  Training Step: 4798...  Training loss: 1.8920...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4799...  Training loss: 1.8433...  0.0527 sec/batch
Epoch: 8/20...  Training Step: 4800...  Training loss: 1.8779...  0.0548 sec/batch
Epoch: 8/20...  Training Step: 4801...  Training loss: 1.8560...  0.0556 sec/batch
Epoch: 8/20...  Training Step: 4802...  Training loss: 1.8968...  0.0522 sec/batch
Epoch: 8/20...  Training Step: 4803...  Training loss: 1.8474...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4804...  Training loss: 1.8624...  0.0584 sec/batch
Epoch: 8/20...  Training Step: 4805...  Training loss: 1.9261...  0.0583 sec/batch
Epoch: 8/20...  Training Step: 4806...  Training loss: 1.9062...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4807...  Training loss: 1.8741...  0.0578 sec/batch
Epoch: 8/20...  Training Step: 4808...  Training loss: 1.8615...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4809...  Training loss: 1.9151...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4810...  Training loss: 1.8796...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4811...  Training loss: 1.8659...  0.0589 sec/batch
Epoch: 8/20...  Training Step: 4812...  Training loss: 1.8790...  0.0558 sec/batch
Epoch: 8/20...  Training Step: 4813...  Training loss: 1.8553...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4814...  Training loss: 1.8236...  0.0545 sec/batch
Epoch: 8/20...  Training Step: 4815...  Training loss: 1.9249...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4816...  Training loss: 1.9193...  0.0547 sec/batch
Epoch: 8/20...  Training Step: 4817...  Training loss: 1.9006...  0.0573 sec/batch
Epoch: 8/20...  Training Step: 4818...  Training loss: 1.9540...  0.0543 sec/batch
Epoch: 8/20...  Training Step: 4819...  Training loss: 1.8618...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4820...  Training loss: 1.9432...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4821...  Training loss: 1.8954...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4822...  Training loss: 1.8696...  0.0564 sec/batch
Epoch: 8/20...  Training Step: 4823...  Training loss: 1.8786...  0.0555 sec/batch
Epoch: 8/20...  Training Step: 4824...  Training loss: 1.9056...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4825...  Training loss: 1.9517...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4826...  Training loss: 1.8647...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4827...  Training loss: 1.9065...  0.0570 sec/batch
Epoch: 8/20...  Training Step: 4828...  Training loss: 1.8529...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4829...  Training loss: 1.8948...  0.0587 sec/batch
Epoch: 8/20...  Training Step: 4830...  Training loss: 1.8802...  0.0536 sec/batch
Epoch: 8/20...  Training Step: 4831...  Training loss: 1.8766...  0.0523 sec/batch
Epoch: 8/20...  Training Step: 4832...  Training loss: 1.9127...  0.0546 sec/batch
Epoch: 8/20...  Training Step: 4833...  Training loss: 1.8800...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4834...  Training loss: 1.8533...  0.0548 sec/batch
Epoch: 8/20...  Training Step: 4835...  Training loss: 1.8416...  0.0562 sec/batch
Epoch: 8/20...  Training Step: 4836...  Training loss: 1.8808...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4837...  Training loss: 1.8730...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4838...  Training loss: 1.9015...  0.0576 sec/batch
Epoch: 8/20...  Training Step: 4839...  Training loss: 1.8043...  0.0555 sec/batch
Epoch: 8/20...  Training Step: 4840...  Training loss: 1.9074...  0.0521 sec/batch
Epoch: 8/20...  Training Step: 4841...  Training loss: 1.9032...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4842...  Training loss: 1.9207...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4843...  Training loss: 1.9469...  0.0523 sec/batch
Epoch: 8/20...  Training Step: 4844...  Training loss: 1.8957...  0.0554 sec/batch
Epoch: 8/20...  Training Step: 4845...  Training loss: 1.8711...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4846...  Training loss: 1.8444...  0.0533 sec/batch
Epoch: 8/20...  Training Step: 4847...  Training loss: 1.9215...  0.0591 sec/batch
Epoch: 8/20...  Training Step: 4848...  Training loss: 1.8629...  0.0547 sec/batch
Epoch: 8/20...  Training Step: 4849...  Training loss: 1.9234...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4850...  Training loss: 1.9009...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4851...  Training loss: 1.9307...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4852...  Training loss: 1.8820...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4853...  Training loss: 1.9416...  0.0570 sec/batch
Epoch: 8/20...  Training Step: 4854...  Training loss: 1.9185...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4855...  Training loss: 1.8988...  0.0583 sec/batch
Epoch: 8/20...  Training Step: 4856...  Training loss: 1.8752...  0.0558 sec/batch
Epoch: 8/20...  Training Step: 4857...  Training loss: 1.8743...  0.0578 sec/batch
Epoch: 8/20...  Training Step: 4858...  Training loss: 1.8393...  0.0572 sec/batch
Epoch: 8/20...  Training Step: 4859...  Training loss: 1.8764...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4860...  Training loss: 1.8732...  0.0523 sec/batch
Epoch: 8/20...  Training Step: 4861...  Training loss: 1.8752...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4862...  Training loss: 1.8327...  0.0530 sec/batch
Epoch: 8/20...  Training Step: 4863...  Training loss: 1.8743...  0.0568 sec/batch
Epoch: 8/20...  Training Step: 4864...  Training loss: 1.7859...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4865...  Training loss: 1.9112...  0.0593 sec/batch
Epoch: 8/20...  Training Step: 4866...  Training loss: 1.9181...  0.0579 sec/batch
Epoch: 8/20...  Training Step: 4867...  Training loss: 1.9148...  0.0524 sec/batch
Epoch: 8/20...  Training Step: 4868...  Training loss: 1.9267...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4869...  Training loss: 1.8620...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4870...  Training loss: 1.8504...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4871...  Training loss: 1.8855...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4872...  Training loss: 1.8419...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4873...  Training loss: 1.8913...  0.0579 sec/batch
Epoch: 8/20...  Training Step: 4874...  Training loss: 1.8677...  0.0582 sec/batch
Epoch: 8/20...  Training Step: 4875...  Training loss: 1.8779...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4876...  Training loss: 1.8877...  0.0553 sec/batch
Epoch: 8/20...  Training Step: 4877...  Training loss: 1.8407...  0.0534 sec/batch
Epoch: 8/20...  Training Step: 4878...  Training loss: 1.8991...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4879...  Training loss: 1.8162...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4880...  Training loss: 1.9072...  0.0527 sec/batch
Epoch: 8/20...  Training Step: 4881...  Training loss: 1.8910...  0.0568 sec/batch
Epoch: 8/20...  Training Step: 4882...  Training loss: 1.8627...  0.0557 sec/batch
Epoch: 8/20...  Training Step: 4883...  Training loss: 1.8520...  0.0595 sec/batch
Epoch: 8/20...  Training Step: 4884...  Training loss: 1.8484...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4885...  Training loss: 1.9294...  0.0527 sec/batch
Epoch: 8/20...  Training Step: 4886...  Training loss: 1.8755...  0.0578 sec/batch
Epoch: 8/20...  Training Step: 4887...  Training loss: 1.9125...  0.0564 sec/batch
Epoch: 8/20...  Training Step: 4888...  Training loss: 1.9174...  0.0550 sec/batch
Epoch: 8/20...  Training Step: 4889...  Training loss: 1.9076...  0.0536 sec/batch
Epoch: 8/20...  Training Step: 4890...  Training loss: 1.8868...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4891...  Training loss: 1.9253...  0.0538 sec/batch
Epoch: 8/20...  Training Step: 4892...  Training loss: 1.8304...  0.0560 sec/batch
Epoch: 8/20...  Training Step: 4893...  Training loss: 1.8822...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4894...  Training loss: 1.8741...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4895...  Training loss: 1.8560...  0.0568 sec/batch
Epoch: 8/20...  Training Step: 4896...  Training loss: 1.8674...  0.0523 sec/batch
Epoch: 8/20...  Training Step: 4897...  Training loss: 1.8917...  0.0604 sec/batch
Epoch: 8/20...  Training Step: 4898...  Training loss: 1.8373...  0.0522 sec/batch
Epoch: 8/20...  Training Step: 4899...  Training loss: 1.8749...  0.0784 sec/batch
Epoch: 8/20...  Training Step: 4900...  Training loss: 1.8626...  0.0566 sec/batch
Epoch: 8/20...  Training Step: 4901...  Training loss: 1.9165...  0.0641 sec/batch
Epoch: 8/20...  Training Step: 4902...  Training loss: 1.9129...  0.0576 sec/batch
Epoch: 8/20...  Training Step: 4903...  Training loss: 1.8801...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4904...  Training loss: 1.9492...  0.0535 sec/batch
Epoch: 8/20...  Training Step: 4905...  Training loss: 1.9921...  0.0561 sec/batch
Epoch: 8/20...  Training Step: 4906...  Training loss: 1.9376...  0.0581 sec/batch
Epoch: 8/20...  Training Step: 4907...  Training loss: 1.8847...  0.0542 sec/batch
Epoch: 8/20...  Training Step: 4908...  Training loss: 1.9586...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4909...  Training loss: 1.8603...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4910...  Training loss: 1.9060...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4911...  Training loss: 1.8978...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4912...  Training loss: 1.9470...  0.0569 sec/batch
Epoch: 8/20...  Training Step: 4913...  Training loss: 1.8869...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4914...  Training loss: 1.8620...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4915...  Training loss: 1.8826...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4916...  Training loss: 1.9337...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4917...  Training loss: 1.8403...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4918...  Training loss: 1.9002...  0.0552 sec/batch
Epoch: 8/20...  Training Step: 4919...  Training loss: 1.9380...  0.0559 sec/batch
Epoch: 8/20...  Training Step: 4920...  Training loss: 1.9041...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4921...  Training loss: 1.9148...  0.0599 sec/batch
Epoch: 8/20...  Training Step: 4922...  Training loss: 1.8701...  0.0546 sec/batch
Epoch: 8/20...  Training Step: 4923...  Training loss: 1.8909...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4924...  Training loss: 1.9099...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4925...  Training loss: 1.9111...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4926...  Training loss: 1.8819...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4927...  Training loss: 1.8312...  0.0566 sec/batch
Epoch: 8/20...  Training Step: 4928...  Training loss: 1.8911...  0.0555 sec/batch
Epoch: 8/20...  Training Step: 4929...  Training loss: 1.8543...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4930...  Training loss: 1.9213...  0.0543 sec/batch
Epoch: 8/20...  Training Step: 4931...  Training loss: 1.8302...  0.0531 sec/batch
Epoch: 8/20...  Training Step: 4932...  Training loss: 1.9362...  0.0523 sec/batch
Epoch: 8/20...  Training Step: 4933...  Training loss: 1.8534...  0.0525 sec/batch
Epoch: 8/20...  Training Step: 4934...  Training loss: 1.8458...  0.0568 sec/batch
Epoch: 8/20...  Training Step: 4935...  Training loss: 1.8733...  0.0540 sec/batch
Epoch: 8/20...  Training Step: 4936...  Training loss: 1.8431...  0.0589 sec/batch
Epoch: 8/20...  Training Step: 4937...  Training loss: 1.8335...  0.0563 sec/batch
Epoch: 8/20...  Training Step: 4938...  Training loss: 1.8823...  0.0578 sec/batch
Epoch: 8/20...  Training Step: 4939...  Training loss: 1.9152...  0.0576 sec/batch
Epoch: 8/20...  Training Step: 4940...  Training loss: 1.8975...  0.0547 sec/batch
Epoch: 8/20...  Training Step: 4941...  Training loss: 1.8805...  0.0573 sec/batch
Epoch: 8/20...  Training Step: 4942...  Training loss: 1.8730...  0.0565 sec/batch
Epoch: 8/20...  Training Step: 4943...  Training loss: 1.8893...  0.0527 sec/batch
Epoch: 8/20...  Training Step: 4944...  Training loss: 1.8399...  0.0567 sec/batch
Epoch: 8/20...  Training Step: 4945...  Training loss: 1.8844...  0.0580 sec/batch
Epoch: 8/20...  Training Step: 4946...  Training loss: 1.8763...  0.0546 sec/batch
Epoch: 8/20...  Training Step: 4947...  Training loss: 1.8486...  0.0551 sec/batch
Epoch: 8/20...  Training Step: 4948...  Training loss: 1.8550...  0.0526 sec/batch
Epoch: 8/20...  Training Step: 4949...  Training loss: 1.8514...  0.0543 sec/batch
Epoch: 8/20...  Training Step: 4950...  Training loss: 1.9175...  0.0580 sec/batch
Epoch: 8/20...  Training Step: 4951...  Training loss: 1.9186...  0.0575 sec/batch
Epoch: 8/20...  Training Step: 4952...  Training loss: 1.8972...  0.0549 sec/batch
Epoch: 8/20...  Training Step: 4953...  Training loss: 1.8503...  0.0558 sec/batch
Epoch: 8/20...  Training Step: 4954...  Training loss: 1.9038...  0.0588 sec/batch
Epoch: 8/20...  Training Step: 4955...  Training loss: 1.8546...  0.0523 sec/batch
Epoch: 8/20...  Training Step: 4956...  Training loss: 1.9125...  0.0528 sec/batch
Epoch: 8/20...  Training Step: 4957...  Training loss: 1.9284...  0.0529 sec/batch
Epoch: 8/20...  Training Step: 4958...  Training loss: 1.8391...  0.0544 sec/batch
Epoch: 8/20...  Training Step: 4959...  Training loss: 1.8430...  0.0532 sec/batch
Epoch: 8/20...  Training Step: 4960...  Training loss: 1.8423...  0.0525 sec/batch
Epoch: 9/20...  Training Step: 4961...  Training loss: 1.9755...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 4962...  Training loss: 1.9607...  0.0557 sec/batch
Epoch: 9/20...  Training Step: 4963...  Training loss: 1.9316...  0.0589 sec/batch
Epoch: 9/20...  Training Step: 4964...  Training loss: 1.8464...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 4965...  Training loss: 1.9062...  0.0587 sec/batch
Epoch: 9/20...  Training Step: 4966...  Training loss: 1.9064...  0.0544 sec/batch
Epoch: 9/20...  Training Step: 4967...  Training loss: 1.8433...  0.0596 sec/batch
Epoch: 9/20...  Training Step: 4968...  Training loss: 1.8435...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 4969...  Training loss: 1.8344...  0.0560 sec/batch
Epoch: 9/20...  Training Step: 4970...  Training loss: 1.8668...  0.0533 sec/batch
Epoch: 9/20...  Training Step: 4971...  Training loss: 1.8654...  0.0534 sec/batch
Epoch: 9/20...  Training Step: 4972...  Training loss: 1.8286...  0.0583 sec/batch
Epoch: 9/20...  Training Step: 4973...  Training loss: 1.8747...  0.0564 sec/batch
Epoch: 9/20...  Training Step: 4974...  Training loss: 1.8624...  0.0567 sec/batch
Epoch: 9/20...  Training Step: 4975...  Training loss: 1.9043...  0.0553 sec/batch
Epoch: 9/20...  Training Step: 4976...  Training loss: 1.9288...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 4977...  Training loss: 1.9004...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 4978...  Training loss: 1.8882...  0.0554 sec/batch
Epoch: 9/20...  Training Step: 4979...  Training loss: 1.8425...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 4980...  Training loss: 1.8740...  0.0554 sec/batch
Epoch: 9/20...  Training Step: 4981...  Training loss: 1.9408...  0.0577 sec/batch
Epoch: 9/20...  Training Step: 4982...  Training loss: 1.8692...  0.0538 sec/batch
Epoch: 9/20...  Training Step: 4983...  Training loss: 1.8353...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 4984...  Training loss: 1.8682...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 4985...  Training loss: 1.8727...  0.0565 sec/batch
Epoch: 9/20...  Training Step: 4986...  Training loss: 1.8250...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 4987...  Training loss: 1.8727...  0.0523 sec/batch
Epoch: 9/20...  Training Step: 4988...  Training loss: 1.8793...  0.0562 sec/batch
Epoch: 9/20...  Training Step: 4989...  Training loss: 1.8725...  0.0551 sec/batch
Epoch: 9/20...  Training Step: 4990...  Training loss: 1.8415...  0.0567 sec/batch
Epoch: 9/20...  Training Step: 4991...  Training loss: 1.8303...  0.0555 sec/batch
Epoch: 9/20...  Training Step: 4992...  Training loss: 1.8939...  0.0563 sec/batch
Epoch: 9/20...  Training Step: 4993...  Training loss: 1.8528...  0.0556 sec/batch
Epoch: 9/20...  Training Step: 4994...  Training loss: 1.8602...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 4995...  Training loss: 1.8749...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 4996...  Training loss: 1.8701...  0.0579 sec/batch
Epoch: 9/20...  Training Step: 4997...  Training loss: 1.8759...  0.0565 sec/batch
Epoch: 9/20...  Training Step: 4998...  Training loss: 1.8681...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 4999...  Training loss: 1.8769...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5000...  Training loss: 1.8446...  0.0570 sec/batch
Epoch: 9/20...  Training Step: 5001...  Training loss: 1.8599...  0.0532 sec/batch
Epoch: 9/20...  Training Step: 5002...  Training loss: 1.9057...  0.0522 sec/batch
Epoch: 9/20...  Training Step: 5003...  Training loss: 1.8594...  0.0557 sec/batch
Epoch: 9/20...  Training Step: 5004...  Training loss: 1.9017...  0.0542 sec/batch
Epoch: 9/20...  Training Step: 5005...  Training loss: 1.8427...  0.0532 sec/batch
Epoch: 9/20...  Training Step: 5006...  Training loss: 1.8611...  0.0522 sec/batch
Epoch: 9/20...  Training Step: 5007...  Training loss: 1.7546...  0.0553 sec/batch
Epoch: 9/20...  Training Step: 5008...  Training loss: 1.8860...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5009...  Training loss: 1.8384...  0.0544 sec/batch
Epoch: 9/20...  Training Step: 5010...  Training loss: 1.8970...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5011...  Training loss: 1.8418...  0.0537 sec/batch
Epoch: 9/20...  Training Step: 5012...  Training loss: 1.8456...  0.0585 sec/batch
Epoch: 9/20...  Training Step: 5013...  Training loss: 1.8582...  0.0568 sec/batch
Epoch: 9/20...  Training Step: 5014...  Training loss: 1.8831...  0.0543 sec/batch
Epoch: 9/20...  Training Step: 5015...  Training loss: 1.8834...  0.0525 sec/batch
Epoch: 9/20...  Training Step: 5016...  Training loss: 1.8652...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5017...  Training loss: 1.8306...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5018...  Training loss: 1.8793...  0.0539 sec/batch
Epoch: 9/20...  Training Step: 5019...  Training loss: 1.8488...  0.0527 sec/batch
Epoch: 9/20...  Training Step: 5020...  Training loss: 1.8958...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5021...  Training loss: 1.8549...  0.0594 sec/batch
Epoch: 9/20...  Training Step: 5022...  Training loss: 1.8286...  0.0566 sec/batch
Epoch: 9/20...  Training Step: 5023...  Training loss: 1.9124...  0.0570 sec/batch
Epoch: 9/20...  Training Step: 5024...  Training loss: 1.8669...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5025...  Training loss: 1.8233...  0.0595 sec/batch
Epoch: 9/20...  Training Step: 5026...  Training loss: 1.8190...  0.0537 sec/batch
Epoch: 9/20...  Training Step: 5027...  Training loss: 1.8287...  0.0559 sec/batch
Epoch: 9/20...  Training Step: 5028...  Training loss: 1.8420...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5029...  Training loss: 1.8685...  0.0536 sec/batch
Epoch: 9/20...  Training Step: 5030...  Training loss: 1.8752...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5031...  Training loss: 1.8933...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5032...  Training loss: 1.8909...  0.0553 sec/batch
Epoch: 9/20...  Training Step: 5033...  Training loss: 1.8189...  0.0555 sec/batch
Epoch: 9/20...  Training Step: 5034...  Training loss: 1.8621...  0.0557 sec/batch
Epoch: 9/20...  Training Step: 5035...  Training loss: 1.9225...  0.0545 sec/batch
Epoch: 9/20...  Training Step: 5036...  Training loss: 1.8925...  0.0531 sec/batch
Epoch: 9/20...  Training Step: 5037...  Training loss: 1.8913...  0.0527 sec/batch
Epoch: 9/20...  Training Step: 5038...  Training loss: 1.8569...  0.0564 sec/batch
Epoch: 9/20...  Training Step: 5039...  Training loss: 1.8632...  0.0565 sec/batch
Epoch: 9/20...  Training Step: 5040...  Training loss: 1.8815...  0.0563 sec/batch
Epoch: 9/20...  Training Step: 5041...  Training loss: 1.8127...  0.0592 sec/batch
Epoch: 9/20...  Training Step: 5042...  Training loss: 1.8673...  0.0544 sec/batch
Epoch: 9/20...  Training Step: 5043...  Training loss: 1.8254...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5044...  Training loss: 1.8526...  0.0565 sec/batch
Epoch: 9/20...  Training Step: 5045...  Training loss: 1.8328...  0.0592 sec/batch
Epoch: 9/20...  Training Step: 5046...  Training loss: 1.9101...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5047...  Training loss: 1.8395...  0.0531 sec/batch
Epoch: 9/20...  Training Step: 5048...  Training loss: 1.9348...  0.0539 sec/batch
Epoch: 9/20...  Training Step: 5049...  Training loss: 1.8665...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5050...  Training loss: 1.8926...  0.0573 sec/batch
Epoch: 9/20...  Training Step: 5051...  Training loss: 1.8454...  0.0545 sec/batch
Epoch: 9/20...  Training Step: 5052...  Training loss: 1.9239...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5053...  Training loss: 1.8444...  0.0585 sec/batch
Epoch: 9/20...  Training Step: 5054...  Training loss: 1.8665...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5055...  Training loss: 1.8552...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5056...  Training loss: 1.8780...  0.0579 sec/batch
Epoch: 9/20...  Training Step: 5057...  Training loss: 1.8819...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5058...  Training loss: 1.8071...  0.0569 sec/batch
Epoch: 9/20...  Training Step: 5059...  Training loss: 1.9107...  0.0531 sec/batch
Epoch: 9/20...  Training Step: 5060...  Training loss: 1.8459...  0.0560 sec/batch
Epoch: 9/20...  Training Step: 5061...  Training loss: 1.8511...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5062...  Training loss: 1.8353...  0.0598 sec/batch
Epoch: 9/20...  Training Step: 5063...  Training loss: 1.8841...  0.0557 sec/batch
Epoch: 9/20...  Training Step: 5064...  Training loss: 1.8996...  0.0533 sec/batch
Epoch: 9/20...  Training Step: 5065...  Training loss: 1.8679...  0.0564 sec/batch
Epoch: 9/20...  Training Step: 5066...  Training loss: 1.8408...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5067...  Training loss: 1.8959...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5068...  Training loss: 1.8557...  0.0553 sec/batch
Epoch: 9/20...  Training Step: 5069...  Training loss: 1.8644...  0.0578 sec/batch
Epoch: 9/20...  Training Step: 5070...  Training loss: 1.8414...  0.0534 sec/batch
Epoch: 9/20...  Training Step: 5071...  Training loss: 1.8329...  0.0566 sec/batch
Epoch: 9/20...  Training Step: 5072...  Training loss: 1.8448...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5073...  Training loss: 1.8635...  0.0596 sec/batch
Epoch: 9/20...  Training Step: 5074...  Training loss: 1.8538...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5075...  Training loss: 1.8741...  0.0602 sec/batch
Epoch: 9/20...  Training Step: 5076...  Training loss: 1.9048...  0.0527 sec/batch
Epoch: 9/20...  Training Step: 5077...  Training loss: 1.8137...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5078...  Training loss: 1.9125...  0.0556 sec/batch
Epoch: 9/20...  Training Step: 5079...  Training loss: 1.8492...  0.0565 sec/batch
Epoch: 9/20...  Training Step: 5080...  Training loss: 1.8521...  0.0555 sec/batch
Epoch: 9/20...  Training Step: 5081...  Training loss: 1.8404...  0.0532 sec/batch
Epoch: 9/20...  Training Step: 5082...  Training loss: 1.8182...  0.0619 sec/batch
Epoch: 9/20...  Training Step: 5083...  Training loss: 1.8450...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5084...  Training loss: 1.9088...  0.0570 sec/batch
Epoch: 9/20...  Training Step: 5085...  Training loss: 1.8825...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5086...  Training loss: 1.9222...  0.0525 sec/batch
Epoch: 9/20...  Training Step: 5087...  Training loss: 1.9221...  0.0574 sec/batch
Epoch: 9/20...  Training Step: 5088...  Training loss: 1.8356...  0.0567 sec/batch
Epoch: 9/20...  Training Step: 5089...  Training loss: 1.8506...  0.0545 sec/batch
Epoch: 9/20...  Training Step: 5090...  Training loss: 1.9035...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5091...  Training loss: 1.8531...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5092...  Training loss: 1.9210...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5093...  Training loss: 1.9144...  0.0564 sec/batch
Epoch: 9/20...  Training Step: 5094...  Training loss: 1.8577...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5095...  Training loss: 1.8457...  0.0532 sec/batch
Epoch: 9/20...  Training Step: 5096...  Training loss: 1.8720...  0.0577 sec/batch
Epoch: 9/20...  Training Step: 5097...  Training loss: 1.8491...  0.0560 sec/batch
Epoch: 9/20...  Training Step: 5098...  Training loss: 1.8694...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5099...  Training loss: 1.9232...  0.0544 sec/batch
Epoch: 9/20...  Training Step: 5100...  Training loss: 1.8704...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5101...  Training loss: 1.9049...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5102...  Training loss: 1.7807...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5103...  Training loss: 1.8586...  0.0542 sec/batch
Epoch: 9/20...  Training Step: 5104...  Training loss: 1.8382...  0.0538 sec/batch
Epoch: 9/20...  Training Step: 5105...  Training loss: 1.8100...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5106...  Training loss: 1.8903...  0.0587 sec/batch
Epoch: 9/20...  Training Step: 5107...  Training loss: 1.8885...  0.0595 sec/batch
Epoch: 9/20...  Training Step: 5108...  Training loss: 1.8912...  0.0527 sec/batch
Epoch: 9/20...  Training Step: 5109...  Training loss: 1.8630...  0.0578 sec/batch
Epoch: 9/20...  Training Step: 5110...  Training loss: 1.8973...  0.0545 sec/batch
Epoch: 9/20...  Training Step: 5111...  Training loss: 1.8668...  0.0581 sec/batch
Epoch: 9/20...  Training Step: 5112...  Training loss: 1.8510...  0.0591 sec/batch
Epoch: 9/20...  Training Step: 5113...  Training loss: 1.8562...  0.0558 sec/batch
Epoch: 9/20...  Training Step: 5114...  Training loss: 1.9033...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5115...  Training loss: 1.8616...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5116...  Training loss: 1.8818...  0.0580 sec/batch
Epoch: 9/20...  Training Step: 5117...  Training loss: 1.8727...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5118...  Training loss: 1.8837...  0.0534 sec/batch
Epoch: 9/20...  Training Step: 5119...  Training loss: 1.9073...  0.0521 sec/batch
Epoch: 9/20...  Training Step: 5120...  Training loss: 1.8393...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5121...  Training loss: 1.8282...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5122...  Training loss: 1.8440...  0.0555 sec/batch
Epoch: 9/20...  Training Step: 5123...  Training loss: 1.8558...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5124...  Training loss: 1.8687...  0.0555 sec/batch
Epoch: 9/20...  Training Step: 5125...  Training loss: 1.8718...  0.0584 sec/batch
Epoch: 9/20...  Training Step: 5126...  Training loss: 1.8656...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5127...  Training loss: 1.8921...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5128...  Training loss: 1.8716...  0.0531 sec/batch
Epoch: 9/20...  Training Step: 5129...  Training loss: 1.8646...  0.0564 sec/batch
Epoch: 9/20...  Training Step: 5130...  Training loss: 1.8271...  0.0595 sec/batch
Epoch: 9/20...  Training Step: 5131...  Training loss: 1.8446...  0.0579 sec/batch
Epoch: 9/20...  Training Step: 5132...  Training loss: 1.8732...  0.0580 sec/batch
Epoch: 9/20...  Training Step: 5133...  Training loss: 1.8678...  0.0582 sec/batch
Epoch: 9/20...  Training Step: 5134...  Training loss: 1.8487...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5135...  Training loss: 1.8586...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5136...  Training loss: 1.8540...  0.0538 sec/batch
Epoch: 9/20...  Training Step: 5137...  Training loss: 1.8785...  0.0555 sec/batch
Epoch: 9/20...  Training Step: 5138...  Training loss: 1.8367...  0.0551 sec/batch
Epoch: 9/20...  Training Step: 5139...  Training loss: 1.8322...  0.0527 sec/batch
Epoch: 9/20...  Training Step: 5140...  Training loss: 1.8502...  0.0553 sec/batch
Epoch: 9/20...  Training Step: 5141...  Training loss: 1.8413...  0.0572 sec/batch
Epoch: 9/20...  Training Step: 5142...  Training loss: 1.8948...  0.0554 sec/batch
Epoch: 9/20...  Training Step: 5143...  Training loss: 1.8833...  0.0534 sec/batch
Epoch: 9/20...  Training Step: 5144...  Training loss: 1.8382...  0.0579 sec/batch
Epoch: 9/20...  Training Step: 5145...  Training loss: 1.8107...  0.0539 sec/batch
Epoch: 9/20...  Training Step: 5146...  Training loss: 1.8764...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5147...  Training loss: 1.8335...  0.0586 sec/batch
Epoch: 9/20...  Training Step: 5148...  Training loss: 1.8600...  0.0554 sec/batch
Epoch: 9/20...  Training Step: 5149...  Training loss: 1.8434...  0.0572 sec/batch
Epoch: 9/20...  Training Step: 5150...  Training loss: 1.9259...  0.0553 sec/batch
Epoch: 9/20...  Training Step: 5151...  Training loss: 1.8790...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5152...  Training loss: 1.9246...  0.0553 sec/batch
Epoch: 9/20...  Training Step: 5153...  Training loss: 1.8760...  0.0551 sec/batch
Epoch: 9/20...  Training Step: 5154...  Training loss: 1.8140...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5155...  Training loss: 1.8611...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5156...  Training loss: 1.9192...  0.0533 sec/batch
Epoch: 9/20...  Training Step: 5157...  Training loss: 1.8773...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5158...  Training loss: 1.9407...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5159...  Training loss: 1.8390...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5160...  Training loss: 1.8936...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5161...  Training loss: 1.8550...  0.0562 sec/batch
Epoch: 9/20...  Training Step: 5162...  Training loss: 1.8542...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5163...  Training loss: 1.8558...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5164...  Training loss: 1.8462...  0.0545 sec/batch
Epoch: 9/20...  Training Step: 5165...  Training loss: 1.8627...  0.0576 sec/batch
Epoch: 9/20...  Training Step: 5166...  Training loss: 1.8434...  0.0551 sec/batch
Epoch: 9/20...  Training Step: 5167...  Training loss: 1.8837...  0.0535 sec/batch
Epoch: 9/20...  Training Step: 5168...  Training loss: 1.8579...  0.0554 sec/batch
Epoch: 9/20...  Training Step: 5169...  Training loss: 1.8599...  0.0535 sec/batch
Epoch: 9/20...  Training Step: 5170...  Training loss: 1.8296...  0.0545 sec/batch
Epoch: 9/20...  Training Step: 5171...  Training loss: 1.8812...  0.0570 sec/batch
Epoch: 9/20...  Training Step: 5172...  Training loss: 1.8527...  0.0583 sec/batch
Epoch: 9/20...  Training Step: 5173...  Training loss: 1.9040...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5174...  Training loss: 1.8932...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5175...  Training loss: 1.8994...  0.0572 sec/batch
Epoch: 9/20...  Training Step: 5176...  Training loss: 1.9078...  0.0572 sec/batch
Epoch: 9/20...  Training Step: 5177...  Training loss: 1.8814...  0.0580 sec/batch
Epoch: 9/20...  Training Step: 5178...  Training loss: 1.8441...  0.0561 sec/batch
Epoch: 9/20...  Training Step: 5179...  Training loss: 1.9310...  0.0533 sec/batch
Epoch: 9/20...  Training Step: 5180...  Training loss: 1.9035...  0.0586 sec/batch
Epoch: 9/20...  Training Step: 5181...  Training loss: 1.8795...  0.0538 sec/batch
Epoch: 9/20...  Training Step: 5182...  Training loss: 1.8813...  0.0586 sec/batch
Epoch: 9/20...  Training Step: 5183...  Training loss: 1.9105...  0.0543 sec/batch
Epoch: 9/20...  Training Step: 5184...  Training loss: 1.8399...  0.0522 sec/batch
Epoch: 9/20...  Training Step: 5185...  Training loss: 1.8369...  0.0535 sec/batch
Epoch: 9/20...  Training Step: 5186...  Training loss: 1.8941...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5187...  Training loss: 1.9065...  0.0565 sec/batch
Epoch: 9/20...  Training Step: 5188...  Training loss: 1.8291...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5189...  Training loss: 1.8919...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5190...  Training loss: 1.8487...  0.0593 sec/batch
Epoch: 9/20...  Training Step: 5191...  Training loss: 1.9184...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5192...  Training loss: 1.8470...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5193...  Training loss: 1.8394...  0.0532 sec/batch
Epoch: 9/20...  Training Step: 5194...  Training loss: 1.8292...  0.0541 sec/batch
Epoch: 9/20...  Training Step: 5195...  Training loss: 1.8407...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5196...  Training loss: 1.8888...  0.0558 sec/batch
Epoch: 9/20...  Training Step: 5197...  Training loss: 1.8503...  0.0559 sec/batch
Epoch: 9/20...  Training Step: 5198...  Training loss: 1.8132...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5199...  Training loss: 1.8428...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5200...  Training loss: 1.8824...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5201...  Training loss: 1.8543...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5202...  Training loss: 1.8294...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5203...  Training loss: 1.8376...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5204...  Training loss: 1.8567...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5205...  Training loss: 1.8773...  0.0537 sec/batch
Epoch: 9/20...  Training Step: 5206...  Training loss: 1.8534...  0.0562 sec/batch
Epoch: 9/20...  Training Step: 5207...  Training loss: 1.8825...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5208...  Training loss: 1.8868...  0.0579 sec/batch
Epoch: 9/20...  Training Step: 5209...  Training loss: 1.8130...  0.0558 sec/batch
Epoch: 9/20...  Training Step: 5210...  Training loss: 1.8453...  0.0577 sec/batch
Epoch: 9/20...  Training Step: 5211...  Training loss: 1.8689...  0.0571 sec/batch
Epoch: 9/20...  Training Step: 5212...  Training loss: 1.8492...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5213...  Training loss: 1.8951...  0.0554 sec/batch
Epoch: 9/20...  Training Step: 5214...  Training loss: 1.8695...  0.0591 sec/batch
Epoch: 9/20...  Training Step: 5215...  Training loss: 1.9044...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5216...  Training loss: 1.8647...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5217...  Training loss: 1.8756...  0.0570 sec/batch
Epoch: 9/20...  Training Step: 5218...  Training loss: 1.8584...  0.0563 sec/batch
Epoch: 9/20...  Training Step: 5219...  Training loss: 1.8565...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5220...  Training loss: 1.8444...  0.0566 sec/batch
Epoch: 9/20...  Training Step: 5221...  Training loss: 1.8508...  0.0531 sec/batch
Epoch: 9/20...  Training Step: 5222...  Training loss: 1.8312...  0.0521 sec/batch
Epoch: 9/20...  Training Step: 5223...  Training loss: 1.8743...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5224...  Training loss: 1.8667...  0.0562 sec/batch
Epoch: 9/20...  Training Step: 5225...  Training loss: 1.8859...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5226...  Training loss: 1.7972...  0.0523 sec/batch
Epoch: 9/20...  Training Step: 5227...  Training loss: 1.8659...  0.0555 sec/batch
Epoch: 9/20...  Training Step: 5228...  Training loss: 1.8723...  0.0518 sec/batch
Epoch: 9/20...  Training Step: 5229...  Training loss: 1.8460...  0.0560 sec/batch
Epoch: 9/20...  Training Step: 5230...  Training loss: 1.8175...  0.0543 sec/batch
Epoch: 9/20...  Training Step: 5231...  Training loss: 1.8154...  0.0577 sec/batch
Epoch: 9/20...  Training Step: 5232...  Training loss: 1.8459...  0.0594 sec/batch
Epoch: 9/20...  Training Step: 5233...  Training loss: 1.8415...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5234...  Training loss: 1.8653...  0.0542 sec/batch
Epoch: 9/20...  Training Step: 5235...  Training loss: 1.8900...  0.0527 sec/batch
Epoch: 9/20...  Training Step: 5236...  Training loss: 1.8911...  0.0527 sec/batch
Epoch: 9/20...  Training Step: 5237...  Training loss: 1.9348...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5238...  Training loss: 1.8853...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5239...  Training loss: 1.9106...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5240...  Training loss: 1.9076...  0.0532 sec/batch
Epoch: 9/20...  Training Step: 5241...  Training loss: 1.8646...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5242...  Training loss: 1.8044...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5243...  Training loss: 1.8304...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5244...  Training loss: 1.8774...  0.0522 sec/batch
Epoch: 9/20...  Training Step: 5245...  Training loss: 1.8344...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5246...  Training loss: 1.8770...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5247...  Training loss: 1.8530...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5248...  Training loss: 1.8663...  0.0584 sec/batch
Epoch: 9/20...  Training Step: 5249...  Training loss: 1.8716...  0.0600 sec/batch
Epoch: 9/20...  Training Step: 5250...  Training loss: 1.9118...  0.0557 sec/batch
Epoch: 9/20...  Training Step: 5251...  Training loss: 1.8498...  0.0523 sec/batch
Epoch: 9/20...  Training Step: 5252...  Training loss: 1.8837...  0.0556 sec/batch
Epoch: 9/20...  Training Step: 5253...  Training loss: 1.8508...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5254...  Training loss: 1.8879...  0.0560 sec/batch
Epoch: 9/20...  Training Step: 5255...  Training loss: 1.8159...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5256...  Training loss: 1.8242...  0.0532 sec/batch
Epoch: 9/20...  Training Step: 5257...  Training loss: 1.8841...  0.0519 sec/batch
Epoch: 9/20...  Training Step: 5258...  Training loss: 1.8968...  0.0582 sec/batch
Epoch: 9/20...  Training Step: 5259...  Training loss: 1.9097...  0.0563 sec/batch
Epoch: 9/20...  Training Step: 5260...  Training loss: 1.8569...  0.0584 sec/batch
Epoch: 9/20...  Training Step: 5261...  Training loss: 1.9055...  0.0544 sec/batch
Epoch: 9/20...  Training Step: 5262...  Training loss: 1.9196...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5263...  Training loss: 1.8187...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5264...  Training loss: 1.8932...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5265...  Training loss: 1.8501...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5266...  Training loss: 1.8550...  0.0527 sec/batch
Epoch: 9/20...  Training Step: 5267...  Training loss: 1.8521...  0.0583 sec/batch
Epoch: 9/20...  Training Step: 5268...  Training loss: 1.8499...  0.0560 sec/batch
Epoch: 9/20...  Training Step: 5269...  Training loss: 1.8671...  0.0574 sec/batch
Epoch: 9/20...  Training Step: 5270...  Training loss: 1.8262...  0.0531 sec/batch
Epoch: 9/20...  Training Step: 5271...  Training loss: 1.8245...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5272...  Training loss: 1.8308...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5273...  Training loss: 1.8497...  0.0591 sec/batch
Epoch: 9/20...  Training Step: 5274...  Training loss: 1.8204...  0.0562 sec/batch
Epoch: 9/20...  Training Step: 5275...  Training loss: 1.8633...  0.0582 sec/batch
Epoch: 9/20...  Training Step: 5276...  Training loss: 1.8689...  0.0531 sec/batch
Epoch: 9/20...  Training Step: 5277...  Training loss: 1.8176...  0.0544 sec/batch
Epoch: 9/20...  Training Step: 5278...  Training loss: 1.8186...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5279...  Training loss: 1.8341...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5280...  Training loss: 1.9102...  0.0571 sec/batch
Epoch: 9/20...  Training Step: 5281...  Training loss: 1.8734...  0.0588 sec/batch
Epoch: 9/20...  Training Step: 5282...  Training loss: 1.8153...  0.0586 sec/batch
Epoch: 9/20...  Training Step: 5283...  Training loss: 1.8593...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5284...  Training loss: 1.8528...  0.0574 sec/batch
Epoch: 9/20...  Training Step: 5285...  Training loss: 1.8250...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5286...  Training loss: 1.8449...  0.0574 sec/batch
Epoch: 9/20...  Training Step: 5287...  Training loss: 1.8292...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5288...  Training loss: 1.8068...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5289...  Training loss: 1.8706...  0.0581 sec/batch
Epoch: 9/20...  Training Step: 5290...  Training loss: 1.8334...  0.0553 sec/batch
Epoch: 9/20...  Training Step: 5291...  Training loss: 1.8197...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5292...  Training loss: 1.8408...  0.0537 sec/batch
Epoch: 9/20...  Training Step: 5293...  Training loss: 1.8381...  0.0556 sec/batch
Epoch: 9/20...  Training Step: 5294...  Training loss: 1.8565...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5295...  Training loss: 1.8580...  0.0523 sec/batch
Epoch: 9/20...  Training Step: 5296...  Training loss: 1.8506...  0.0543 sec/batch
Epoch: 9/20...  Training Step: 5297...  Training loss: 1.8322...  0.0596 sec/batch
Epoch: 9/20...  Training Step: 5298...  Training loss: 1.8217...  0.0541 sec/batch
Epoch: 9/20...  Training Step: 5299...  Training loss: 1.8261...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5300...  Training loss: 1.8369...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5301...  Training loss: 1.8683...  0.0557 sec/batch
Epoch: 9/20...  Training Step: 5302...  Training loss: 1.8408...  0.0521 sec/batch
Epoch: 9/20...  Training Step: 5303...  Training loss: 1.8121...  0.0555 sec/batch
Epoch: 9/20...  Training Step: 5304...  Training loss: 1.8430...  0.0616 sec/batch
Epoch: 9/20...  Training Step: 5305...  Training loss: 1.8615...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5306...  Training loss: 1.8579...  0.0554 sec/batch
Epoch: 9/20...  Training Step: 5307...  Training loss: 1.8665...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5308...  Training loss: 1.8723...  0.0531 sec/batch
Epoch: 9/20...  Training Step: 5309...  Training loss: 1.8482...  0.0531 sec/batch
Epoch: 9/20...  Training Step: 5310...  Training loss: 1.8563...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5311...  Training loss: 1.8901...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5312...  Training loss: 1.8486...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5313...  Training loss: 1.8742...  0.0551 sec/batch
Epoch: 9/20...  Training Step: 5314...  Training loss: 1.8439...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5315...  Training loss: 1.8244...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5316...  Training loss: 1.9205...  0.0543 sec/batch
Epoch: 9/20...  Training Step: 5317...  Training loss: 1.9394...  0.0551 sec/batch
Epoch: 9/20...  Training Step: 5318...  Training loss: 1.8855...  0.0542 sec/batch
Epoch: 9/20...  Training Step: 5319...  Training loss: 1.8534...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5320...  Training loss: 1.8668...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5321...  Training loss: 1.8721...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5322...  Training loss: 1.8316...  0.0599 sec/batch
Epoch: 9/20...  Training Step: 5323...  Training loss: 1.7998...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5324...  Training loss: 1.8048...  0.0521 sec/batch
Epoch: 9/20...  Training Step: 5325...  Training loss: 1.8644...  0.0533 sec/batch
Epoch: 9/20...  Training Step: 5326...  Training loss: 1.8640...  0.0585 sec/batch
Epoch: 9/20...  Training Step: 5327...  Training loss: 1.8379...  0.0525 sec/batch
Epoch: 9/20...  Training Step: 5328...  Training loss: 1.8929...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5329...  Training loss: 1.8820...  0.0609 sec/batch
Epoch: 9/20...  Training Step: 5330...  Training loss: 1.8438...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5331...  Training loss: 1.8889...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5332...  Training loss: 1.9419...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5333...  Training loss: 1.8621...  0.0587 sec/batch
Epoch: 9/20...  Training Step: 5334...  Training loss: 1.8466...  0.0565 sec/batch
Epoch: 9/20...  Training Step: 5335...  Training loss: 1.8464...  0.0554 sec/batch
Epoch: 9/20...  Training Step: 5336...  Training loss: 1.8383...  0.0553 sec/batch
Epoch: 9/20...  Training Step: 5337...  Training loss: 1.8323...  0.0561 sec/batch
Epoch: 9/20...  Training Step: 5338...  Training loss: 1.9127...  0.0523 sec/batch
Epoch: 9/20...  Training Step: 5339...  Training loss: 1.8677...  0.0571 sec/batch
Epoch: 9/20...  Training Step: 5340...  Training loss: 1.8487...  0.0628 sec/batch
Epoch: 9/20...  Training Step: 5341...  Training loss: 1.7882...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5342...  Training loss: 1.9119...  0.0532 sec/batch
Epoch: 9/20...  Training Step: 5343...  Training loss: 1.8314...  0.0522 sec/batch
Epoch: 9/20...  Training Step: 5344...  Training loss: 1.8526...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5345...  Training loss: 1.8713...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5346...  Training loss: 1.8008...  0.0575 sec/batch
Epoch: 9/20...  Training Step: 5347...  Training loss: 1.8006...  0.0521 sec/batch
Epoch: 9/20...  Training Step: 5348...  Training loss: 1.8638...  0.0531 sec/batch
Epoch: 9/20...  Training Step: 5349...  Training loss: 1.7850...  0.0555 sec/batch
Epoch: 9/20...  Training Step: 5350...  Training loss: 1.8158...  0.0567 sec/batch
Epoch: 9/20...  Training Step: 5351...  Training loss: 1.8940...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5352...  Training loss: 1.7992...  0.0527 sec/batch
Epoch: 9/20...  Training Step: 5353...  Training loss: 1.8556...  0.0566 sec/batch
Epoch: 9/20...  Training Step: 5354...  Training loss: 1.8928...  0.0544 sec/batch
Epoch: 9/20...  Training Step: 5355...  Training loss: 1.8205...  0.0587 sec/batch
Epoch: 9/20...  Training Step: 5356...  Training loss: 1.8624...  0.0586 sec/batch
Epoch: 9/20...  Training Step: 5357...  Training loss: 1.8392...  0.0583 sec/batch
Epoch: 9/20...  Training Step: 5358...  Training loss: 1.8606...  0.0535 sec/batch
Epoch: 9/20...  Training Step: 5359...  Training loss: 1.8337...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5360...  Training loss: 1.8812...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5361...  Training loss: 1.8876...  0.0537 sec/batch
Epoch: 9/20...  Training Step: 5362...  Training loss: 1.8700...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5363...  Training loss: 1.8279...  0.0565 sec/batch
Epoch: 9/20...  Training Step: 5364...  Training loss: 1.8935...  0.0554 sec/batch
Epoch: 9/20...  Training Step: 5365...  Training loss: 1.9067...  0.0586 sec/batch
Epoch: 9/20...  Training Step: 5366...  Training loss: 1.8840...  0.0571 sec/batch
Epoch: 9/20...  Training Step: 5367...  Training loss: 1.9265...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5368...  Training loss: 1.8779...  0.0540 sec/batch
Epoch: 9/20...  Training Step: 5369...  Training loss: 1.9152...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5370...  Training loss: 1.8782...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5371...  Training loss: 1.8341...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5372...  Training loss: 1.8798...  0.0579 sec/batch
Epoch: 9/20...  Training Step: 5373...  Training loss: 1.8809...  0.0572 sec/batch
Epoch: 9/20...  Training Step: 5374...  Training loss: 1.8354...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5375...  Training loss: 1.8315...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5376...  Training loss: 1.8060...  0.0589 sec/batch
Epoch: 9/20...  Training Step: 5377...  Training loss: 1.8445...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5378...  Training loss: 1.8662...  0.0575 sec/batch
Epoch: 9/20...  Training Step: 5379...  Training loss: 1.8942...  0.0545 sec/batch
Epoch: 9/20...  Training Step: 5380...  Training loss: 1.8542...  0.0576 sec/batch
Epoch: 9/20...  Training Step: 5381...  Training loss: 1.8180...  0.0560 sec/batch
Epoch: 9/20...  Training Step: 5382...  Training loss: 1.8505...  0.0568 sec/batch
Epoch: 9/20...  Training Step: 5383...  Training loss: 1.8652...  0.0525 sec/batch
Epoch: 9/20...  Training Step: 5384...  Training loss: 1.8287...  0.0565 sec/batch
Epoch: 9/20...  Training Step: 5385...  Training loss: 1.8913...  0.0575 sec/batch
Epoch: 9/20...  Training Step: 5386...  Training loss: 1.8880...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5387...  Training loss: 1.8387...  0.0545 sec/batch
Epoch: 9/20...  Training Step: 5388...  Training loss: 1.8565...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5389...  Training loss: 1.8550...  0.0586 sec/batch
Epoch: 9/20...  Training Step: 5390...  Training loss: 1.8170...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5391...  Training loss: 1.8407...  0.0572 sec/batch
Epoch: 9/20...  Training Step: 5392...  Training loss: 1.8886...  0.0579 sec/batch
Epoch: 9/20...  Training Step: 5393...  Training loss: 1.8641...  0.0618 sec/batch
Epoch: 9/20...  Training Step: 5394...  Training loss: 1.8517...  0.0551 sec/batch
Epoch: 9/20...  Training Step: 5395...  Training loss: 1.8261...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5396...  Training loss: 1.8365...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5397...  Training loss: 1.8069...  0.0557 sec/batch
Epoch: 9/20...  Training Step: 5398...  Training loss: 1.8535...  0.0559 sec/batch
Epoch: 9/20...  Training Step: 5399...  Training loss: 1.8587...  0.0522 sec/batch
Epoch: 9/20...  Training Step: 5400...  Training loss: 1.8335...  0.0553 sec/batch
Epoch: 9/20...  Training Step: 5401...  Training loss: 1.8749...  0.0560 sec/batch
Epoch: 9/20...  Training Step: 5402...  Training loss: 1.8495...  0.0558 sec/batch
Epoch: 9/20...  Training Step: 5403...  Training loss: 1.8882...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5404...  Training loss: 1.8623...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5405...  Training loss: 1.7536...  0.0558 sec/batch
Epoch: 9/20...  Training Step: 5406...  Training loss: 1.8564...  0.0584 sec/batch
Epoch: 9/20...  Training Step: 5407...  Training loss: 1.8254...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5408...  Training loss: 1.8206...  0.0554 sec/batch
Epoch: 9/20...  Training Step: 5409...  Training loss: 1.8497...  0.0531 sec/batch
Epoch: 9/20...  Training Step: 5410...  Training loss: 1.9069...  0.0527 sec/batch
Epoch: 9/20...  Training Step: 5411...  Training loss: 1.9063...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5412...  Training loss: 1.8833...  0.0575 sec/batch
Epoch: 9/20...  Training Step: 5413...  Training loss: 1.8300...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5414...  Training loss: 1.8670...  0.0566 sec/batch
Epoch: 9/20...  Training Step: 5415...  Training loss: 1.8327...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5416...  Training loss: 1.8394...  0.0544 sec/batch
Epoch: 9/20...  Training Step: 5417...  Training loss: 1.8682...  0.0583 sec/batch
Epoch: 9/20...  Training Step: 5418...  Training loss: 1.8765...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5419...  Training loss: 1.8540...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5420...  Training loss: 1.8498...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5421...  Training loss: 1.8061...  0.0569 sec/batch
Epoch: 9/20...  Training Step: 5422...  Training loss: 1.8580...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5423...  Training loss: 1.8257...  0.0551 sec/batch
Epoch: 9/20...  Training Step: 5424...  Training loss: 1.8503...  0.0543 sec/batch
Epoch: 9/20...  Training Step: 5425...  Training loss: 1.9103...  0.0544 sec/batch
Epoch: 9/20...  Training Step: 5426...  Training loss: 1.8694...  0.0556 sec/batch
Epoch: 9/20...  Training Step: 5427...  Training loss: 1.8193...  0.0576 sec/batch
Epoch: 9/20...  Training Step: 5428...  Training loss: 1.8455...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5429...  Training loss: 1.8486...  0.0531 sec/batch
Epoch: 9/20...  Training Step: 5430...  Training loss: 1.8376...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5431...  Training loss: 1.8298...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5432...  Training loss: 1.8664...  0.0522 sec/batch
Epoch: 9/20...  Training Step: 5433...  Training loss: 1.8317...  0.0541 sec/batch
Epoch: 9/20...  Training Step: 5434...  Training loss: 1.8078...  0.0580 sec/batch
Epoch: 9/20...  Training Step: 5435...  Training loss: 1.9082...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5436...  Training loss: 1.9026...  0.0523 sec/batch
Epoch: 9/20...  Training Step: 5437...  Training loss: 1.8689...  0.0582 sec/batch
Epoch: 9/20...  Training Step: 5438...  Training loss: 1.9233...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5439...  Training loss: 1.8135...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5440...  Training loss: 1.9169...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5441...  Training loss: 1.8450...  0.0558 sec/batch
Epoch: 9/20...  Training Step: 5442...  Training loss: 1.8273...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5443...  Training loss: 1.8933...  0.0580 sec/batch
Epoch: 9/20...  Training Step: 5444...  Training loss: 1.8390...  0.0591 sec/batch
Epoch: 9/20...  Training Step: 5445...  Training loss: 1.9012...  0.0553 sec/batch
Epoch: 9/20...  Training Step: 5446...  Training loss: 1.8300...  0.0559 sec/batch
Epoch: 9/20...  Training Step: 5447...  Training loss: 1.8748...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5448...  Training loss: 1.8611...  0.0542 sec/batch
Epoch: 9/20...  Training Step: 5449...  Training loss: 1.8696...  0.0535 sec/batch
Epoch: 9/20...  Training Step: 5450...  Training loss: 1.8584...  0.0554 sec/batch
Epoch: 9/20...  Training Step: 5451...  Training loss: 1.8466...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5452...  Training loss: 1.8801...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5453...  Training loss: 1.8460...  0.0554 sec/batch
Epoch: 9/20...  Training Step: 5454...  Training loss: 1.8397...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5455...  Training loss: 1.8376...  0.0575 sec/batch
Epoch: 9/20...  Training Step: 5456...  Training loss: 1.8720...  0.0553 sec/batch
Epoch: 9/20...  Training Step: 5457...  Training loss: 1.8446...  0.0534 sec/batch
Epoch: 9/20...  Training Step: 5458...  Training loss: 1.9082...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5459...  Training loss: 1.7964...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5460...  Training loss: 1.8623...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5461...  Training loss: 1.8697...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5462...  Training loss: 1.8888...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5463...  Training loss: 1.9292...  0.0522 sec/batch
Epoch: 9/20...  Training Step: 5464...  Training loss: 1.8795...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5465...  Training loss: 1.8281...  0.0570 sec/batch
Epoch: 9/20...  Training Step: 5466...  Training loss: 1.8219...  0.0579 sec/batch
Epoch: 9/20...  Training Step: 5467...  Training loss: 1.8703...  0.0551 sec/batch
Epoch: 9/20...  Training Step: 5468...  Training loss: 1.8294...  0.0523 sec/batch
Epoch: 9/20...  Training Step: 5469...  Training loss: 1.8853...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5470...  Training loss: 1.8739...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5471...  Training loss: 1.9129...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5472...  Training loss: 1.8815...  0.0582 sec/batch
Epoch: 9/20...  Training Step: 5473...  Training loss: 1.9075...  0.0645 sec/batch
Epoch: 9/20...  Training Step: 5474...  Training loss: 1.8981...  0.0531 sec/batch
Epoch: 9/20...  Training Step: 5475...  Training loss: 1.8895...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5476...  Training loss: 1.8453...  0.0533 sec/batch
Epoch: 9/20...  Training Step: 5477...  Training loss: 1.8703...  0.0553 sec/batch
Epoch: 9/20...  Training Step: 5478...  Training loss: 1.8669...  0.0571 sec/batch
Epoch: 9/20...  Training Step: 5479...  Training loss: 1.8447...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5480...  Training loss: 1.8331...  0.0579 sec/batch
Epoch: 9/20...  Training Step: 5481...  Training loss: 1.8386...  0.0577 sec/batch
Epoch: 9/20...  Training Step: 5482...  Training loss: 1.8182...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5483...  Training loss: 1.8421...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5484...  Training loss: 1.7666...  0.0542 sec/batch
Epoch: 9/20...  Training Step: 5485...  Training loss: 1.8752...  0.0587 sec/batch
Epoch: 9/20...  Training Step: 5486...  Training loss: 1.8985...  0.0530 sec/batch
Epoch: 9/20...  Training Step: 5487...  Training loss: 1.8989...  0.0556 sec/batch
Epoch: 9/20...  Training Step: 5488...  Training loss: 1.8740...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5489...  Training loss: 1.8558...  0.0556 sec/batch
Epoch: 9/20...  Training Step: 5490...  Training loss: 1.8237...  0.0541 sec/batch
Epoch: 9/20...  Training Step: 5491...  Training loss: 1.8521...  0.0551 sec/batch
Epoch: 9/20...  Training Step: 5492...  Training loss: 1.8293...  0.0525 sec/batch
Epoch: 9/20...  Training Step: 5493...  Training loss: 1.8204...  0.0527 sec/batch
Epoch: 9/20...  Training Step: 5494...  Training loss: 1.8455...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5495...  Training loss: 1.8759...  0.0522 sec/batch
Epoch: 9/20...  Training Step: 5496...  Training loss: 1.8590...  0.0585 sec/batch
Epoch: 9/20...  Training Step: 5497...  Training loss: 1.8199...  0.0543 sec/batch
Epoch: 9/20...  Training Step: 5498...  Training loss: 1.8490...  0.0577 sec/batch
Epoch: 9/20...  Training Step: 5499...  Training loss: 1.7894...  0.0541 sec/batch
Epoch: 9/20...  Training Step: 5500...  Training loss: 1.8649...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5501...  Training loss: 1.8723...  0.0542 sec/batch
Epoch: 9/20...  Training Step: 5502...  Training loss: 1.8266...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5503...  Training loss: 1.8411...  0.0578 sec/batch
Epoch: 9/20...  Training Step: 5504...  Training loss: 1.8012...  0.0525 sec/batch
Epoch: 9/20...  Training Step: 5505...  Training loss: 1.8974...  0.0532 sec/batch
Epoch: 9/20...  Training Step: 5506...  Training loss: 1.8515...  0.0540 sec/batch
Epoch: 9/20...  Training Step: 5507...  Training loss: 1.8863...  0.0544 sec/batch
Epoch: 9/20...  Training Step: 5508...  Training loss: 1.9061...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5509...  Training loss: 1.8974...  0.0572 sec/batch
Epoch: 9/20...  Training Step: 5510...  Training loss: 1.8420...  0.0541 sec/batch
Epoch: 9/20...  Training Step: 5511...  Training loss: 1.8726...  0.0587 sec/batch
Epoch: 9/20...  Training Step: 5512...  Training loss: 1.8056...  0.0544 sec/batch
Epoch: 9/20...  Training Step: 5513...  Training loss: 1.8609...  0.0568 sec/batch
Epoch: 9/20...  Training Step: 5514...  Training loss: 1.8447...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5515...  Training loss: 1.8263...  0.0601 sec/batch
Epoch: 9/20...  Training Step: 5516...  Training loss: 1.8285...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5517...  Training loss: 1.8426...  0.0607 sec/batch
Epoch: 9/20...  Training Step: 5518...  Training loss: 1.8170...  0.0525 sec/batch
Epoch: 9/20...  Training Step: 5519...  Training loss: 1.8545...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5520...  Training loss: 1.8340...  0.0565 sec/batch
Epoch: 9/20...  Training Step: 5521...  Training loss: 1.8935...  0.0566 sec/batch
Epoch: 9/20...  Training Step: 5522...  Training loss: 1.8549...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5523...  Training loss: 1.8654...  0.0566 sec/batch
Epoch: 9/20...  Training Step: 5524...  Training loss: 1.9273...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5525...  Training loss: 1.9534...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5526...  Training loss: 1.9213...  0.0564 sec/batch
Epoch: 9/20...  Training Step: 5527...  Training loss: 1.8448...  0.0579 sec/batch
Epoch: 9/20...  Training Step: 5528...  Training loss: 1.9175...  0.0551 sec/batch
Epoch: 9/20...  Training Step: 5529...  Training loss: 1.8270...  0.0528 sec/batch
Epoch: 9/20...  Training Step: 5530...  Training loss: 1.8775...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5531...  Training loss: 1.8682...  0.0542 sec/batch
Epoch: 9/20...  Training Step: 5532...  Training loss: 1.9239...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5533...  Training loss: 1.8421...  0.0525 sec/batch
Epoch: 9/20...  Training Step: 5534...  Training loss: 1.8436...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5535...  Training loss: 1.8533...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5536...  Training loss: 1.8720...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5537...  Training loss: 1.8147...  0.0523 sec/batch
Epoch: 9/20...  Training Step: 5538...  Training loss: 1.8715...  0.0533 sec/batch
Epoch: 9/20...  Training Step: 5539...  Training loss: 1.8787...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5540...  Training loss: 1.8794...  0.0581 sec/batch
Epoch: 9/20...  Training Step: 5541...  Training loss: 1.8930...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5542...  Training loss: 1.8534...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5543...  Training loss: 1.8612...  0.0557 sec/batch
Epoch: 9/20...  Training Step: 5544...  Training loss: 1.8869...  0.0522 sec/batch
Epoch: 9/20...  Training Step: 5545...  Training loss: 1.8695...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5546...  Training loss: 1.8619...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5547...  Training loss: 1.8220...  0.0551 sec/batch
Epoch: 9/20...  Training Step: 5548...  Training loss: 1.8662...  0.0522 sec/batch
Epoch: 9/20...  Training Step: 5549...  Training loss: 1.8326...  0.0579 sec/batch
Epoch: 9/20...  Training Step: 5550...  Training loss: 1.8857...  0.0575 sec/batch
Epoch: 9/20...  Training Step: 5551...  Training loss: 1.8046...  0.0632 sec/batch
Epoch: 9/20...  Training Step: 5552...  Training loss: 1.9059...  0.0550 sec/batch
Epoch: 9/20...  Training Step: 5553...  Training loss: 1.8515...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5554...  Training loss: 1.8302...  0.0583 sec/batch
Epoch: 9/20...  Training Step: 5555...  Training loss: 1.8156...  0.0523 sec/batch
Epoch: 9/20...  Training Step: 5556...  Training loss: 1.8428...  0.0557 sec/batch
Epoch: 9/20...  Training Step: 5557...  Training loss: 1.8224...  0.0588 sec/batch
Epoch: 9/20...  Training Step: 5558...  Training loss: 1.8512...  0.0522 sec/batch
Epoch: 9/20...  Training Step: 5559...  Training loss: 1.8783...  0.0548 sec/batch
Epoch: 9/20...  Training Step: 5560...  Training loss: 1.8897...  0.0583 sec/batch
Epoch: 9/20...  Training Step: 5561...  Training loss: 1.8395...  0.0536 sec/batch
Epoch: 9/20...  Training Step: 5562...  Training loss: 1.8515...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5563...  Training loss: 1.8416...  0.0526 sec/batch
Epoch: 9/20...  Training Step: 5564...  Training loss: 1.8116...  0.0525 sec/batch
Epoch: 9/20...  Training Step: 5565...  Training loss: 1.8606...  0.0553 sec/batch
Epoch: 9/20...  Training Step: 5566...  Training loss: 1.8457...  0.0566 sec/batch
Epoch: 9/20...  Training Step: 5567...  Training loss: 1.8233...  0.0546 sec/batch
Epoch: 9/20...  Training Step: 5568...  Training loss: 1.8198...  0.0579 sec/batch
Epoch: 9/20...  Training Step: 5569...  Training loss: 1.8349...  0.0521 sec/batch
Epoch: 9/20...  Training Step: 5570...  Training loss: 1.9018...  0.0552 sec/batch
Epoch: 9/20...  Training Step: 5571...  Training loss: 1.8902...  0.0549 sec/batch
Epoch: 9/20...  Training Step: 5572...  Training loss: 1.8877...  0.0551 sec/batch
Epoch: 9/20...  Training Step: 5573...  Training loss: 1.8186...  0.0588 sec/batch
Epoch: 9/20...  Training Step: 5574...  Training loss: 1.8767...  0.0557 sec/batch
Epoch: 9/20...  Training Step: 5575...  Training loss: 1.8105...  0.0545 sec/batch
Epoch: 9/20...  Training Step: 5576...  Training loss: 1.8705...  0.0524 sec/batch
Epoch: 9/20...  Training Step: 5577...  Training loss: 1.9129...  0.0529 sec/batch
Epoch: 9/20...  Training Step: 5578...  Training loss: 1.8233...  0.0543 sec/batch
Epoch: 9/20...  Training Step: 5579...  Training loss: 1.8217...  0.0547 sec/batch
Epoch: 9/20...  Training Step: 5580...  Training loss: 1.8031...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 5581...  Training loss: 1.9415...  0.0546 sec/batch
Epoch: 10/20...  Training Step: 5582...  Training loss: 1.9349...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 5583...  Training loss: 1.8912...  0.0553 sec/batch
Epoch: 10/20...  Training Step: 5584...  Training loss: 1.8233...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 5585...  Training loss: 1.8364...  0.0533 sec/batch
Epoch: 10/20...  Training Step: 5586...  Training loss: 1.8765...  0.0533 sec/batch
Epoch: 10/20...  Training Step: 5587...  Training loss: 1.8161...  0.0601 sec/batch
Epoch: 10/20...  Training Step: 5588...  Training loss: 1.8075...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5589...  Training loss: 1.7904...  0.0572 sec/batch
Epoch: 10/20...  Training Step: 5590...  Training loss: 1.8270...  0.0581 sec/batch
Epoch: 10/20...  Training Step: 5591...  Training loss: 1.8427...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 5592...  Training loss: 1.8175...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5593...  Training loss: 1.8639...  0.0520 sec/batch
Epoch: 10/20...  Training Step: 5594...  Training loss: 1.8164...  0.0578 sec/batch
Epoch: 10/20...  Training Step: 5595...  Training loss: 1.8851...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 5596...  Training loss: 1.8841...  0.0541 sec/batch
Epoch: 10/20...  Training Step: 5597...  Training loss: 1.8836...  0.0536 sec/batch
Epoch: 10/20...  Training Step: 5598...  Training loss: 1.8565...  0.0543 sec/batch
Epoch: 10/20...  Training Step: 5599...  Training loss: 1.8214...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5600...  Training loss: 1.8751...  0.0543 sec/batch
Epoch: 10/20...  Training Step: 5601...  Training loss: 1.9076...  0.0554 sec/batch
Epoch: 10/20...  Training Step: 5602...  Training loss: 1.8362...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 5603...  Training loss: 1.8371...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 5604...  Training loss: 1.8731...  0.0557 sec/batch
Epoch: 10/20...  Training Step: 5605...  Training loss: 1.8333...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 5606...  Training loss: 1.8178...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 5607...  Training loss: 1.8401...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5608...  Training loss: 1.8399...  0.0561 sec/batch
Epoch: 10/20...  Training Step: 5609...  Training loss: 1.8433...  0.0532 sec/batch
Epoch: 10/20...  Training Step: 5610...  Training loss: 1.8217...  0.0585 sec/batch
Epoch: 10/20...  Training Step: 5611...  Training loss: 1.8075...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 5612...  Training loss: 1.8742...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5613...  Training loss: 1.8310...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 5614...  Training loss: 1.8316...  0.0584 sec/batch
Epoch: 10/20...  Training Step: 5615...  Training loss: 1.8369...  0.0552 sec/batch
Epoch: 10/20...  Training Step: 5616...  Training loss: 1.8464...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 5617...  Training loss: 1.8550...  0.0590 sec/batch
Epoch: 10/20...  Training Step: 5618...  Training loss: 1.8686...  0.0595 sec/batch
Epoch: 10/20...  Training Step: 5619...  Training loss: 1.8565...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5620...  Training loss: 1.8057...  0.0522 sec/batch
Epoch: 10/20...  Training Step: 5621...  Training loss: 1.8517...  0.0559 sec/batch
Epoch: 10/20...  Training Step: 5622...  Training loss: 1.8706...  0.0546 sec/batch
Epoch: 10/20...  Training Step: 5623...  Training loss: 1.8402...  0.0531 sec/batch
Epoch: 10/20...  Training Step: 5624...  Training loss: 1.8668...  0.0577 sec/batch
Epoch: 10/20...  Training Step: 5625...  Training loss: 1.8275...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5626...  Training loss: 1.8310...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5627...  Training loss: 1.7248...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 5628...  Training loss: 1.8484...  0.0523 sec/batch
Epoch: 10/20...  Training Step: 5629...  Training loss: 1.8138...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 5630...  Training loss: 1.8486...  0.0579 sec/batch
Epoch: 10/20...  Training Step: 5631...  Training loss: 1.8182...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5632...  Training loss: 1.8130...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 5633...  Training loss: 1.8447...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5634...  Training loss: 1.8643...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 5635...  Training loss: 1.8879...  0.0531 sec/batch
Epoch: 10/20...  Training Step: 5636...  Training loss: 1.8451...  0.0588 sec/batch
Epoch: 10/20...  Training Step: 5637...  Training loss: 1.8191...  0.0520 sec/batch
Epoch: 10/20...  Training Step: 5638...  Training loss: 1.8507...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5639...  Training loss: 1.8524...  0.0553 sec/batch
Epoch: 10/20...  Training Step: 5640...  Training loss: 1.8829...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 5641...  Training loss: 1.8552...  0.0565 sec/batch
Epoch: 10/20...  Training Step: 5642...  Training loss: 1.8219...  0.0522 sec/batch
Epoch: 10/20...  Training Step: 5643...  Training loss: 1.8725...  0.0533 sec/batch
Epoch: 10/20...  Training Step: 5644...  Training loss: 1.8148...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5645...  Training loss: 1.8258...  0.0543 sec/batch
Epoch: 10/20...  Training Step: 5646...  Training loss: 1.7918...  0.0574 sec/batch
Epoch: 10/20...  Training Step: 5647...  Training loss: 1.8171...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5648...  Training loss: 1.8088...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5649...  Training loss: 1.8538...  0.0587 sec/batch
Epoch: 10/20...  Training Step: 5650...  Training loss: 1.8489...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5651...  Training loss: 1.8740...  0.0542 sec/batch
Epoch: 10/20...  Training Step: 5652...  Training loss: 1.8722...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 5653...  Training loss: 1.7815...  0.0596 sec/batch
Epoch: 10/20...  Training Step: 5654...  Training loss: 1.8345...  0.0583 sec/batch
Epoch: 10/20...  Training Step: 5655...  Training loss: 1.8911...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5656...  Training loss: 1.8467...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5657...  Training loss: 1.8493...  0.0519 sec/batch
Epoch: 10/20...  Training Step: 5658...  Training loss: 1.8279...  0.0538 sec/batch
Epoch: 10/20...  Training Step: 5659...  Training loss: 1.8461...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 5660...  Training loss: 1.8481...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 5661...  Training loss: 1.8043...  0.0540 sec/batch
Epoch: 10/20...  Training Step: 5662...  Training loss: 1.8617...  0.0540 sec/batch
Epoch: 10/20...  Training Step: 5663...  Training loss: 1.7902...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5664...  Training loss: 1.8218...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 5665...  Training loss: 1.8346...  0.0535 sec/batch
Epoch: 10/20...  Training Step: 5666...  Training loss: 1.8861...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5667...  Training loss: 1.8078...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5668...  Training loss: 1.8804...  0.0578 sec/batch
Epoch: 10/20...  Training Step: 5669...  Training loss: 1.8321...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 5670...  Training loss: 1.8511...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 5671...  Training loss: 1.8026...  0.0540 sec/batch
Epoch: 10/20...  Training Step: 5672...  Training loss: 1.8975...  0.0577 sec/batch
Epoch: 10/20...  Training Step: 5673...  Training loss: 1.8380...  0.0536 sec/batch
Epoch: 10/20...  Training Step: 5674...  Training loss: 1.8480...  0.0552 sec/batch
Epoch: 10/20...  Training Step: 5675...  Training loss: 1.8374...  0.0582 sec/batch
Epoch: 10/20...  Training Step: 5676...  Training loss: 1.8693...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5677...  Training loss: 1.8624...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 5678...  Training loss: 1.7823...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 5679...  Training loss: 1.8918...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5680...  Training loss: 1.8227...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 5681...  Training loss: 1.8378...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5682...  Training loss: 1.7934...  0.0568 sec/batch
Epoch: 10/20...  Training Step: 5683...  Training loss: 1.8727...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 5684...  Training loss: 1.8910...  0.0546 sec/batch
Epoch: 10/20...  Training Step: 5685...  Training loss: 1.8447...  0.0531 sec/batch
Epoch: 10/20...  Training Step: 5686...  Training loss: 1.8181...  0.0562 sec/batch
Epoch: 10/20...  Training Step: 5687...  Training loss: 1.8535...  0.0624 sec/batch
Epoch: 10/20...  Training Step: 5688...  Training loss: 1.8239...  0.0539 sec/batch
Epoch: 10/20...  Training Step: 5689...  Training loss: 1.8289...  0.0532 sec/batch
Epoch: 10/20...  Training Step: 5690...  Training loss: 1.8093...  0.0577 sec/batch
Epoch: 10/20...  Training Step: 5691...  Training loss: 1.7968...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5692...  Training loss: 1.8296...  0.0532 sec/batch
Epoch: 10/20...  Training Step: 5693...  Training loss: 1.8316...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5694...  Training loss: 1.8053...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5695...  Training loss: 1.8555...  0.0541 sec/batch
Epoch: 10/20...  Training Step: 5696...  Training loss: 1.8802...  0.0546 sec/batch
Epoch: 10/20...  Training Step: 5697...  Training loss: 1.7894...  0.0554 sec/batch
Epoch: 10/20...  Training Step: 5698...  Training loss: 1.8752...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5699...  Training loss: 1.8215...  0.0561 sec/batch
Epoch: 10/20...  Training Step: 5700...  Training loss: 1.8152...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 5701...  Training loss: 1.8292...  0.0554 sec/batch
Epoch: 10/20...  Training Step: 5702...  Training loss: 1.7914...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 5703...  Training loss: 1.8196...  0.0559 sec/batch
Epoch: 10/20...  Training Step: 5704...  Training loss: 1.8755...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 5705...  Training loss: 1.8648...  0.0534 sec/batch
Epoch: 10/20...  Training Step: 5706...  Training loss: 1.8778...  0.0520 sec/batch
Epoch: 10/20...  Training Step: 5707...  Training loss: 1.8908...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5708...  Training loss: 1.8102...  0.0582 sec/batch
Epoch: 10/20...  Training Step: 5709...  Training loss: 1.8372...  0.0588 sec/batch
Epoch: 10/20...  Training Step: 5710...  Training loss: 1.8898...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5711...  Training loss: 1.8177...  0.0523 sec/batch
Epoch: 10/20...  Training Step: 5712...  Training loss: 1.8689...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 5713...  Training loss: 1.8774...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 5714...  Training loss: 1.8275...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5715...  Training loss: 1.8088...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5716...  Training loss: 1.8558...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5717...  Training loss: 1.8385...  0.0571 sec/batch
Epoch: 10/20...  Training Step: 5718...  Training loss: 1.8401...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5719...  Training loss: 1.8988...  0.0575 sec/batch
Epoch: 10/20...  Training Step: 5720...  Training loss: 1.8435...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 5721...  Training loss: 1.8622...  0.0581 sec/batch
Epoch: 10/20...  Training Step: 5722...  Training loss: 1.7581...  0.0546 sec/batch
Epoch: 10/20...  Training Step: 5723...  Training loss: 1.8514...  0.0556 sec/batch
Epoch: 10/20...  Training Step: 5724...  Training loss: 1.8238...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 5725...  Training loss: 1.7953...  0.0586 sec/batch
Epoch: 10/20...  Training Step: 5726...  Training loss: 1.8727...  0.0582 sec/batch
Epoch: 10/20...  Training Step: 5727...  Training loss: 1.8765...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5728...  Training loss: 1.8697...  0.0534 sec/batch
Epoch: 10/20...  Training Step: 5729...  Training loss: 1.8273...  0.0521 sec/batch
Epoch: 10/20...  Training Step: 5730...  Training loss: 1.8546...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5731...  Training loss: 1.8652...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 5732...  Training loss: 1.8220...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 5733...  Training loss: 1.8398...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 5734...  Training loss: 1.8832...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5735...  Training loss: 1.8127...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 5736...  Training loss: 1.8337...  0.0533 sec/batch
Epoch: 10/20...  Training Step: 5737...  Training loss: 1.8439...  0.0522 sec/batch
Epoch: 10/20...  Training Step: 5738...  Training loss: 1.8587...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5739...  Training loss: 1.8628...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5740...  Training loss: 1.8028...  0.0538 sec/batch
Epoch: 10/20...  Training Step: 5741...  Training loss: 1.7977...  0.0575 sec/batch
Epoch: 10/20...  Training Step: 5742...  Training loss: 1.8188...  0.0542 sec/batch
Epoch: 10/20...  Training Step: 5743...  Training loss: 1.8639...  0.0531 sec/batch
Epoch: 10/20...  Training Step: 5744...  Training loss: 1.8519...  0.0531 sec/batch
Epoch: 10/20...  Training Step: 5745...  Training loss: 1.8505...  0.0552 sec/batch
Epoch: 10/20...  Training Step: 5746...  Training loss: 1.8607...  0.0575 sec/batch
Epoch: 10/20...  Training Step: 5747...  Training loss: 1.8663...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5748...  Training loss: 1.8540...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5749...  Training loss: 1.8487...  0.0562 sec/batch
Epoch: 10/20...  Training Step: 5750...  Training loss: 1.7848...  0.0559 sec/batch
Epoch: 10/20...  Training Step: 5751...  Training loss: 1.8225...  0.0583 sec/batch
Epoch: 10/20...  Training Step: 5752...  Training loss: 1.8448...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5753...  Training loss: 1.8445...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 5754...  Training loss: 1.8351...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5755...  Training loss: 1.8184...  0.0522 sec/batch
Epoch: 10/20...  Training Step: 5756...  Training loss: 1.8377...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5757...  Training loss: 1.8682...  0.0558 sec/batch
Epoch: 10/20...  Training Step: 5758...  Training loss: 1.8147...  0.0552 sec/batch
Epoch: 10/20...  Training Step: 5759...  Training loss: 1.8194...  0.0531 sec/batch
Epoch: 10/20...  Training Step: 5760...  Training loss: 1.8316...  0.0578 sec/batch
Epoch: 10/20...  Training Step: 5761...  Training loss: 1.8129...  0.0563 sec/batch
Epoch: 10/20...  Training Step: 5762...  Training loss: 1.8571...  0.0562 sec/batch
Epoch: 10/20...  Training Step: 5763...  Training loss: 1.8470...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 5764...  Training loss: 1.8061...  0.0521 sec/batch
Epoch: 10/20...  Training Step: 5765...  Training loss: 1.7990...  0.0554 sec/batch
Epoch: 10/20...  Training Step: 5766...  Training loss: 1.8412...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5767...  Training loss: 1.8226...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5768...  Training loss: 1.8396...  0.0546 sec/batch
Epoch: 10/20...  Training Step: 5769...  Training loss: 1.8232...  0.0562 sec/batch
Epoch: 10/20...  Training Step: 5770...  Training loss: 1.9005...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 5771...  Training loss: 1.8528...  0.0563 sec/batch
Epoch: 10/20...  Training Step: 5772...  Training loss: 1.8922...  0.0552 sec/batch
Epoch: 10/20...  Training Step: 5773...  Training loss: 1.8717...  0.0540 sec/batch
Epoch: 10/20...  Training Step: 5774...  Training loss: 1.8251...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 5775...  Training loss: 1.8363...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5776...  Training loss: 1.8970...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5777...  Training loss: 1.8416...  0.0521 sec/batch
Epoch: 10/20...  Training Step: 5778...  Training loss: 1.9234...  0.0532 sec/batch
Epoch: 10/20...  Training Step: 5779...  Training loss: 1.8291...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5780...  Training loss: 1.8589...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5781...  Training loss: 1.8247...  0.0561 sec/batch
Epoch: 10/20...  Training Step: 5782...  Training loss: 1.8261...  0.0554 sec/batch
Epoch: 10/20...  Training Step: 5783...  Training loss: 1.8209...  0.0531 sec/batch
Epoch: 10/20...  Training Step: 5784...  Training loss: 1.8136...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5785...  Training loss: 1.8525...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5786...  Training loss: 1.8077...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 5787...  Training loss: 1.8655...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5788...  Training loss: 1.8357...  0.0522 sec/batch
Epoch: 10/20...  Training Step: 5789...  Training loss: 1.8283...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 5790...  Training loss: 1.7996...  0.0574 sec/batch
Epoch: 10/20...  Training Step: 5791...  Training loss: 1.8457...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 5792...  Training loss: 1.8330...  0.0582 sec/batch
Epoch: 10/20...  Training Step: 5793...  Training loss: 1.8482...  0.0521 sec/batch
Epoch: 10/20...  Training Step: 5794...  Training loss: 1.8716...  0.0535 sec/batch
Epoch: 10/20...  Training Step: 5795...  Training loss: 1.8685...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 5796...  Training loss: 1.8658...  0.0558 sec/batch
Epoch: 10/20...  Training Step: 5797...  Training loss: 1.8740...  0.0605 sec/batch
Epoch: 10/20...  Training Step: 5798...  Training loss: 1.7949...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 5799...  Training loss: 1.9106...  0.0585 sec/batch
Epoch: 10/20...  Training Step: 5800...  Training loss: 1.8755...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 5801...  Training loss: 1.8668...  0.0554 sec/batch
Epoch: 10/20...  Training Step: 5802...  Training loss: 1.8974...  0.0591 sec/batch
Epoch: 10/20...  Training Step: 5803...  Training loss: 1.8884...  0.0552 sec/batch
Epoch: 10/20...  Training Step: 5804...  Training loss: 1.8022...  0.0563 sec/batch
Epoch: 10/20...  Training Step: 5805...  Training loss: 1.8052...  0.0531 sec/batch
Epoch: 10/20...  Training Step: 5806...  Training loss: 1.8789...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 5807...  Training loss: 1.8807...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5808...  Training loss: 1.8085...  0.0542 sec/batch
Epoch: 10/20...  Training Step: 5809...  Training loss: 1.8817...  0.0555 sec/batch
Epoch: 10/20...  Training Step: 5810...  Training loss: 1.8286...  0.0567 sec/batch
Epoch: 10/20...  Training Step: 5811...  Training loss: 1.8992...  0.0554 sec/batch
Epoch: 10/20...  Training Step: 5812...  Training loss: 1.8025...  0.0561 sec/batch
Epoch: 10/20...  Training Step: 5813...  Training loss: 1.8059...  0.0537 sec/batch
Epoch: 10/20...  Training Step: 5814...  Training loss: 1.8181...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5815...  Training loss: 1.8219...  0.0559 sec/batch
Epoch: 10/20...  Training Step: 5816...  Training loss: 1.8460...  0.0580 sec/batch
Epoch: 10/20...  Training Step: 5817...  Training loss: 1.8394...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5818...  Training loss: 1.7997...  0.0555 sec/batch
Epoch: 10/20...  Training Step: 5819...  Training loss: 1.8145...  0.0523 sec/batch
Epoch: 10/20...  Training Step: 5820...  Training loss: 1.8667...  0.0531 sec/batch
Epoch: 10/20...  Training Step: 5821...  Training loss: 1.8331...  0.0522 sec/batch
Epoch: 10/20...  Training Step: 5822...  Training loss: 1.8036...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5823...  Training loss: 1.8268...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 5824...  Training loss: 1.8070...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5825...  Training loss: 1.8332...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 5826...  Training loss: 1.8494...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 5827...  Training loss: 1.8613...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5828...  Training loss: 1.8346...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5829...  Training loss: 1.7896...  0.0559 sec/batch
Epoch: 10/20...  Training Step: 5830...  Training loss: 1.8154...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 5831...  Training loss: 1.8430...  0.0558 sec/batch
Epoch: 10/20...  Training Step: 5832...  Training loss: 1.8031...  0.0522 sec/batch
Epoch: 10/20...  Training Step: 5833...  Training loss: 1.8625...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5834...  Training loss: 1.8633...  0.0523 sec/batch
Epoch: 10/20...  Training Step: 5835...  Training loss: 1.8895...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5836...  Training loss: 1.8433...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5837...  Training loss: 1.8298...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5838...  Training loss: 1.8278...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5839...  Training loss: 1.8570...  0.0533 sec/batch
Epoch: 10/20...  Training Step: 5840...  Training loss: 1.8299...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5841...  Training loss: 1.8458...  0.0543 sec/batch
Epoch: 10/20...  Training Step: 5842...  Training loss: 1.8216...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 5843...  Training loss: 1.8305...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5844...  Training loss: 1.8372...  0.0546 sec/batch
Epoch: 10/20...  Training Step: 5845...  Training loss: 1.8589...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 5846...  Training loss: 1.7854...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5847...  Training loss: 1.8404...  0.0586 sec/batch
Epoch: 10/20...  Training Step: 5848...  Training loss: 1.8564...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 5849...  Training loss: 1.8320...  0.0597 sec/batch
Epoch: 10/20...  Training Step: 5850...  Training loss: 1.8105...  0.0580 sec/batch
Epoch: 10/20...  Training Step: 5851...  Training loss: 1.8044...  0.0553 sec/batch
Epoch: 10/20...  Training Step: 5852...  Training loss: 1.8251...  0.0546 sec/batch
Epoch: 10/20...  Training Step: 5853...  Training loss: 1.8252...  0.0569 sec/batch
Epoch: 10/20...  Training Step: 5854...  Training loss: 1.8218...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5855...  Training loss: 1.8527...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 5856...  Training loss: 1.8774...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5857...  Training loss: 1.9238...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5858...  Training loss: 1.8436...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 5859...  Training loss: 1.8741...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 5860...  Training loss: 1.8859...  0.0583 sec/batch
Epoch: 10/20...  Training Step: 5861...  Training loss: 1.8390...  0.0575 sec/batch
Epoch: 10/20...  Training Step: 5862...  Training loss: 1.7692...  0.0534 sec/batch
Epoch: 10/20...  Training Step: 5863...  Training loss: 1.7890...  0.0577 sec/batch
Epoch: 10/20...  Training Step: 5864...  Training loss: 1.8565...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5865...  Training loss: 1.8152...  0.0591 sec/batch
Epoch: 10/20...  Training Step: 5866...  Training loss: 1.8539...  0.0594 sec/batch
Epoch: 10/20...  Training Step: 5867...  Training loss: 1.8133...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5868...  Training loss: 1.8490...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 5869...  Training loss: 1.8476...  0.0531 sec/batch
Epoch: 10/20...  Training Step: 5870...  Training loss: 1.8882...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 5871...  Training loss: 1.8251...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5872...  Training loss: 1.8086...  0.0568 sec/batch
Epoch: 10/20...  Training Step: 5873...  Training loss: 1.8342...  0.0538 sec/batch
Epoch: 10/20...  Training Step: 5874...  Training loss: 1.8572...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5875...  Training loss: 1.8156...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5876...  Training loss: 1.7960...  0.0579 sec/batch
Epoch: 10/20...  Training Step: 5877...  Training loss: 1.8388...  0.0558 sec/batch
Epoch: 10/20...  Training Step: 5878...  Training loss: 1.8864...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5879...  Training loss: 1.8739...  0.0565 sec/batch
Epoch: 10/20...  Training Step: 5880...  Training loss: 1.8579...  0.0570 sec/batch
Epoch: 10/20...  Training Step: 5881...  Training loss: 1.8557...  0.0554 sec/batch
Epoch: 10/20...  Training Step: 5882...  Training loss: 1.9317...  0.0543 sec/batch
Epoch: 10/20...  Training Step: 5883...  Training loss: 1.7996...  0.0566 sec/batch
Epoch: 10/20...  Training Step: 5884...  Training loss: 1.8727...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 5885...  Training loss: 1.7976...  0.0556 sec/batch
Epoch: 10/20...  Training Step: 5886...  Training loss: 1.8344...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 5887...  Training loss: 1.8316...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 5888...  Training loss: 1.8282...  0.0531 sec/batch
Epoch: 10/20...  Training Step: 5889...  Training loss: 1.8216...  0.0554 sec/batch
Epoch: 10/20...  Training Step: 5890...  Training loss: 1.7983...  0.0570 sec/batch
Epoch: 10/20...  Training Step: 5891...  Training loss: 1.7829...  0.0537 sec/batch
Epoch: 10/20...  Training Step: 5892...  Training loss: 1.8005...  0.0539 sec/batch
Epoch: 10/20...  Training Step: 5893...  Training loss: 1.8073...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 5894...  Training loss: 1.7840...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5895...  Training loss: 1.8348...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 5896...  Training loss: 1.8656...  0.0531 sec/batch
Epoch: 10/20...  Training Step: 5897...  Training loss: 1.8105...  0.0532 sec/batch
Epoch: 10/20...  Training Step: 5898...  Training loss: 1.8081...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5899...  Training loss: 1.7991...  0.0556 sec/batch
Epoch: 10/20...  Training Step: 5900...  Training loss: 1.8657...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5901...  Training loss: 1.8391...  0.0560 sec/batch
Epoch: 10/20...  Training Step: 5902...  Training loss: 1.7857...  0.0553 sec/batch
Epoch: 10/20...  Training Step: 5903...  Training loss: 1.8395...  0.0534 sec/batch
Epoch: 10/20...  Training Step: 5904...  Training loss: 1.8197...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 5905...  Training loss: 1.8183...  0.0556 sec/batch
Epoch: 10/20...  Training Step: 5906...  Training loss: 1.8322...  0.0521 sec/batch
Epoch: 10/20...  Training Step: 5907...  Training loss: 1.8047...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 5908...  Training loss: 1.7811...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5909...  Training loss: 1.8359...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5910...  Training loss: 1.8124...  0.0531 sec/batch
Epoch: 10/20...  Training Step: 5911...  Training loss: 1.7969...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 5912...  Training loss: 1.8196...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 5913...  Training loss: 1.8100...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5914...  Training loss: 1.8165...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5915...  Training loss: 1.8349...  0.0533 sec/batch
Epoch: 10/20...  Training Step: 5916...  Training loss: 1.8197...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5917...  Training loss: 1.7947...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 5918...  Training loss: 1.8141...  0.0546 sec/batch
Epoch: 10/20...  Training Step: 5919...  Training loss: 1.7997...  0.0523 sec/batch
Epoch: 10/20...  Training Step: 5920...  Training loss: 1.8332...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5921...  Training loss: 1.8257...  0.0569 sec/batch
Epoch: 10/20...  Training Step: 5922...  Training loss: 1.8097...  0.0594 sec/batch
Epoch: 10/20...  Training Step: 5923...  Training loss: 1.7886...  0.0552 sec/batch
Epoch: 10/20...  Training Step: 5924...  Training loss: 1.8065...  0.0532 sec/batch
Epoch: 10/20...  Training Step: 5925...  Training loss: 1.8258...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5926...  Training loss: 1.8391...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 5927...  Training loss: 1.8379...  0.0533 sec/batch
Epoch: 10/20...  Training Step: 5928...  Training loss: 1.8661...  0.0546 sec/batch
Epoch: 10/20...  Training Step: 5929...  Training loss: 1.8322...  0.0531 sec/batch
Epoch: 10/20...  Training Step: 5930...  Training loss: 1.8015...  0.0523 sec/batch
Epoch: 10/20...  Training Step: 5931...  Training loss: 1.8874...  0.0546 sec/batch
Epoch: 10/20...  Training Step: 5932...  Training loss: 1.8335...  0.0586 sec/batch
Epoch: 10/20...  Training Step: 5933...  Training loss: 1.8458...  0.0557 sec/batch
Epoch: 10/20...  Training Step: 5934...  Training loss: 1.8120...  0.0581 sec/batch
Epoch: 10/20...  Training Step: 5935...  Training loss: 1.8107...  0.0562 sec/batch
Epoch: 10/20...  Training Step: 5936...  Training loss: 1.8792...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5937...  Training loss: 1.9102...  0.0555 sec/batch
Epoch: 10/20...  Training Step: 5938...  Training loss: 1.8815...  0.0554 sec/batch
Epoch: 10/20...  Training Step: 5939...  Training loss: 1.8302...  0.0576 sec/batch
Epoch: 10/20...  Training Step: 5940...  Training loss: 1.8379...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5941...  Training loss: 1.8618...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5942...  Training loss: 1.8086...  0.0553 sec/batch
Epoch: 10/20...  Training Step: 5943...  Training loss: 1.7690...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 5944...  Training loss: 1.7715...  0.0543 sec/batch
Epoch: 10/20...  Training Step: 5945...  Training loss: 1.8304...  0.0534 sec/batch
Epoch: 10/20...  Training Step: 5946...  Training loss: 1.8253...  0.0541 sec/batch
Epoch: 10/20...  Training Step: 5947...  Training loss: 1.7896...  0.0552 sec/batch
Epoch: 10/20...  Training Step: 5948...  Training loss: 1.8756...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5949...  Training loss: 1.8441...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5950...  Training loss: 1.8155...  0.0543 sec/batch
Epoch: 10/20...  Training Step: 5951...  Training loss: 1.8281...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5952...  Training loss: 1.8937...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 5953...  Training loss: 1.8430...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 5954...  Training loss: 1.8300...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5955...  Training loss: 1.8301...  0.0562 sec/batch
Epoch: 10/20...  Training Step: 5956...  Training loss: 1.8402...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 5957...  Training loss: 1.7987...  0.0541 sec/batch
Epoch: 10/20...  Training Step: 5958...  Training loss: 1.8971...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5959...  Training loss: 1.8309...  0.0583 sec/batch
Epoch: 10/20...  Training Step: 5960...  Training loss: 1.8296...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 5961...  Training loss: 1.7632...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 5962...  Training loss: 1.8834...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5963...  Training loss: 1.8007...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 5964...  Training loss: 1.8389...  0.0543 sec/batch
Epoch: 10/20...  Training Step: 5965...  Training loss: 1.8387...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 5966...  Training loss: 1.7580...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 5967...  Training loss: 1.7684...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 5968...  Training loss: 1.8309...  0.0579 sec/batch
Epoch: 10/20...  Training Step: 5969...  Training loss: 1.7772...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5970...  Training loss: 1.8117...  0.0552 sec/batch
Epoch: 10/20...  Training Step: 5971...  Training loss: 1.8356...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5972...  Training loss: 1.7786...  0.0563 sec/batch
Epoch: 10/20...  Training Step: 5973...  Training loss: 1.8311...  0.0561 sec/batch
Epoch: 10/20...  Training Step: 5974...  Training loss: 1.8396...  0.0589 sec/batch
Epoch: 10/20...  Training Step: 5975...  Training loss: 1.7985...  0.0593 sec/batch
Epoch: 10/20...  Training Step: 5976...  Training loss: 1.8413...  0.0533 sec/batch
Epoch: 10/20...  Training Step: 5977...  Training loss: 1.8220...  0.0593 sec/batch
Epoch: 10/20...  Training Step: 5978...  Training loss: 1.8402...  0.0555 sec/batch
Epoch: 10/20...  Training Step: 5979...  Training loss: 1.8078...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5980...  Training loss: 1.8496...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 5981...  Training loss: 1.8690...  0.0558 sec/batch
Epoch: 10/20...  Training Step: 5982...  Training loss: 1.8502...  0.0577 sec/batch
Epoch: 10/20...  Training Step: 5983...  Training loss: 1.7932...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 5984...  Training loss: 1.8689...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 5985...  Training loss: 1.8907...  0.0543 sec/batch
Epoch: 10/20...  Training Step: 5986...  Training loss: 1.8669...  0.0534 sec/batch
Epoch: 10/20...  Training Step: 5987...  Training loss: 1.9176...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 5988...  Training loss: 1.8439...  0.0546 sec/batch
Epoch: 10/20...  Training Step: 5989...  Training loss: 1.8727...  0.0556 sec/batch
Epoch: 10/20...  Training Step: 5990...  Training loss: 1.8520...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 5991...  Training loss: 1.8029...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 5992...  Training loss: 1.8622...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 5993...  Training loss: 1.8521...  0.0591 sec/batch
Epoch: 10/20...  Training Step: 5994...  Training loss: 1.8260...  0.0561 sec/batch
Epoch: 10/20...  Training Step: 5995...  Training loss: 1.7920...  0.0565 sec/batch
Epoch: 10/20...  Training Step: 5996...  Training loss: 1.7692...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5997...  Training loss: 1.8300...  0.0556 sec/batch
Epoch: 10/20...  Training Step: 5998...  Training loss: 1.8361...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 5999...  Training loss: 1.8648...  0.0563 sec/batch
Epoch: 10/20...  Training Step: 6000...  Training loss: 1.8176...  0.0570 sec/batch
Epoch: 10/20...  Training Step: 6001...  Training loss: 1.7857...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 6002...  Training loss: 1.8284...  0.0586 sec/batch
Epoch: 10/20...  Training Step: 6003...  Training loss: 1.8420...  0.0553 sec/batch
Epoch: 10/20...  Training Step: 6004...  Training loss: 1.8005...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 6005...  Training loss: 1.8555...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 6006...  Training loss: 1.8499...  0.0570 sec/batch
Epoch: 10/20...  Training Step: 6007...  Training loss: 1.8123...  0.0539 sec/batch
Epoch: 10/20...  Training Step: 6008...  Training loss: 1.8319...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 6009...  Training loss: 1.8209...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 6010...  Training loss: 1.7947...  0.0539 sec/batch
Epoch: 10/20...  Training Step: 6011...  Training loss: 1.8232...  0.0542 sec/batch
Epoch: 10/20...  Training Step: 6012...  Training loss: 1.8882...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 6013...  Training loss: 1.8459...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 6014...  Training loss: 1.8027...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 6015...  Training loss: 1.7850...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 6016...  Training loss: 1.8258...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 6017...  Training loss: 1.7914...  0.0585 sec/batch
Epoch: 10/20...  Training Step: 6018...  Training loss: 1.8335...  0.0589 sec/batch
Epoch: 10/20...  Training Step: 6019...  Training loss: 1.8178...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 6020...  Training loss: 1.8316...  0.0573 sec/batch
Epoch: 10/20...  Training Step: 6021...  Training loss: 1.8319...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 6022...  Training loss: 1.8380...  0.0532 sec/batch
Epoch: 10/20...  Training Step: 6023...  Training loss: 1.8837...  0.0568 sec/batch
Epoch: 10/20...  Training Step: 6024...  Training loss: 1.8449...  0.0558 sec/batch
Epoch: 10/20...  Training Step: 6025...  Training loss: 1.7604...  0.0570 sec/batch
Epoch: 10/20...  Training Step: 6026...  Training loss: 1.8167...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 6027...  Training loss: 1.8019...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 6028...  Training loss: 1.7693...  0.0541 sec/batch
Epoch: 10/20...  Training Step: 6029...  Training loss: 1.8506...  0.0569 sec/batch
Epoch: 10/20...  Training Step: 6030...  Training loss: 1.8550...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 6031...  Training loss: 1.8896...  0.0580 sec/batch
Epoch: 10/20...  Training Step: 6032...  Training loss: 1.8565...  0.0532 sec/batch
Epoch: 10/20...  Training Step: 6033...  Training loss: 1.7808...  0.0583 sec/batch
Epoch: 10/20...  Training Step: 6034...  Training loss: 1.8410...  0.0552 sec/batch
Epoch: 10/20...  Training Step: 6035...  Training loss: 1.8113...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 6036...  Training loss: 1.8184...  0.0562 sec/batch
Epoch: 10/20...  Training Step: 6037...  Training loss: 1.8253...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 6038...  Training loss: 1.8462...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 6039...  Training loss: 1.8104...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 6040...  Training loss: 1.8277...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 6041...  Training loss: 1.7756...  0.0543 sec/batch
Epoch: 10/20...  Training Step: 6042...  Training loss: 1.8525...  0.0591 sec/batch
Epoch: 10/20...  Training Step: 6043...  Training loss: 1.8067...  0.0560 sec/batch
Epoch: 10/20...  Training Step: 6044...  Training loss: 1.8254...  0.0562 sec/batch
Epoch: 10/20...  Training Step: 6045...  Training loss: 1.8518...  0.0588 sec/batch
Epoch: 10/20...  Training Step: 6046...  Training loss: 1.8440...  0.0543 sec/batch
Epoch: 10/20...  Training Step: 6047...  Training loss: 1.8094...  0.0553 sec/batch
Epoch: 10/20...  Training Step: 6048...  Training loss: 1.8360...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 6049...  Training loss: 1.8486...  0.0574 sec/batch
Epoch: 10/20...  Training Step: 6050...  Training loss: 1.8336...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 6051...  Training loss: 1.8270...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 6052...  Training loss: 1.8383...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 6053...  Training loss: 1.8137...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 6054...  Training loss: 1.7839...  0.0567 sec/batch
Epoch: 10/20...  Training Step: 6055...  Training loss: 1.8976...  0.0546 sec/batch
Epoch: 10/20...  Training Step: 6056...  Training loss: 1.8690...  0.0552 sec/batch
Epoch: 10/20...  Training Step: 6057...  Training loss: 1.8424...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 6058...  Training loss: 1.8855...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 6059...  Training loss: 1.7994...  0.0554 sec/batch
Epoch: 10/20...  Training Step: 6060...  Training loss: 1.8627...  0.0564 sec/batch
Epoch: 10/20...  Training Step: 6061...  Training loss: 1.8291...  0.0556 sec/batch
Epoch: 10/20...  Training Step: 6062...  Training loss: 1.8011...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 6063...  Training loss: 1.8450...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 6064...  Training loss: 1.8490...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 6065...  Training loss: 1.8865...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 6066...  Training loss: 1.8223...  0.0522 sec/batch
Epoch: 10/20...  Training Step: 6067...  Training loss: 1.8317...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 6068...  Training loss: 1.8234...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 6069...  Training loss: 1.8442...  0.0542 sec/batch
Epoch: 10/20...  Training Step: 6070...  Training loss: 1.8536...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 6071...  Training loss: 1.8077...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 6072...  Training loss: 1.8522...  0.0576 sec/batch
Epoch: 10/20...  Training Step: 6073...  Training loss: 1.8117...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 6074...  Training loss: 1.8059...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 6075...  Training loss: 1.7962...  0.0527 sec/batch
Epoch: 10/20...  Training Step: 6076...  Training loss: 1.8384...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 6077...  Training loss: 1.8205...  0.0540 sec/batch
Epoch: 10/20...  Training Step: 6078...  Training loss: 1.8693...  0.0561 sec/batch
Epoch: 10/20...  Training Step: 6079...  Training loss: 1.7651...  0.0594 sec/batch
Epoch: 10/20...  Training Step: 6080...  Training loss: 1.8440...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 6081...  Training loss: 1.8287...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 6082...  Training loss: 1.8629...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 6083...  Training loss: 1.9029...  0.0553 sec/batch
Epoch: 10/20...  Training Step: 6084...  Training loss: 1.8330...  0.0584 sec/batch
Epoch: 10/20...  Training Step: 6085...  Training loss: 1.8007...  0.0588 sec/batch
Epoch: 10/20...  Training Step: 6086...  Training loss: 1.7825...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 6087...  Training loss: 1.8618...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 6088...  Training loss: 1.8217...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 6089...  Training loss: 1.8734...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 6090...  Training loss: 1.8558...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 6091...  Training loss: 1.8776...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 6092...  Training loss: 1.8452...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 6093...  Training loss: 1.9111...  0.0570 sec/batch
Epoch: 10/20...  Training Step: 6094...  Training loss: 1.8585...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 6095...  Training loss: 1.8536...  0.0556 sec/batch
Epoch: 10/20...  Training Step: 6096...  Training loss: 1.8211...  0.0561 sec/batch
Epoch: 10/20...  Training Step: 6097...  Training loss: 1.8091...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 6098...  Training loss: 1.8134...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 6099...  Training loss: 1.8196...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 6100...  Training loss: 1.8105...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 6101...  Training loss: 1.8097...  0.0583 sec/batch
Epoch: 10/20...  Training Step: 6102...  Training loss: 1.7755...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 6103...  Training loss: 1.8337...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 6104...  Training loss: 1.7471...  0.0576 sec/batch
Epoch: 10/20...  Training Step: 6105...  Training loss: 1.8436...  0.0553 sec/batch
Epoch: 10/20...  Training Step: 6106...  Training loss: 1.8799...  0.0543 sec/batch
Epoch: 10/20...  Training Step: 6107...  Training loss: 1.8567...  0.0553 sec/batch
Epoch: 10/20...  Training Step: 6108...  Training loss: 1.8430...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 6109...  Training loss: 1.8288...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 6110...  Training loss: 1.7874...  0.0581 sec/batch
Epoch: 10/20...  Training Step: 6111...  Training loss: 1.8215...  0.0576 sec/batch
Epoch: 10/20...  Training Step: 6112...  Training loss: 1.8064...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 6113...  Training loss: 1.8149...  0.0523 sec/batch
Epoch: 10/20...  Training Step: 6114...  Training loss: 1.8214...  0.0553 sec/batch
Epoch: 10/20...  Training Step: 6115...  Training loss: 1.8262...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 6116...  Training loss: 1.8342...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 6117...  Training loss: 1.7992...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 6118...  Training loss: 1.8098...  0.0575 sec/batch
Epoch: 10/20...  Training Step: 6119...  Training loss: 1.7652...  0.0582 sec/batch
Epoch: 10/20...  Training Step: 6120...  Training loss: 1.8448...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 6121...  Training loss: 1.8443...  0.0562 sec/batch
Epoch: 10/20...  Training Step: 6122...  Training loss: 1.7944...  0.0526 sec/batch
Epoch: 10/20...  Training Step: 6123...  Training loss: 1.8100...  0.0532 sec/batch
Epoch: 10/20...  Training Step: 6124...  Training loss: 1.7772...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 6125...  Training loss: 1.8584...  0.0553 sec/batch
Epoch: 10/20...  Training Step: 6126...  Training loss: 1.8346...  0.0591 sec/batch
Epoch: 10/20...  Training Step: 6127...  Training loss: 1.8499...  0.0576 sec/batch
Epoch: 10/20...  Training Step: 6128...  Training loss: 1.8710...  0.0552 sec/batch
Epoch: 10/20...  Training Step: 6129...  Training loss: 1.8692...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 6130...  Training loss: 1.7974...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 6131...  Training loss: 1.8487...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 6132...  Training loss: 1.7830...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 6133...  Training loss: 1.8134...  0.0560 sec/batch
Epoch: 10/20...  Training Step: 6134...  Training loss: 1.8343...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 6135...  Training loss: 1.8218...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 6136...  Training loss: 1.8293...  0.0532 sec/batch
Epoch: 10/20...  Training Step: 6137...  Training loss: 1.8270...  0.0524 sec/batch
Epoch: 10/20...  Training Step: 6138...  Training loss: 1.7837...  0.0542 sec/batch
Epoch: 10/20...  Training Step: 6139...  Training loss: 1.8210...  0.0554 sec/batch
Epoch: 10/20...  Training Step: 6140...  Training loss: 1.8084...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 6141...  Training loss: 1.8612...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 6142...  Training loss: 1.8416...  0.0539 sec/batch
Epoch: 10/20...  Training Step: 6143...  Training loss: 1.8252...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 6144...  Training loss: 1.8977...  0.0582 sec/batch
Epoch: 10/20...  Training Step: 6145...  Training loss: 1.9176...  0.0584 sec/batch
Epoch: 10/20...  Training Step: 6146...  Training loss: 1.8944...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 6147...  Training loss: 1.8493...  0.0528 sec/batch
Epoch: 10/20...  Training Step: 6148...  Training loss: 1.8945...  0.0521 sec/batch
Epoch: 10/20...  Training Step: 6149...  Training loss: 1.8234...  0.0580 sec/batch
Epoch: 10/20...  Training Step: 6150...  Training loss: 1.8489...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 6151...  Training loss: 1.8453...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 6152...  Training loss: 1.8760...  0.0589 sec/batch
Epoch: 10/20...  Training Step: 6153...  Training loss: 1.8218...  0.0553 sec/batch
Epoch: 10/20...  Training Step: 6154...  Training loss: 1.8132...  0.0552 sec/batch
Epoch: 10/20...  Training Step: 6155...  Training loss: 1.8261...  0.0554 sec/batch
Epoch: 10/20...  Training Step: 6156...  Training loss: 1.8476...  0.0555 sec/batch
Epoch: 10/20...  Training Step: 6157...  Training loss: 1.7864...  0.0555 sec/batch
Epoch: 10/20...  Training Step: 6158...  Training loss: 1.8386...  0.0583 sec/batch
Epoch: 10/20...  Training Step: 6159...  Training loss: 1.8919...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 6160...  Training loss: 1.8569...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 6161...  Training loss: 1.8792...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 6162...  Training loss: 1.8257...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 6163...  Training loss: 1.8365...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 6164...  Training loss: 1.8719...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 6165...  Training loss: 1.8639...  0.0557 sec/batch
Epoch: 10/20...  Training Step: 6166...  Training loss: 1.8310...  0.0521 sec/batch
Epoch: 10/20...  Training Step: 6167...  Training loss: 1.8048...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 6168...  Training loss: 1.8352...  0.0575 sec/batch
Epoch: 10/20...  Training Step: 6169...  Training loss: 1.8067...  0.0585 sec/batch
Epoch: 10/20...  Training Step: 6170...  Training loss: 1.8579...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 6171...  Training loss: 1.8090...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 6172...  Training loss: 1.8583...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 6173...  Training loss: 1.8377...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 6174...  Training loss: 1.8025...  0.0557 sec/batch
Epoch: 10/20...  Training Step: 6175...  Training loss: 1.8066...  0.0577 sec/batch
Epoch: 10/20...  Training Step: 6176...  Training loss: 1.8204...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 6177...  Training loss: 1.7730...  0.0562 sec/batch
Epoch: 10/20...  Training Step: 6178...  Training loss: 1.8331...  0.0545 sec/batch
Epoch: 10/20...  Training Step: 6179...  Training loss: 1.8632...  0.0532 sec/batch
Epoch: 10/20...  Training Step: 6180...  Training loss: 1.8731...  0.0544 sec/batch
Epoch: 10/20...  Training Step: 6181...  Training loss: 1.8277...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 6182...  Training loss: 1.8247...  0.0550 sec/batch
Epoch: 10/20...  Training Step: 6183...  Training loss: 1.8339...  0.0534 sec/batch
Epoch: 10/20...  Training Step: 6184...  Training loss: 1.8081...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 6185...  Training loss: 1.8567...  0.0529 sec/batch
Epoch: 10/20...  Training Step: 6186...  Training loss: 1.8340...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 6187...  Training loss: 1.8020...  0.0533 sec/batch
Epoch: 10/20...  Training Step: 6188...  Training loss: 1.7954...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 6189...  Training loss: 1.8245...  0.0565 sec/batch
Epoch: 10/20...  Training Step: 6190...  Training loss: 1.8909...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 6191...  Training loss: 1.8672...  0.0548 sec/batch
Epoch: 10/20...  Training Step: 6192...  Training loss: 1.8479...  0.0572 sec/batch
Epoch: 10/20...  Training Step: 6193...  Training loss: 1.7749...  0.0525 sec/batch
Epoch: 10/20...  Training Step: 6194...  Training loss: 1.8391...  0.0581 sec/batch
Epoch: 10/20...  Training Step: 6195...  Training loss: 1.7992...  0.0551 sec/batch
Epoch: 10/20...  Training Step: 6196...  Training loss: 1.8732...  0.0547 sec/batch
Epoch: 10/20...  Training Step: 6197...  Training loss: 1.8672...  0.0541 sec/batch
Epoch: 10/20...  Training Step: 6198...  Training loss: 1.7910...  0.0549 sec/batch
Epoch: 10/20...  Training Step: 6199...  Training loss: 1.7768...  0.0530 sec/batch
Epoch: 10/20...  Training Step: 6200...  Training loss: 1.7976...  0.0540 sec/batch
Epoch: 11/20...  Training Step: 6201...  Training loss: 1.9096...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6202...  Training loss: 1.9020...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6203...  Training loss: 1.8863...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6204...  Training loss: 1.7906...  0.0572 sec/batch
Epoch: 11/20...  Training Step: 6205...  Training loss: 1.8142...  0.0553 sec/batch
Epoch: 11/20...  Training Step: 6206...  Training loss: 1.8305...  0.0524 sec/batch
Epoch: 11/20...  Training Step: 6207...  Training loss: 1.7932...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6208...  Training loss: 1.7682...  0.0566 sec/batch
Epoch: 11/20...  Training Step: 6209...  Training loss: 1.7661...  0.0589 sec/batch
Epoch: 11/20...  Training Step: 6210...  Training loss: 1.7992...  0.0561 sec/batch
Epoch: 11/20...  Training Step: 6211...  Training loss: 1.8154...  0.0532 sec/batch
Epoch: 11/20...  Training Step: 6212...  Training loss: 1.7950...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6213...  Training loss: 1.8268...  0.0589 sec/batch
Epoch: 11/20...  Training Step: 6214...  Training loss: 1.8036...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6215...  Training loss: 1.8447...  0.0586 sec/batch
Epoch: 11/20...  Training Step: 6216...  Training loss: 1.8532...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6217...  Training loss: 1.8498...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6218...  Training loss: 1.8473...  0.0591 sec/batch
Epoch: 11/20...  Training Step: 6219...  Training loss: 1.7944...  0.0563 sec/batch
Epoch: 11/20...  Training Step: 6220...  Training loss: 1.8449...  0.0575 sec/batch
Epoch: 11/20...  Training Step: 6221...  Training loss: 1.8769...  0.0574 sec/batch
Epoch: 11/20...  Training Step: 6222...  Training loss: 1.8256...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6223...  Training loss: 1.8069...  0.0536 sec/batch
Epoch: 11/20...  Training Step: 6224...  Training loss: 1.8359...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6225...  Training loss: 1.8067...  0.0562 sec/batch
Epoch: 11/20...  Training Step: 6226...  Training loss: 1.7940...  0.0523 sec/batch
Epoch: 11/20...  Training Step: 6227...  Training loss: 1.8022...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6228...  Training loss: 1.8358...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6229...  Training loss: 1.8326...  0.0541 sec/batch
Epoch: 11/20...  Training Step: 6230...  Training loss: 1.7891...  0.0587 sec/batch
Epoch: 11/20...  Training Step: 6231...  Training loss: 1.8036...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6232...  Training loss: 1.8271...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6233...  Training loss: 1.8052...  0.0537 sec/batch
Epoch: 11/20...  Training Step: 6234...  Training loss: 1.8108...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6235...  Training loss: 1.8177...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6236...  Training loss: 1.8123...  0.0537 sec/batch
Epoch: 11/20...  Training Step: 6237...  Training loss: 1.8213...  0.0521 sec/batch
Epoch: 11/20...  Training Step: 6238...  Training loss: 1.8392...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6239...  Training loss: 1.8189...  0.0553 sec/batch
Epoch: 11/20...  Training Step: 6240...  Training loss: 1.7860...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6241...  Training loss: 1.8252...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6242...  Training loss: 1.8373...  0.0540 sec/batch
Epoch: 11/20...  Training Step: 6243...  Training loss: 1.8326...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6244...  Training loss: 1.8417...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6245...  Training loss: 1.8139...  0.0555 sec/batch
Epoch: 11/20...  Training Step: 6246...  Training loss: 1.8156...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6247...  Training loss: 1.7116...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6248...  Training loss: 1.8234...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6249...  Training loss: 1.7861...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6250...  Training loss: 1.8584...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6251...  Training loss: 1.8005...  0.0557 sec/batch
Epoch: 11/20...  Training Step: 6252...  Training loss: 1.7795...  0.0524 sec/batch
Epoch: 11/20...  Training Step: 6253...  Training loss: 1.8175...  0.0524 sec/batch
Epoch: 11/20...  Training Step: 6254...  Training loss: 1.8515...  0.0587 sec/batch
Epoch: 11/20...  Training Step: 6255...  Training loss: 1.8422...  0.0579 sec/batch
Epoch: 11/20...  Training Step: 6256...  Training loss: 1.8226...  0.0572 sec/batch
Epoch: 11/20...  Training Step: 6257...  Training loss: 1.7695...  0.0535 sec/batch
Epoch: 11/20...  Training Step: 6258...  Training loss: 1.8332...  0.0535 sec/batch
Epoch: 11/20...  Training Step: 6259...  Training loss: 1.8281...  0.0545 sec/batch
Epoch: 11/20...  Training Step: 6260...  Training loss: 1.8461...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6261...  Training loss: 1.8296...  0.0563 sec/batch
Epoch: 11/20...  Training Step: 6262...  Training loss: 1.7871...  0.0525 sec/batch
Epoch: 11/20...  Training Step: 6263...  Training loss: 1.8344...  0.0534 sec/batch
Epoch: 11/20...  Training Step: 6264...  Training loss: 1.8010...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6265...  Training loss: 1.7932...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6266...  Training loss: 1.7667...  0.0574 sec/batch
Epoch: 11/20...  Training Step: 6267...  Training loss: 1.7837...  0.0585 sec/batch
Epoch: 11/20...  Training Step: 6268...  Training loss: 1.8053...  0.0545 sec/batch
Epoch: 11/20...  Training Step: 6269...  Training loss: 1.8294...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6270...  Training loss: 1.8468...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6271...  Training loss: 1.8777...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6272...  Training loss: 1.8390...  0.0571 sec/batch
Epoch: 11/20...  Training Step: 6273...  Training loss: 1.7734...  0.0556 sec/batch
Epoch: 11/20...  Training Step: 6274...  Training loss: 1.8098...  0.0574 sec/batch
Epoch: 11/20...  Training Step: 6275...  Training loss: 1.8716...  0.0520 sec/batch
Epoch: 11/20...  Training Step: 6276...  Training loss: 1.8516...  0.0554 sec/batch
Epoch: 11/20...  Training Step: 6277...  Training loss: 1.8326...  0.0570 sec/batch
Epoch: 11/20...  Training Step: 6278...  Training loss: 1.8002...  0.0567 sec/batch
Epoch: 11/20...  Training Step: 6279...  Training loss: 1.8217...  0.0525 sec/batch
Epoch: 11/20...  Training Step: 6280...  Training loss: 1.8680...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6281...  Training loss: 1.7591...  0.0557 sec/batch
Epoch: 11/20...  Training Step: 6282...  Training loss: 1.8282...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6283...  Training loss: 1.7603...  0.0534 sec/batch
Epoch: 11/20...  Training Step: 6284...  Training loss: 1.8234...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6285...  Training loss: 1.7879...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6286...  Training loss: 1.8638...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6287...  Training loss: 1.7870...  0.0577 sec/batch
Epoch: 11/20...  Training Step: 6288...  Training loss: 1.8605...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6289...  Training loss: 1.8156...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6290...  Training loss: 1.8371...  0.0599 sec/batch
Epoch: 11/20...  Training Step: 6291...  Training loss: 1.7839...  0.0525 sec/batch
Epoch: 11/20...  Training Step: 6292...  Training loss: 1.8689...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6293...  Training loss: 1.8264...  0.0556 sec/batch
Epoch: 11/20...  Training Step: 6294...  Training loss: 1.8144...  0.0557 sec/batch
Epoch: 11/20...  Training Step: 6295...  Training loss: 1.8092...  0.0541 sec/batch
Epoch: 11/20...  Training Step: 6296...  Training loss: 1.8454...  0.0553 sec/batch
Epoch: 11/20...  Training Step: 6297...  Training loss: 1.8605...  0.0523 sec/batch
Epoch: 11/20...  Training Step: 6298...  Training loss: 1.7642...  0.0541 sec/batch
Epoch: 11/20...  Training Step: 6299...  Training loss: 1.8734...  0.0578 sec/batch
Epoch: 11/20...  Training Step: 6300...  Training loss: 1.7981...  0.0521 sec/batch
Epoch: 11/20...  Training Step: 6301...  Training loss: 1.8083...  0.0569 sec/batch
Epoch: 11/20...  Training Step: 6302...  Training loss: 1.8017...  0.0554 sec/batch
Epoch: 11/20...  Training Step: 6303...  Training loss: 1.8461...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6304...  Training loss: 1.8719...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6305...  Training loss: 1.8235...  0.0582 sec/batch
Epoch: 11/20...  Training Step: 6306...  Training loss: 1.7934...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6307...  Training loss: 1.8425...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6308...  Training loss: 1.7969...  0.0554 sec/batch
Epoch: 11/20...  Training Step: 6309...  Training loss: 1.8164...  0.0524 sec/batch
Epoch: 11/20...  Training Step: 6310...  Training loss: 1.7778...  0.0579 sec/batch
Epoch: 11/20...  Training Step: 6311...  Training loss: 1.7813...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6312...  Training loss: 1.8113...  0.0565 sec/batch
Epoch: 11/20...  Training Step: 6313...  Training loss: 1.8079...  0.0578 sec/batch
Epoch: 11/20...  Training Step: 6314...  Training loss: 1.7963...  0.0525 sec/batch
Epoch: 11/20...  Training Step: 6315...  Training loss: 1.8435...  0.0536 sec/batch
Epoch: 11/20...  Training Step: 6316...  Training loss: 1.8438...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6317...  Training loss: 1.7719...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6318...  Training loss: 1.8470...  0.0560 sec/batch
Epoch: 11/20...  Training Step: 6319...  Training loss: 1.7870...  0.0565 sec/batch
Epoch: 11/20...  Training Step: 6320...  Training loss: 1.8179...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6321...  Training loss: 1.7978...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6322...  Training loss: 1.7497...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6323...  Training loss: 1.7972...  0.0552 sec/batch
Epoch: 11/20...  Training Step: 6324...  Training loss: 1.8324...  0.0522 sec/batch
Epoch: 11/20...  Training Step: 6325...  Training loss: 1.8345...  0.0557 sec/batch
Epoch: 11/20...  Training Step: 6326...  Training loss: 1.8676...  0.0606 sec/batch
Epoch: 11/20...  Training Step: 6327...  Training loss: 1.8651...  0.0570 sec/batch
Epoch: 11/20...  Training Step: 6328...  Training loss: 1.7855...  0.0582 sec/batch
Epoch: 11/20...  Training Step: 6329...  Training loss: 1.8191...  0.0565 sec/batch
Epoch: 11/20...  Training Step: 6330...  Training loss: 1.8701...  0.0532 sec/batch
Epoch: 11/20...  Training Step: 6331...  Training loss: 1.8187...  0.0579 sec/batch
Epoch: 11/20...  Training Step: 6332...  Training loss: 1.8749...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6333...  Training loss: 1.8714...  0.0525 sec/batch
Epoch: 11/20...  Training Step: 6334...  Training loss: 1.8114...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6335...  Training loss: 1.8019...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6336...  Training loss: 1.8158...  0.0574 sec/batch
Epoch: 11/20...  Training Step: 6337...  Training loss: 1.8032...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6338...  Training loss: 1.8229...  0.0543 sec/batch
Epoch: 11/20...  Training Step: 6339...  Training loss: 1.8717...  0.0533 sec/batch
Epoch: 11/20...  Training Step: 6340...  Training loss: 1.8345...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6341...  Training loss: 1.8582...  0.0577 sec/batch
Epoch: 11/20...  Training Step: 6342...  Training loss: 1.7428...  0.0521 sec/batch
Epoch: 11/20...  Training Step: 6343...  Training loss: 1.8379...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6344...  Training loss: 1.7932...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6345...  Training loss: 1.7777...  0.0543 sec/batch
Epoch: 11/20...  Training Step: 6346...  Training loss: 1.8413...  0.0559 sec/batch
Epoch: 11/20...  Training Step: 6347...  Training loss: 1.8316...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6348...  Training loss: 1.8469...  0.0552 sec/batch
Epoch: 11/20...  Training Step: 6349...  Training loss: 1.8222...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6350...  Training loss: 1.8377...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6351...  Training loss: 1.8396...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6352...  Training loss: 1.8055...  0.0532 sec/batch
Epoch: 11/20...  Training Step: 6353...  Training loss: 1.8168...  0.0520 sec/batch
Epoch: 11/20...  Training Step: 6354...  Training loss: 1.8600...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6355...  Training loss: 1.8171...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6356...  Training loss: 1.8211...  0.0561 sec/batch
Epoch: 11/20...  Training Step: 6357...  Training loss: 1.8161...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6358...  Training loss: 1.8475...  0.0579 sec/batch
Epoch: 11/20...  Training Step: 6359...  Training loss: 1.8375...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6360...  Training loss: 1.7812...  0.0553 sec/batch
Epoch: 11/20...  Training Step: 6361...  Training loss: 1.7744...  0.0554 sec/batch
Epoch: 11/20...  Training Step: 6362...  Training loss: 1.7963...  0.0577 sec/batch
Epoch: 11/20...  Training Step: 6363...  Training loss: 1.8286...  0.0555 sec/batch
Epoch: 11/20...  Training Step: 6364...  Training loss: 1.8022...  0.0582 sec/batch
Epoch: 11/20...  Training Step: 6365...  Training loss: 1.8525...  0.0578 sec/batch
Epoch: 11/20...  Training Step: 6366...  Training loss: 1.8125...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6367...  Training loss: 1.8393...  0.0523 sec/batch
Epoch: 11/20...  Training Step: 6368...  Training loss: 1.8270...  0.0542 sec/batch
Epoch: 11/20...  Training Step: 6369...  Training loss: 1.7952...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6370...  Training loss: 1.7759...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6371...  Training loss: 1.8017...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6372...  Training loss: 1.8257...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6373...  Training loss: 1.8162...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6374...  Training loss: 1.8005...  0.0525 sec/batch
Epoch: 11/20...  Training Step: 6375...  Training loss: 1.7969...  0.0554 sec/batch
Epoch: 11/20...  Training Step: 6376...  Training loss: 1.8293...  0.0535 sec/batch
Epoch: 11/20...  Training Step: 6377...  Training loss: 1.8139...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6378...  Training loss: 1.7955...  0.0566 sec/batch
Epoch: 11/20...  Training Step: 6379...  Training loss: 1.8014...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6380...  Training loss: 1.8065...  0.0597 sec/batch
Epoch: 11/20...  Training Step: 6381...  Training loss: 1.7955...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6382...  Training loss: 1.8499...  0.0522 sec/batch
Epoch: 11/20...  Training Step: 6383...  Training loss: 1.8251...  0.0564 sec/batch
Epoch: 11/20...  Training Step: 6384...  Training loss: 1.7803...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6385...  Training loss: 1.7717...  0.0559 sec/batch
Epoch: 11/20...  Training Step: 6386...  Training loss: 1.8089...  0.0554 sec/batch
Epoch: 11/20...  Training Step: 6387...  Training loss: 1.7980...  0.0539 sec/batch
Epoch: 11/20...  Training Step: 6388...  Training loss: 1.7969...  0.0553 sec/batch
Epoch: 11/20...  Training Step: 6389...  Training loss: 1.8082...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6390...  Training loss: 1.8871...  0.0570 sec/batch
Epoch: 11/20...  Training Step: 6391...  Training loss: 1.8166...  0.0579 sec/batch
Epoch: 11/20...  Training Step: 6392...  Training loss: 1.8510...  0.0541 sec/batch
Epoch: 11/20...  Training Step: 6393...  Training loss: 1.8275...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6394...  Training loss: 1.8064...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6395...  Training loss: 1.8181...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6396...  Training loss: 1.8788...  0.0542 sec/batch
Epoch: 11/20...  Training Step: 6397...  Training loss: 1.8045...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6398...  Training loss: 1.8816...  0.0541 sec/batch
Epoch: 11/20...  Training Step: 6399...  Training loss: 1.7881...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6400...  Training loss: 1.8415...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6401...  Training loss: 1.8154...  0.0557 sec/batch
Epoch: 11/20...  Training Step: 6402...  Training loss: 1.8099...  0.0542 sec/batch
Epoch: 11/20...  Training Step: 6403...  Training loss: 1.8251...  0.0565 sec/batch
Epoch: 11/20...  Training Step: 6404...  Training loss: 1.7923...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6405...  Training loss: 1.8143...  0.0571 sec/batch
Epoch: 11/20...  Training Step: 6406...  Training loss: 1.7818...  0.0568 sec/batch
Epoch: 11/20...  Training Step: 6407...  Training loss: 1.8308...  0.0554 sec/batch
Epoch: 11/20...  Training Step: 6408...  Training loss: 1.8067...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6409...  Training loss: 1.8318...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6410...  Training loss: 1.7938...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6411...  Training loss: 1.8195...  0.0583 sec/batch
Epoch: 11/20...  Training Step: 6412...  Training loss: 1.8276...  0.0577 sec/batch
Epoch: 11/20...  Training Step: 6413...  Training loss: 1.8313...  0.0564 sec/batch
Epoch: 11/20...  Training Step: 6414...  Training loss: 1.8478...  0.0568 sec/batch
Epoch: 11/20...  Training Step: 6415...  Training loss: 1.8456...  0.0523 sec/batch
Epoch: 11/20...  Training Step: 6416...  Training loss: 1.8263...  0.0575 sec/batch
Epoch: 11/20...  Training Step: 6417...  Training loss: 1.8314...  0.0554 sec/batch
Epoch: 11/20...  Training Step: 6418...  Training loss: 1.8036...  0.0525 sec/batch
Epoch: 11/20...  Training Step: 6419...  Training loss: 1.8927...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6420...  Training loss: 1.8791...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6421...  Training loss: 1.8286...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6422...  Training loss: 1.8449...  0.0524 sec/batch
Epoch: 11/20...  Training Step: 6423...  Training loss: 1.8859...  0.0555 sec/batch
Epoch: 11/20...  Training Step: 6424...  Training loss: 1.7843...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6425...  Training loss: 1.8189...  0.0540 sec/batch
Epoch: 11/20...  Training Step: 6426...  Training loss: 1.8417...  0.0583 sec/batch
Epoch: 11/20...  Training Step: 6427...  Training loss: 1.8490...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6428...  Training loss: 1.7777...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6429...  Training loss: 1.8284...  0.0605 sec/batch
Epoch: 11/20...  Training Step: 6430...  Training loss: 1.7915...  0.0565 sec/batch
Epoch: 11/20...  Training Step: 6431...  Training loss: 1.8748...  0.0552 sec/batch
Epoch: 11/20...  Training Step: 6432...  Training loss: 1.7884...  0.0552 sec/batch
Epoch: 11/20...  Training Step: 6433...  Training loss: 1.8044...  0.0586 sec/batch
Epoch: 11/20...  Training Step: 6434...  Training loss: 1.7963...  0.0533 sec/batch
Epoch: 11/20...  Training Step: 6435...  Training loss: 1.7689...  0.0545 sec/batch
Epoch: 11/20...  Training Step: 6436...  Training loss: 1.8386...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6437...  Training loss: 1.8100...  0.0532 sec/batch
Epoch: 11/20...  Training Step: 6438...  Training loss: 1.7786...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6439...  Training loss: 1.7939...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6440...  Training loss: 1.8346...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6441...  Training loss: 1.7764...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6442...  Training loss: 1.7852...  0.0577 sec/batch
Epoch: 11/20...  Training Step: 6443...  Training loss: 1.7957...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6444...  Training loss: 1.8107...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6445...  Training loss: 1.8050...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6446...  Training loss: 1.8142...  0.0583 sec/batch
Epoch: 11/20...  Training Step: 6447...  Training loss: 1.8286...  0.0572 sec/batch
Epoch: 11/20...  Training Step: 6448...  Training loss: 1.8298...  0.0556 sec/batch
Epoch: 11/20...  Training Step: 6449...  Training loss: 1.7787...  0.0525 sec/batch
Epoch: 11/20...  Training Step: 6450...  Training loss: 1.7912...  0.0575 sec/batch
Epoch: 11/20...  Training Step: 6451...  Training loss: 1.8124...  0.0545 sec/batch
Epoch: 11/20...  Training Step: 6452...  Training loss: 1.8078...  0.0545 sec/batch
Epoch: 11/20...  Training Step: 6453...  Training loss: 1.8282...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6454...  Training loss: 1.8328...  0.0535 sec/batch
Epoch: 11/20...  Training Step: 6455...  Training loss: 1.8724...  0.0566 sec/batch
Epoch: 11/20...  Training Step: 6456...  Training loss: 1.8276...  0.0545 sec/batch
Epoch: 11/20...  Training Step: 6457...  Training loss: 1.8094...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6458...  Training loss: 1.8158...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6459...  Training loss: 1.8174...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6460...  Training loss: 1.8062...  0.0587 sec/batch
Epoch: 11/20...  Training Step: 6461...  Training loss: 1.8452...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6462...  Training loss: 1.7693...  0.0524 sec/batch
Epoch: 11/20...  Training Step: 6463...  Training loss: 1.8265...  0.0579 sec/batch
Epoch: 11/20...  Training Step: 6464...  Training loss: 1.8070...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6465...  Training loss: 1.8476...  0.0584 sec/batch
Epoch: 11/20...  Training Step: 6466...  Training loss: 1.7483...  0.0572 sec/batch
Epoch: 11/20...  Training Step: 6467...  Training loss: 1.8234...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6468...  Training loss: 1.8384...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6469...  Training loss: 1.8101...  0.0521 sec/batch
Epoch: 11/20...  Training Step: 6470...  Training loss: 1.7807...  0.0543 sec/batch
Epoch: 11/20...  Training Step: 6471...  Training loss: 1.7922...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6472...  Training loss: 1.8214...  0.0525 sec/batch
Epoch: 11/20...  Training Step: 6473...  Training loss: 1.7961...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6474...  Training loss: 1.8200...  0.0572 sec/batch
Epoch: 11/20...  Training Step: 6475...  Training loss: 1.8417...  0.0561 sec/batch
Epoch: 11/20...  Training Step: 6476...  Training loss: 1.8343...  0.0545 sec/batch
Epoch: 11/20...  Training Step: 6477...  Training loss: 1.8922...  0.0562 sec/batch
Epoch: 11/20...  Training Step: 6478...  Training loss: 1.8480...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6479...  Training loss: 1.8409...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6480...  Training loss: 1.8576...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6481...  Training loss: 1.8298...  0.0583 sec/batch
Epoch: 11/20...  Training Step: 6482...  Training loss: 1.7618...  0.0577 sec/batch
Epoch: 11/20...  Training Step: 6483...  Training loss: 1.7990...  0.0568 sec/batch
Epoch: 11/20...  Training Step: 6484...  Training loss: 1.8495...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6485...  Training loss: 1.7845...  0.0556 sec/batch
Epoch: 11/20...  Training Step: 6486...  Training loss: 1.8361...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6487...  Training loss: 1.8061...  0.0522 sec/batch
Epoch: 11/20...  Training Step: 6488...  Training loss: 1.8162...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6489...  Training loss: 1.8214...  0.0585 sec/batch
Epoch: 11/20...  Training Step: 6490...  Training loss: 1.8548...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6491...  Training loss: 1.8266...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6492...  Training loss: 1.8003...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6493...  Training loss: 1.7922...  0.0532 sec/batch
Epoch: 11/20...  Training Step: 6494...  Training loss: 1.8226...  0.0541 sec/batch
Epoch: 11/20...  Training Step: 6495...  Training loss: 1.8049...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6496...  Training loss: 1.7785...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6497...  Training loss: 1.8343...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6498...  Training loss: 1.8595...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6499...  Training loss: 1.8597...  0.0557 sec/batch
Epoch: 11/20...  Training Step: 6500...  Training loss: 1.7949...  0.0584 sec/batch
Epoch: 11/20...  Training Step: 6501...  Training loss: 1.8568...  0.0594 sec/batch
Epoch: 11/20...  Training Step: 6502...  Training loss: 1.8728...  0.0572 sec/batch
Epoch: 11/20...  Training Step: 6503...  Training loss: 1.7748...  0.0543 sec/batch
Epoch: 11/20...  Training Step: 6504...  Training loss: 1.8300...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6505...  Training loss: 1.8106...  0.0554 sec/batch
Epoch: 11/20...  Training Step: 6506...  Training loss: 1.8068...  0.0587 sec/batch
Epoch: 11/20...  Training Step: 6507...  Training loss: 1.8116...  0.0569 sec/batch
Epoch: 11/20...  Training Step: 6508...  Training loss: 1.8019...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6509...  Training loss: 1.8051...  0.0533 sec/batch
Epoch: 11/20...  Training Step: 6510...  Training loss: 1.7868...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6511...  Training loss: 1.7726...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6512...  Training loss: 1.7742...  0.0543 sec/batch
Epoch: 11/20...  Training Step: 6513...  Training loss: 1.7780...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6514...  Training loss: 1.7719...  0.0545 sec/batch
Epoch: 11/20...  Training Step: 6515...  Training loss: 1.8073...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6516...  Training loss: 1.8353...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6517...  Training loss: 1.7966...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6518...  Training loss: 1.7527...  0.0553 sec/batch
Epoch: 11/20...  Training Step: 6519...  Training loss: 1.7916...  0.0601 sec/batch
Epoch: 11/20...  Training Step: 6520...  Training loss: 1.8597...  0.0573 sec/batch
Epoch: 11/20...  Training Step: 6521...  Training loss: 1.7940...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6522...  Training loss: 1.7593...  0.0559 sec/batch
Epoch: 11/20...  Training Step: 6523...  Training loss: 1.8335...  0.0545 sec/batch
Epoch: 11/20...  Training Step: 6524...  Training loss: 1.8061...  0.0577 sec/batch
Epoch: 11/20...  Training Step: 6525...  Training loss: 1.7815...  0.0541 sec/batch
Epoch: 11/20...  Training Step: 6526...  Training loss: 1.8002...  0.0555 sec/batch
Epoch: 11/20...  Training Step: 6527...  Training loss: 1.7739...  0.0578 sec/batch
Epoch: 11/20...  Training Step: 6528...  Training loss: 1.7605...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6529...  Training loss: 1.7947...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6530...  Training loss: 1.7916...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6531...  Training loss: 1.7866...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6532...  Training loss: 1.7925...  0.0556 sec/batch
Epoch: 11/20...  Training Step: 6533...  Training loss: 1.7949...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6534...  Training loss: 1.7938...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6535...  Training loss: 1.7812...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6536...  Training loss: 1.8033...  0.0542 sec/batch
Epoch: 11/20...  Training Step: 6537...  Training loss: 1.7625...  0.0580 sec/batch
Epoch: 11/20...  Training Step: 6538...  Training loss: 1.7908...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6539...  Training loss: 1.7667...  0.0542 sec/batch
Epoch: 11/20...  Training Step: 6540...  Training loss: 1.8225...  0.0532 sec/batch
Epoch: 11/20...  Training Step: 6541...  Training loss: 1.8329...  0.0524 sec/batch
Epoch: 11/20...  Training Step: 6542...  Training loss: 1.8116...  0.0525 sec/batch
Epoch: 11/20...  Training Step: 6543...  Training loss: 1.7647...  0.0537 sec/batch
Epoch: 11/20...  Training Step: 6544...  Training loss: 1.8053...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6545...  Training loss: 1.7980...  0.0536 sec/batch
Epoch: 11/20...  Training Step: 6546...  Training loss: 1.8241...  0.0563 sec/batch
Epoch: 11/20...  Training Step: 6547...  Training loss: 1.8236...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6548...  Training loss: 1.8304...  0.0574 sec/batch
Epoch: 11/20...  Training Step: 6549...  Training loss: 1.7992...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6550...  Training loss: 1.7892...  0.0568 sec/batch
Epoch: 11/20...  Training Step: 6551...  Training loss: 1.8295...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6552...  Training loss: 1.8216...  0.0552 sec/batch
Epoch: 11/20...  Training Step: 6553...  Training loss: 1.8280...  0.0589 sec/batch
Epoch: 11/20...  Training Step: 6554...  Training loss: 1.7820...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6555...  Training loss: 1.7823...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6556...  Training loss: 1.8473...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6557...  Training loss: 1.8896...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6558...  Training loss: 1.8499...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6559...  Training loss: 1.8067...  0.0543 sec/batch
Epoch: 11/20...  Training Step: 6560...  Training loss: 1.8099...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6561...  Training loss: 1.8404...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6562...  Training loss: 1.7856...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6563...  Training loss: 1.7572...  0.0570 sec/batch
Epoch: 11/20...  Training Step: 6564...  Training loss: 1.7675...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6565...  Training loss: 1.7963...  0.0565 sec/batch
Epoch: 11/20...  Training Step: 6566...  Training loss: 1.8171...  0.0536 sec/batch
Epoch: 11/20...  Training Step: 6567...  Training loss: 1.7871...  0.0522 sec/batch
Epoch: 11/20...  Training Step: 6568...  Training loss: 1.8583...  0.0545 sec/batch
Epoch: 11/20...  Training Step: 6569...  Training loss: 1.8382...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6570...  Training loss: 1.7890...  0.0541 sec/batch
Epoch: 11/20...  Training Step: 6571...  Training loss: 1.8362...  0.0564 sec/batch
Epoch: 11/20...  Training Step: 6572...  Training loss: 1.8743...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6573...  Training loss: 1.8275...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6574...  Training loss: 1.8112...  0.0524 sec/batch
Epoch: 11/20...  Training Step: 6575...  Training loss: 1.7830...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6576...  Training loss: 1.8013...  0.0522 sec/batch
Epoch: 11/20...  Training Step: 6577...  Training loss: 1.7865...  0.0553 sec/batch
Epoch: 11/20...  Training Step: 6578...  Training loss: 1.8751...  0.0520 sec/batch
Epoch: 11/20...  Training Step: 6579...  Training loss: 1.8125...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6580...  Training loss: 1.8216...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6581...  Training loss: 1.7420...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6582...  Training loss: 1.8510...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6583...  Training loss: 1.7807...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6584...  Training loss: 1.8176...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6585...  Training loss: 1.8260...  0.0545 sec/batch
Epoch: 11/20...  Training Step: 6586...  Training loss: 1.7309...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6587...  Training loss: 1.7447...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6588...  Training loss: 1.8265...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6589...  Training loss: 1.7700...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6590...  Training loss: 1.7804...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6591...  Training loss: 1.8522...  0.0580 sec/batch
Epoch: 11/20...  Training Step: 6592...  Training loss: 1.7633...  0.0567 sec/batch
Epoch: 11/20...  Training Step: 6593...  Training loss: 1.7863...  0.0552 sec/batch
Epoch: 11/20...  Training Step: 6594...  Training loss: 1.8064...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6595...  Training loss: 1.7590...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6596...  Training loss: 1.8174...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6597...  Training loss: 1.7990...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6598...  Training loss: 1.8347...  0.0582 sec/batch
Epoch: 11/20...  Training Step: 6599...  Training loss: 1.7999...  0.0553 sec/batch
Epoch: 11/20...  Training Step: 6600...  Training loss: 1.8128...  0.0562 sec/batch
Epoch: 11/20...  Training Step: 6601...  Training loss: 1.8603...  0.0534 sec/batch
Epoch: 11/20...  Training Step: 6602...  Training loss: 1.8295...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6603...  Training loss: 1.7665...  0.0558 sec/batch
Epoch: 11/20...  Training Step: 6604...  Training loss: 1.8235...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6605...  Training loss: 1.8488...  0.0628 sec/batch
Epoch: 11/20...  Training Step: 6606...  Training loss: 1.8503...  0.0569 sec/batch
Epoch: 11/20...  Training Step: 6607...  Training loss: 1.8669...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6608...  Training loss: 1.8267...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6609...  Training loss: 1.8845...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6610...  Training loss: 1.8563...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6611...  Training loss: 1.7954...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6612...  Training loss: 1.8397...  0.0533 sec/batch
Epoch: 11/20...  Training Step: 6613...  Training loss: 1.8386...  0.0560 sec/batch
Epoch: 11/20...  Training Step: 6614...  Training loss: 1.8065...  0.0560 sec/batch
Epoch: 11/20...  Training Step: 6615...  Training loss: 1.7628...  0.0558 sec/batch
Epoch: 11/20...  Training Step: 6616...  Training loss: 1.7856...  0.0583 sec/batch
Epoch: 11/20...  Training Step: 6617...  Training loss: 1.7897...  0.0556 sec/batch
Epoch: 11/20...  Training Step: 6618...  Training loss: 1.8105...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6619...  Training loss: 1.8606...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6620...  Training loss: 1.8207...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6621...  Training loss: 1.7749...  0.0553 sec/batch
Epoch: 11/20...  Training Step: 6622...  Training loss: 1.8149...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6623...  Training loss: 1.8268...  0.0582 sec/batch
Epoch: 11/20...  Training Step: 6624...  Training loss: 1.7718...  0.0573 sec/batch
Epoch: 11/20...  Training Step: 6625...  Training loss: 1.8642...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6626...  Training loss: 1.8308...  0.0554 sec/batch
Epoch: 11/20...  Training Step: 6627...  Training loss: 1.7996...  0.0583 sec/batch
Epoch: 11/20...  Training Step: 6628...  Training loss: 1.8248...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6629...  Training loss: 1.7972...  0.0621 sec/batch
Epoch: 11/20...  Training Step: 6630...  Training loss: 1.7721...  0.0532 sec/batch
Epoch: 11/20...  Training Step: 6631...  Training loss: 1.8011...  0.0582 sec/batch
Epoch: 11/20...  Training Step: 6632...  Training loss: 1.8470...  0.0567 sec/batch
Epoch: 11/20...  Training Step: 6633...  Training loss: 1.8354...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6634...  Training loss: 1.7805...  0.0541 sec/batch
Epoch: 11/20...  Training Step: 6635...  Training loss: 1.7692...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6636...  Training loss: 1.7859...  0.0541 sec/batch
Epoch: 11/20...  Training Step: 6637...  Training loss: 1.7727...  0.0554 sec/batch
Epoch: 11/20...  Training Step: 6638...  Training loss: 1.8073...  0.0525 sec/batch
Epoch: 11/20...  Training Step: 6639...  Training loss: 1.7993...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6640...  Training loss: 1.7895...  0.0524 sec/batch
Epoch: 11/20...  Training Step: 6641...  Training loss: 1.7908...  0.0568 sec/batch
Epoch: 11/20...  Training Step: 6642...  Training loss: 1.7757...  0.0525 sec/batch
Epoch: 11/20...  Training Step: 6643...  Training loss: 1.8476...  0.0533 sec/batch
Epoch: 11/20...  Training Step: 6644...  Training loss: 1.8255...  0.0542 sec/batch
Epoch: 11/20...  Training Step: 6645...  Training loss: 1.7195...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6646...  Training loss: 1.8029...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6647...  Training loss: 1.7734...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6648...  Training loss: 1.7581...  0.0563 sec/batch
Epoch: 11/20...  Training Step: 6649...  Training loss: 1.8172...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6650...  Training loss: 1.8463...  0.0564 sec/batch
Epoch: 11/20...  Training Step: 6651...  Training loss: 1.8480...  0.0574 sec/batch
Epoch: 11/20...  Training Step: 6652...  Training loss: 1.8318...  0.0561 sec/batch
Epoch: 11/20...  Training Step: 6653...  Training loss: 1.7769...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6654...  Training loss: 1.8189...  0.0552 sec/batch
Epoch: 11/20...  Training Step: 6655...  Training loss: 1.7851...  0.0571 sec/batch
Epoch: 11/20...  Training Step: 6656...  Training loss: 1.8111...  0.0564 sec/batch
Epoch: 11/20...  Training Step: 6657...  Training loss: 1.8011...  0.0534 sec/batch
Epoch: 11/20...  Training Step: 6658...  Training loss: 1.8327...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6659...  Training loss: 1.7915...  0.0605 sec/batch
Epoch: 11/20...  Training Step: 6660...  Training loss: 1.8141...  0.0559 sec/batch
Epoch: 11/20...  Training Step: 6661...  Training loss: 1.7747...  0.0583 sec/batch
Epoch: 11/20...  Training Step: 6662...  Training loss: 1.8232...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6663...  Training loss: 1.7581...  0.0557 sec/batch
Epoch: 11/20...  Training Step: 6664...  Training loss: 1.7727...  0.0556 sec/batch
Epoch: 11/20...  Training Step: 6665...  Training loss: 1.8382...  0.0592 sec/batch
Epoch: 11/20...  Training Step: 6666...  Training loss: 1.8347...  0.0538 sec/batch
Epoch: 11/20...  Training Step: 6667...  Training loss: 1.7898...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6668...  Training loss: 1.7982...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6669...  Training loss: 1.8175...  0.0558 sec/batch
Epoch: 11/20...  Training Step: 6670...  Training loss: 1.7997...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6671...  Training loss: 1.8081...  0.0579 sec/batch
Epoch: 11/20...  Training Step: 6672...  Training loss: 1.8195...  0.0521 sec/batch
Epoch: 11/20...  Training Step: 6673...  Training loss: 1.7935...  0.0575 sec/batch
Epoch: 11/20...  Training Step: 6674...  Training loss: 1.7734...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6675...  Training loss: 1.8667...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6676...  Training loss: 1.8511...  0.0552 sec/batch
Epoch: 11/20...  Training Step: 6677...  Training loss: 1.8328...  0.0543 sec/batch
Epoch: 11/20...  Training Step: 6678...  Training loss: 1.8805...  0.0521 sec/batch
Epoch: 11/20...  Training Step: 6679...  Training loss: 1.7714...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6680...  Training loss: 1.8707...  0.0553 sec/batch
Epoch: 11/20...  Training Step: 6681...  Training loss: 1.8155...  0.0539 sec/batch
Epoch: 11/20...  Training Step: 6682...  Training loss: 1.7686...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6683...  Training loss: 1.8127...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6684...  Training loss: 1.8200...  0.0579 sec/batch
Epoch: 11/20...  Training Step: 6685...  Training loss: 1.8722...  0.0542 sec/batch
Epoch: 11/20...  Training Step: 6686...  Training loss: 1.7962...  0.0535 sec/batch
Epoch: 11/20...  Training Step: 6687...  Training loss: 1.8289...  0.0582 sec/batch
Epoch: 11/20...  Training Step: 6688...  Training loss: 1.8164...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6689...  Training loss: 1.8282...  0.0533 sec/batch
Epoch: 11/20...  Training Step: 6690...  Training loss: 1.8098...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6691...  Training loss: 1.8229...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6692...  Training loss: 1.8103...  0.0524 sec/batch
Epoch: 11/20...  Training Step: 6693...  Training loss: 1.7945...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6694...  Training loss: 1.7930...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6695...  Training loss: 1.7933...  0.0593 sec/batch
Epoch: 11/20...  Training Step: 6696...  Training loss: 1.8202...  0.0558 sec/batch
Epoch: 11/20...  Training Step: 6697...  Training loss: 1.8004...  0.0539 sec/batch
Epoch: 11/20...  Training Step: 6698...  Training loss: 1.8592...  0.0586 sec/batch
Epoch: 11/20...  Training Step: 6699...  Training loss: 1.7380...  0.0592 sec/batch
Epoch: 11/20...  Training Step: 6700...  Training loss: 1.7963...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6701...  Training loss: 1.8276...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6702...  Training loss: 1.8437...  0.0580 sec/batch
Epoch: 11/20...  Training Step: 6703...  Training loss: 1.8746...  0.0544 sec/batch
Epoch: 11/20...  Training Step: 6704...  Training loss: 1.8121...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6705...  Training loss: 1.7896...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6706...  Training loss: 1.7750...  0.0532 sec/batch
Epoch: 11/20...  Training Step: 6707...  Training loss: 1.8305...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6708...  Training loss: 1.7856...  0.0574 sec/batch
Epoch: 11/20...  Training Step: 6709...  Training loss: 1.8351...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6710...  Training loss: 1.8152...  0.0552 sec/batch
Epoch: 11/20...  Training Step: 6711...  Training loss: 1.8692...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6712...  Training loss: 1.8407...  0.0566 sec/batch
Epoch: 11/20...  Training Step: 6713...  Training loss: 1.8651...  0.0618 sec/batch
Epoch: 11/20...  Training Step: 6714...  Training loss: 1.8503...  0.0563 sec/batch
Epoch: 11/20...  Training Step: 6715...  Training loss: 1.8200...  0.0538 sec/batch
Epoch: 11/20...  Training Step: 6716...  Training loss: 1.8048...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6717...  Training loss: 1.7990...  0.0533 sec/batch
Epoch: 11/20...  Training Step: 6718...  Training loss: 1.7808...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6719...  Training loss: 1.7872...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6720...  Training loss: 1.7922...  0.0572 sec/batch
Epoch: 11/20...  Training Step: 6721...  Training loss: 1.8045...  0.0574 sec/batch
Epoch: 11/20...  Training Step: 6722...  Training loss: 1.7665...  0.0564 sec/batch
Epoch: 11/20...  Training Step: 6723...  Training loss: 1.8041...  0.0555 sec/batch
Epoch: 11/20...  Training Step: 6724...  Training loss: 1.7266...  0.0590 sec/batch
Epoch: 11/20...  Training Step: 6725...  Training loss: 1.8320...  0.0562 sec/batch
Epoch: 11/20...  Training Step: 6726...  Training loss: 1.8741...  0.0523 sec/batch
Epoch: 11/20...  Training Step: 6727...  Training loss: 1.8227...  0.0537 sec/batch
Epoch: 11/20...  Training Step: 6728...  Training loss: 1.8170...  0.0557 sec/batch
Epoch: 11/20...  Training Step: 6729...  Training loss: 1.8064...  0.0533 sec/batch
Epoch: 11/20...  Training Step: 6730...  Training loss: 1.7845...  0.0588 sec/batch
Epoch: 11/20...  Training Step: 6731...  Training loss: 1.8078...  0.0576 sec/batch
Epoch: 11/20...  Training Step: 6732...  Training loss: 1.7974...  0.0525 sec/batch
Epoch: 11/20...  Training Step: 6733...  Training loss: 1.8030...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6734...  Training loss: 1.8129...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6735...  Training loss: 1.8324...  0.0576 sec/batch
Epoch: 11/20...  Training Step: 6736...  Training loss: 1.7966...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6737...  Training loss: 1.7635...  0.0574 sec/batch
Epoch: 11/20...  Training Step: 6738...  Training loss: 1.8232...  0.0534 sec/batch
Epoch: 11/20...  Training Step: 6739...  Training loss: 1.7516...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6740...  Training loss: 1.8377...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6741...  Training loss: 1.8313...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6742...  Training loss: 1.8100...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6743...  Training loss: 1.7901...  0.0522 sec/batch
Epoch: 11/20...  Training Step: 6744...  Training loss: 1.7703...  0.0574 sec/batch
Epoch: 11/20...  Training Step: 6745...  Training loss: 1.8345...  0.0551 sec/batch
Epoch: 11/20...  Training Step: 6746...  Training loss: 1.7903...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6747...  Training loss: 1.8607...  0.0533 sec/batch
Epoch: 11/20...  Training Step: 6748...  Training loss: 1.8517...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6749...  Training loss: 1.8360...  0.0568 sec/batch
Epoch: 11/20...  Training Step: 6750...  Training loss: 1.7766...  0.0526 sec/batch
Epoch: 11/20...  Training Step: 6751...  Training loss: 1.8342...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6752...  Training loss: 1.7473...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6753...  Training loss: 1.8062...  0.0578 sec/batch
Epoch: 11/20...  Training Step: 6754...  Training loss: 1.7943...  0.0533 sec/batch
Epoch: 11/20...  Training Step: 6755...  Training loss: 1.7794...  0.0577 sec/batch
Epoch: 11/20...  Training Step: 6756...  Training loss: 1.8089...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6757...  Training loss: 1.8105...  0.0555 sec/batch
Epoch: 11/20...  Training Step: 6758...  Training loss: 1.7696...  0.0545 sec/batch
Epoch: 11/20...  Training Step: 6759...  Training loss: 1.7988...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6760...  Training loss: 1.7841...  0.0569 sec/batch
Epoch: 11/20...  Training Step: 6761...  Training loss: 1.8517...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6762...  Training loss: 1.8182...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6763...  Training loss: 1.8053...  0.0525 sec/batch
Epoch: 11/20...  Training Step: 6764...  Training loss: 1.8582...  0.0560 sec/batch
Epoch: 11/20...  Training Step: 6765...  Training loss: 1.9103...  0.0577 sec/batch
Epoch: 11/20...  Training Step: 6766...  Training loss: 1.8845...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6767...  Training loss: 1.8028...  0.0609 sec/batch
Epoch: 11/20...  Training Step: 6768...  Training loss: 1.8738...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6769...  Training loss: 1.7836...  0.0550 sec/batch
Epoch: 11/20...  Training Step: 6770...  Training loss: 1.8251...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6771...  Training loss: 1.8246...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6772...  Training loss: 1.8646...  0.0577 sec/batch
Epoch: 11/20...  Training Step: 6773...  Training loss: 1.8102...  0.0553 sec/batch
Epoch: 11/20...  Training Step: 6774...  Training loss: 1.7940...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6775...  Training loss: 1.8206...  0.0523 sec/batch
Epoch: 11/20...  Training Step: 6776...  Training loss: 1.8313...  0.0568 sec/batch
Epoch: 11/20...  Training Step: 6777...  Training loss: 1.7631...  0.0533 sec/batch
Epoch: 11/20...  Training Step: 6778...  Training loss: 1.8276...  0.0537 sec/batch
Epoch: 11/20...  Training Step: 6779...  Training loss: 1.8509...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6780...  Training loss: 1.8347...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6781...  Training loss: 1.8388...  0.0519 sec/batch
Epoch: 11/20...  Training Step: 6782...  Training loss: 1.8066...  0.0582 sec/batch
Epoch: 11/20...  Training Step: 6783...  Training loss: 1.8161...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6784...  Training loss: 1.8541...  0.0542 sec/batch
Epoch: 11/20...  Training Step: 6785...  Training loss: 1.8378...  0.0578 sec/batch
Epoch: 11/20...  Training Step: 6786...  Training loss: 1.8092...  0.0547 sec/batch
Epoch: 11/20...  Training Step: 6787...  Training loss: 1.7716...  0.0575 sec/batch
Epoch: 11/20...  Training Step: 6788...  Training loss: 1.8144...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6789...  Training loss: 1.7883...  0.0559 sec/batch
Epoch: 11/20...  Training Step: 6790...  Training loss: 1.8496...  0.0528 sec/batch
Epoch: 11/20...  Training Step: 6791...  Training loss: 1.7716...  0.0535 sec/batch
Epoch: 11/20...  Training Step: 6792...  Training loss: 1.8493...  0.0565 sec/batch
Epoch: 11/20...  Training Step: 6793...  Training loss: 1.7943...  0.0549 sec/batch
Epoch: 11/20...  Training Step: 6794...  Training loss: 1.7541...  0.0566 sec/batch
Epoch: 11/20...  Training Step: 6795...  Training loss: 1.7913...  0.0541 sec/batch
Epoch: 11/20...  Training Step: 6796...  Training loss: 1.7659...  0.0533 sec/batch
Epoch: 11/20...  Training Step: 6797...  Training loss: 1.7585...  0.0581 sec/batch
Epoch: 11/20...  Training Step: 6798...  Training loss: 1.8263...  0.0534 sec/batch
Epoch: 11/20...  Training Step: 6799...  Training loss: 1.8276...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6800...  Training loss: 1.8193...  0.0560 sec/batch
Epoch: 11/20...  Training Step: 6801...  Training loss: 1.7899...  0.0577 sec/batch
Epoch: 11/20...  Training Step: 6802...  Training loss: 1.8006...  0.0554 sec/batch
Epoch: 11/20...  Training Step: 6803...  Training loss: 1.8156...  0.0553 sec/batch
Epoch: 11/20...  Training Step: 6804...  Training loss: 1.7869...  0.0546 sec/batch
Epoch: 11/20...  Training Step: 6805...  Training loss: 1.8201...  0.0554 sec/batch
Epoch: 11/20...  Training Step: 6806...  Training loss: 1.8255...  0.0578 sec/batch
Epoch: 11/20...  Training Step: 6807...  Training loss: 1.7650...  0.0564 sec/batch
Epoch: 11/20...  Training Step: 6808...  Training loss: 1.7797...  0.0548 sec/batch
Epoch: 11/20...  Training Step: 6809...  Training loss: 1.7941...  0.0541 sec/batch
Epoch: 11/20...  Training Step: 6810...  Training loss: 1.8663...  0.0527 sec/batch
Epoch: 11/20...  Training Step: 6811...  Training loss: 1.8715...  0.0534 sec/batch
Epoch: 11/20...  Training Step: 6812...  Training loss: 1.8300...  0.0555 sec/batch
Epoch: 11/20...  Training Step: 6813...  Training loss: 1.7823...  0.0557 sec/batch
Epoch: 11/20...  Training Step: 6814...  Training loss: 1.8179...  0.0529 sec/batch
Epoch: 11/20...  Training Step: 6815...  Training loss: 1.7750...  0.0530 sec/batch
Epoch: 11/20...  Training Step: 6816...  Training loss: 1.8372...  0.0591 sec/batch
Epoch: 11/20...  Training Step: 6817...  Training loss: 1.8509...  0.0537 sec/batch
Epoch: 11/20...  Training Step: 6818...  Training loss: 1.7621...  0.0560 sec/batch
Epoch: 11/20...  Training Step: 6819...  Training loss: 1.7490...  0.0531 sec/batch
Epoch: 11/20...  Training Step: 6820...  Training loss: 1.7642...  0.0538 sec/batch
Epoch: 12/20...  Training Step: 6821...  Training loss: 1.8914...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 6822...  Training loss: 1.8847...  0.0537 sec/batch
Epoch: 12/20...  Training Step: 6823...  Training loss: 1.8745...  0.0525 sec/batch
Epoch: 12/20...  Training Step: 6824...  Training loss: 1.7681...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 6825...  Training loss: 1.8201...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 6826...  Training loss: 1.8192...  0.0576 sec/batch
Epoch: 12/20...  Training Step: 6827...  Training loss: 1.7711...  0.0524 sec/batch
Epoch: 12/20...  Training Step: 6828...  Training loss: 1.7592...  0.0587 sec/batch
Epoch: 12/20...  Training Step: 6829...  Training loss: 1.7375...  0.0541 sec/batch
Epoch: 12/20...  Training Step: 6830...  Training loss: 1.7702...  0.0526 sec/batch
Epoch: 12/20...  Training Step: 6831...  Training loss: 1.7758...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 6832...  Training loss: 1.7696...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 6833...  Training loss: 1.7966...  0.0573 sec/batch
Epoch: 12/20...  Training Step: 6834...  Training loss: 1.7686...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 6835...  Training loss: 1.8282...  0.0595 sec/batch
Epoch: 12/20...  Training Step: 6836...  Training loss: 1.8444...  0.0526 sec/batch
Epoch: 12/20...  Training Step: 6837...  Training loss: 1.8183...  0.0602 sec/batch
Epoch: 12/20...  Training Step: 6838...  Training loss: 1.8210...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 6839...  Training loss: 1.7543...  0.0565 sec/batch
Epoch: 12/20...  Training Step: 6840...  Training loss: 1.8109...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 6841...  Training loss: 1.8726...  0.0570 sec/batch
Epoch: 12/20...  Training Step: 6842...  Training loss: 1.7849...  0.0584 sec/batch
Epoch: 12/20...  Training Step: 6843...  Training loss: 1.7668...  0.0552 sec/batch
Epoch: 12/20...  Training Step: 6844...  Training loss: 1.8114...  0.0578 sec/batch
Epoch: 12/20...  Training Step: 6845...  Training loss: 1.7912...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 6846...  Training loss: 1.7720...  0.0573 sec/batch
Epoch: 12/20...  Training Step: 6847...  Training loss: 1.7956...  0.0538 sec/batch
Epoch: 12/20...  Training Step: 6848...  Training loss: 1.8026...  0.0591 sec/batch
Epoch: 12/20...  Training Step: 6849...  Training loss: 1.8172...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 6850...  Training loss: 1.7709...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 6851...  Training loss: 1.7671...  0.0557 sec/batch
Epoch: 12/20...  Training Step: 6852...  Training loss: 1.8208...  0.0582 sec/batch
Epoch: 12/20...  Training Step: 6853...  Training loss: 1.7934...  0.0563 sec/batch
Epoch: 12/20...  Training Step: 6854...  Training loss: 1.7860...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 6855...  Training loss: 1.7876...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 6856...  Training loss: 1.8003...  0.0577 sec/batch
Epoch: 12/20...  Training Step: 6857...  Training loss: 1.8034...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 6858...  Training loss: 1.8160...  0.0552 sec/batch
Epoch: 12/20...  Training Step: 6859...  Training loss: 1.8265...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 6860...  Training loss: 1.7850...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 6861...  Training loss: 1.8244...  0.0556 sec/batch
Epoch: 12/20...  Training Step: 6862...  Training loss: 1.8241...  0.0561 sec/batch
Epoch: 12/20...  Training Step: 6863...  Training loss: 1.8098...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 6864...  Training loss: 1.8409...  0.0542 sec/batch
Epoch: 12/20...  Training Step: 6865...  Training loss: 1.7710...  0.0564 sec/batch
Epoch: 12/20...  Training Step: 6866...  Training loss: 1.7995...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 6867...  Training loss: 1.6867...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 6868...  Training loss: 1.7811...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 6869...  Training loss: 1.7708...  0.0582 sec/batch
Epoch: 12/20...  Training Step: 6870...  Training loss: 1.8195...  0.0565 sec/batch
Epoch: 12/20...  Training Step: 6871...  Training loss: 1.7665...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 6872...  Training loss: 1.7802...  0.0536 sec/batch
Epoch: 12/20...  Training Step: 6873...  Training loss: 1.7858...  0.0575 sec/batch
Epoch: 12/20...  Training Step: 6874...  Training loss: 1.8176...  0.0535 sec/batch
Epoch: 12/20...  Training Step: 6875...  Training loss: 1.8098...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 6876...  Training loss: 1.8075...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 6877...  Training loss: 1.7781...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 6878...  Training loss: 1.7950...  0.0583 sec/batch
Epoch: 12/20...  Training Step: 6879...  Training loss: 1.7885...  0.0561 sec/batch
Epoch: 12/20...  Training Step: 6880...  Training loss: 1.8310...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 6881...  Training loss: 1.7990...  0.0536 sec/batch
Epoch: 12/20...  Training Step: 6882...  Training loss: 1.7668...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 6883...  Training loss: 1.8250...  0.0538 sec/batch
Epoch: 12/20...  Training Step: 6884...  Training loss: 1.7756...  0.0557 sec/batch
Epoch: 12/20...  Training Step: 6885...  Training loss: 1.7679...  0.0539 sec/batch
Epoch: 12/20...  Training Step: 6886...  Training loss: 1.7419...  0.0542 sec/batch
Epoch: 12/20...  Training Step: 6887...  Training loss: 1.7676...  0.0538 sec/batch
Epoch: 12/20...  Training Step: 6888...  Training loss: 1.7643...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 6889...  Training loss: 1.8006...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 6890...  Training loss: 1.8161...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 6891...  Training loss: 1.8447...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 6892...  Training loss: 1.8235...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 6893...  Training loss: 1.7349...  0.0524 sec/batch
Epoch: 12/20...  Training Step: 6894...  Training loss: 1.7900...  0.0582 sec/batch
Epoch: 12/20...  Training Step: 6895...  Training loss: 1.8602...  0.0526 sec/batch
Epoch: 12/20...  Training Step: 6896...  Training loss: 1.8363...  0.0569 sec/batch
Epoch: 12/20...  Training Step: 6897...  Training loss: 1.8006...  0.0587 sec/batch
Epoch: 12/20...  Training Step: 6898...  Training loss: 1.7748...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 6899...  Training loss: 1.8200...  0.0526 sec/batch
Epoch: 12/20...  Training Step: 6900...  Training loss: 1.8046...  0.0530 sec/batch
Epoch: 12/20...  Training Step: 6901...  Training loss: 1.7473...  0.0537 sec/batch
Epoch: 12/20...  Training Step: 6902...  Training loss: 1.7948...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 6903...  Training loss: 1.7496...  0.0530 sec/batch
Epoch: 12/20...  Training Step: 6904...  Training loss: 1.7739...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 6905...  Training loss: 1.7949...  0.0537 sec/batch
Epoch: 12/20...  Training Step: 6906...  Training loss: 1.8460...  0.0586 sec/batch
Epoch: 12/20...  Training Step: 6907...  Training loss: 1.7716...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 6908...  Training loss: 1.8565...  0.0578 sec/batch
Epoch: 12/20...  Training Step: 6909...  Training loss: 1.7900...  0.0583 sec/batch
Epoch: 12/20...  Training Step: 6910...  Training loss: 1.7956...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 6911...  Training loss: 1.7593...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 6912...  Training loss: 1.8383...  0.0552 sec/batch
Epoch: 12/20...  Training Step: 6913...  Training loss: 1.8090...  0.0555 sec/batch
Epoch: 12/20...  Training Step: 6914...  Training loss: 1.7981...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 6915...  Training loss: 1.8049...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 6916...  Training loss: 1.8355...  0.0529 sec/batch
Epoch: 12/20...  Training Step: 6917...  Training loss: 1.8268...  0.0542 sec/batch
Epoch: 12/20...  Training Step: 6918...  Training loss: 1.7528...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 6919...  Training loss: 1.8402...  0.0580 sec/batch
Epoch: 12/20...  Training Step: 6920...  Training loss: 1.7964...  0.0578 sec/batch
Epoch: 12/20...  Training Step: 6921...  Training loss: 1.7795...  0.0557 sec/batch
Epoch: 12/20...  Training Step: 6922...  Training loss: 1.7751...  0.0569 sec/batch
Epoch: 12/20...  Training Step: 6923...  Training loss: 1.8072...  0.0529 sec/batch
Epoch: 12/20...  Training Step: 6924...  Training loss: 1.8420...  0.0578 sec/batch
Epoch: 12/20...  Training Step: 6925...  Training loss: 1.7988...  0.0552 sec/batch
Epoch: 12/20...  Training Step: 6926...  Training loss: 1.7458...  0.0530 sec/batch
Epoch: 12/20...  Training Step: 6927...  Training loss: 1.8204...  0.0582 sec/batch
Epoch: 12/20...  Training Step: 6928...  Training loss: 1.7910...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 6929...  Training loss: 1.7943...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 6930...  Training loss: 1.7606...  0.0590 sec/batch
Epoch: 12/20...  Training Step: 6931...  Training loss: 1.7436...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 6932...  Training loss: 1.7828...  0.0558 sec/batch
Epoch: 12/20...  Training Step: 6933...  Training loss: 1.7832...  0.0573 sec/batch
Epoch: 12/20...  Training Step: 6934...  Training loss: 1.7761...  0.0542 sec/batch
Epoch: 12/20...  Training Step: 6935...  Training loss: 1.8079...  0.0564 sec/batch
Epoch: 12/20...  Training Step: 6936...  Training loss: 1.8270...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 6937...  Training loss: 1.7531...  0.0536 sec/batch
Epoch: 12/20...  Training Step: 6938...  Training loss: 1.8514...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 6939...  Training loss: 1.7827...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 6940...  Training loss: 1.8067...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 6941...  Training loss: 1.7825...  0.0582 sec/batch
Epoch: 12/20...  Training Step: 6942...  Training loss: 1.7360...  0.0621 sec/batch
Epoch: 12/20...  Training Step: 6943...  Training loss: 1.7750...  0.0556 sec/batch
Epoch: 12/20...  Training Step: 6944...  Training loss: 1.8314...  0.0559 sec/batch
Epoch: 12/20...  Training Step: 6945...  Training loss: 1.8159...  0.0550 sec/batch
Epoch: 12/20...  Training Step: 6946...  Training loss: 1.8291...  0.0541 sec/batch
Epoch: 12/20...  Training Step: 6947...  Training loss: 1.8538...  0.0529 sec/batch
Epoch: 12/20...  Training Step: 6948...  Training loss: 1.7608...  0.0799 sec/batch
Epoch: 12/20...  Training Step: 6949...  Training loss: 1.7937...  0.0606 sec/batch
Epoch: 12/20...  Training Step: 6950...  Training loss: 1.8592...  0.0572 sec/batch
Epoch: 12/20...  Training Step: 6951...  Training loss: 1.7922...  0.0585 sec/batch
Epoch: 12/20...  Training Step: 6952...  Training loss: 1.8575...  0.0568 sec/batch
Epoch: 12/20...  Training Step: 6953...  Training loss: 1.8385...  0.0562 sec/batch
Epoch: 12/20...  Training Step: 6954...  Training loss: 1.8240...  0.0556 sec/batch
Epoch: 12/20...  Training Step: 6955...  Training loss: 1.7745...  0.0529 sec/batch
Epoch: 12/20...  Training Step: 6956...  Training loss: 1.8003...  0.0557 sec/batch
Epoch: 12/20...  Training Step: 6957...  Training loss: 1.8142...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 6958...  Training loss: 1.8205...  0.0558 sec/batch
Epoch: 12/20...  Training Step: 6959...  Training loss: 1.8374...  0.0580 sec/batch
Epoch: 12/20...  Training Step: 6960...  Training loss: 1.8022...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 6961...  Training loss: 1.8680...  0.0595 sec/batch
Epoch: 12/20...  Training Step: 6962...  Training loss: 1.7246...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 6963...  Training loss: 1.8136...  0.0581 sec/batch
Epoch: 12/20...  Training Step: 6964...  Training loss: 1.7801...  0.0540 sec/batch
Epoch: 12/20...  Training Step: 6965...  Training loss: 1.7366...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 6966...  Training loss: 1.8150...  0.0600 sec/batch
Epoch: 12/20...  Training Step: 6967...  Training loss: 1.8117...  0.0535 sec/batch
Epoch: 12/20...  Training Step: 6968...  Training loss: 1.8036...  0.0589 sec/batch
Epoch: 12/20...  Training Step: 6969...  Training loss: 1.8148...  0.0538 sec/batch
Epoch: 12/20...  Training Step: 6970...  Training loss: 1.8334...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 6971...  Training loss: 1.8201...  0.0579 sec/batch
Epoch: 12/20...  Training Step: 6972...  Training loss: 1.7805...  0.0552 sec/batch
Epoch: 12/20...  Training Step: 6973...  Training loss: 1.7926...  0.0600 sec/batch
Epoch: 12/20...  Training Step: 6974...  Training loss: 1.8415...  0.0539 sec/batch
Epoch: 12/20...  Training Step: 6975...  Training loss: 1.7816...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 6976...  Training loss: 1.8105...  0.0561 sec/batch
Epoch: 12/20...  Training Step: 6977...  Training loss: 1.7832...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 6978...  Training loss: 1.8446...  0.0552 sec/batch
Epoch: 12/20...  Training Step: 6979...  Training loss: 1.8022...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 6980...  Training loss: 1.7489...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 6981...  Training loss: 1.7432...  0.0565 sec/batch
Epoch: 12/20...  Training Step: 6982...  Training loss: 1.7670...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 6983...  Training loss: 1.8220...  0.0535 sec/batch
Epoch: 12/20...  Training Step: 6984...  Training loss: 1.7996...  0.0537 sec/batch
Epoch: 12/20...  Training Step: 6985...  Training loss: 1.8223...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 6986...  Training loss: 1.7959...  0.0577 sec/batch
Epoch: 12/20...  Training Step: 6987...  Training loss: 1.8230...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 6988...  Training loss: 1.8235...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 6989...  Training loss: 1.7812...  0.0559 sec/batch
Epoch: 12/20...  Training Step: 6990...  Training loss: 1.7780...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 6991...  Training loss: 1.7819...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 6992...  Training loss: 1.8104...  0.0583 sec/batch
Epoch: 12/20...  Training Step: 6993...  Training loss: 1.7857...  0.0538 sec/batch
Epoch: 12/20...  Training Step: 6994...  Training loss: 1.7667...  0.0560 sec/batch
Epoch: 12/20...  Training Step: 6995...  Training loss: 1.7895...  0.0567 sec/batch
Epoch: 12/20...  Training Step: 6996...  Training loss: 1.8072...  0.0535 sec/batch
Epoch: 12/20...  Training Step: 6997...  Training loss: 1.8007...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 6998...  Training loss: 1.7703...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 6999...  Training loss: 1.7622...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 7000...  Training loss: 1.7644...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 7001...  Training loss: 1.7736...  0.0584 sec/batch
Epoch: 12/20...  Training Step: 7002...  Training loss: 1.8179...  0.0535 sec/batch
Epoch: 12/20...  Training Step: 7003...  Training loss: 1.7973...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 7004...  Training loss: 1.7508...  0.0586 sec/batch
Epoch: 12/20...  Training Step: 7005...  Training loss: 1.7623...  0.0588 sec/batch
Epoch: 12/20...  Training Step: 7006...  Training loss: 1.7860...  0.0530 sec/batch
Epoch: 12/20...  Training Step: 7007...  Training loss: 1.7840...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 7008...  Training loss: 1.7974...  0.0570 sec/batch
Epoch: 12/20...  Training Step: 7009...  Training loss: 1.7916...  0.0590 sec/batch
Epoch: 12/20...  Training Step: 7010...  Training loss: 1.8527...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 7011...  Training loss: 1.8098...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 7012...  Training loss: 1.8413...  0.0525 sec/batch
Epoch: 12/20...  Training Step: 7013...  Training loss: 1.8191...  0.0565 sec/batch
Epoch: 12/20...  Training Step: 7014...  Training loss: 1.7799...  0.0537 sec/batch
Epoch: 12/20...  Training Step: 7015...  Training loss: 1.7633...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 7016...  Training loss: 1.8620...  0.0541 sec/batch
Epoch: 12/20...  Training Step: 7017...  Training loss: 1.8156...  0.0529 sec/batch
Epoch: 12/20...  Training Step: 7018...  Training loss: 1.8849...  0.0558 sec/batch
Epoch: 12/20...  Training Step: 7019...  Training loss: 1.7674...  0.0530 sec/batch
Epoch: 12/20...  Training Step: 7020...  Training loss: 1.8187...  0.0538 sec/batch
Epoch: 12/20...  Training Step: 7021...  Training loss: 1.7785...  0.0541 sec/batch
Epoch: 12/20...  Training Step: 7022...  Training loss: 1.7855...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 7023...  Training loss: 1.7905...  0.0522 sec/batch
Epoch: 12/20...  Training Step: 7024...  Training loss: 1.7482...  0.0565 sec/batch
Epoch: 12/20...  Training Step: 7025...  Training loss: 1.8055...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 7026...  Training loss: 1.7668...  0.0575 sec/batch
Epoch: 12/20...  Training Step: 7027...  Training loss: 1.8324...  0.0539 sec/batch
Epoch: 12/20...  Training Step: 7028...  Training loss: 1.7949...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7029...  Training loss: 1.7914...  0.0560 sec/batch
Epoch: 12/20...  Training Step: 7030...  Training loss: 1.7829...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7031...  Training loss: 1.7864...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 7032...  Training loss: 1.8137...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 7033...  Training loss: 1.8441...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7034...  Training loss: 1.8188...  0.0529 sec/batch
Epoch: 12/20...  Training Step: 7035...  Training loss: 1.8107...  0.0526 sec/batch
Epoch: 12/20...  Training Step: 7036...  Training loss: 1.8142...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 7037...  Training loss: 1.8265...  0.0590 sec/batch
Epoch: 12/20...  Training Step: 7038...  Training loss: 1.7799...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 7039...  Training loss: 1.8742...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7040...  Training loss: 1.8345...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7041...  Training loss: 1.8127...  0.0559 sec/batch
Epoch: 12/20...  Training Step: 7042...  Training loss: 1.8294...  0.0574 sec/batch
Epoch: 12/20...  Training Step: 7043...  Training loss: 1.8400...  0.0579 sec/batch
Epoch: 12/20...  Training Step: 7044...  Training loss: 1.7640...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 7045...  Training loss: 1.7871...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 7046...  Training loss: 1.8261...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 7047...  Training loss: 1.8386...  0.0580 sec/batch
Epoch: 12/20...  Training Step: 7048...  Training loss: 1.7485...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 7049...  Training loss: 1.8024...  0.0581 sec/batch
Epoch: 12/20...  Training Step: 7050...  Training loss: 1.7778...  0.0525 sec/batch
Epoch: 12/20...  Training Step: 7051...  Training loss: 1.8641...  0.0583 sec/batch
Epoch: 12/20...  Training Step: 7052...  Training loss: 1.7651...  0.0550 sec/batch
Epoch: 12/20...  Training Step: 7053...  Training loss: 1.7597...  0.0530 sec/batch
Epoch: 12/20...  Training Step: 7054...  Training loss: 1.7808...  0.0550 sec/batch
Epoch: 12/20...  Training Step: 7055...  Training loss: 1.7647...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7056...  Training loss: 1.8360...  0.0552 sec/batch
Epoch: 12/20...  Training Step: 7057...  Training loss: 1.8014...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7058...  Training loss: 1.7661...  0.0573 sec/batch
Epoch: 12/20...  Training Step: 7059...  Training loss: 1.7866...  0.0550 sec/batch
Epoch: 12/20...  Training Step: 7060...  Training loss: 1.8171...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 7061...  Training loss: 1.7582...  0.0561 sec/batch
Epoch: 12/20...  Training Step: 7062...  Training loss: 1.7541...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 7063...  Training loss: 1.7632...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 7064...  Training loss: 1.7642...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7065...  Training loss: 1.7833...  0.0559 sec/batch
Epoch: 12/20...  Training Step: 7066...  Training loss: 1.7769...  0.0560 sec/batch
Epoch: 12/20...  Training Step: 7067...  Training loss: 1.8013...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 7068...  Training loss: 1.8236...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 7069...  Training loss: 1.7529...  0.0578 sec/batch
Epoch: 12/20...  Training Step: 7070...  Training loss: 1.7820...  0.0555 sec/batch
Epoch: 12/20...  Training Step: 7071...  Training loss: 1.7834...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 7072...  Training loss: 1.7632...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 7073...  Training loss: 1.8248...  0.0543 sec/batch
Epoch: 12/20...  Training Step: 7074...  Training loss: 1.7939...  0.0550 sec/batch
Epoch: 12/20...  Training Step: 7075...  Training loss: 1.8449...  0.0582 sec/batch
Epoch: 12/20...  Training Step: 7076...  Training loss: 1.7769...  0.0594 sec/batch
Epoch: 12/20...  Training Step: 7077...  Training loss: 1.7944...  0.0561 sec/batch
Epoch: 12/20...  Training Step: 7078...  Training loss: 1.7626...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 7079...  Training loss: 1.8031...  0.0575 sec/batch
Epoch: 12/20...  Training Step: 7080...  Training loss: 1.7766...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 7081...  Training loss: 1.8385...  0.0585 sec/batch
Epoch: 12/20...  Training Step: 7082...  Training loss: 1.7622...  0.0576 sec/batch
Epoch: 12/20...  Training Step: 7083...  Training loss: 1.8168...  0.0590 sec/batch
Epoch: 12/20...  Training Step: 7084...  Training loss: 1.8072...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7085...  Training loss: 1.8282...  0.0538 sec/batch
Epoch: 12/20...  Training Step: 7086...  Training loss: 1.7390...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 7087...  Training loss: 1.8019...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 7088...  Training loss: 1.7909...  0.0563 sec/batch
Epoch: 12/20...  Training Step: 7089...  Training loss: 1.7678...  0.0529 sec/batch
Epoch: 12/20...  Training Step: 7090...  Training loss: 1.7572...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 7091...  Training loss: 1.7537...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 7092...  Training loss: 1.7983...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 7093...  Training loss: 1.7875...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 7094...  Training loss: 1.7773...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 7095...  Training loss: 1.8162...  0.0566 sec/batch
Epoch: 12/20...  Training Step: 7096...  Training loss: 1.8371...  0.0542 sec/batch
Epoch: 12/20...  Training Step: 7097...  Training loss: 1.8852...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 7098...  Training loss: 1.8190...  0.0593 sec/batch
Epoch: 12/20...  Training Step: 7099...  Training loss: 1.8427...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 7100...  Training loss: 1.8523...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 7101...  Training loss: 1.8286...  0.0564 sec/batch
Epoch: 12/20...  Training Step: 7102...  Training loss: 1.7413...  0.0563 sec/batch
Epoch: 12/20...  Training Step: 7103...  Training loss: 1.7434...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7104...  Training loss: 1.8245...  0.0539 sec/batch
Epoch: 12/20...  Training Step: 7105...  Training loss: 1.7743...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 7106...  Training loss: 1.8169...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7107...  Training loss: 1.7873...  0.0593 sec/batch
Epoch: 12/20...  Training Step: 7108...  Training loss: 1.7953...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 7109...  Training loss: 1.8007...  0.0596 sec/batch
Epoch: 12/20...  Training Step: 7110...  Training loss: 1.8243...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 7111...  Training loss: 1.7871...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 7112...  Training loss: 1.8032...  0.0563 sec/batch
Epoch: 12/20...  Training Step: 7113...  Training loss: 1.7686...  0.0561 sec/batch
Epoch: 12/20...  Training Step: 7114...  Training loss: 1.8184...  0.0567 sec/batch
Epoch: 12/20...  Training Step: 7115...  Training loss: 1.7797...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 7116...  Training loss: 1.7654...  0.0556 sec/batch
Epoch: 12/20...  Training Step: 7117...  Training loss: 1.7990...  0.0559 sec/batch
Epoch: 12/20...  Training Step: 7118...  Training loss: 1.8454...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 7119...  Training loss: 1.8325...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 7120...  Training loss: 1.7962...  0.0535 sec/batch
Epoch: 12/20...  Training Step: 7121...  Training loss: 1.8574...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 7122...  Training loss: 1.8835...  0.0529 sec/batch
Epoch: 12/20...  Training Step: 7123...  Training loss: 1.7425...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 7124...  Training loss: 1.8292...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 7125...  Training loss: 1.7869...  0.0526 sec/batch
Epoch: 12/20...  Training Step: 7126...  Training loss: 1.7873...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 7127...  Training loss: 1.8121...  0.0524 sec/batch
Epoch: 12/20...  Training Step: 7128...  Training loss: 1.7768...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 7129...  Training loss: 1.7966...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 7130...  Training loss: 1.7687...  0.0559 sec/batch
Epoch: 12/20...  Training Step: 7131...  Training loss: 1.7598...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 7132...  Training loss: 1.7541...  0.0574 sec/batch
Epoch: 12/20...  Training Step: 7133...  Training loss: 1.7613...  0.0573 sec/batch
Epoch: 12/20...  Training Step: 7134...  Training loss: 1.7452...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7135...  Training loss: 1.7989...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 7136...  Training loss: 1.8267...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 7137...  Training loss: 1.7640...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7138...  Training loss: 1.7180...  0.0522 sec/batch
Epoch: 12/20...  Training Step: 7139...  Training loss: 1.7670...  0.0536 sec/batch
Epoch: 12/20...  Training Step: 7140...  Training loss: 1.8521...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 7141...  Training loss: 1.7841...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 7142...  Training loss: 1.7563...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 7143...  Training loss: 1.8041...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7144...  Training loss: 1.7909...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 7145...  Training loss: 1.7555...  0.0558 sec/batch
Epoch: 12/20...  Training Step: 7146...  Training loss: 1.7679...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 7147...  Training loss: 1.7691...  0.0566 sec/batch
Epoch: 12/20...  Training Step: 7148...  Training loss: 1.7584...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 7149...  Training loss: 1.7969...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 7150...  Training loss: 1.7859...  0.0564 sec/batch
Epoch: 12/20...  Training Step: 7151...  Training loss: 1.7737...  0.0559 sec/batch
Epoch: 12/20...  Training Step: 7152...  Training loss: 1.7798...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 7153...  Training loss: 1.7722...  0.0559 sec/batch
Epoch: 12/20...  Training Step: 7154...  Training loss: 1.7783...  0.0583 sec/batch
Epoch: 12/20...  Training Step: 7155...  Training loss: 1.7839...  0.0575 sec/batch
Epoch: 12/20...  Training Step: 7156...  Training loss: 1.7670...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 7157...  Training loss: 1.7636...  0.0568 sec/batch
Epoch: 12/20...  Training Step: 7158...  Training loss: 1.7716...  0.0570 sec/batch
Epoch: 12/20...  Training Step: 7159...  Training loss: 1.7563...  0.0529 sec/batch
Epoch: 12/20...  Training Step: 7160...  Training loss: 1.7694...  0.0529 sec/batch
Epoch: 12/20...  Training Step: 7161...  Training loss: 1.7999...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 7162...  Training loss: 1.7852...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 7163...  Training loss: 1.7604...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 7164...  Training loss: 1.7541...  0.0536 sec/batch
Epoch: 12/20...  Training Step: 7165...  Training loss: 1.8111...  0.0578 sec/batch
Epoch: 12/20...  Training Step: 7166...  Training loss: 1.8097...  0.0582 sec/batch
Epoch: 12/20...  Training Step: 7167...  Training loss: 1.8136...  0.0556 sec/batch
Epoch: 12/20...  Training Step: 7168...  Training loss: 1.7971...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7169...  Training loss: 1.7757...  0.0541 sec/batch
Epoch: 12/20...  Training Step: 7170...  Training loss: 1.7818...  0.0557 sec/batch
Epoch: 12/20...  Training Step: 7171...  Training loss: 1.8332...  0.0558 sec/batch
Epoch: 12/20...  Training Step: 7172...  Training loss: 1.7919...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 7173...  Training loss: 1.8139...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 7174...  Training loss: 1.7677...  0.0579 sec/batch
Epoch: 12/20...  Training Step: 7175...  Training loss: 1.7737...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 7176...  Training loss: 1.8348...  0.0565 sec/batch
Epoch: 12/20...  Training Step: 7177...  Training loss: 1.8773...  0.0557 sec/batch
Epoch: 12/20...  Training Step: 7178...  Training loss: 1.8283...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 7179...  Training loss: 1.8136...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 7180...  Training loss: 1.7959...  0.0560 sec/batch
Epoch: 12/20...  Training Step: 7181...  Training loss: 1.8421...  0.0619 sec/batch
Epoch: 12/20...  Training Step: 7182...  Training loss: 1.7629...  0.0541 sec/batch
Epoch: 12/20...  Training Step: 7183...  Training loss: 1.7597...  0.0572 sec/batch
Epoch: 12/20...  Training Step: 7184...  Training loss: 1.7489...  0.0539 sec/batch
Epoch: 12/20...  Training Step: 7185...  Training loss: 1.7877...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 7186...  Training loss: 1.7951...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 7187...  Training loss: 1.7805...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 7188...  Training loss: 1.8228...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 7189...  Training loss: 1.7802...  0.0550 sec/batch
Epoch: 12/20...  Training Step: 7190...  Training loss: 1.7858...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7191...  Training loss: 1.7991...  0.0561 sec/batch
Epoch: 12/20...  Training Step: 7192...  Training loss: 1.8708...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 7193...  Training loss: 1.8083...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 7194...  Training loss: 1.7893...  0.0569 sec/batch
Epoch: 12/20...  Training Step: 7195...  Training loss: 1.7931...  0.0615 sec/batch
Epoch: 12/20...  Training Step: 7196...  Training loss: 1.7883...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 7197...  Training loss: 1.7517...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 7198...  Training loss: 1.8616...  0.0570 sec/batch
Epoch: 12/20...  Training Step: 7199...  Training loss: 1.8124...  0.0520 sec/batch
Epoch: 12/20...  Training Step: 7200...  Training loss: 1.7909...  0.0555 sec/batch
Epoch: 12/20...  Training Step: 7201...  Training loss: 1.7267...  0.0562 sec/batch
Epoch: 12/20...  Training Step: 7202...  Training loss: 1.8379...  0.0552 sec/batch
Epoch: 12/20...  Training Step: 7203...  Training loss: 1.7712...  0.0590 sec/batch
Epoch: 12/20...  Training Step: 7204...  Training loss: 1.8028...  0.0536 sec/batch
Epoch: 12/20...  Training Step: 7205...  Training loss: 1.8048...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 7206...  Training loss: 1.7114...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 7207...  Training loss: 1.7254...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 7208...  Training loss: 1.8096...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 7209...  Training loss: 1.7483...  0.0556 sec/batch
Epoch: 12/20...  Training Step: 7210...  Training loss: 1.7839...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 7211...  Training loss: 1.8101...  0.0586 sec/batch
Epoch: 12/20...  Training Step: 7212...  Training loss: 1.7466...  0.0543 sec/batch
Epoch: 12/20...  Training Step: 7213...  Training loss: 1.7789...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 7214...  Training loss: 1.8126...  0.0577 sec/batch
Epoch: 12/20...  Training Step: 7215...  Training loss: 1.7496...  0.0535 sec/batch
Epoch: 12/20...  Training Step: 7216...  Training loss: 1.8125...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7217...  Training loss: 1.7794...  0.0526 sec/batch
Epoch: 12/20...  Training Step: 7218...  Training loss: 1.8024...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7219...  Training loss: 1.7640...  0.0522 sec/batch
Epoch: 12/20...  Training Step: 7220...  Training loss: 1.8148...  0.0550 sec/batch
Epoch: 12/20...  Training Step: 7221...  Training loss: 1.8405...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 7222...  Training loss: 1.8058...  0.0536 sec/batch
Epoch: 12/20...  Training Step: 7223...  Training loss: 1.7499...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 7224...  Training loss: 1.8404...  0.0587 sec/batch
Epoch: 12/20...  Training Step: 7225...  Training loss: 1.8438...  0.0558 sec/batch
Epoch: 12/20...  Training Step: 7226...  Training loss: 1.8346...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 7227...  Training loss: 1.8521...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 7228...  Training loss: 1.7951...  0.0581 sec/batch
Epoch: 12/20...  Training Step: 7229...  Training loss: 1.8439...  0.0556 sec/batch
Epoch: 12/20...  Training Step: 7230...  Training loss: 1.8316...  0.0569 sec/batch
Epoch: 12/20...  Training Step: 7231...  Training loss: 1.7569...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 7232...  Training loss: 1.8316...  0.0576 sec/batch
Epoch: 12/20...  Training Step: 7233...  Training loss: 1.8174...  0.0557 sec/batch
Epoch: 12/20...  Training Step: 7234...  Training loss: 1.7695...  0.0557 sec/batch
Epoch: 12/20...  Training Step: 7235...  Training loss: 1.7659...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 7236...  Training loss: 1.7356...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7237...  Training loss: 1.7776...  0.0535 sec/batch
Epoch: 12/20...  Training Step: 7238...  Training loss: 1.7975...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 7239...  Training loss: 1.8276...  0.0560 sec/batch
Epoch: 12/20...  Training Step: 7240...  Training loss: 1.7795...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 7241...  Training loss: 1.7635...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7242...  Training loss: 1.7843...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7243...  Training loss: 1.8130...  0.0523 sec/batch
Epoch: 12/20...  Training Step: 7244...  Training loss: 1.7741...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 7245...  Training loss: 1.8379...  0.0583 sec/batch
Epoch: 12/20...  Training Step: 7246...  Training loss: 1.8113...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 7247...  Training loss: 1.7725...  0.0570 sec/batch
Epoch: 12/20...  Training Step: 7248...  Training loss: 1.8075...  0.0543 sec/batch
Epoch: 12/20...  Training Step: 7249...  Training loss: 1.7733...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 7250...  Training loss: 1.7407...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7251...  Training loss: 1.8014...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 7252...  Training loss: 1.8395...  0.0525 sec/batch
Epoch: 12/20...  Training Step: 7253...  Training loss: 1.8062...  0.0587 sec/batch
Epoch: 12/20...  Training Step: 7254...  Training loss: 1.7750...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 7255...  Training loss: 1.7519...  0.0565 sec/batch
Epoch: 12/20...  Training Step: 7256...  Training loss: 1.7836...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7257...  Training loss: 1.7410...  0.0552 sec/batch
Epoch: 12/20...  Training Step: 7258...  Training loss: 1.7689...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 7259...  Training loss: 1.7951...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 7260...  Training loss: 1.7769...  0.0537 sec/batch
Epoch: 12/20...  Training Step: 7261...  Training loss: 1.7879...  0.0568 sec/batch
Epoch: 12/20...  Training Step: 7262...  Training loss: 1.7745...  0.0538 sec/batch
Epoch: 12/20...  Training Step: 7263...  Training loss: 1.8197...  0.0569 sec/batch
Epoch: 12/20...  Training Step: 7264...  Training loss: 1.7996...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 7265...  Training loss: 1.6880...  0.0555 sec/batch
Epoch: 12/20...  Training Step: 7266...  Training loss: 1.7632...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 7267...  Training loss: 1.7523...  0.0557 sec/batch
Epoch: 12/20...  Training Step: 7268...  Training loss: 1.7348...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 7269...  Training loss: 1.7899...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7270...  Training loss: 1.8427...  0.0522 sec/batch
Epoch: 12/20...  Training Step: 7271...  Training loss: 1.8522...  0.0576 sec/batch
Epoch: 12/20...  Training Step: 7272...  Training loss: 1.8042...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 7273...  Training loss: 1.7506...  0.0539 sec/batch
Epoch: 12/20...  Training Step: 7274...  Training loss: 1.7942...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 7275...  Training loss: 1.7669...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 7276...  Training loss: 1.7831...  0.0550 sec/batch
Epoch: 12/20...  Training Step: 7277...  Training loss: 1.7876...  0.0542 sec/batch
Epoch: 12/20...  Training Step: 7278...  Training loss: 1.7830...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 7279...  Training loss: 1.7836...  0.0559 sec/batch
Epoch: 12/20...  Training Step: 7280...  Training loss: 1.7844...  0.0537 sec/batch
Epoch: 12/20...  Training Step: 7281...  Training loss: 1.7500...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 7282...  Training loss: 1.7980...  0.0543 sec/batch
Epoch: 12/20...  Training Step: 7283...  Training loss: 1.7457...  0.0524 sec/batch
Epoch: 12/20...  Training Step: 7284...  Training loss: 1.7862...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 7285...  Training loss: 1.8106...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 7286...  Training loss: 1.8117...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 7287...  Training loss: 1.7713...  0.0560 sec/batch
Epoch: 12/20...  Training Step: 7288...  Training loss: 1.7979...  0.0537 sec/batch
Epoch: 12/20...  Training Step: 7289...  Training loss: 1.7941...  0.0538 sec/batch
Epoch: 12/20...  Training Step: 7290...  Training loss: 1.7893...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 7291...  Training loss: 1.7801...  0.0573 sec/batch
Epoch: 12/20...  Training Step: 7292...  Training loss: 1.7858...  0.0565 sec/batch
Epoch: 12/20...  Training Step: 7293...  Training loss: 1.7615...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 7294...  Training loss: 1.7297...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 7295...  Training loss: 1.8272...  0.0569 sec/batch
Epoch: 12/20...  Training Step: 7296...  Training loss: 1.8414...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 7297...  Training loss: 1.8075...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 7298...  Training loss: 1.8765...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 7299...  Training loss: 1.7594...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 7300...  Training loss: 1.8341...  0.0561 sec/batch
Epoch: 12/20...  Training Step: 7301...  Training loss: 1.7777...  0.0525 sec/batch
Epoch: 12/20...  Training Step: 7302...  Training loss: 1.7698...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 7303...  Training loss: 1.8254...  0.0524 sec/batch
Epoch: 12/20...  Training Step: 7304...  Training loss: 1.8136...  0.0555 sec/batch
Epoch: 12/20...  Training Step: 7305...  Training loss: 1.8741...  0.0535 sec/batch
Epoch: 12/20...  Training Step: 7306...  Training loss: 1.7760...  0.0539 sec/batch
Epoch: 12/20...  Training Step: 7307...  Training loss: 1.8233...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 7308...  Training loss: 1.7867...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7309...  Training loss: 1.8147...  0.0572 sec/batch
Epoch: 12/20...  Training Step: 7310...  Training loss: 1.7754...  0.0550 sec/batch
Epoch: 12/20...  Training Step: 7311...  Training loss: 1.7778...  0.0537 sec/batch
Epoch: 12/20...  Training Step: 7312...  Training loss: 1.8036...  0.0526 sec/batch
Epoch: 12/20...  Training Step: 7313...  Training loss: 1.7877...  0.0583 sec/batch
Epoch: 12/20...  Training Step: 7314...  Training loss: 1.7556...  0.0550 sec/batch
Epoch: 12/20...  Training Step: 7315...  Training loss: 1.7597...  0.0558 sec/batch
Epoch: 12/20...  Training Step: 7316...  Training loss: 1.7816...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 7317...  Training loss: 1.7775...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7318...  Training loss: 1.8580...  0.0582 sec/batch
Epoch: 12/20...  Training Step: 7319...  Training loss: 1.7315...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 7320...  Training loss: 1.7829...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 7321...  Training loss: 1.7892...  0.0555 sec/batch
Epoch: 12/20...  Training Step: 7322...  Training loss: 1.8211...  0.0563 sec/batch
Epoch: 12/20...  Training Step: 7323...  Training loss: 1.8697...  0.0530 sec/batch
Epoch: 12/20...  Training Step: 7324...  Training loss: 1.8008...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 7325...  Training loss: 1.7494...  0.0606 sec/batch
Epoch: 12/20...  Training Step: 7326...  Training loss: 1.7309...  0.0557 sec/batch
Epoch: 12/20...  Training Step: 7327...  Training loss: 1.8249...  0.0579 sec/batch
Epoch: 12/20...  Training Step: 7328...  Training loss: 1.7857...  0.0530 sec/batch
Epoch: 12/20...  Training Step: 7329...  Training loss: 1.8194...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 7330...  Training loss: 1.8033...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 7331...  Training loss: 1.8436...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 7332...  Training loss: 1.8251...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 7333...  Training loss: 1.8513...  0.0522 sec/batch
Epoch: 12/20...  Training Step: 7334...  Training loss: 1.8481...  0.0579 sec/batch
Epoch: 12/20...  Training Step: 7335...  Training loss: 1.7968...  0.0570 sec/batch
Epoch: 12/20...  Training Step: 7336...  Training loss: 1.7761...  0.0559 sec/batch
Epoch: 12/20...  Training Step: 7337...  Training loss: 1.7984...  0.0535 sec/batch
Epoch: 12/20...  Training Step: 7338...  Training loss: 1.7818...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 7339...  Training loss: 1.7718...  0.0530 sec/batch
Epoch: 12/20...  Training Step: 7340...  Training loss: 1.7588...  0.0578 sec/batch
Epoch: 12/20...  Training Step: 7341...  Training loss: 1.7725...  0.0551 sec/batch
Epoch: 12/20...  Training Step: 7342...  Training loss: 1.7481...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 7343...  Training loss: 1.7669...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 7344...  Training loss: 1.7038...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 7345...  Training loss: 1.8138...  0.0612 sec/batch
Epoch: 12/20...  Training Step: 7346...  Training loss: 1.8438...  0.0552 sec/batch
Epoch: 12/20...  Training Step: 7347...  Training loss: 1.8142...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7348...  Training loss: 1.7938...  0.0568 sec/batch
Epoch: 12/20...  Training Step: 7349...  Training loss: 1.7814...  0.0552 sec/batch
Epoch: 12/20...  Training Step: 7350...  Training loss: 1.7674...  0.0557 sec/batch
Epoch: 12/20...  Training Step: 7351...  Training loss: 1.7756...  0.0530 sec/batch
Epoch: 12/20...  Training Step: 7352...  Training loss: 1.7646...  0.0552 sec/batch
Epoch: 12/20...  Training Step: 7353...  Training loss: 1.7891...  0.0529 sec/batch
Epoch: 12/20...  Training Step: 7354...  Training loss: 1.7862...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 7355...  Training loss: 1.7972...  0.0543 sec/batch
Epoch: 12/20...  Training Step: 7356...  Training loss: 1.8065...  0.0530 sec/batch
Epoch: 12/20...  Training Step: 7357...  Training loss: 1.7414...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 7358...  Training loss: 1.7895...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 7359...  Training loss: 1.7191...  0.0577 sec/batch
Epoch: 12/20...  Training Step: 7360...  Training loss: 1.8111...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 7361...  Training loss: 1.7792...  0.0540 sec/batch
Epoch: 12/20...  Training Step: 7362...  Training loss: 1.7666...  0.0535 sec/batch
Epoch: 12/20...  Training Step: 7363...  Training loss: 1.7661...  0.0596 sec/batch
Epoch: 12/20...  Training Step: 7364...  Training loss: 1.7453...  0.0564 sec/batch
Epoch: 12/20...  Training Step: 7365...  Training loss: 1.8273...  0.0530 sec/batch
Epoch: 12/20...  Training Step: 7366...  Training loss: 1.7750...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 7367...  Training loss: 1.7962...  0.0538 sec/batch
Epoch: 12/20...  Training Step: 7368...  Training loss: 1.8300...  0.0544 sec/batch
Epoch: 12/20...  Training Step: 7369...  Training loss: 1.8390...  0.0556 sec/batch
Epoch: 12/20...  Training Step: 7370...  Training loss: 1.7764...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 7371...  Training loss: 1.8083...  0.0548 sec/batch
Epoch: 12/20...  Training Step: 7372...  Training loss: 1.7453...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 7373...  Training loss: 1.7893...  0.0554 sec/batch
Epoch: 12/20...  Training Step: 7374...  Training loss: 1.7962...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 7375...  Training loss: 1.7719...  0.0580 sec/batch
Epoch: 12/20...  Training Step: 7376...  Training loss: 1.7812...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 7377...  Training loss: 1.7927...  0.0583 sec/batch
Epoch: 12/20...  Training Step: 7378...  Training loss: 1.7545...  0.0543 sec/batch
Epoch: 12/20...  Training Step: 7379...  Training loss: 1.7989...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 7380...  Training loss: 1.7841...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 7381...  Training loss: 1.8348...  0.0670 sec/batch
Epoch: 12/20...  Training Step: 7382...  Training loss: 1.8179...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7383...  Training loss: 1.7830...  0.0579 sec/batch
Epoch: 12/20...  Training Step: 7384...  Training loss: 1.8697...  0.0571 sec/batch
Epoch: 12/20...  Training Step: 7385...  Training loss: 1.9004...  0.0553 sec/batch
Epoch: 12/20...  Training Step: 7386...  Training loss: 1.8402...  0.0555 sec/batch
Epoch: 12/20...  Training Step: 7387...  Training loss: 1.7707...  0.0540 sec/batch
Epoch: 12/20...  Training Step: 7388...  Training loss: 1.8781...  0.0550 sec/batch
Epoch: 12/20...  Training Step: 7389...  Training loss: 1.7699...  0.0539 sec/batch
Epoch: 12/20...  Training Step: 7390...  Training loss: 1.8231...  0.0533 sec/batch
Epoch: 12/20...  Training Step: 7391...  Training loss: 1.8108...  0.0591 sec/batch
Epoch: 12/20...  Training Step: 7392...  Training loss: 1.8587...  0.0536 sec/batch
Epoch: 12/20...  Training Step: 7393...  Training loss: 1.7825...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 7394...  Training loss: 1.7606...  0.0530 sec/batch
Epoch: 12/20...  Training Step: 7395...  Training loss: 1.8098...  0.0555 sec/batch
Epoch: 12/20...  Training Step: 7396...  Training loss: 1.8157...  0.0540 sec/batch
Epoch: 12/20...  Training Step: 7397...  Training loss: 1.7413...  0.0543 sec/batch
Epoch: 12/20...  Training Step: 7398...  Training loss: 1.7844...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 7399...  Training loss: 1.8291...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 7400...  Training loss: 1.8206...  0.0531 sec/batch
Epoch: 12/20...  Training Step: 7401...  Training loss: 1.8330...  0.0537 sec/batch
Epoch: 12/20...  Training Step: 7402...  Training loss: 1.7851...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 7403...  Training loss: 1.8069...  0.0522 sec/batch
Epoch: 12/20...  Training Step: 7404...  Training loss: 1.8236...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 7405...  Training loss: 1.8045...  0.0523 sec/batch
Epoch: 12/20...  Training Step: 7406...  Training loss: 1.8067...  0.0536 sec/batch
Epoch: 12/20...  Training Step: 7407...  Training loss: 1.7619...  0.0576 sec/batch
Epoch: 12/20...  Training Step: 7408...  Training loss: 1.7933...  0.0572 sec/batch
Epoch: 12/20...  Training Step: 7409...  Training loss: 1.7897...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 7410...  Training loss: 1.8375...  0.0546 sec/batch
Epoch: 12/20...  Training Step: 7411...  Training loss: 1.7671...  0.0581 sec/batch
Epoch: 12/20...  Training Step: 7412...  Training loss: 1.8369...  0.0582 sec/batch
Epoch: 12/20...  Training Step: 7413...  Training loss: 1.7872...  0.0566 sec/batch
Epoch: 12/20...  Training Step: 7414...  Training loss: 1.7646...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 7415...  Training loss: 1.7617...  0.0536 sec/batch
Epoch: 12/20...  Training Step: 7416...  Training loss: 1.7663...  0.0528 sec/batch
Epoch: 12/20...  Training Step: 7417...  Training loss: 1.7395...  0.0569 sec/batch
Epoch: 12/20...  Training Step: 7418...  Training loss: 1.7965...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 7419...  Training loss: 1.8088...  0.0532 sec/batch
Epoch: 12/20...  Training Step: 7420...  Training loss: 1.8252...  0.0576 sec/batch
Epoch: 12/20...  Training Step: 7421...  Training loss: 1.7674...  0.0577 sec/batch
Epoch: 12/20...  Training Step: 7422...  Training loss: 1.7983...  0.0576 sec/batch
Epoch: 12/20...  Training Step: 7423...  Training loss: 1.7934...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 7424...  Training loss: 1.7676...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 7425...  Training loss: 1.7980...  0.0547 sec/batch
Epoch: 12/20...  Training Step: 7426...  Training loss: 1.7974...  0.0529 sec/batch
Epoch: 12/20...  Training Step: 7427...  Training loss: 1.7438...  0.0580 sec/batch
Epoch: 12/20...  Training Step: 7428...  Training loss: 1.7531...  0.0574 sec/batch
Epoch: 12/20...  Training Step: 7429...  Training loss: 1.7727...  0.0527 sec/batch
Epoch: 12/20...  Training Step: 7430...  Training loss: 1.8395...  0.0602 sec/batch
Epoch: 12/20...  Training Step: 7431...  Training loss: 1.8488...  0.0562 sec/batch
Epoch: 12/20...  Training Step: 7432...  Training loss: 1.7978...  0.0569 sec/batch
Epoch: 12/20...  Training Step: 7433...  Training loss: 1.7484...  0.0583 sec/batch
Epoch: 12/20...  Training Step: 7434...  Training loss: 1.7888...  0.0534 sec/batch
Epoch: 12/20...  Training Step: 7435...  Training loss: 1.7481...  0.0530 sec/batch
Epoch: 12/20...  Training Step: 7436...  Training loss: 1.8262...  0.0549 sec/batch
Epoch: 12/20...  Training Step: 7437...  Training loss: 1.8449...  0.0612 sec/batch
Epoch: 12/20...  Training Step: 7438...  Training loss: 1.7615...  0.0538 sec/batch
Epoch: 12/20...  Training Step: 7439...  Training loss: 1.7374...  0.0545 sec/batch
Epoch: 12/20...  Training Step: 7440...  Training loss: 1.7488...  0.0544 sec/batch
Epoch: 13/20...  Training Step: 7441...  Training loss: 1.8563...  0.0562 sec/batch
Epoch: 13/20...  Training Step: 7442...  Training loss: 1.8781...  0.0573 sec/batch
Epoch: 13/20...  Training Step: 7443...  Training loss: 1.8336...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 7444...  Training loss: 1.7626...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7445...  Training loss: 1.7962...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7446...  Training loss: 1.8196...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7447...  Training loss: 1.7597...  0.0559 sec/batch
Epoch: 13/20...  Training Step: 7448...  Training loss: 1.7634...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 7449...  Training loss: 1.7428...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7450...  Training loss: 1.7608...  0.0536 sec/batch
Epoch: 13/20...  Training Step: 7451...  Training loss: 1.7660...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 7452...  Training loss: 1.7599...  0.0580 sec/batch
Epoch: 13/20...  Training Step: 7453...  Training loss: 1.7781...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7454...  Training loss: 1.7480...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 7455...  Training loss: 1.8195...  0.0570 sec/batch
Epoch: 13/20...  Training Step: 7456...  Training loss: 1.8348...  0.0554 sec/batch
Epoch: 13/20...  Training Step: 7457...  Training loss: 1.7755...  0.0554 sec/batch
Epoch: 13/20...  Training Step: 7458...  Training loss: 1.7937...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7459...  Training loss: 1.7696...  0.0562 sec/batch
Epoch: 13/20...  Training Step: 7460...  Training loss: 1.7890...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7461...  Training loss: 1.8406...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 7462...  Training loss: 1.7757...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 7463...  Training loss: 1.7680...  0.0584 sec/batch
Epoch: 13/20...  Training Step: 7464...  Training loss: 1.8072...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7465...  Training loss: 1.7819...  0.0568 sec/batch
Epoch: 13/20...  Training Step: 7466...  Training loss: 1.7468...  0.0602 sec/batch
Epoch: 13/20...  Training Step: 7467...  Training loss: 1.7866...  0.0584 sec/batch
Epoch: 13/20...  Training Step: 7468...  Training loss: 1.8226...  0.0565 sec/batch
Epoch: 13/20...  Training Step: 7469...  Training loss: 1.7872...  0.0568 sec/batch
Epoch: 13/20...  Training Step: 7470...  Training loss: 1.7428...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7471...  Training loss: 1.7395...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7472...  Training loss: 1.8044...  0.0586 sec/batch
Epoch: 13/20...  Training Step: 7473...  Training loss: 1.7868...  0.0575 sec/batch
Epoch: 13/20...  Training Step: 7474...  Training loss: 1.7741...  0.0530 sec/batch
Epoch: 13/20...  Training Step: 7475...  Training loss: 1.7784...  0.0572 sec/batch
Epoch: 13/20...  Training Step: 7476...  Training loss: 1.7903...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7477...  Training loss: 1.7800...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7478...  Training loss: 1.8067...  0.0550 sec/batch
Epoch: 13/20...  Training Step: 7479...  Training loss: 1.7907...  0.0554 sec/batch
Epoch: 13/20...  Training Step: 7480...  Training loss: 1.7632...  0.0523 sec/batch
Epoch: 13/20...  Training Step: 7481...  Training loss: 1.7906...  0.0558 sec/batch
Epoch: 13/20...  Training Step: 7482...  Training loss: 1.8092...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7483...  Training loss: 1.8054...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7484...  Training loss: 1.7926...  0.0563 sec/batch
Epoch: 13/20...  Training Step: 7485...  Training loss: 1.7785...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7486...  Training loss: 1.7676...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7487...  Training loss: 1.6746...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7488...  Training loss: 1.7793...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7489...  Training loss: 1.7336...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 7490...  Training loss: 1.8129...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7491...  Training loss: 1.7561...  0.0585 sec/batch
Epoch: 13/20...  Training Step: 7492...  Training loss: 1.7504...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7493...  Training loss: 1.7669...  0.0580 sec/batch
Epoch: 13/20...  Training Step: 7494...  Training loss: 1.7985...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7495...  Training loss: 1.7966...  0.0543 sec/batch
Epoch: 13/20...  Training Step: 7496...  Training loss: 1.7718...  0.0526 sec/batch
Epoch: 13/20...  Training Step: 7497...  Training loss: 1.7339...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 7498...  Training loss: 1.7784...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7499...  Training loss: 1.7665...  0.0621 sec/batch
Epoch: 13/20...  Training Step: 7500...  Training loss: 1.8369...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7501...  Training loss: 1.7726...  0.0581 sec/batch
Epoch: 13/20...  Training Step: 7502...  Training loss: 1.7609...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7503...  Training loss: 1.8160...  0.0564 sec/batch
Epoch: 13/20...  Training Step: 7504...  Training loss: 1.7713...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7505...  Training loss: 1.7435...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7506...  Training loss: 1.7120...  0.0588 sec/batch
Epoch: 13/20...  Training Step: 7507...  Training loss: 1.7562...  0.0587 sec/batch
Epoch: 13/20...  Training Step: 7508...  Training loss: 1.7515...  0.0562 sec/batch
Epoch: 13/20...  Training Step: 7509...  Training loss: 1.7955...  0.0555 sec/batch
Epoch: 13/20...  Training Step: 7510...  Training loss: 1.7807...  0.0569 sec/batch
Epoch: 13/20...  Training Step: 7511...  Training loss: 1.8251...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 7512...  Training loss: 1.7922...  0.0579 sec/batch
Epoch: 13/20...  Training Step: 7513...  Training loss: 1.7089...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7514...  Training loss: 1.7493...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7515...  Training loss: 1.8325...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 7516...  Training loss: 1.8036...  0.0524 sec/batch
Epoch: 13/20...  Training Step: 7517...  Training loss: 1.7718...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7518...  Training loss: 1.7586...  0.0574 sec/batch
Epoch: 13/20...  Training Step: 7519...  Training loss: 1.7827...  0.0616 sec/batch
Epoch: 13/20...  Training Step: 7520...  Training loss: 1.8036...  0.0572 sec/batch
Epoch: 13/20...  Training Step: 7521...  Training loss: 1.7239...  0.0581 sec/batch
Epoch: 13/20...  Training Step: 7522...  Training loss: 1.7909...  0.0550 sec/batch
Epoch: 13/20...  Training Step: 7523...  Training loss: 1.7530...  0.0578 sec/batch
Epoch: 13/20...  Training Step: 7524...  Training loss: 1.7554...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7525...  Training loss: 1.7514...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7526...  Training loss: 1.8218...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7527...  Training loss: 1.7502...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7528...  Training loss: 1.8271...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7529...  Training loss: 1.7657...  0.0540 sec/batch
Epoch: 13/20...  Training Step: 7530...  Training loss: 1.7983...  0.0552 sec/batch
Epoch: 13/20...  Training Step: 7531...  Training loss: 1.7451...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7532...  Training loss: 1.8334...  0.0560 sec/batch
Epoch: 13/20...  Training Step: 7533...  Training loss: 1.7923...  0.0555 sec/batch
Epoch: 13/20...  Training Step: 7534...  Training loss: 1.7679...  0.0558 sec/batch
Epoch: 13/20...  Training Step: 7535...  Training loss: 1.7622...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7536...  Training loss: 1.8005...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7537...  Training loss: 1.8225...  0.0592 sec/batch
Epoch: 13/20...  Training Step: 7538...  Training loss: 1.7175...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7539...  Training loss: 1.8224...  0.0555 sec/batch
Epoch: 13/20...  Training Step: 7540...  Training loss: 1.7561...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7541...  Training loss: 1.7620...  0.0541 sec/batch
Epoch: 13/20...  Training Step: 7542...  Training loss: 1.7442...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7543...  Training loss: 1.8022...  0.0554 sec/batch
Epoch: 13/20...  Training Step: 7544...  Training loss: 1.8334...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7545...  Training loss: 1.7893...  0.0586 sec/batch
Epoch: 13/20...  Training Step: 7546...  Training loss: 1.7619...  0.0573 sec/batch
Epoch: 13/20...  Training Step: 7547...  Training loss: 1.8098...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7548...  Training loss: 1.7720...  0.0524 sec/batch
Epoch: 13/20...  Training Step: 7549...  Training loss: 1.7788...  0.0558 sec/batch
Epoch: 13/20...  Training Step: 7550...  Training loss: 1.7467...  0.0584 sec/batch
Epoch: 13/20...  Training Step: 7551...  Training loss: 1.7447...  0.0534 sec/batch
Epoch: 13/20...  Training Step: 7552...  Training loss: 1.7646...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7553...  Training loss: 1.7546...  0.0552 sec/batch
Epoch: 13/20...  Training Step: 7554...  Training loss: 1.7709...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 7555...  Training loss: 1.8078...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7556...  Training loss: 1.8173...  0.0587 sec/batch
Epoch: 13/20...  Training Step: 7557...  Training loss: 1.7369...  0.0552 sec/batch
Epoch: 13/20...  Training Step: 7558...  Training loss: 1.8102...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 7559...  Training loss: 1.7772...  0.0527 sec/batch
Epoch: 13/20...  Training Step: 7560...  Training loss: 1.7734...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7561...  Training loss: 1.7547...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7562...  Training loss: 1.7301...  0.0550 sec/batch
Epoch: 13/20...  Training Step: 7563...  Training loss: 1.7576...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7564...  Training loss: 1.8055...  0.0526 sec/batch
Epoch: 13/20...  Training Step: 7565...  Training loss: 1.8007...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7566...  Training loss: 1.8235...  0.0527 sec/batch
Epoch: 13/20...  Training Step: 7567...  Training loss: 1.8366...  0.0558 sec/batch
Epoch: 13/20...  Training Step: 7568...  Training loss: 1.7422...  0.0527 sec/batch
Epoch: 13/20...  Training Step: 7569...  Training loss: 1.7692...  0.0579 sec/batch
Epoch: 13/20...  Training Step: 7570...  Training loss: 1.8229...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7571...  Training loss: 1.7808...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 7572...  Training loss: 1.8181...  0.0583 sec/batch
Epoch: 13/20...  Training Step: 7573...  Training loss: 1.8333...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7574...  Training loss: 1.7793...  0.0537 sec/batch
Epoch: 13/20...  Training Step: 7575...  Training loss: 1.7613...  0.0538 sec/batch
Epoch: 13/20...  Training Step: 7576...  Training loss: 1.7611...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7577...  Training loss: 1.7877...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7578...  Training loss: 1.7717...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7579...  Training loss: 1.8236...  0.0522 sec/batch
Epoch: 13/20...  Training Step: 7580...  Training loss: 1.7982...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7581...  Training loss: 1.8318...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 7582...  Training loss: 1.7077...  0.0540 sec/batch
Epoch: 13/20...  Training Step: 7583...  Training loss: 1.7843...  0.0534 sec/batch
Epoch: 13/20...  Training Step: 7584...  Training loss: 1.7601...  0.0544 sec/batch
Epoch: 13/20...  Training Step: 7585...  Training loss: 1.7331...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7586...  Training loss: 1.8035...  0.0530 sec/batch
Epoch: 13/20...  Training Step: 7587...  Training loss: 1.7860...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 7588...  Training loss: 1.8113...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7589...  Training loss: 1.7818...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7590...  Training loss: 1.8280...  0.0523 sec/batch
Epoch: 13/20...  Training Step: 7591...  Training loss: 1.8080...  0.0593 sec/batch
Epoch: 13/20...  Training Step: 7592...  Training loss: 1.7710...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7593...  Training loss: 1.7705...  0.0538 sec/batch
Epoch: 13/20...  Training Step: 7594...  Training loss: 1.8301...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7595...  Training loss: 1.7620...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7596...  Training loss: 1.8030...  0.0574 sec/batch
Epoch: 13/20...  Training Step: 7597...  Training loss: 1.7865...  0.0567 sec/batch
Epoch: 13/20...  Training Step: 7598...  Training loss: 1.8093...  0.0538 sec/batch
Epoch: 13/20...  Training Step: 7599...  Training loss: 1.8010...  0.0578 sec/batch
Epoch: 13/20...  Training Step: 7600...  Training loss: 1.7461...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7601...  Training loss: 1.7441...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7602...  Training loss: 1.7352...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7603...  Training loss: 1.7833...  0.0567 sec/batch
Epoch: 13/20...  Training Step: 7604...  Training loss: 1.7777...  0.0614 sec/batch
Epoch: 13/20...  Training Step: 7605...  Training loss: 1.7919...  0.0538 sec/batch
Epoch: 13/20...  Training Step: 7606...  Training loss: 1.8021...  0.0555 sec/batch
Epoch: 13/20...  Training Step: 7607...  Training loss: 1.7856...  0.0583 sec/batch
Epoch: 13/20...  Training Step: 7608...  Training loss: 1.7846...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 7609...  Training loss: 1.7778...  0.0536 sec/batch
Epoch: 13/20...  Training Step: 7610...  Training loss: 1.7440...  0.0573 sec/batch
Epoch: 13/20...  Training Step: 7611...  Training loss: 1.7656...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 7612...  Training loss: 1.7877...  0.0526 sec/batch
Epoch: 13/20...  Training Step: 7613...  Training loss: 1.7784...  0.0565 sec/batch
Epoch: 13/20...  Training Step: 7614...  Training loss: 1.7528...  0.0536 sec/batch
Epoch: 13/20...  Training Step: 7615...  Training loss: 1.7420...  0.0574 sec/batch
Epoch: 13/20...  Training Step: 7616...  Training loss: 1.7816...  0.0550 sec/batch
Epoch: 13/20...  Training Step: 7617...  Training loss: 1.7937...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7618...  Training loss: 1.7309...  0.0537 sec/batch
Epoch: 13/20...  Training Step: 7619...  Training loss: 1.7279...  0.0577 sec/batch
Epoch: 13/20...  Training Step: 7620...  Training loss: 1.7566...  0.0566 sec/batch
Epoch: 13/20...  Training Step: 7621...  Training loss: 1.7440...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7622...  Training loss: 1.8087...  0.0566 sec/batch
Epoch: 13/20...  Training Step: 7623...  Training loss: 1.7979...  0.0564 sec/batch
Epoch: 13/20...  Training Step: 7624...  Training loss: 1.7633...  0.0571 sec/batch
Epoch: 13/20...  Training Step: 7625...  Training loss: 1.7293...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 7626...  Training loss: 1.7754...  0.0544 sec/batch
Epoch: 13/20...  Training Step: 7627...  Training loss: 1.7802...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7628...  Training loss: 1.7430...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 7629...  Training loss: 1.7716...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7630...  Training loss: 1.8510...  0.0536 sec/batch
Epoch: 13/20...  Training Step: 7631...  Training loss: 1.8015...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7632...  Training loss: 1.8414...  0.0554 sec/batch
Epoch: 13/20...  Training Step: 7633...  Training loss: 1.8127...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7634...  Training loss: 1.7556...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7635...  Training loss: 1.7579...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 7636...  Training loss: 1.8593...  0.0530 sec/batch
Epoch: 13/20...  Training Step: 7637...  Training loss: 1.7714...  0.0527 sec/batch
Epoch: 13/20...  Training Step: 7638...  Training loss: 1.8433...  0.0534 sec/batch
Epoch: 13/20...  Training Step: 7639...  Training loss: 1.7689...  0.0587 sec/batch
Epoch: 13/20...  Training Step: 7640...  Training loss: 1.7927...  0.0591 sec/batch
Epoch: 13/20...  Training Step: 7641...  Training loss: 1.7743...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7642...  Training loss: 1.7795...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 7643...  Training loss: 1.7653...  0.0583 sec/batch
Epoch: 13/20...  Training Step: 7644...  Training loss: 1.7662...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7645...  Training loss: 1.7830...  0.0570 sec/batch
Epoch: 13/20...  Training Step: 7646...  Training loss: 1.7444...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 7647...  Training loss: 1.8018...  0.0530 sec/batch
Epoch: 13/20...  Training Step: 7648...  Training loss: 1.7906...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7649...  Training loss: 1.7685...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7650...  Training loss: 1.7456...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7651...  Training loss: 1.7879...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7652...  Training loss: 1.7720...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7653...  Training loss: 1.8168...  0.0595 sec/batch
Epoch: 13/20...  Training Step: 7654...  Training loss: 1.8021...  0.0534 sec/batch
Epoch: 13/20...  Training Step: 7655...  Training loss: 1.7929...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7656...  Training loss: 1.8070...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7657...  Training loss: 1.8040...  0.0523 sec/batch
Epoch: 13/20...  Training Step: 7658...  Training loss: 1.7496...  0.0602 sec/batch
Epoch: 13/20...  Training Step: 7659...  Training loss: 1.8524...  0.0544 sec/batch
Epoch: 13/20...  Training Step: 7660...  Training loss: 1.8335...  0.0526 sec/batch
Epoch: 13/20...  Training Step: 7661...  Training loss: 1.7958...  0.0563 sec/batch
Epoch: 13/20...  Training Step: 7662...  Training loss: 1.8231...  0.0525 sec/batch
Epoch: 13/20...  Training Step: 7663...  Training loss: 1.8256...  0.0561 sec/batch
Epoch: 13/20...  Training Step: 7664...  Training loss: 1.7468...  0.0552 sec/batch
Epoch: 13/20...  Training Step: 7665...  Training loss: 1.7597...  0.0561 sec/batch
Epoch: 13/20...  Training Step: 7666...  Training loss: 1.8202...  0.0555 sec/batch
Epoch: 13/20...  Training Step: 7667...  Training loss: 1.8136...  0.0530 sec/batch
Epoch: 13/20...  Training Step: 7668...  Training loss: 1.7452...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7669...  Training loss: 1.8004...  0.0525 sec/batch
Epoch: 13/20...  Training Step: 7670...  Training loss: 1.7550...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7671...  Training loss: 1.8374...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7672...  Training loss: 1.7588...  0.0578 sec/batch
Epoch: 13/20...  Training Step: 7673...  Training loss: 1.7461...  0.0550 sec/batch
Epoch: 13/20...  Training Step: 7674...  Training loss: 1.7757...  0.0527 sec/batch
Epoch: 13/20...  Training Step: 7675...  Training loss: 1.7272...  0.0615 sec/batch
Epoch: 13/20...  Training Step: 7676...  Training loss: 1.8023...  0.0588 sec/batch
Epoch: 13/20...  Training Step: 7677...  Training loss: 1.7672...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7678...  Training loss: 1.7448...  0.0525 sec/batch
Epoch: 13/20...  Training Step: 7679...  Training loss: 1.7633...  0.0537 sec/batch
Epoch: 13/20...  Training Step: 7680...  Training loss: 1.8038...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7681...  Training loss: 1.7415...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 7682...  Training loss: 1.7453...  0.0581 sec/batch
Epoch: 13/20...  Training Step: 7683...  Training loss: 1.7627...  0.0585 sec/batch
Epoch: 13/20...  Training Step: 7684...  Training loss: 1.7524...  0.0582 sec/batch
Epoch: 13/20...  Training Step: 7685...  Training loss: 1.7868...  0.0580 sec/batch
Epoch: 13/20...  Training Step: 7686...  Training loss: 1.7649...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7687...  Training loss: 1.7914...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 7688...  Training loss: 1.7991...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 7689...  Training loss: 1.7491...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 7690...  Training loss: 1.7650...  0.0559 sec/batch
Epoch: 13/20...  Training Step: 7691...  Training loss: 1.7881...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 7692...  Training loss: 1.7445...  0.0581 sec/batch
Epoch: 13/20...  Training Step: 7693...  Training loss: 1.7957...  0.0583 sec/batch
Epoch: 13/20...  Training Step: 7694...  Training loss: 1.8046...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7695...  Training loss: 1.8496...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7696...  Training loss: 1.7899...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7697...  Training loss: 1.7781...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7698...  Training loss: 1.7731...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7699...  Training loss: 1.7856...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 7700...  Training loss: 1.7622...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7701...  Training loss: 1.7921...  0.0541 sec/batch
Epoch: 13/20...  Training Step: 7702...  Training loss: 1.7695...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 7703...  Training loss: 1.7922...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7704...  Training loss: 1.7833...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7705...  Training loss: 1.7845...  0.0558 sec/batch
Epoch: 13/20...  Training Step: 7706...  Training loss: 1.7209...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7707...  Training loss: 1.7649...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7708...  Training loss: 1.7982...  0.0570 sec/batch
Epoch: 13/20...  Training Step: 7709...  Training loss: 1.7684...  0.0538 sec/batch
Epoch: 13/20...  Training Step: 7710...  Training loss: 1.7319...  0.0527 sec/batch
Epoch: 13/20...  Training Step: 7711...  Training loss: 1.7392...  0.0562 sec/batch
Epoch: 13/20...  Training Step: 7712...  Training loss: 1.7773...  0.0572 sec/batch
Epoch: 13/20...  Training Step: 7713...  Training loss: 1.7643...  0.0539 sec/batch
Epoch: 13/20...  Training Step: 7714...  Training loss: 1.7557...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7715...  Training loss: 1.7992...  0.0537 sec/batch
Epoch: 13/20...  Training Step: 7716...  Training loss: 1.8127...  0.0573 sec/batch
Epoch: 13/20...  Training Step: 7717...  Training loss: 1.8719...  0.0563 sec/batch
Epoch: 13/20...  Training Step: 7718...  Training loss: 1.8088...  0.0555 sec/batch
Epoch: 13/20...  Training Step: 7719...  Training loss: 1.8276...  0.0580 sec/batch
Epoch: 13/20...  Training Step: 7720...  Training loss: 1.8367...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7721...  Training loss: 1.7712...  0.0534 sec/batch
Epoch: 13/20...  Training Step: 7722...  Training loss: 1.7246...  0.0539 sec/batch
Epoch: 13/20...  Training Step: 7723...  Training loss: 1.7495...  0.0524 sec/batch
Epoch: 13/20...  Training Step: 7724...  Training loss: 1.7884...  0.0578 sec/batch
Epoch: 13/20...  Training Step: 7725...  Training loss: 1.7738...  0.0544 sec/batch
Epoch: 13/20...  Training Step: 7726...  Training loss: 1.8054...  0.0565 sec/batch
Epoch: 13/20...  Training Step: 7727...  Training loss: 1.7576...  0.0526 sec/batch
Epoch: 13/20...  Training Step: 7728...  Training loss: 1.7787...  0.0572 sec/batch
Epoch: 13/20...  Training Step: 7729...  Training loss: 1.7890...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7730...  Training loss: 1.8327...  0.0597 sec/batch
Epoch: 13/20...  Training Step: 7731...  Training loss: 1.7615...  0.0536 sec/batch
Epoch: 13/20...  Training Step: 7732...  Training loss: 1.7870...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7733...  Training loss: 1.7682...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7734...  Training loss: 1.7939...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7735...  Training loss: 1.7716...  0.0539 sec/batch
Epoch: 13/20...  Training Step: 7736...  Training loss: 1.7323...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7737...  Training loss: 1.8070...  0.0541 sec/batch
Epoch: 13/20...  Training Step: 7738...  Training loss: 1.8075...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7739...  Training loss: 1.8004...  0.0544 sec/batch
Epoch: 13/20...  Training Step: 7740...  Training loss: 1.7787...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7741...  Training loss: 1.8215...  0.0562 sec/batch
Epoch: 13/20...  Training Step: 7742...  Training loss: 1.8696...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7743...  Training loss: 1.7511...  0.0530 sec/batch
Epoch: 13/20...  Training Step: 7744...  Training loss: 1.8186...  0.0588 sec/batch
Epoch: 13/20...  Training Step: 7745...  Training loss: 1.7545...  0.0523 sec/batch
Epoch: 13/20...  Training Step: 7746...  Training loss: 1.7700...  0.0561 sec/batch
Epoch: 13/20...  Training Step: 7747...  Training loss: 1.7915...  0.0527 sec/batch
Epoch: 13/20...  Training Step: 7748...  Training loss: 1.7652...  0.0578 sec/batch
Epoch: 13/20...  Training Step: 7749...  Training loss: 1.7688...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 7750...  Training loss: 1.7717...  0.0539 sec/batch
Epoch: 13/20...  Training Step: 7751...  Training loss: 1.7405...  0.0561 sec/batch
Epoch: 13/20...  Training Step: 7752...  Training loss: 1.7472...  0.0526 sec/batch
Epoch: 13/20...  Training Step: 7753...  Training loss: 1.7384...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7754...  Training loss: 1.7293...  0.0578 sec/batch
Epoch: 13/20...  Training Step: 7755...  Training loss: 1.7850...  0.0566 sec/batch
Epoch: 13/20...  Training Step: 7756...  Training loss: 1.8058...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7757...  Training loss: 1.7537...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7758...  Training loss: 1.7263...  0.0552 sec/batch
Epoch: 13/20...  Training Step: 7759...  Training loss: 1.7430...  0.0536 sec/batch
Epoch: 13/20...  Training Step: 7760...  Training loss: 1.8171...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7761...  Training loss: 1.7501...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 7762...  Training loss: 1.7291...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7763...  Training loss: 1.7810...  0.0525 sec/batch
Epoch: 13/20...  Training Step: 7764...  Training loss: 1.7648...  0.0566 sec/batch
Epoch: 13/20...  Training Step: 7765...  Training loss: 1.7528...  0.0524 sec/batch
Epoch: 13/20...  Training Step: 7766...  Training loss: 1.7651...  0.0583 sec/batch
Epoch: 13/20...  Training Step: 7767...  Training loss: 1.7232...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7768...  Training loss: 1.7335...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7769...  Training loss: 1.7896...  0.0534 sec/batch
Epoch: 13/20...  Training Step: 7770...  Training loss: 1.7700...  0.0527 sec/batch
Epoch: 13/20...  Training Step: 7771...  Training loss: 1.7868...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 7772...  Training loss: 1.7725...  0.0550 sec/batch
Epoch: 13/20...  Training Step: 7773...  Training loss: 1.7472...  0.0569 sec/batch
Epoch: 13/20...  Training Step: 7774...  Training loss: 1.7791...  0.0522 sec/batch
Epoch: 13/20...  Training Step: 7775...  Training loss: 1.7813...  0.0552 sec/batch
Epoch: 13/20...  Training Step: 7776...  Training loss: 1.7736...  0.0525 sec/batch
Epoch: 13/20...  Training Step: 7777...  Training loss: 1.7470...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7778...  Training loss: 1.7483...  0.0587 sec/batch
Epoch: 13/20...  Training Step: 7779...  Training loss: 1.7484...  0.0579 sec/batch
Epoch: 13/20...  Training Step: 7780...  Training loss: 1.7622...  0.0536 sec/batch
Epoch: 13/20...  Training Step: 7781...  Training loss: 1.7836...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7782...  Training loss: 1.7564...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7783...  Training loss: 1.7334...  0.0544 sec/batch
Epoch: 13/20...  Training Step: 7784...  Training loss: 1.7547...  0.0554 sec/batch
Epoch: 13/20...  Training Step: 7785...  Training loss: 1.7629...  0.0530 sec/batch
Epoch: 13/20...  Training Step: 7786...  Training loss: 1.7702...  0.0550 sec/batch
Epoch: 13/20...  Training Step: 7787...  Training loss: 1.7929...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7788...  Training loss: 1.7863...  0.0554 sec/batch
Epoch: 13/20...  Training Step: 7789...  Training loss: 1.7584...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 7790...  Training loss: 1.7441...  0.0530 sec/batch
Epoch: 13/20...  Training Step: 7791...  Training loss: 1.8305...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7792...  Training loss: 1.7862...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7793...  Training loss: 1.7834...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7794...  Training loss: 1.7582...  0.0526 sec/batch
Epoch: 13/20...  Training Step: 7795...  Training loss: 1.7436...  0.0552 sec/batch
Epoch: 13/20...  Training Step: 7796...  Training loss: 1.8439...  0.0585 sec/batch
Epoch: 13/20...  Training Step: 7797...  Training loss: 1.8750...  0.0527 sec/batch
Epoch: 13/20...  Training Step: 7798...  Training loss: 1.7930...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7799...  Training loss: 1.7925...  0.0526 sec/batch
Epoch: 13/20...  Training Step: 7800...  Training loss: 1.7881...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7801...  Training loss: 1.8018...  0.0559 sec/batch
Epoch: 13/20...  Training Step: 7802...  Training loss: 1.7609...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7803...  Training loss: 1.7314...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7804...  Training loss: 1.7302...  0.0523 sec/batch
Epoch: 13/20...  Training Step: 7805...  Training loss: 1.7683...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7806...  Training loss: 1.7870...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7807...  Training loss: 1.7602...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7808...  Training loss: 1.8094...  0.0569 sec/batch
Epoch: 13/20...  Training Step: 7809...  Training loss: 1.7921...  0.0526 sec/batch
Epoch: 13/20...  Training Step: 7810...  Training loss: 1.7491...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7811...  Training loss: 1.7738...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 7812...  Training loss: 1.8431...  0.0584 sec/batch
Epoch: 13/20...  Training Step: 7813...  Training loss: 1.7886...  0.0560 sec/batch
Epoch: 13/20...  Training Step: 7814...  Training loss: 1.7788...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7815...  Training loss: 1.7717...  0.0588 sec/batch
Epoch: 13/20...  Training Step: 7816...  Training loss: 1.7610...  0.0569 sec/batch
Epoch: 13/20...  Training Step: 7817...  Training loss: 1.7485...  0.0593 sec/batch
Epoch: 13/20...  Training Step: 7818...  Training loss: 1.8573...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7819...  Training loss: 1.7928...  0.0558 sec/batch
Epoch: 13/20...  Training Step: 7820...  Training loss: 1.7787...  0.0559 sec/batch
Epoch: 13/20...  Training Step: 7821...  Training loss: 1.6990...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7822...  Training loss: 1.8339...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7823...  Training loss: 1.7325...  0.0579 sec/batch
Epoch: 13/20...  Training Step: 7824...  Training loss: 1.7725...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7825...  Training loss: 1.7893...  0.0583 sec/batch
Epoch: 13/20...  Training Step: 7826...  Training loss: 1.7035...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 7827...  Training loss: 1.7094...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7828...  Training loss: 1.7814...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7829...  Training loss: 1.7360...  0.0558 sec/batch
Epoch: 13/20...  Training Step: 7830...  Training loss: 1.7303...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7831...  Training loss: 1.7891...  0.0550 sec/batch
Epoch: 13/20...  Training Step: 7832...  Training loss: 1.7198...  0.0522 sec/batch
Epoch: 13/20...  Training Step: 7833...  Training loss: 1.7645...  0.0573 sec/batch
Epoch: 13/20...  Training Step: 7834...  Training loss: 1.7997...  0.0562 sec/batch
Epoch: 13/20...  Training Step: 7835...  Training loss: 1.7311...  0.0560 sec/batch
Epoch: 13/20...  Training Step: 7836...  Training loss: 1.7858...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7837...  Training loss: 1.7461...  0.0581 sec/batch
Epoch: 13/20...  Training Step: 7838...  Training loss: 1.7853...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 7839...  Training loss: 1.7202...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7840...  Training loss: 1.7926...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7841...  Training loss: 1.8157...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7842...  Training loss: 1.7861...  0.0534 sec/batch
Epoch: 13/20...  Training Step: 7843...  Training loss: 1.7420...  0.0555 sec/batch
Epoch: 13/20...  Training Step: 7844...  Training loss: 1.8120...  0.0530 sec/batch
Epoch: 13/20...  Training Step: 7845...  Training loss: 1.8359...  0.0537 sec/batch
Epoch: 13/20...  Training Step: 7846...  Training loss: 1.7870...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7847...  Training loss: 1.8368...  0.0560 sec/batch
Epoch: 13/20...  Training Step: 7848...  Training loss: 1.7754...  0.0589 sec/batch
Epoch: 13/20...  Training Step: 7849...  Training loss: 1.8319...  0.0574 sec/batch
Epoch: 13/20...  Training Step: 7850...  Training loss: 1.8105...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7851...  Training loss: 1.7533...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 7852...  Training loss: 1.7965...  0.0559 sec/batch
Epoch: 13/20...  Training Step: 7853...  Training loss: 1.7918...  0.0544 sec/batch
Epoch: 13/20...  Training Step: 7854...  Training loss: 1.7826...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7855...  Training loss: 1.7358...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7856...  Training loss: 1.7160...  0.0534 sec/batch
Epoch: 13/20...  Training Step: 7857...  Training loss: 1.7540...  0.0527 sec/batch
Epoch: 13/20...  Training Step: 7858...  Training loss: 1.7792...  0.0543 sec/batch
Epoch: 13/20...  Training Step: 7859...  Training loss: 1.8174...  0.0538 sec/batch
Epoch: 13/20...  Training Step: 7860...  Training loss: 1.7686...  0.0577 sec/batch
Epoch: 13/20...  Training Step: 7861...  Training loss: 1.7435...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7862...  Training loss: 1.7818...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7863...  Training loss: 1.7897...  0.0527 sec/batch
Epoch: 13/20...  Training Step: 7864...  Training loss: 1.7384...  0.0537 sec/batch
Epoch: 13/20...  Training Step: 7865...  Training loss: 1.8057...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7866...  Training loss: 1.8020...  0.0543 sec/batch
Epoch: 13/20...  Training Step: 7867...  Training loss: 1.7361...  0.0554 sec/batch
Epoch: 13/20...  Training Step: 7868...  Training loss: 1.7961...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7869...  Training loss: 1.7651...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 7870...  Training loss: 1.7284...  0.0579 sec/batch
Epoch: 13/20...  Training Step: 7871...  Training loss: 1.7636...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 7872...  Training loss: 1.8067...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7873...  Training loss: 1.7855...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 7874...  Training loss: 1.7477...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7875...  Training loss: 1.7458...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 7876...  Training loss: 1.7619...  0.0573 sec/batch
Epoch: 13/20...  Training Step: 7877...  Training loss: 1.7346...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7878...  Training loss: 1.7572...  0.0530 sec/batch
Epoch: 13/20...  Training Step: 7879...  Training loss: 1.7837...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7880...  Training loss: 1.7764...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7881...  Training loss: 1.7629...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7882...  Training loss: 1.7601...  0.0558 sec/batch
Epoch: 13/20...  Training Step: 7883...  Training loss: 1.8256...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7884...  Training loss: 1.7639...  0.0542 sec/batch
Epoch: 13/20...  Training Step: 7885...  Training loss: 1.6925...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7886...  Training loss: 1.7702...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7887...  Training loss: 1.7319...  0.0563 sec/batch
Epoch: 13/20...  Training Step: 7888...  Training loss: 1.7184...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7889...  Training loss: 1.7720...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 7890...  Training loss: 1.8307...  0.0530 sec/batch
Epoch: 13/20...  Training Step: 7891...  Training loss: 1.8263...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7892...  Training loss: 1.8152...  0.0543 sec/batch
Epoch: 13/20...  Training Step: 7893...  Training loss: 1.7338...  0.0538 sec/batch
Epoch: 13/20...  Training Step: 7894...  Training loss: 1.7901...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 7895...  Training loss: 1.7474...  0.0544 sec/batch
Epoch: 13/20...  Training Step: 7896...  Training loss: 1.7795...  0.0543 sec/batch
Epoch: 13/20...  Training Step: 7897...  Training loss: 1.7720...  0.0544 sec/batch
Epoch: 13/20...  Training Step: 7898...  Training loss: 1.7743...  0.0571 sec/batch
Epoch: 13/20...  Training Step: 7899...  Training loss: 1.7731...  0.0569 sec/batch
Epoch: 13/20...  Training Step: 7900...  Training loss: 1.7652...  0.0572 sec/batch
Epoch: 13/20...  Training Step: 7901...  Training loss: 1.7246...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7902...  Training loss: 1.7536...  0.0589 sec/batch
Epoch: 13/20...  Training Step: 7903...  Training loss: 1.7561...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 7904...  Training loss: 1.7705...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 7905...  Training loss: 1.8192...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7906...  Training loss: 1.8017...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7907...  Training loss: 1.7563...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7908...  Training loss: 1.7619...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7909...  Training loss: 1.8002...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7910...  Training loss: 1.7530...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7911...  Training loss: 1.7838...  0.0558 sec/batch
Epoch: 13/20...  Training Step: 7912...  Training loss: 1.7887...  0.0557 sec/batch
Epoch: 13/20...  Training Step: 7913...  Training loss: 1.7478...  0.0574 sec/batch
Epoch: 13/20...  Training Step: 7914...  Training loss: 1.7347...  0.0536 sec/batch
Epoch: 13/20...  Training Step: 7915...  Training loss: 1.8320...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7916...  Training loss: 1.8162...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7917...  Training loss: 1.7966...  0.0555 sec/batch
Epoch: 13/20...  Training Step: 7918...  Training loss: 1.8408...  0.0555 sec/batch
Epoch: 13/20...  Training Step: 7919...  Training loss: 1.7480...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7920...  Training loss: 1.8496...  0.0552 sec/batch
Epoch: 13/20...  Training Step: 7921...  Training loss: 1.7609...  0.0544 sec/batch
Epoch: 13/20...  Training Step: 7922...  Training loss: 1.7557...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7923...  Training loss: 1.7968...  0.0538 sec/batch
Epoch: 13/20...  Training Step: 7924...  Training loss: 1.8121...  0.0543 sec/batch
Epoch: 13/20...  Training Step: 7925...  Training loss: 1.8398...  0.0585 sec/batch
Epoch: 13/20...  Training Step: 7926...  Training loss: 1.7698...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7927...  Training loss: 1.7775...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7928...  Training loss: 1.7731...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7929...  Training loss: 1.8000...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7930...  Training loss: 1.7976...  0.0552 sec/batch
Epoch: 13/20...  Training Step: 7931...  Training loss: 1.7732...  0.0541 sec/batch
Epoch: 13/20...  Training Step: 7932...  Training loss: 1.7966...  0.0550 sec/batch
Epoch: 13/20...  Training Step: 7933...  Training loss: 1.7648...  0.0525 sec/batch
Epoch: 13/20...  Training Step: 7934...  Training loss: 1.7367...  0.0566 sec/batch
Epoch: 13/20...  Training Step: 7935...  Training loss: 1.7527...  0.0525 sec/batch
Epoch: 13/20...  Training Step: 7936...  Training loss: 1.7623...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7937...  Training loss: 1.7523...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 7938...  Training loss: 1.8316...  0.0572 sec/batch
Epoch: 13/20...  Training Step: 7939...  Training loss: 1.7245...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7940...  Training loss: 1.7799...  0.0545 sec/batch
Epoch: 13/20...  Training Step: 7941...  Training loss: 1.7755...  0.0582 sec/batch
Epoch: 13/20...  Training Step: 7942...  Training loss: 1.7842...  0.0534 sec/batch
Epoch: 13/20...  Training Step: 7943...  Training loss: 1.8524...  0.0541 sec/batch
Epoch: 13/20...  Training Step: 7944...  Training loss: 1.7933...  0.0538 sec/batch
Epoch: 13/20...  Training Step: 7945...  Training loss: 1.7407...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7946...  Training loss: 1.7267...  0.0564 sec/batch
Epoch: 13/20...  Training Step: 7947...  Training loss: 1.8040...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7948...  Training loss: 1.7598...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7949...  Training loss: 1.8142...  0.0558 sec/batch
Epoch: 13/20...  Training Step: 7950...  Training loss: 1.7827...  0.0526 sec/batch
Epoch: 13/20...  Training Step: 7951...  Training loss: 1.8233...  0.0550 sec/batch
Epoch: 13/20...  Training Step: 7952...  Training loss: 1.8035...  0.0584 sec/batch
Epoch: 13/20...  Training Step: 7953...  Training loss: 1.8261...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7954...  Training loss: 1.8169...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 7955...  Training loss: 1.7973...  0.0546 sec/batch
Epoch: 13/20...  Training Step: 7956...  Training loss: 1.7739...  0.0582 sec/batch
Epoch: 13/20...  Training Step: 7957...  Training loss: 1.7648...  0.0560 sec/batch
Epoch: 13/20...  Training Step: 7958...  Training loss: 1.7504...  0.0563 sec/batch
Epoch: 13/20...  Training Step: 7959...  Training loss: 1.7518...  0.0577 sec/batch
Epoch: 13/20...  Training Step: 7960...  Training loss: 1.7601...  0.0534 sec/batch
Epoch: 13/20...  Training Step: 7961...  Training loss: 1.7699...  0.0634 sec/batch
Epoch: 13/20...  Training Step: 7962...  Training loss: 1.7317...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 7963...  Training loss: 1.7740...  0.0538 sec/batch
Epoch: 13/20...  Training Step: 7964...  Training loss: 1.7036...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 7965...  Training loss: 1.8127...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7966...  Training loss: 1.8218...  0.0554 sec/batch
Epoch: 13/20...  Training Step: 7967...  Training loss: 1.7924...  0.0579 sec/batch
Epoch: 13/20...  Training Step: 7968...  Training loss: 1.8171...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 7969...  Training loss: 1.7760...  0.0554 sec/batch
Epoch: 13/20...  Training Step: 7970...  Training loss: 1.7365...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 7971...  Training loss: 1.7666...  0.0579 sec/batch
Epoch: 13/20...  Training Step: 7972...  Training loss: 1.7504...  0.0550 sec/batch
Epoch: 13/20...  Training Step: 7973...  Training loss: 1.7455...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7974...  Training loss: 1.7857...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7975...  Training loss: 1.7632...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 7976...  Training loss: 1.7738...  0.0586 sec/batch
Epoch: 13/20...  Training Step: 7977...  Training loss: 1.7466...  0.0638 sec/batch
Epoch: 13/20...  Training Step: 7978...  Training loss: 1.7734...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 7979...  Training loss: 1.7093...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 7980...  Training loss: 1.7806...  0.0552 sec/batch
Epoch: 13/20...  Training Step: 7981...  Training loss: 1.7809...  0.0560 sec/batch
Epoch: 13/20...  Training Step: 7982...  Training loss: 1.7574...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 7983...  Training loss: 1.7541...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 7984...  Training loss: 1.7553...  0.0583 sec/batch
Epoch: 13/20...  Training Step: 7985...  Training loss: 1.7988...  0.0524 sec/batch
Epoch: 13/20...  Training Step: 7986...  Training loss: 1.7901...  0.0571 sec/batch
Epoch: 13/20...  Training Step: 7987...  Training loss: 1.8004...  0.0566 sec/batch
Epoch: 13/20...  Training Step: 7988...  Training loss: 1.8289...  0.0570 sec/batch
Epoch: 13/20...  Training Step: 7989...  Training loss: 1.8084...  0.0570 sec/batch
Epoch: 13/20...  Training Step: 7990...  Training loss: 1.7551...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 7991...  Training loss: 1.8004...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 7992...  Training loss: 1.7229...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 7993...  Training loss: 1.8013...  0.0550 sec/batch
Epoch: 13/20...  Training Step: 7994...  Training loss: 1.7724...  0.0558 sec/batch
Epoch: 13/20...  Training Step: 7995...  Training loss: 1.7626...  0.0588 sec/batch
Epoch: 13/20...  Training Step: 7996...  Training loss: 1.7717...  0.0559 sec/batch
Epoch: 13/20...  Training Step: 7997...  Training loss: 1.7667...  0.0537 sec/batch
Epoch: 13/20...  Training Step: 7998...  Training loss: 1.7356...  0.0526 sec/batch
Epoch: 13/20...  Training Step: 7999...  Training loss: 1.7627...  0.0558 sec/batch
Epoch: 13/20...  Training Step: 8000...  Training loss: 1.7617...  0.0526 sec/batch
Epoch: 13/20...  Training Step: 8001...  Training loss: 1.7870...  0.0530 sec/batch
Epoch: 13/20...  Training Step: 8002...  Training loss: 1.7945...  0.0540 sec/batch
Epoch: 13/20...  Training Step: 8003...  Training loss: 1.7707...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 8004...  Training loss: 1.8490...  0.0572 sec/batch
Epoch: 13/20...  Training Step: 8005...  Training loss: 1.8705...  0.0529 sec/batch
Epoch: 13/20...  Training Step: 8006...  Training loss: 1.8437...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 8007...  Training loss: 1.7743...  0.0556 sec/batch
Epoch: 13/20...  Training Step: 8008...  Training loss: 1.8396...  0.0552 sec/batch
Epoch: 13/20...  Training Step: 8009...  Training loss: 1.7670...  0.0575 sec/batch
Epoch: 13/20...  Training Step: 8010...  Training loss: 1.7866...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 8011...  Training loss: 1.7980...  0.0547 sec/batch
Epoch: 13/20...  Training Step: 8012...  Training loss: 1.8189...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 8013...  Training loss: 1.7641...  0.0562 sec/batch
Epoch: 13/20...  Training Step: 8014...  Training loss: 1.7577...  0.0555 sec/batch
Epoch: 13/20...  Training Step: 8015...  Training loss: 1.7785...  0.0570 sec/batch
Epoch: 13/20...  Training Step: 8016...  Training loss: 1.8109...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 8017...  Training loss: 1.7114...  0.0581 sec/batch
Epoch: 13/20...  Training Step: 8018...  Training loss: 1.7804...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 8019...  Training loss: 1.8238...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 8020...  Training loss: 1.7826...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 8021...  Training loss: 1.8169...  0.0587 sec/batch
Epoch: 13/20...  Training Step: 8022...  Training loss: 1.7697...  0.0564 sec/batch
Epoch: 13/20...  Training Step: 8023...  Training loss: 1.7808...  0.0535 sec/batch
Epoch: 13/20...  Training Step: 8024...  Training loss: 1.8188...  0.0527 sec/batch
Epoch: 13/20...  Training Step: 8025...  Training loss: 1.8053...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 8026...  Training loss: 1.7973...  0.0605 sec/batch
Epoch: 13/20...  Training Step: 8027...  Training loss: 1.7284...  0.0559 sec/batch
Epoch: 13/20...  Training Step: 8028...  Training loss: 1.8059...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 8029...  Training loss: 1.7838...  0.0564 sec/batch
Epoch: 13/20...  Training Step: 8030...  Training loss: 1.8115...  0.0575 sec/batch
Epoch: 13/20...  Training Step: 8031...  Training loss: 1.7458...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 8032...  Training loss: 1.8063...  0.0527 sec/batch
Epoch: 13/20...  Training Step: 8033...  Training loss: 1.7674...  0.0530 sec/batch
Epoch: 13/20...  Training Step: 8034...  Training loss: 1.7451...  0.0531 sec/batch
Epoch: 13/20...  Training Step: 8035...  Training loss: 1.7420...  0.0550 sec/batch
Epoch: 13/20...  Training Step: 8036...  Training loss: 1.7421...  0.0579 sec/batch
Epoch: 13/20...  Training Step: 8037...  Training loss: 1.7165...  0.0549 sec/batch
Epoch: 13/20...  Training Step: 8038...  Training loss: 1.7787...  0.0552 sec/batch
Epoch: 13/20...  Training Step: 8039...  Training loss: 1.7853...  0.0538 sec/batch
Epoch: 13/20...  Training Step: 8040...  Training loss: 1.8110...  0.0532 sec/batch
Epoch: 13/20...  Training Step: 8041...  Training loss: 1.7588...  0.0562 sec/batch
Epoch: 13/20...  Training Step: 8042...  Training loss: 1.7611...  0.0527 sec/batch
Epoch: 13/20...  Training Step: 8043...  Training loss: 1.7836...  0.0528 sec/batch
Epoch: 13/20...  Training Step: 8044...  Training loss: 1.7462...  0.0550 sec/batch
Epoch: 13/20...  Training Step: 8045...  Training loss: 1.7738...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 8046...  Training loss: 1.7799...  0.0548 sec/batch
Epoch: 13/20...  Training Step: 8047...  Training loss: 1.7306...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 8048...  Training loss: 1.7548...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 8049...  Training loss: 1.7705...  0.0533 sec/batch
Epoch: 13/20...  Training Step: 8050...  Training loss: 1.8192...  0.0578 sec/batch
Epoch: 13/20...  Training Step: 8051...  Training loss: 1.8176...  0.0553 sec/batch
Epoch: 13/20...  Training Step: 8052...  Training loss: 1.7820...  0.0579 sec/batch
Epoch: 13/20...  Training Step: 8053...  Training loss: 1.7343...  0.0589 sec/batch
Epoch: 13/20...  Training Step: 8054...  Training loss: 1.7741...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 8055...  Training loss: 1.7291...  0.0521 sec/batch
Epoch: 13/20...  Training Step: 8056...  Training loss: 1.7984...  0.0530 sec/batch
Epoch: 13/20...  Training Step: 8057...  Training loss: 1.8326...  0.0551 sec/batch
Epoch: 13/20...  Training Step: 8058...  Training loss: 1.7467...  0.0567 sec/batch
Epoch: 13/20...  Training Step: 8059...  Training loss: 1.7368...  0.0534 sec/batch
Epoch: 13/20...  Training Step: 8060...  Training loss: 1.7552...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8061...  Training loss: 1.8463...  0.0556 sec/batch
Epoch: 14/20...  Training Step: 8062...  Training loss: 1.8594...  0.0584 sec/batch
Epoch: 14/20...  Training Step: 8063...  Training loss: 1.8383...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8064...  Training loss: 1.7544...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8065...  Training loss: 1.7682...  0.0561 sec/batch
Epoch: 14/20...  Training Step: 8066...  Training loss: 1.8051...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8067...  Training loss: 1.7381...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8068...  Training loss: 1.7277...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8069...  Training loss: 1.7180...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8070...  Training loss: 1.7452...  0.0554 sec/batch
Epoch: 14/20...  Training Step: 8071...  Training loss: 1.7555...  0.0595 sec/batch
Epoch: 14/20...  Training Step: 8072...  Training loss: 1.7369...  0.0550 sec/batch
Epoch: 14/20...  Training Step: 8073...  Training loss: 1.7755...  0.0554 sec/batch
Epoch: 14/20...  Training Step: 8074...  Training loss: 1.7346...  0.0536 sec/batch
Epoch: 14/20...  Training Step: 8075...  Training loss: 1.7980...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8076...  Training loss: 1.8097...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8077...  Training loss: 1.8035...  0.0569 sec/batch
Epoch: 14/20...  Training Step: 8078...  Training loss: 1.7598...  0.0554 sec/batch
Epoch: 14/20...  Training Step: 8079...  Training loss: 1.7196...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8080...  Training loss: 1.7834...  0.0564 sec/batch
Epoch: 14/20...  Training Step: 8081...  Training loss: 1.8127...  0.0533 sec/batch
Epoch: 14/20...  Training Step: 8082...  Training loss: 1.7626...  0.0579 sec/batch
Epoch: 14/20...  Training Step: 8083...  Training loss: 1.7517...  0.0533 sec/batch
Epoch: 14/20...  Training Step: 8084...  Training loss: 1.7705...  0.0532 sec/batch
Epoch: 14/20...  Training Step: 8085...  Training loss: 1.7465...  0.0543 sec/batch
Epoch: 14/20...  Training Step: 8086...  Training loss: 1.7338...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8087...  Training loss: 1.7719...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8088...  Training loss: 1.7686...  0.0568 sec/batch
Epoch: 14/20...  Training Step: 8089...  Training loss: 1.7738...  0.0585 sec/batch
Epoch: 14/20...  Training Step: 8090...  Training loss: 1.7460...  0.0547 sec/batch
Epoch: 14/20...  Training Step: 8091...  Training loss: 1.7319...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8092...  Training loss: 1.7858...  0.0542 sec/batch
Epoch: 14/20...  Training Step: 8093...  Training loss: 1.7800...  0.0575 sec/batch
Epoch: 14/20...  Training Step: 8094...  Training loss: 1.7541...  0.0542 sec/batch
Epoch: 14/20...  Training Step: 8095...  Training loss: 1.7742...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8096...  Training loss: 1.7445...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8097...  Training loss: 1.7671...  0.0536 sec/batch
Epoch: 14/20...  Training Step: 8098...  Training loss: 1.7787...  0.0556 sec/batch
Epoch: 14/20...  Training Step: 8099...  Training loss: 1.7983...  0.0580 sec/batch
Epoch: 14/20...  Training Step: 8100...  Training loss: 1.7440...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8101...  Training loss: 1.7865...  0.0526 sec/batch
Epoch: 14/20...  Training Step: 8102...  Training loss: 1.8095...  0.0555 sec/batch
Epoch: 14/20...  Training Step: 8103...  Training loss: 1.7724...  0.0580 sec/batch
Epoch: 14/20...  Training Step: 8104...  Training loss: 1.7992...  0.0553 sec/batch
Epoch: 14/20...  Training Step: 8105...  Training loss: 1.7538...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8106...  Training loss: 1.7502...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8107...  Training loss: 1.6469...  0.0578 sec/batch
Epoch: 14/20...  Training Step: 8108...  Training loss: 1.7613...  0.0573 sec/batch
Epoch: 14/20...  Training Step: 8109...  Training loss: 1.7268...  0.0566 sec/batch
Epoch: 14/20...  Training Step: 8110...  Training loss: 1.7880...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8111...  Training loss: 1.7607...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8112...  Training loss: 1.7364...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8113...  Training loss: 1.7599...  0.0595 sec/batch
Epoch: 14/20...  Training Step: 8114...  Training loss: 1.7937...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8115...  Training loss: 1.7789...  0.0565 sec/batch
Epoch: 14/20...  Training Step: 8116...  Training loss: 1.7593...  0.0526 sec/batch
Epoch: 14/20...  Training Step: 8117...  Training loss: 1.7203...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8118...  Training loss: 1.7657...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8119...  Training loss: 1.7615...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8120...  Training loss: 1.7957...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8121...  Training loss: 1.7572...  0.0535 sec/batch
Epoch: 14/20...  Training Step: 8122...  Training loss: 1.7395...  0.0586 sec/batch
Epoch: 14/20...  Training Step: 8123...  Training loss: 1.7902...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8124...  Training loss: 1.7605...  0.0537 sec/batch
Epoch: 14/20...  Training Step: 8125...  Training loss: 1.7251...  0.0541 sec/batch
Epoch: 14/20...  Training Step: 8126...  Training loss: 1.7119...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8127...  Training loss: 1.7497...  0.0573 sec/batch
Epoch: 14/20...  Training Step: 8128...  Training loss: 1.7294...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8129...  Training loss: 1.7697...  0.0572 sec/batch
Epoch: 14/20...  Training Step: 8130...  Training loss: 1.7706...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8131...  Training loss: 1.8041...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8132...  Training loss: 1.7767...  0.0576 sec/batch
Epoch: 14/20...  Training Step: 8133...  Training loss: 1.6920...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8134...  Training loss: 1.7586...  0.0562 sec/batch
Epoch: 14/20...  Training Step: 8135...  Training loss: 1.8009...  0.0536 sec/batch
Epoch: 14/20...  Training Step: 8136...  Training loss: 1.8053...  0.0553 sec/batch
Epoch: 14/20...  Training Step: 8137...  Training loss: 1.7745...  0.0672 sec/batch
Epoch: 14/20...  Training Step: 8138...  Training loss: 1.7397...  0.0550 sec/batch
Epoch: 14/20...  Training Step: 8139...  Training loss: 1.7756...  0.0558 sec/batch
Epoch: 14/20...  Training Step: 8140...  Training loss: 1.8001...  0.0535 sec/batch
Epoch: 14/20...  Training Step: 8141...  Training loss: 1.7036...  0.0565 sec/batch
Epoch: 14/20...  Training Step: 8142...  Training loss: 1.7536...  0.0550 sec/batch
Epoch: 14/20...  Training Step: 8143...  Training loss: 1.7452...  0.0533 sec/batch
Epoch: 14/20...  Training Step: 8144...  Training loss: 1.7644...  0.0543 sec/batch
Epoch: 14/20...  Training Step: 8145...  Training loss: 1.7562...  0.0583 sec/batch
Epoch: 14/20...  Training Step: 8146...  Training loss: 1.8013...  0.0523 sec/batch
Epoch: 14/20...  Training Step: 8147...  Training loss: 1.7160...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8148...  Training loss: 1.8112...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8149...  Training loss: 1.7559...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8150...  Training loss: 1.7672...  0.0582 sec/batch
Epoch: 14/20...  Training Step: 8151...  Training loss: 1.7404...  0.0582 sec/batch
Epoch: 14/20...  Training Step: 8152...  Training loss: 1.8282...  0.0550 sec/batch
Epoch: 14/20...  Training Step: 8153...  Training loss: 1.7768...  0.0578 sec/batch
Epoch: 14/20...  Training Step: 8154...  Training loss: 1.7661...  0.0583 sec/batch
Epoch: 14/20...  Training Step: 8155...  Training loss: 1.7482...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8156...  Training loss: 1.8008...  0.0587 sec/batch
Epoch: 14/20...  Training Step: 8157...  Training loss: 1.8042...  0.0522 sec/batch
Epoch: 14/20...  Training Step: 8158...  Training loss: 1.6980...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8159...  Training loss: 1.7927...  0.0583 sec/batch
Epoch: 14/20...  Training Step: 8160...  Training loss: 1.7281...  0.0522 sec/batch
Epoch: 14/20...  Training Step: 8161...  Training loss: 1.7441...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8162...  Training loss: 1.7625...  0.0520 sec/batch
Epoch: 14/20...  Training Step: 8163...  Training loss: 1.8049...  0.0543 sec/batch
Epoch: 14/20...  Training Step: 8164...  Training loss: 1.8218...  0.0522 sec/batch
Epoch: 14/20...  Training Step: 8165...  Training loss: 1.7502...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8166...  Training loss: 1.7299...  0.0542 sec/batch
Epoch: 14/20...  Training Step: 8167...  Training loss: 1.7870...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8168...  Training loss: 1.7669...  0.0542 sec/batch
Epoch: 14/20...  Training Step: 8169...  Training loss: 1.7626...  0.0604 sec/batch
Epoch: 14/20...  Training Step: 8170...  Training loss: 1.7144...  0.0560 sec/batch
Epoch: 14/20...  Training Step: 8171...  Training loss: 1.7203...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8172...  Training loss: 1.7355...  0.0541 sec/batch
Epoch: 14/20...  Training Step: 8173...  Training loss: 1.7555...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8174...  Training loss: 1.7575...  0.0576 sec/batch
Epoch: 14/20...  Training Step: 8175...  Training loss: 1.7803...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8176...  Training loss: 1.7825...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8177...  Training loss: 1.7294...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8178...  Training loss: 1.7987...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8179...  Training loss: 1.7498...  0.0521 sec/batch
Epoch: 14/20...  Training Step: 8180...  Training loss: 1.7521...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8181...  Training loss: 1.7360...  0.0586 sec/batch
Epoch: 14/20...  Training Step: 8182...  Training loss: 1.7120...  0.0539 sec/batch
Epoch: 14/20...  Training Step: 8183...  Training loss: 1.7506...  0.0577 sec/batch
Epoch: 14/20...  Training Step: 8184...  Training loss: 1.7836...  0.0554 sec/batch
Epoch: 14/20...  Training Step: 8185...  Training loss: 1.7932...  0.0572 sec/batch
Epoch: 14/20...  Training Step: 8186...  Training loss: 1.8099...  0.0520 sec/batch
Epoch: 14/20...  Training Step: 8187...  Training loss: 1.8135...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8188...  Training loss: 1.7319...  0.0596 sec/batch
Epoch: 14/20...  Training Step: 8189...  Training loss: 1.7641...  0.0522 sec/batch
Epoch: 14/20...  Training Step: 8190...  Training loss: 1.8218...  0.0577 sec/batch
Epoch: 14/20...  Training Step: 8191...  Training loss: 1.7621...  0.0566 sec/batch
Epoch: 14/20...  Training Step: 8192...  Training loss: 1.8143...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8193...  Training loss: 1.7959...  0.0593 sec/batch
Epoch: 14/20...  Training Step: 8194...  Training loss: 1.7616...  0.0558 sec/batch
Epoch: 14/20...  Training Step: 8195...  Training loss: 1.7237...  0.0568 sec/batch
Epoch: 14/20...  Training Step: 8196...  Training loss: 1.7500...  0.0547 sec/batch
Epoch: 14/20...  Training Step: 8197...  Training loss: 1.7572...  0.0555 sec/batch
Epoch: 14/20...  Training Step: 8198...  Training loss: 1.7698...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8199...  Training loss: 1.8024...  0.0532 sec/batch
Epoch: 14/20...  Training Step: 8200...  Training loss: 1.7764...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8201...  Training loss: 1.8189...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8202...  Training loss: 1.6864...  0.0569 sec/batch
Epoch: 14/20...  Training Step: 8203...  Training loss: 1.7710...  0.0544 sec/batch
Epoch: 14/20...  Training Step: 8204...  Training loss: 1.7513...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8205...  Training loss: 1.7113...  0.0618 sec/batch
Epoch: 14/20...  Training Step: 8206...  Training loss: 1.7953...  0.0529 sec/batch
Epoch: 14/20...  Training Step: 8207...  Training loss: 1.7846...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8208...  Training loss: 1.7939...  0.0535 sec/batch
Epoch: 14/20...  Training Step: 8209...  Training loss: 1.7735...  0.0590 sec/batch
Epoch: 14/20...  Training Step: 8210...  Training loss: 1.7890...  0.0521 sec/batch
Epoch: 14/20...  Training Step: 8211...  Training loss: 1.7892...  0.0570 sec/batch
Epoch: 14/20...  Training Step: 8212...  Training loss: 1.7465...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8213...  Training loss: 1.7504...  0.0582 sec/batch
Epoch: 14/20...  Training Step: 8214...  Training loss: 1.8038...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8215...  Training loss: 1.7510...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8216...  Training loss: 1.7655...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8217...  Training loss: 1.7723...  0.0539 sec/batch
Epoch: 14/20...  Training Step: 8218...  Training loss: 1.7544...  0.0603 sec/batch
Epoch: 14/20...  Training Step: 8219...  Training loss: 1.7867...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8220...  Training loss: 1.7280...  0.0544 sec/batch
Epoch: 14/20...  Training Step: 8221...  Training loss: 1.7219...  0.0554 sec/batch
Epoch: 14/20...  Training Step: 8222...  Training loss: 1.7436...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8223...  Training loss: 1.7879...  0.0569 sec/batch
Epoch: 14/20...  Training Step: 8224...  Training loss: 1.7822...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8225...  Training loss: 1.7922...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8226...  Training loss: 1.7814...  0.0582 sec/batch
Epoch: 14/20...  Training Step: 8227...  Training loss: 1.7706...  0.0539 sec/batch
Epoch: 14/20...  Training Step: 8228...  Training loss: 1.7608...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8229...  Training loss: 1.7512...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8230...  Training loss: 1.7398...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8231...  Training loss: 1.7615...  0.0543 sec/batch
Epoch: 14/20...  Training Step: 8232...  Training loss: 1.7757...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8233...  Training loss: 1.7521...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8234...  Training loss: 1.7516...  0.0543 sec/batch
Epoch: 14/20...  Training Step: 8235...  Training loss: 1.7374...  0.0558 sec/batch
Epoch: 14/20...  Training Step: 8236...  Training loss: 1.7717...  0.0616 sec/batch
Epoch: 14/20...  Training Step: 8237...  Training loss: 1.7667...  0.0522 sec/batch
Epoch: 14/20...  Training Step: 8238...  Training loss: 1.7360...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8239...  Training loss: 1.7324...  0.0553 sec/batch
Epoch: 14/20...  Training Step: 8240...  Training loss: 1.7369...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8241...  Training loss: 1.7571...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8242...  Training loss: 1.8048...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8243...  Training loss: 1.7819...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8244...  Training loss: 1.7300...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8245...  Training loss: 1.7038...  0.0564 sec/batch
Epoch: 14/20...  Training Step: 8246...  Training loss: 1.7384...  0.0544 sec/batch
Epoch: 14/20...  Training Step: 8247...  Training loss: 1.7587...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8248...  Training loss: 1.7440...  0.0522 sec/batch
Epoch: 14/20...  Training Step: 8249...  Training loss: 1.7504...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8250...  Training loss: 1.8159...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8251...  Training loss: 1.7861...  0.0563 sec/batch
Epoch: 14/20...  Training Step: 8252...  Training loss: 1.8000...  0.0577 sec/batch
Epoch: 14/20...  Training Step: 8253...  Training loss: 1.7962...  0.0583 sec/batch
Epoch: 14/20...  Training Step: 8254...  Training loss: 1.7561...  0.0567 sec/batch
Epoch: 14/20...  Training Step: 8255...  Training loss: 1.7335...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8256...  Training loss: 1.8401...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8257...  Training loss: 1.7564...  0.0601 sec/batch
Epoch: 14/20...  Training Step: 8258...  Training loss: 1.8208...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8259...  Training loss: 1.7612...  0.0557 sec/batch
Epoch: 14/20...  Training Step: 8260...  Training loss: 1.7923...  0.0543 sec/batch
Epoch: 14/20...  Training Step: 8261...  Training loss: 1.7399...  0.0555 sec/batch
Epoch: 14/20...  Training Step: 8262...  Training loss: 1.7542...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8263...  Training loss: 1.7552...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8264...  Training loss: 1.7527...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8265...  Training loss: 1.7756...  0.0569 sec/batch
Epoch: 14/20...  Training Step: 8266...  Training loss: 1.7167...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8267...  Training loss: 1.7842...  0.0554 sec/batch
Epoch: 14/20...  Training Step: 8268...  Training loss: 1.7682...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8269...  Training loss: 1.7591...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8270...  Training loss: 1.7464...  0.0567 sec/batch
Epoch: 14/20...  Training Step: 8271...  Training loss: 1.7829...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8272...  Training loss: 1.7852...  0.0584 sec/batch
Epoch: 14/20...  Training Step: 8273...  Training loss: 1.8073...  0.0558 sec/batch
Epoch: 14/20...  Training Step: 8274...  Training loss: 1.8007...  0.0587 sec/batch
Epoch: 14/20...  Training Step: 8275...  Training loss: 1.7813...  0.0556 sec/batch
Epoch: 14/20...  Training Step: 8276...  Training loss: 1.8024...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8277...  Training loss: 1.7784...  0.0534 sec/batch
Epoch: 14/20...  Training Step: 8278...  Training loss: 1.7402...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8279...  Training loss: 1.8529...  0.0535 sec/batch
Epoch: 14/20...  Training Step: 8280...  Training loss: 1.8158...  0.0540 sec/batch
Epoch: 14/20...  Training Step: 8281...  Training loss: 1.8032...  0.0542 sec/batch
Epoch: 14/20...  Training Step: 8282...  Training loss: 1.7944...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8283...  Training loss: 1.8034...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8284...  Training loss: 1.7226...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8285...  Training loss: 1.7545...  0.0562 sec/batch
Epoch: 14/20...  Training Step: 8286...  Training loss: 1.8046...  0.0532 sec/batch
Epoch: 14/20...  Training Step: 8287...  Training loss: 1.7968...  0.0555 sec/batch
Epoch: 14/20...  Training Step: 8288...  Training loss: 1.7410...  0.0553 sec/batch
Epoch: 14/20...  Training Step: 8289...  Training loss: 1.7810...  0.0536 sec/batch
Epoch: 14/20...  Training Step: 8290...  Training loss: 1.7416...  0.0578 sec/batch
Epoch: 14/20...  Training Step: 8291...  Training loss: 1.8146...  0.0590 sec/batch
Epoch: 14/20...  Training Step: 8292...  Training loss: 1.7209...  0.0574 sec/batch
Epoch: 14/20...  Training Step: 8293...  Training loss: 1.7399...  0.0557 sec/batch
Epoch: 14/20...  Training Step: 8294...  Training loss: 1.7472...  0.0529 sec/batch
Epoch: 14/20...  Training Step: 8295...  Training loss: 1.7243...  0.0578 sec/batch
Epoch: 14/20...  Training Step: 8296...  Training loss: 1.8054...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8297...  Training loss: 1.7710...  0.0533 sec/batch
Epoch: 14/20...  Training Step: 8298...  Training loss: 1.7220...  0.0526 sec/batch
Epoch: 14/20...  Training Step: 8299...  Training loss: 1.7489...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8300...  Training loss: 1.7915...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8301...  Training loss: 1.7439...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8302...  Training loss: 1.7449...  0.0550 sec/batch
Epoch: 14/20...  Training Step: 8303...  Training loss: 1.7337...  0.0544 sec/batch
Epoch: 14/20...  Training Step: 8304...  Training loss: 1.7397...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8305...  Training loss: 1.7761...  0.0532 sec/batch
Epoch: 14/20...  Training Step: 8306...  Training loss: 1.7693...  0.0565 sec/batch
Epoch: 14/20...  Training Step: 8307...  Training loss: 1.7702...  0.0543 sec/batch
Epoch: 14/20...  Training Step: 8308...  Training loss: 1.7996...  0.0563 sec/batch
Epoch: 14/20...  Training Step: 8309...  Training loss: 1.7317...  0.0574 sec/batch
Epoch: 14/20...  Training Step: 8310...  Training loss: 1.7427...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8311...  Training loss: 1.7729...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8312...  Training loss: 1.7534...  0.0565 sec/batch
Epoch: 14/20...  Training Step: 8313...  Training loss: 1.7909...  0.0567 sec/batch
Epoch: 14/20...  Training Step: 8314...  Training loss: 1.7839...  0.0590 sec/batch
Epoch: 14/20...  Training Step: 8315...  Training loss: 1.8134...  0.0526 sec/batch
Epoch: 14/20...  Training Step: 8316...  Training loss: 1.7638...  0.0574 sec/batch
Epoch: 14/20...  Training Step: 8317...  Training loss: 1.7827...  0.0574 sec/batch
Epoch: 14/20...  Training Step: 8318...  Training loss: 1.7489...  0.0522 sec/batch
Epoch: 14/20...  Training Step: 8319...  Training loss: 1.7668...  0.0547 sec/batch
Epoch: 14/20...  Training Step: 8320...  Training loss: 1.7546...  0.0561 sec/batch
Epoch: 14/20...  Training Step: 8321...  Training loss: 1.7770...  0.0529 sec/batch
Epoch: 14/20...  Training Step: 8322...  Training loss: 1.7322...  0.0544 sec/batch
Epoch: 14/20...  Training Step: 8323...  Training loss: 1.7976...  0.0523 sec/batch
Epoch: 14/20...  Training Step: 8324...  Training loss: 1.7632...  0.0556 sec/batch
Epoch: 14/20...  Training Step: 8325...  Training loss: 1.7868...  0.0521 sec/batch
Epoch: 14/20...  Training Step: 8326...  Training loss: 1.7027...  0.0568 sec/batch
Epoch: 14/20...  Training Step: 8327...  Training loss: 1.7673...  0.0563 sec/batch
Epoch: 14/20...  Training Step: 8328...  Training loss: 1.7739...  0.0544 sec/batch
Epoch: 14/20...  Training Step: 8329...  Training loss: 1.7591...  0.0550 sec/batch
Epoch: 14/20...  Training Step: 8330...  Training loss: 1.7295...  0.0555 sec/batch
Epoch: 14/20...  Training Step: 8331...  Training loss: 1.7165...  0.0578 sec/batch
Epoch: 14/20...  Training Step: 8332...  Training loss: 1.7775...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8333...  Training loss: 1.7321...  0.0534 sec/batch
Epoch: 14/20...  Training Step: 8334...  Training loss: 1.7451...  0.0539 sec/batch
Epoch: 14/20...  Training Step: 8335...  Training loss: 1.7764...  0.0572 sec/batch
Epoch: 14/20...  Training Step: 8336...  Training loss: 1.7797...  0.0544 sec/batch
Epoch: 14/20...  Training Step: 8337...  Training loss: 1.8451...  0.0591 sec/batch
Epoch: 14/20...  Training Step: 8338...  Training loss: 1.8075...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8339...  Training loss: 1.8146...  0.0542 sec/batch
Epoch: 14/20...  Training Step: 8340...  Training loss: 1.8027...  0.0584 sec/batch
Epoch: 14/20...  Training Step: 8341...  Training loss: 1.7677...  0.0550 sec/batch
Epoch: 14/20...  Training Step: 8342...  Training loss: 1.6966...  0.0529 sec/batch
Epoch: 14/20...  Training Step: 8343...  Training loss: 1.7219...  0.0559 sec/batch
Epoch: 14/20...  Training Step: 8344...  Training loss: 1.7786...  0.0568 sec/batch
Epoch: 14/20...  Training Step: 8345...  Training loss: 1.7418...  0.0536 sec/batch
Epoch: 14/20...  Training Step: 8346...  Training loss: 1.7906...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8347...  Training loss: 1.7341...  0.0526 sec/batch
Epoch: 14/20...  Training Step: 8348...  Training loss: 1.7713...  0.0526 sec/batch
Epoch: 14/20...  Training Step: 8349...  Training loss: 1.7581...  0.0523 sec/batch
Epoch: 14/20...  Training Step: 8350...  Training loss: 1.8106...  0.0586 sec/batch
Epoch: 14/20...  Training Step: 8351...  Training loss: 1.7503...  0.0534 sec/batch
Epoch: 14/20...  Training Step: 8352...  Training loss: 1.7496...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8353...  Training loss: 1.7430...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8354...  Training loss: 1.7798...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8355...  Training loss: 1.7317...  0.0550 sec/batch
Epoch: 14/20...  Training Step: 8356...  Training loss: 1.7195...  0.0568 sec/batch
Epoch: 14/20...  Training Step: 8357...  Training loss: 1.7828...  0.0559 sec/batch
Epoch: 14/20...  Training Step: 8358...  Training loss: 1.8064...  0.0529 sec/batch
Epoch: 14/20...  Training Step: 8359...  Training loss: 1.7834...  0.0537 sec/batch
Epoch: 14/20...  Training Step: 8360...  Training loss: 1.7455...  0.0582 sec/batch
Epoch: 14/20...  Training Step: 8361...  Training loss: 1.7982...  0.0580 sec/batch
Epoch: 14/20...  Training Step: 8362...  Training loss: 1.8422...  0.0597 sec/batch
Epoch: 14/20...  Training Step: 8363...  Training loss: 1.7151...  0.0534 sec/batch
Epoch: 14/20...  Training Step: 8364...  Training loss: 1.8014...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8365...  Training loss: 1.7495...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8366...  Training loss: 1.7533...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8367...  Training loss: 1.7770...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8368...  Training loss: 1.7511...  0.0547 sec/batch
Epoch: 14/20...  Training Step: 8369...  Training loss: 1.7393...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8370...  Training loss: 1.7380...  0.0578 sec/batch
Epoch: 14/20...  Training Step: 8371...  Training loss: 1.7291...  0.0554 sec/batch
Epoch: 14/20...  Training Step: 8372...  Training loss: 1.7210...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8373...  Training loss: 1.7338...  0.0532 sec/batch
Epoch: 14/20...  Training Step: 8374...  Training loss: 1.7314...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8375...  Training loss: 1.7629...  0.0557 sec/batch
Epoch: 14/20...  Training Step: 8376...  Training loss: 1.8047...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8377...  Training loss: 1.7562...  0.0558 sec/batch
Epoch: 14/20...  Training Step: 8378...  Training loss: 1.7074...  0.0522 sec/batch
Epoch: 14/20...  Training Step: 8379...  Training loss: 1.7400...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8380...  Training loss: 1.8209...  0.0555 sec/batch
Epoch: 14/20...  Training Step: 8381...  Training loss: 1.7536...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8382...  Training loss: 1.6870...  0.0556 sec/batch
Epoch: 14/20...  Training Step: 8383...  Training loss: 1.7799...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8384...  Training loss: 1.7486...  0.0550 sec/batch
Epoch: 14/20...  Training Step: 8385...  Training loss: 1.7341...  0.0533 sec/batch
Epoch: 14/20...  Training Step: 8386...  Training loss: 1.7462...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8387...  Training loss: 1.7311...  0.0553 sec/batch
Epoch: 14/20...  Training Step: 8388...  Training loss: 1.7447...  0.0538 sec/batch
Epoch: 14/20...  Training Step: 8389...  Training loss: 1.7643...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8390...  Training loss: 1.7459...  0.0533 sec/batch
Epoch: 14/20...  Training Step: 8391...  Training loss: 1.7190...  0.0574 sec/batch
Epoch: 14/20...  Training Step: 8392...  Training loss: 1.7564...  0.0539 sec/batch
Epoch: 14/20...  Training Step: 8393...  Training loss: 1.7278...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8394...  Training loss: 1.7526...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8395...  Training loss: 1.7534...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8396...  Training loss: 1.7588...  0.0529 sec/batch
Epoch: 14/20...  Training Step: 8397...  Training loss: 1.7080...  0.0550 sec/batch
Epoch: 14/20...  Training Step: 8398...  Training loss: 1.7466...  0.0526 sec/batch
Epoch: 14/20...  Training Step: 8399...  Training loss: 1.7139...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8400...  Training loss: 1.7562...  0.0586 sec/batch
Epoch: 14/20...  Training Step: 8401...  Training loss: 1.7523...  0.0561 sec/batch
Epoch: 14/20...  Training Step: 8402...  Training loss: 1.7572...  0.0542 sec/batch
Epoch: 14/20...  Training Step: 8403...  Training loss: 1.7242...  0.0534 sec/batch
Epoch: 14/20...  Training Step: 8404...  Training loss: 1.7397...  0.0543 sec/batch
Epoch: 14/20...  Training Step: 8405...  Training loss: 1.7396...  0.0536 sec/batch
Epoch: 14/20...  Training Step: 8406...  Training loss: 1.7710...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8407...  Training loss: 1.7610...  0.0587 sec/batch
Epoch: 14/20...  Training Step: 8408...  Training loss: 1.7790...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8409...  Training loss: 1.7558...  0.0536 sec/batch
Epoch: 14/20...  Training Step: 8410...  Training loss: 1.7530...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8411...  Training loss: 1.8137...  0.0544 sec/batch
Epoch: 14/20...  Training Step: 8412...  Training loss: 1.7776...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8413...  Training loss: 1.7611...  0.0526 sec/batch
Epoch: 14/20...  Training Step: 8414...  Training loss: 1.7321...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8415...  Training loss: 1.7270...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8416...  Training loss: 1.8084...  0.0584 sec/batch
Epoch: 14/20...  Training Step: 8417...  Training loss: 1.8363...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8418...  Training loss: 1.7979...  0.0558 sec/batch
Epoch: 14/20...  Training Step: 8419...  Training loss: 1.7595...  0.0602 sec/batch
Epoch: 14/20...  Training Step: 8420...  Training loss: 1.7685...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8421...  Training loss: 1.7868...  0.0591 sec/batch
Epoch: 14/20...  Training Step: 8422...  Training loss: 1.7117...  0.0588 sec/batch
Epoch: 14/20...  Training Step: 8423...  Training loss: 1.7026...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8424...  Training loss: 1.7103...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8425...  Training loss: 1.7537...  0.0554 sec/batch
Epoch: 14/20...  Training Step: 8426...  Training loss: 1.7738...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8427...  Training loss: 1.7381...  0.0582 sec/batch
Epoch: 14/20...  Training Step: 8428...  Training loss: 1.7890...  0.0536 sec/batch
Epoch: 14/20...  Training Step: 8429...  Training loss: 1.7920...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8430...  Training loss: 1.7338...  0.0568 sec/batch
Epoch: 14/20...  Training Step: 8431...  Training loss: 1.7591...  0.0543 sec/batch
Epoch: 14/20...  Training Step: 8432...  Training loss: 1.8321...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8433...  Training loss: 1.7785...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8434...  Training loss: 1.7611...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8435...  Training loss: 1.7453...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8436...  Training loss: 1.7616...  0.0555 sec/batch
Epoch: 14/20...  Training Step: 8437...  Training loss: 1.7262...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8438...  Training loss: 1.8390...  0.0532 sec/batch
Epoch: 14/20...  Training Step: 8439...  Training loss: 1.7878...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8440...  Training loss: 1.7368...  0.0547 sec/batch
Epoch: 14/20...  Training Step: 8441...  Training loss: 1.6963...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8442...  Training loss: 1.8120...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8443...  Training loss: 1.7489...  0.0574 sec/batch
Epoch: 14/20...  Training Step: 8444...  Training loss: 1.7880...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8445...  Training loss: 1.7638...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8446...  Training loss: 1.6880...  0.0542 sec/batch
Epoch: 14/20...  Training Step: 8447...  Training loss: 1.7065...  0.0576 sec/batch
Epoch: 14/20...  Training Step: 8448...  Training loss: 1.7665...  0.0541 sec/batch
Epoch: 14/20...  Training Step: 8449...  Training loss: 1.7090...  0.0588 sec/batch
Epoch: 14/20...  Training Step: 8450...  Training loss: 1.7337...  0.0529 sec/batch
Epoch: 14/20...  Training Step: 8451...  Training loss: 1.7816...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8452...  Training loss: 1.7263...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8453...  Training loss: 1.7630...  0.0578 sec/batch
Epoch: 14/20...  Training Step: 8454...  Training loss: 1.7833...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8455...  Training loss: 1.7268...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8456...  Training loss: 1.7808...  0.0533 sec/batch
Epoch: 14/20...  Training Step: 8457...  Training loss: 1.7362...  0.0587 sec/batch
Epoch: 14/20...  Training Step: 8458...  Training loss: 1.7728...  0.0577 sec/batch
Epoch: 14/20...  Training Step: 8459...  Training loss: 1.7245...  0.0571 sec/batch
Epoch: 14/20...  Training Step: 8460...  Training loss: 1.7682...  0.0544 sec/batch
Epoch: 14/20...  Training Step: 8461...  Training loss: 1.7892...  0.0563 sec/batch
Epoch: 14/20...  Training Step: 8462...  Training loss: 1.7601...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8463...  Training loss: 1.7339...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8464...  Training loss: 1.7746...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8465...  Training loss: 1.7935...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8466...  Training loss: 1.7921...  0.0580 sec/batch
Epoch: 14/20...  Training Step: 8467...  Training loss: 1.8061...  0.0542 sec/batch
Epoch: 14/20...  Training Step: 8468...  Training loss: 1.7768...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8469...  Training loss: 1.8111...  0.0547 sec/batch
Epoch: 14/20...  Training Step: 8470...  Training loss: 1.8111...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8471...  Training loss: 1.7588...  0.0583 sec/batch
Epoch: 14/20...  Training Step: 8472...  Training loss: 1.7819...  0.0529 sec/batch
Epoch: 14/20...  Training Step: 8473...  Training loss: 1.7858...  0.0534 sec/batch
Epoch: 14/20...  Training Step: 8474...  Training loss: 1.7483...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8475...  Training loss: 1.7267...  0.0544 sec/batch
Epoch: 14/20...  Training Step: 8476...  Training loss: 1.6920...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8477...  Training loss: 1.7320...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8478...  Training loss: 1.7608...  0.0526 sec/batch
Epoch: 14/20...  Training Step: 8479...  Training loss: 1.7963...  0.0554 sec/batch
Epoch: 14/20...  Training Step: 8480...  Training loss: 1.7468...  0.0555 sec/batch
Epoch: 14/20...  Training Step: 8481...  Training loss: 1.7340...  0.0593 sec/batch
Epoch: 14/20...  Training Step: 8482...  Training loss: 1.7425...  0.0547 sec/batch
Epoch: 14/20...  Training Step: 8483...  Training loss: 1.7562...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8484...  Training loss: 1.7267...  0.0539 sec/batch
Epoch: 14/20...  Training Step: 8485...  Training loss: 1.7986...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8486...  Training loss: 1.7938...  0.0532 sec/batch
Epoch: 14/20...  Training Step: 8487...  Training loss: 1.7270...  0.0568 sec/batch
Epoch: 14/20...  Training Step: 8488...  Training loss: 1.7908...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8489...  Training loss: 1.7436...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8490...  Training loss: 1.7185...  0.0580 sec/batch
Epoch: 14/20...  Training Step: 8491...  Training loss: 1.7499...  0.0564 sec/batch
Epoch: 14/20...  Training Step: 8492...  Training loss: 1.7834...  0.0534 sec/batch
Epoch: 14/20...  Training Step: 8493...  Training loss: 1.7697...  0.0585 sec/batch
Epoch: 14/20...  Training Step: 8494...  Training loss: 1.7279...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8495...  Training loss: 1.7176...  0.0556 sec/batch
Epoch: 14/20...  Training Step: 8496...  Training loss: 1.7302...  0.0523 sec/batch
Epoch: 14/20...  Training Step: 8497...  Training loss: 1.7327...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8498...  Training loss: 1.7479...  0.0575 sec/batch
Epoch: 14/20...  Training Step: 8499...  Training loss: 1.7652...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8500...  Training loss: 1.7662...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8501...  Training loss: 1.7419...  0.0569 sec/batch
Epoch: 14/20...  Training Step: 8502...  Training loss: 1.7643...  0.0574 sec/batch
Epoch: 14/20...  Training Step: 8503...  Training loss: 1.7909...  0.0583 sec/batch
Epoch: 14/20...  Training Step: 8504...  Training loss: 1.7541...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8505...  Training loss: 1.6837...  0.0529 sec/batch
Epoch: 14/20...  Training Step: 8506...  Training loss: 1.7541...  0.0529 sec/batch
Epoch: 14/20...  Training Step: 8507...  Training loss: 1.7146...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8508...  Training loss: 1.7098...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8509...  Training loss: 1.7368...  0.0568 sec/batch
Epoch: 14/20...  Training Step: 8510...  Training loss: 1.8184...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8511...  Training loss: 1.7957...  0.0522 sec/batch
Epoch: 14/20...  Training Step: 8512...  Training loss: 1.7793...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8513...  Training loss: 1.7262...  0.0544 sec/batch
Epoch: 14/20...  Training Step: 8514...  Training loss: 1.7677...  0.0578 sec/batch
Epoch: 14/20...  Training Step: 8515...  Training loss: 1.7198...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8516...  Training loss: 1.7533...  0.0577 sec/batch
Epoch: 14/20...  Training Step: 8517...  Training loss: 1.7640...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8518...  Training loss: 1.7579...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8519...  Training loss: 1.7581...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8520...  Training loss: 1.7477...  0.0581 sec/batch
Epoch: 14/20...  Training Step: 8521...  Training loss: 1.7223...  0.0606 sec/batch
Epoch: 14/20...  Training Step: 8522...  Training loss: 1.7536...  0.0523 sec/batch
Epoch: 14/20...  Training Step: 8523...  Training loss: 1.7561...  0.0540 sec/batch
Epoch: 14/20...  Training Step: 8524...  Training loss: 1.7610...  0.0575 sec/batch
Epoch: 14/20...  Training Step: 8525...  Training loss: 1.7664...  0.0550 sec/batch
Epoch: 14/20...  Training Step: 8526...  Training loss: 1.7665...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8527...  Training loss: 1.7370...  0.0543 sec/batch
Epoch: 14/20...  Training Step: 8528...  Training loss: 1.7455...  0.0620 sec/batch
Epoch: 14/20...  Training Step: 8529...  Training loss: 1.7774...  0.0520 sec/batch
Epoch: 14/20...  Training Step: 8530...  Training loss: 1.7433...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8531...  Training loss: 1.7507...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8532...  Training loss: 1.7641...  0.0547 sec/batch
Epoch: 14/20...  Training Step: 8533...  Training loss: 1.7344...  0.0590 sec/batch
Epoch: 14/20...  Training Step: 8534...  Training loss: 1.7277...  0.0521 sec/batch
Epoch: 14/20...  Training Step: 8535...  Training loss: 1.8075...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8536...  Training loss: 1.7952...  0.0583 sec/batch
Epoch: 14/20...  Training Step: 8537...  Training loss: 1.7699...  0.0584 sec/batch
Epoch: 14/20...  Training Step: 8538...  Training loss: 1.8295...  0.0577 sec/batch
Epoch: 14/20...  Training Step: 8539...  Training loss: 1.7548...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8540...  Training loss: 1.8233...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8541...  Training loss: 1.7606...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8542...  Training loss: 1.7078...  0.0560 sec/batch
Epoch: 14/20...  Training Step: 8543...  Training loss: 1.7739...  0.0543 sec/batch
Epoch: 14/20...  Training Step: 8544...  Training loss: 1.7952...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8545...  Training loss: 1.8442...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8546...  Training loss: 1.7665...  0.0526 sec/batch
Epoch: 14/20...  Training Step: 8547...  Training loss: 1.7762...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8548...  Training loss: 1.7676...  0.0582 sec/batch
Epoch: 14/20...  Training Step: 8549...  Training loss: 1.7806...  0.0598 sec/batch
Epoch: 14/20...  Training Step: 8550...  Training loss: 1.7661...  0.0539 sec/batch
Epoch: 14/20...  Training Step: 8551...  Training loss: 1.7520...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8552...  Training loss: 1.7678...  0.0590 sec/batch
Epoch: 14/20...  Training Step: 8553...  Training loss: 1.7662...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8554...  Training loss: 1.7292...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8555...  Training loss: 1.7335...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8556...  Training loss: 1.7689...  0.0539 sec/batch
Epoch: 14/20...  Training Step: 8557...  Training loss: 1.7311...  0.0534 sec/batch
Epoch: 14/20...  Training Step: 8558...  Training loss: 1.8159...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8559...  Training loss: 1.6912...  0.0558 sec/batch
Epoch: 14/20...  Training Step: 8560...  Training loss: 1.7633...  0.0573 sec/batch
Epoch: 14/20...  Training Step: 8561...  Training loss: 1.7607...  0.0584 sec/batch
Epoch: 14/20...  Training Step: 8562...  Training loss: 1.7635...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8563...  Training loss: 1.8305...  0.0540 sec/batch
Epoch: 14/20...  Training Step: 8564...  Training loss: 1.7658...  0.0541 sec/batch
Epoch: 14/20...  Training Step: 8565...  Training loss: 1.7370...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8566...  Training loss: 1.7159...  0.0529 sec/batch
Epoch: 14/20...  Training Step: 8567...  Training loss: 1.7887...  0.0581 sec/batch
Epoch: 14/20...  Training Step: 8568...  Training loss: 1.7406...  0.0560 sec/batch
Epoch: 14/20...  Training Step: 8569...  Training loss: 1.8068...  0.0565 sec/batch
Epoch: 14/20...  Training Step: 8570...  Training loss: 1.7740...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8571...  Training loss: 1.8113...  0.0547 sec/batch
Epoch: 14/20...  Training Step: 8572...  Training loss: 1.7933...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8573...  Training loss: 1.8110...  0.0553 sec/batch
Epoch: 14/20...  Training Step: 8574...  Training loss: 1.7995...  0.0572 sec/batch
Epoch: 14/20...  Training Step: 8575...  Training loss: 1.7844...  0.0567 sec/batch
Epoch: 14/20...  Training Step: 8576...  Training loss: 1.7417...  0.0583 sec/batch
Epoch: 14/20...  Training Step: 8577...  Training loss: 1.7574...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8578...  Training loss: 1.7346...  0.0544 sec/batch
Epoch: 14/20...  Training Step: 8579...  Training loss: 1.7503...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8580...  Training loss: 1.7618...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8581...  Training loss: 1.7343...  0.0577 sec/batch
Epoch: 14/20...  Training Step: 8582...  Training loss: 1.7315...  0.0550 sec/batch
Epoch: 14/20...  Training Step: 8583...  Training loss: 1.7695...  0.0529 sec/batch
Epoch: 14/20...  Training Step: 8584...  Training loss: 1.6790...  0.0526 sec/batch
Epoch: 14/20...  Training Step: 8585...  Training loss: 1.7848...  0.0520 sec/batch
Epoch: 14/20...  Training Step: 8586...  Training loss: 1.8206...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8587...  Training loss: 1.7964...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8588...  Training loss: 1.7736...  0.0552 sec/batch
Epoch: 14/20...  Training Step: 8589...  Training loss: 1.7664...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8590...  Training loss: 1.7429...  0.0572 sec/batch
Epoch: 14/20...  Training Step: 8591...  Training loss: 1.7321...  0.0576 sec/batch
Epoch: 14/20...  Training Step: 8592...  Training loss: 1.7433...  0.0608 sec/batch
Epoch: 14/20...  Training Step: 8593...  Training loss: 1.7637...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8594...  Training loss: 1.7436...  0.0568 sec/batch
Epoch: 14/20...  Training Step: 8595...  Training loss: 1.7653...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8596...  Training loss: 1.7599...  0.0547 sec/batch
Epoch: 14/20...  Training Step: 8597...  Training loss: 1.7291...  0.0557 sec/batch
Epoch: 14/20...  Training Step: 8598...  Training loss: 1.7546...  0.0541 sec/batch
Epoch: 14/20...  Training Step: 8599...  Training loss: 1.6873...  0.0572 sec/batch
Epoch: 14/20...  Training Step: 8600...  Training loss: 1.7882...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8601...  Training loss: 1.7978...  0.0579 sec/batch
Epoch: 14/20...  Training Step: 8602...  Training loss: 1.7340...  0.0587 sec/batch
Epoch: 14/20...  Training Step: 8603...  Training loss: 1.7333...  0.0567 sec/batch
Epoch: 14/20...  Training Step: 8604...  Training loss: 1.7289...  0.0550 sec/batch
Epoch: 14/20...  Training Step: 8605...  Training loss: 1.7777...  0.0550 sec/batch
Epoch: 14/20...  Training Step: 8606...  Training loss: 1.7565...  0.0558 sec/batch
Epoch: 14/20...  Training Step: 8607...  Training loss: 1.7947...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8608...  Training loss: 1.7907...  0.0541 sec/batch
Epoch: 14/20...  Training Step: 8609...  Training loss: 1.7965...  0.0541 sec/batch
Epoch: 14/20...  Training Step: 8610...  Training loss: 1.7309...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8611...  Training loss: 1.7816...  0.0540 sec/batch
Epoch: 14/20...  Training Step: 8612...  Training loss: 1.7077...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8613...  Training loss: 1.7719...  0.0585 sec/batch
Epoch: 14/20...  Training Step: 8614...  Training loss: 1.7262...  0.0584 sec/batch
Epoch: 14/20...  Training Step: 8615...  Training loss: 1.7633...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8616...  Training loss: 1.7525...  0.0563 sec/batch
Epoch: 14/20...  Training Step: 8617...  Training loss: 1.7584...  0.0564 sec/batch
Epoch: 14/20...  Training Step: 8618...  Training loss: 1.7236...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8619...  Training loss: 1.7539...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8620...  Training loss: 1.7315...  0.0528 sec/batch
Epoch: 14/20...  Training Step: 8621...  Training loss: 1.7850...  0.0542 sec/batch
Epoch: 14/20...  Training Step: 8622...  Training loss: 1.7740...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8623...  Training loss: 1.7551...  0.0540 sec/batch
Epoch: 14/20...  Training Step: 8624...  Training loss: 1.8373...  0.0574 sec/batch
Epoch: 14/20...  Training Step: 8625...  Training loss: 1.8636...  0.0577 sec/batch
Epoch: 14/20...  Training Step: 8626...  Training loss: 1.8328...  0.0617 sec/batch
Epoch: 14/20...  Training Step: 8627...  Training loss: 1.7489...  0.0542 sec/batch
Epoch: 14/20...  Training Step: 8628...  Training loss: 1.8162...  0.0526 sec/batch
Epoch: 14/20...  Training Step: 8629...  Training loss: 1.7442...  0.0582 sec/batch
Epoch: 14/20...  Training Step: 8630...  Training loss: 1.7712...  0.0568 sec/batch
Epoch: 14/20...  Training Step: 8631...  Training loss: 1.7817...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8632...  Training loss: 1.8041...  0.0572 sec/batch
Epoch: 14/20...  Training Step: 8633...  Training loss: 1.7519...  0.0556 sec/batch
Epoch: 14/20...  Training Step: 8634...  Training loss: 1.7495...  0.0522 sec/batch
Epoch: 14/20...  Training Step: 8635...  Training loss: 1.7733...  0.0548 sec/batch
Epoch: 14/20...  Training Step: 8636...  Training loss: 1.7795...  0.0522 sec/batch
Epoch: 14/20...  Training Step: 8637...  Training loss: 1.7198...  0.0558 sec/batch
Epoch: 14/20...  Training Step: 8638...  Training loss: 1.7800...  0.0570 sec/batch
Epoch: 14/20...  Training Step: 8639...  Training loss: 1.7937...  0.0547 sec/batch
Epoch: 14/20...  Training Step: 8640...  Training loss: 1.7920...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8641...  Training loss: 1.8001...  0.0582 sec/batch
Epoch: 14/20...  Training Step: 8642...  Training loss: 1.7600...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8643...  Training loss: 1.7691...  0.0537 sec/batch
Epoch: 14/20...  Training Step: 8644...  Training loss: 1.8085...  0.0577 sec/batch
Epoch: 14/20...  Training Step: 8645...  Training loss: 1.7865...  0.0521 sec/batch
Epoch: 14/20...  Training Step: 8646...  Training loss: 1.7613...  0.0544 sec/batch
Epoch: 14/20...  Training Step: 8647...  Training loss: 1.7207...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8648...  Training loss: 1.7827...  0.0523 sec/batch
Epoch: 14/20...  Training Step: 8649...  Training loss: 1.7469...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8650...  Training loss: 1.8053...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8651...  Training loss: 1.7208...  0.0580 sec/batch
Epoch: 14/20...  Training Step: 8652...  Training loss: 1.8004...  0.0547 sec/batch
Epoch: 14/20...  Training Step: 8653...  Training loss: 1.7600...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8654...  Training loss: 1.7497...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8655...  Training loss: 1.7573...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8656...  Training loss: 1.7357...  0.0563 sec/batch
Epoch: 14/20...  Training Step: 8657...  Training loss: 1.7051...  0.0524 sec/batch
Epoch: 14/20...  Training Step: 8658...  Training loss: 1.7573...  0.0532 sec/batch
Epoch: 14/20...  Training Step: 8659...  Training loss: 1.7767...  0.0532 sec/batch
Epoch: 14/20...  Training Step: 8660...  Training loss: 1.7782...  0.0531 sec/batch
Epoch: 14/20...  Training Step: 8661...  Training loss: 1.7493...  0.0558 sec/batch
Epoch: 14/20...  Training Step: 8662...  Training loss: 1.7690...  0.0576 sec/batch
Epoch: 14/20...  Training Step: 8663...  Training loss: 1.7733...  0.0549 sec/batch
Epoch: 14/20...  Training Step: 8664...  Training loss: 1.7467...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8665...  Training loss: 1.7504...  0.0544 sec/batch
Epoch: 14/20...  Training Step: 8666...  Training loss: 1.7560...  0.0527 sec/batch
Epoch: 14/20...  Training Step: 8667...  Training loss: 1.7199...  0.0522 sec/batch
Epoch: 14/20...  Training Step: 8668...  Training loss: 1.7141...  0.0525 sec/batch
Epoch: 14/20...  Training Step: 8669...  Training loss: 1.7595...  0.0568 sec/batch
Epoch: 14/20...  Training Step: 8670...  Training loss: 1.8269...  0.0521 sec/batch
Epoch: 14/20...  Training Step: 8671...  Training loss: 1.8194...  0.0530 sec/batch
Epoch: 14/20...  Training Step: 8672...  Training loss: 1.7743...  0.0573 sec/batch
Epoch: 14/20...  Training Step: 8673...  Training loss: 1.6968...  0.0536 sec/batch
Epoch: 14/20...  Training Step: 8674...  Training loss: 1.7595...  0.0546 sec/batch
Epoch: 14/20...  Training Step: 8675...  Training loss: 1.6916...  0.0545 sec/batch
Epoch: 14/20...  Training Step: 8676...  Training loss: 1.7773...  0.0575 sec/batch
Epoch: 14/20...  Training Step: 8677...  Training loss: 1.7895...  0.0551 sec/batch
Epoch: 14/20...  Training Step: 8678...  Training loss: 1.7194...  0.0526 sec/batch
Epoch: 14/20...  Training Step: 8679...  Training loss: 1.7138...  0.0534 sec/batch
Epoch: 14/20...  Training Step: 8680...  Training loss: 1.7201...  0.0556 sec/batch
Epoch: 15/20...  Training Step: 8681...  Training loss: 1.8309...  0.0563 sec/batch
Epoch: 15/20...  Training Step: 8682...  Training loss: 1.8339...  0.0535 sec/batch
Epoch: 15/20...  Training Step: 8683...  Training loss: 1.8111...  0.0524 sec/batch
Epoch: 15/20...  Training Step: 8684...  Training loss: 1.7331...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 8685...  Training loss: 1.7676...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 8686...  Training loss: 1.7936...  0.0577 sec/batch
Epoch: 15/20...  Training Step: 8687...  Training loss: 1.7311...  0.0523 sec/batch
Epoch: 15/20...  Training Step: 8688...  Training loss: 1.7163...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8689...  Training loss: 1.7002...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8690...  Training loss: 1.7240...  0.0550 sec/batch
Epoch: 15/20...  Training Step: 8691...  Training loss: 1.7420...  0.0541 sec/batch
Epoch: 15/20...  Training Step: 8692...  Training loss: 1.7146...  0.0525 sec/batch
Epoch: 15/20...  Training Step: 8693...  Training loss: 1.7576...  0.0550 sec/batch
Epoch: 15/20...  Training Step: 8694...  Training loss: 1.7300...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 8695...  Training loss: 1.7871...  0.0530 sec/batch
Epoch: 15/20...  Training Step: 8696...  Training loss: 1.7961...  0.0587 sec/batch
Epoch: 15/20...  Training Step: 8697...  Training loss: 1.7677...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8698...  Training loss: 1.7565...  0.0520 sec/batch
Epoch: 15/20...  Training Step: 8699...  Training loss: 1.7178...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 8700...  Training loss: 1.7706...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8701...  Training loss: 1.8269...  0.0560 sec/batch
Epoch: 15/20...  Training Step: 8702...  Training loss: 1.7510...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 8703...  Training loss: 1.7490...  0.0569 sec/batch
Epoch: 15/20...  Training Step: 8704...  Training loss: 1.7611...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 8705...  Training loss: 1.7472...  0.0564 sec/batch
Epoch: 15/20...  Training Step: 8706...  Training loss: 1.7265...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 8707...  Training loss: 1.7479...  0.0592 sec/batch
Epoch: 15/20...  Training Step: 8708...  Training loss: 1.7645...  0.0550 sec/batch
Epoch: 15/20...  Training Step: 8709...  Training loss: 1.7599...  0.0581 sec/batch
Epoch: 15/20...  Training Step: 8710...  Training loss: 1.7066...  0.0522 sec/batch
Epoch: 15/20...  Training Step: 8711...  Training loss: 1.7292...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 8712...  Training loss: 1.7625...  0.0563 sec/batch
Epoch: 15/20...  Training Step: 8713...  Training loss: 1.7461...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 8714...  Training loss: 1.7382...  0.0577 sec/batch
Epoch: 15/20...  Training Step: 8715...  Training loss: 1.7331...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 8716...  Training loss: 1.7383...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 8717...  Training loss: 1.7805...  0.0530 sec/batch
Epoch: 15/20...  Training Step: 8718...  Training loss: 1.7641...  0.0577 sec/batch
Epoch: 15/20...  Training Step: 8719...  Training loss: 1.7696...  0.0578 sec/batch
Epoch: 15/20...  Training Step: 8720...  Training loss: 1.7229...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8721...  Training loss: 1.7561...  0.0581 sec/batch
Epoch: 15/20...  Training Step: 8722...  Training loss: 1.7671...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8723...  Training loss: 1.7511...  0.0577 sec/batch
Epoch: 15/20...  Training Step: 8724...  Training loss: 1.7721...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 8725...  Training loss: 1.7606...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 8726...  Training loss: 1.7457...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 8727...  Training loss: 1.6243...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 8728...  Training loss: 1.7508...  0.0519 sec/batch
Epoch: 15/20...  Training Step: 8729...  Training loss: 1.7070...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 8730...  Training loss: 1.7758...  0.0543 sec/batch
Epoch: 15/20...  Training Step: 8731...  Training loss: 1.7356...  0.0589 sec/batch
Epoch: 15/20...  Training Step: 8732...  Training loss: 1.7247...  0.0556 sec/batch
Epoch: 15/20...  Training Step: 8733...  Training loss: 1.7566...  0.0552 sec/batch
Epoch: 15/20...  Training Step: 8734...  Training loss: 1.7768...  0.0541 sec/batch
Epoch: 15/20...  Training Step: 8735...  Training loss: 1.7650...  0.0535 sec/batch
Epoch: 15/20...  Training Step: 8736...  Training loss: 1.7695...  0.0564 sec/batch
Epoch: 15/20...  Training Step: 8737...  Training loss: 1.7276...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 8738...  Training loss: 1.7500...  0.0566 sec/batch
Epoch: 15/20...  Training Step: 8739...  Training loss: 1.7214...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 8740...  Training loss: 1.7920...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 8741...  Training loss: 1.7486...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8742...  Training loss: 1.7319...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 8743...  Training loss: 1.7842...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 8744...  Training loss: 1.7431...  0.0562 sec/batch
Epoch: 15/20...  Training Step: 8745...  Training loss: 1.7119...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 8746...  Training loss: 1.6876...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8747...  Training loss: 1.7147...  0.0579 sec/batch
Epoch: 15/20...  Training Step: 8748...  Training loss: 1.7418...  0.0542 sec/batch
Epoch: 15/20...  Training Step: 8749...  Training loss: 1.7423...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 8750...  Training loss: 1.7571...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8751...  Training loss: 1.7986...  0.0574 sec/batch
Epoch: 15/20...  Training Step: 8752...  Training loss: 1.7634...  0.0543 sec/batch
Epoch: 15/20...  Training Step: 8753...  Training loss: 1.6774...  0.0569 sec/batch
Epoch: 15/20...  Training Step: 8754...  Training loss: 1.7484...  0.0567 sec/batch
Epoch: 15/20...  Training Step: 8755...  Training loss: 1.7878...  0.0524 sec/batch
Epoch: 15/20...  Training Step: 8756...  Training loss: 1.7718...  0.0524 sec/batch
Epoch: 15/20...  Training Step: 8757...  Training loss: 1.7723...  0.0523 sec/batch
Epoch: 15/20...  Training Step: 8758...  Training loss: 1.7372...  0.0573 sec/batch
Epoch: 15/20...  Training Step: 8759...  Training loss: 1.7789...  0.0558 sec/batch
Epoch: 15/20...  Training Step: 8760...  Training loss: 1.7832...  0.0533 sec/batch
Epoch: 15/20...  Training Step: 8761...  Training loss: 1.6791...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 8762...  Training loss: 1.7470...  0.0550 sec/batch
Epoch: 15/20...  Training Step: 8763...  Training loss: 1.7165...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 8764...  Training loss: 1.7369...  0.0553 sec/batch
Epoch: 15/20...  Training Step: 8765...  Training loss: 1.7377...  0.0560 sec/batch
Epoch: 15/20...  Training Step: 8766...  Training loss: 1.7888...  0.0525 sec/batch
Epoch: 15/20...  Training Step: 8767...  Training loss: 1.7079...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 8768...  Training loss: 1.8015...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8769...  Training loss: 1.7466...  0.0554 sec/batch
Epoch: 15/20...  Training Step: 8770...  Training loss: 1.7551...  0.0523 sec/batch
Epoch: 15/20...  Training Step: 8771...  Training loss: 1.6916...  0.0551 sec/batch
Epoch: 15/20...  Training Step: 8772...  Training loss: 1.7953...  0.0614 sec/batch
Epoch: 15/20...  Training Step: 8773...  Training loss: 1.7413...  0.0531 sec/batch
Epoch: 15/20...  Training Step: 8774...  Training loss: 1.7602...  0.0569 sec/batch
Epoch: 15/20...  Training Step: 8775...  Training loss: 1.7372...  0.0573 sec/batch
Epoch: 15/20...  Training Step: 8776...  Training loss: 1.7755...  0.0564 sec/batch
Epoch: 15/20...  Training Step: 8777...  Training loss: 1.7837...  0.0560 sec/batch
Epoch: 15/20...  Training Step: 8778...  Training loss: 1.6872...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 8779...  Training loss: 1.7907...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 8780...  Training loss: 1.7001...  0.0533 sec/batch
Epoch: 15/20...  Training Step: 8781...  Training loss: 1.7266...  0.0596 sec/batch
Epoch: 15/20...  Training Step: 8782...  Training loss: 1.7171...  0.0537 sec/batch
Epoch: 15/20...  Training Step: 8783...  Training loss: 1.7951...  0.0564 sec/batch
Epoch: 15/20...  Training Step: 8784...  Training loss: 1.8114...  0.0521 sec/batch
Epoch: 15/20...  Training Step: 8785...  Training loss: 1.7645...  0.0594 sec/batch
Epoch: 15/20...  Training Step: 8786...  Training loss: 1.7169...  0.0571 sec/batch
Epoch: 15/20...  Training Step: 8787...  Training loss: 1.7950...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 8788...  Training loss: 1.7325...  0.0550 sec/batch
Epoch: 15/20...  Training Step: 8789...  Training loss: 1.7743...  0.0556 sec/batch
Epoch: 15/20...  Training Step: 8790...  Training loss: 1.7217...  0.0517 sec/batch
Epoch: 15/20...  Training Step: 8791...  Training loss: 1.7172...  0.0576 sec/batch
Epoch: 15/20...  Training Step: 8792...  Training loss: 1.7205...  0.0576 sec/batch
Epoch: 15/20...  Training Step: 8793...  Training loss: 1.7533...  0.0524 sec/batch
Epoch: 15/20...  Training Step: 8794...  Training loss: 1.7220...  0.0557 sec/batch
Epoch: 15/20...  Training Step: 8795...  Training loss: 1.7483...  0.0580 sec/batch
Epoch: 15/20...  Training Step: 8796...  Training loss: 1.7899...  0.0535 sec/batch
Epoch: 15/20...  Training Step: 8797...  Training loss: 1.7174...  0.0521 sec/batch
Epoch: 15/20...  Training Step: 8798...  Training loss: 1.7871...  0.0551 sec/batch
Epoch: 15/20...  Training Step: 8799...  Training loss: 1.7207...  0.0522 sec/batch
Epoch: 15/20...  Training Step: 8800...  Training loss: 1.7556...  0.0584 sec/batch
Epoch: 15/20...  Training Step: 8801...  Training loss: 1.7237...  0.0536 sec/batch
Epoch: 15/20...  Training Step: 8802...  Training loss: 1.6971...  0.0576 sec/batch
Epoch: 15/20...  Training Step: 8803...  Training loss: 1.7506...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8804...  Training loss: 1.7550...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 8805...  Training loss: 1.7757...  0.0564 sec/batch
Epoch: 15/20...  Training Step: 8806...  Training loss: 1.7691...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 8807...  Training loss: 1.8238...  0.0552 sec/batch
Epoch: 15/20...  Training Step: 8808...  Training loss: 1.7219...  0.0530 sec/batch
Epoch: 15/20...  Training Step: 8809...  Training loss: 1.7707...  0.0521 sec/batch
Epoch: 15/20...  Training Step: 8810...  Training loss: 1.7860...  0.0578 sec/batch
Epoch: 15/20...  Training Step: 8811...  Training loss: 1.7561...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 8812...  Training loss: 1.8025...  0.0524 sec/batch
Epoch: 15/20...  Training Step: 8813...  Training loss: 1.7853...  0.0556 sec/batch
Epoch: 15/20...  Training Step: 8814...  Training loss: 1.7686...  0.0522 sec/batch
Epoch: 15/20...  Training Step: 8815...  Training loss: 1.7459...  0.0530 sec/batch
Epoch: 15/20...  Training Step: 8816...  Training loss: 1.7404...  0.0524 sec/batch
Epoch: 15/20...  Training Step: 8817...  Training loss: 1.7408...  0.0578 sec/batch
Epoch: 15/20...  Training Step: 8818...  Training loss: 1.7423...  0.0525 sec/batch
Epoch: 15/20...  Training Step: 8819...  Training loss: 1.7927...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 8820...  Training loss: 1.7592...  0.0576 sec/batch
Epoch: 15/20...  Training Step: 8821...  Training loss: 1.8037...  0.0577 sec/batch
Epoch: 15/20...  Training Step: 8822...  Training loss: 1.6779...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8823...  Training loss: 1.7405...  0.0542 sec/batch
Epoch: 15/20...  Training Step: 8824...  Training loss: 1.7444...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 8825...  Training loss: 1.7096...  0.0601 sec/batch
Epoch: 15/20...  Training Step: 8826...  Training loss: 1.7949...  0.0555 sec/batch
Epoch: 15/20...  Training Step: 8827...  Training loss: 1.7689...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 8828...  Training loss: 1.7638...  0.0584 sec/batch
Epoch: 15/20...  Training Step: 8829...  Training loss: 1.7582...  0.0577 sec/batch
Epoch: 15/20...  Training Step: 8830...  Training loss: 1.7930...  0.0522 sec/batch
Epoch: 15/20...  Training Step: 8831...  Training loss: 1.7524...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 8832...  Training loss: 1.7201...  0.0523 sec/batch
Epoch: 15/20...  Training Step: 8833...  Training loss: 1.7379...  0.0531 sec/batch
Epoch: 15/20...  Training Step: 8834...  Training loss: 1.7979...  0.0531 sec/batch
Epoch: 15/20...  Training Step: 8835...  Training loss: 1.7439...  0.0586 sec/batch
Epoch: 15/20...  Training Step: 8836...  Training loss: 1.7668...  0.0521 sec/batch
Epoch: 15/20...  Training Step: 8837...  Training loss: 1.7560...  0.0558 sec/batch
Epoch: 15/20...  Training Step: 8838...  Training loss: 1.7806...  0.0521 sec/batch
Epoch: 15/20...  Training Step: 8839...  Training loss: 1.7740...  0.0565 sec/batch
Epoch: 15/20...  Training Step: 8840...  Training loss: 1.7164...  0.0555 sec/batch
Epoch: 15/20...  Training Step: 8841...  Training loss: 1.7271...  0.0523 sec/batch
Epoch: 15/20...  Training Step: 8842...  Training loss: 1.7287...  0.0558 sec/batch
Epoch: 15/20...  Training Step: 8843...  Training loss: 1.7769...  0.0573 sec/batch
Epoch: 15/20...  Training Step: 8844...  Training loss: 1.7447...  0.0577 sec/batch
Epoch: 15/20...  Training Step: 8845...  Training loss: 1.7930...  0.0568 sec/batch
Epoch: 15/20...  Training Step: 8846...  Training loss: 1.7511...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8847...  Training loss: 1.7646...  0.0580 sec/batch
Epoch: 15/20...  Training Step: 8848...  Training loss: 1.7431...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8849...  Training loss: 1.7365...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 8850...  Training loss: 1.7253...  0.0543 sec/batch
Epoch: 15/20...  Training Step: 8851...  Training loss: 1.7341...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 8852...  Training loss: 1.7626...  0.0539 sec/batch
Epoch: 15/20...  Training Step: 8853...  Training loss: 1.7389...  0.0619 sec/batch
Epoch: 15/20...  Training Step: 8854...  Training loss: 1.7179...  0.0551 sec/batch
Epoch: 15/20...  Training Step: 8855...  Training loss: 1.7404...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 8856...  Training loss: 1.7544...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 8857...  Training loss: 1.7339...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 8858...  Training loss: 1.7310...  0.0553 sec/batch
Epoch: 15/20...  Training Step: 8859...  Training loss: 1.7298...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 8860...  Training loss: 1.7235...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 8861...  Training loss: 1.7102...  0.0568 sec/batch
Epoch: 15/20...  Training Step: 8862...  Training loss: 1.7756...  0.0543 sec/batch
Epoch: 15/20...  Training Step: 8863...  Training loss: 1.7581...  0.0580 sec/batch
Epoch: 15/20...  Training Step: 8864...  Training loss: 1.6993...  0.0550 sec/batch
Epoch: 15/20...  Training Step: 8865...  Training loss: 1.7062...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 8866...  Training loss: 1.7468...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 8867...  Training loss: 1.7413...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 8868...  Training loss: 1.7294...  0.0543 sec/batch
Epoch: 15/20...  Training Step: 8869...  Training loss: 1.7455...  0.0555 sec/batch
Epoch: 15/20...  Training Step: 8870...  Training loss: 1.8082...  0.0579 sec/batch
Epoch: 15/20...  Training Step: 8871...  Training loss: 1.7570...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 8872...  Training loss: 1.7972...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8873...  Training loss: 1.7695...  0.0566 sec/batch
Epoch: 15/20...  Training Step: 8874...  Training loss: 1.7230...  0.0574 sec/batch
Epoch: 15/20...  Training Step: 8875...  Training loss: 1.7345...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 8876...  Training loss: 1.8076...  0.0565 sec/batch
Epoch: 15/20...  Training Step: 8877...  Training loss: 1.7505...  0.0559 sec/batch
Epoch: 15/20...  Training Step: 8878...  Training loss: 1.8290...  0.0584 sec/batch
Epoch: 15/20...  Training Step: 8879...  Training loss: 1.7371...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 8880...  Training loss: 1.7717...  0.0530 sec/batch
Epoch: 15/20...  Training Step: 8881...  Training loss: 1.7346...  0.0567 sec/batch
Epoch: 15/20...  Training Step: 8882...  Training loss: 1.7228...  0.0567 sec/batch
Epoch: 15/20...  Training Step: 8883...  Training loss: 1.7436...  0.0567 sec/batch
Epoch: 15/20...  Training Step: 8884...  Training loss: 1.7165...  0.0561 sec/batch
Epoch: 15/20...  Training Step: 8885...  Training loss: 1.7520...  0.0592 sec/batch
Epoch: 15/20...  Training Step: 8886...  Training loss: 1.7186...  0.0541 sec/batch
Epoch: 15/20...  Training Step: 8887...  Training loss: 1.7959...  0.0552 sec/batch
Epoch: 15/20...  Training Step: 8888...  Training loss: 1.7559...  0.0575 sec/batch
Epoch: 15/20...  Training Step: 8889...  Training loss: 1.7520...  0.0539 sec/batch
Epoch: 15/20...  Training Step: 8890...  Training loss: 1.7189...  0.0521 sec/batch
Epoch: 15/20...  Training Step: 8891...  Training loss: 1.7554...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 8892...  Training loss: 1.7669...  0.0550 sec/batch
Epoch: 15/20...  Training Step: 8893...  Training loss: 1.7794...  0.0555 sec/batch
Epoch: 15/20...  Training Step: 8894...  Training loss: 1.7876...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 8895...  Training loss: 1.7917...  0.0538 sec/batch
Epoch: 15/20...  Training Step: 8896...  Training loss: 1.7911...  0.0555 sec/batch
Epoch: 15/20...  Training Step: 8897...  Training loss: 1.7787...  0.0524 sec/batch
Epoch: 15/20...  Training Step: 8898...  Training loss: 1.7404...  0.0533 sec/batch
Epoch: 15/20...  Training Step: 8899...  Training loss: 1.8254...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 8900...  Training loss: 1.7854...  0.0578 sec/batch
Epoch: 15/20...  Training Step: 8901...  Training loss: 1.7603...  0.0573 sec/batch
Epoch: 15/20...  Training Step: 8902...  Training loss: 1.7674...  0.0573 sec/batch
Epoch: 15/20...  Training Step: 8903...  Training loss: 1.7983...  0.0533 sec/batch
Epoch: 15/20...  Training Step: 8904...  Training loss: 1.7152...  0.0522 sec/batch
Epoch: 15/20...  Training Step: 8905...  Training loss: 1.7487...  0.0550 sec/batch
Epoch: 15/20...  Training Step: 8906...  Training loss: 1.7866...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 8907...  Training loss: 1.7771...  0.0551 sec/batch
Epoch: 15/20...  Training Step: 8908...  Training loss: 1.7264...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 8909...  Training loss: 1.7790...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8910...  Training loss: 1.7385...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 8911...  Training loss: 1.8008...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8912...  Training loss: 1.7225...  0.0552 sec/batch
Epoch: 15/20...  Training Step: 8913...  Training loss: 1.7148...  0.0542 sec/batch
Epoch: 15/20...  Training Step: 8914...  Training loss: 1.7409...  0.0565 sec/batch
Epoch: 15/20...  Training Step: 8915...  Training loss: 1.7222...  0.0522 sec/batch
Epoch: 15/20...  Training Step: 8916...  Training loss: 1.7754...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 8917...  Training loss: 1.7700...  0.0530 sec/batch
Epoch: 15/20...  Training Step: 8918...  Training loss: 1.7142...  0.0628 sec/batch
Epoch: 15/20...  Training Step: 8919...  Training loss: 1.7315...  0.0562 sec/batch
Epoch: 15/20...  Training Step: 8920...  Training loss: 1.7678...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8921...  Training loss: 1.7061...  0.0552 sec/batch
Epoch: 15/20...  Training Step: 8922...  Training loss: 1.6948...  0.0521 sec/batch
Epoch: 15/20...  Training Step: 8923...  Training loss: 1.7126...  0.0530 sec/batch
Epoch: 15/20...  Training Step: 8924...  Training loss: 1.7346...  0.0552 sec/batch
Epoch: 15/20...  Training Step: 8925...  Training loss: 1.7507...  0.0617 sec/batch
Epoch: 15/20...  Training Step: 8926...  Training loss: 1.7406...  0.0564 sec/batch
Epoch: 15/20...  Training Step: 8927...  Training loss: 1.7708...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8928...  Training loss: 1.7660...  0.0521 sec/batch
Epoch: 15/20...  Training Step: 8929...  Training loss: 1.7135...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8930...  Training loss: 1.7510...  0.0523 sec/batch
Epoch: 15/20...  Training Step: 8931...  Training loss: 1.7542...  0.0578 sec/batch
Epoch: 15/20...  Training Step: 8932...  Training loss: 1.7338...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 8933...  Training loss: 1.7564...  0.0523 sec/batch
Epoch: 15/20...  Training Step: 8934...  Training loss: 1.7522...  0.0542 sec/batch
Epoch: 15/20...  Training Step: 8935...  Training loss: 1.7984...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8936...  Training loss: 1.7376...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8937...  Training loss: 1.7306...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8938...  Training loss: 1.7559...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8939...  Training loss: 1.7741...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8940...  Training loss: 1.7462...  0.0582 sec/batch
Epoch: 15/20...  Training Step: 8941...  Training loss: 1.7599...  0.0553 sec/batch
Epoch: 15/20...  Training Step: 8942...  Training loss: 1.7168...  0.0557 sec/batch
Epoch: 15/20...  Training Step: 8943...  Training loss: 1.7393...  0.0583 sec/batch
Epoch: 15/20...  Training Step: 8944...  Training loss: 1.7706...  0.0571 sec/batch
Epoch: 15/20...  Training Step: 8945...  Training loss: 1.7626...  0.0552 sec/batch
Epoch: 15/20...  Training Step: 8946...  Training loss: 1.6952...  0.0524 sec/batch
Epoch: 15/20...  Training Step: 8947...  Training loss: 1.7466...  0.0581 sec/batch
Epoch: 15/20...  Training Step: 8948...  Training loss: 1.7711...  0.0543 sec/batch
Epoch: 15/20...  Training Step: 8949...  Training loss: 1.7491...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 8950...  Training loss: 1.7115...  0.0541 sec/batch
Epoch: 15/20...  Training Step: 8951...  Training loss: 1.7194...  0.0523 sec/batch
Epoch: 15/20...  Training Step: 8952...  Training loss: 1.7581...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 8953...  Training loss: 1.7225...  0.0568 sec/batch
Epoch: 15/20...  Training Step: 8954...  Training loss: 1.7347...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 8955...  Training loss: 1.7690...  0.0597 sec/batch
Epoch: 15/20...  Training Step: 8956...  Training loss: 1.7906...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 8957...  Training loss: 1.8379...  0.0584 sec/batch
Epoch: 15/20...  Training Step: 8958...  Training loss: 1.7572...  0.0538 sec/batch
Epoch: 15/20...  Training Step: 8959...  Training loss: 1.7982...  0.0575 sec/batch
Epoch: 15/20...  Training Step: 8960...  Training loss: 1.7927...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 8961...  Training loss: 1.7676...  0.0553 sec/batch
Epoch: 15/20...  Training Step: 8962...  Training loss: 1.6897...  0.0562 sec/batch
Epoch: 15/20...  Training Step: 8963...  Training loss: 1.7064...  0.0573 sec/batch
Epoch: 15/20...  Training Step: 8964...  Training loss: 1.7696...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 8965...  Training loss: 1.7214...  0.0576 sec/batch
Epoch: 15/20...  Training Step: 8966...  Training loss: 1.7617...  0.0572 sec/batch
Epoch: 15/20...  Training Step: 8967...  Training loss: 1.7349...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8968...  Training loss: 1.7626...  0.0551 sec/batch
Epoch: 15/20...  Training Step: 8969...  Training loss: 1.7643...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 8970...  Training loss: 1.7976...  0.0552 sec/batch
Epoch: 15/20...  Training Step: 8971...  Training loss: 1.7529...  0.0523 sec/batch
Epoch: 15/20...  Training Step: 8972...  Training loss: 1.7639...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 8973...  Training loss: 1.7483...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 8974...  Training loss: 1.7634...  0.0578 sec/batch
Epoch: 15/20...  Training Step: 8975...  Training loss: 1.7264...  0.0522 sec/batch
Epoch: 15/20...  Training Step: 8976...  Training loss: 1.7056...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 8977...  Training loss: 1.7558...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 8978...  Training loss: 1.7827...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8979...  Training loss: 1.7970...  0.0560 sec/batch
Epoch: 15/20...  Training Step: 8980...  Training loss: 1.7324...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8981...  Training loss: 1.7924...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8982...  Training loss: 1.8302...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 8983...  Training loss: 1.7242...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 8984...  Training loss: 1.7740...  0.0552 sec/batch
Epoch: 15/20...  Training Step: 8985...  Training loss: 1.7165...  0.0553 sec/batch
Epoch: 15/20...  Training Step: 8986...  Training loss: 1.7542...  0.0555 sec/batch
Epoch: 15/20...  Training Step: 8987...  Training loss: 1.7422...  0.0573 sec/batch
Epoch: 15/20...  Training Step: 8988...  Training loss: 1.7517...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 8989...  Training loss: 1.7423...  0.0572 sec/batch
Epoch: 15/20...  Training Step: 8990...  Training loss: 1.7302...  0.0550 sec/batch
Epoch: 15/20...  Training Step: 8991...  Training loss: 1.7225...  0.0533 sec/batch
Epoch: 15/20...  Training Step: 8992...  Training loss: 1.7029...  0.0535 sec/batch
Epoch: 15/20...  Training Step: 8993...  Training loss: 1.7293...  0.0550 sec/batch
Epoch: 15/20...  Training Step: 8994...  Training loss: 1.6841...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 8995...  Training loss: 1.7595...  0.0520 sec/batch
Epoch: 15/20...  Training Step: 8996...  Training loss: 1.7799...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 8997...  Training loss: 1.7260...  0.0559 sec/batch
Epoch: 15/20...  Training Step: 8998...  Training loss: 1.6761...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 8999...  Training loss: 1.7130...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9000...  Training loss: 1.7824...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 9001...  Training loss: 1.7566...  0.0566 sec/batch
Epoch: 15/20...  Training Step: 9002...  Training loss: 1.6914...  0.0562 sec/batch
Epoch: 15/20...  Training Step: 9003...  Training loss: 1.7666...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 9004...  Training loss: 1.7499...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 9005...  Training loss: 1.7102...  0.0531 sec/batch
Epoch: 15/20...  Training Step: 9006...  Training loss: 1.7235...  0.0525 sec/batch
Epoch: 15/20...  Training Step: 9007...  Training loss: 1.7098...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 9008...  Training loss: 1.7076...  0.0560 sec/batch
Epoch: 15/20...  Training Step: 9009...  Training loss: 1.7486...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 9010...  Training loss: 1.7357...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 9011...  Training loss: 1.7098...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 9012...  Training loss: 1.7367...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 9013...  Training loss: 1.7297...  0.0575 sec/batch
Epoch: 15/20...  Training Step: 9014...  Training loss: 1.7369...  0.0582 sec/batch
Epoch: 15/20...  Training Step: 9015...  Training loss: 1.7421...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 9016...  Training loss: 1.7422...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 9017...  Training loss: 1.7088...  0.0520 sec/batch
Epoch: 15/20...  Training Step: 9018...  Training loss: 1.7189...  0.0531 sec/batch
Epoch: 15/20...  Training Step: 9019...  Training loss: 1.7047...  0.0523 sec/batch
Epoch: 15/20...  Training Step: 9020...  Training loss: 1.7530...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 9021...  Training loss: 1.7609...  0.0595 sec/batch
Epoch: 15/20...  Training Step: 9022...  Training loss: 1.7349...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 9023...  Training loss: 1.6940...  0.0557 sec/batch
Epoch: 15/20...  Training Step: 9024...  Training loss: 1.7298...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 9025...  Training loss: 1.7286...  0.0567 sec/batch
Epoch: 15/20...  Training Step: 9026...  Training loss: 1.7488...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 9027...  Training loss: 1.7569...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 9028...  Training loss: 1.7792...  0.0551 sec/batch
Epoch: 15/20...  Training Step: 9029...  Training loss: 1.7471...  0.0569 sec/batch
Epoch: 15/20...  Training Step: 9030...  Training loss: 1.7394...  0.0554 sec/batch
Epoch: 15/20...  Training Step: 9031...  Training loss: 1.7725...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 9032...  Training loss: 1.7459...  0.0530 sec/batch
Epoch: 15/20...  Training Step: 9033...  Training loss: 1.7567...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 9034...  Training loss: 1.7128...  0.0557 sec/batch
Epoch: 15/20...  Training Step: 9035...  Training loss: 1.7147...  0.0542 sec/batch
Epoch: 15/20...  Training Step: 9036...  Training loss: 1.8010...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9037...  Training loss: 1.8458...  0.0522 sec/batch
Epoch: 15/20...  Training Step: 9038...  Training loss: 1.8141...  0.0565 sec/batch
Epoch: 15/20...  Training Step: 9039...  Training loss: 1.7593...  0.0568 sec/batch
Epoch: 15/20...  Training Step: 9040...  Training loss: 1.7625...  0.0578 sec/batch
Epoch: 15/20...  Training Step: 9041...  Training loss: 1.7744...  0.0556 sec/batch
Epoch: 15/20...  Training Step: 9042...  Training loss: 1.7078...  0.0535 sec/batch
Epoch: 15/20...  Training Step: 9043...  Training loss: 1.7187...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 9044...  Training loss: 1.7060...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9045...  Training loss: 1.7420...  0.0538 sec/batch
Epoch: 15/20...  Training Step: 9046...  Training loss: 1.7510...  0.0559 sec/batch
Epoch: 15/20...  Training Step: 9047...  Training loss: 1.7558...  0.0556 sec/batch
Epoch: 15/20...  Training Step: 9048...  Training loss: 1.7820...  0.0531 sec/batch
Epoch: 15/20...  Training Step: 9049...  Training loss: 1.7565...  0.0578 sec/batch
Epoch: 15/20...  Training Step: 9050...  Training loss: 1.7402...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 9051...  Training loss: 1.7575...  0.0580 sec/batch
Epoch: 15/20...  Training Step: 9052...  Training loss: 1.8362...  0.0583 sec/batch
Epoch: 15/20...  Training Step: 9053...  Training loss: 1.7551...  0.0559 sec/batch
Epoch: 15/20...  Training Step: 9054...  Training loss: 1.7532...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 9055...  Training loss: 1.7155...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 9056...  Training loss: 1.7437...  0.0564 sec/batch
Epoch: 15/20...  Training Step: 9057...  Training loss: 1.7164...  0.0588 sec/batch
Epoch: 15/20...  Training Step: 9058...  Training loss: 1.8257...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 9059...  Training loss: 1.7608...  0.0632 sec/batch
Epoch: 15/20...  Training Step: 9060...  Training loss: 1.7134...  0.0523 sec/batch
Epoch: 15/20...  Training Step: 9061...  Training loss: 1.6674...  0.0551 sec/batch
Epoch: 15/20...  Training Step: 9062...  Training loss: 1.7834...  0.0524 sec/batch
Epoch: 15/20...  Training Step: 9063...  Training loss: 1.7298...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 9064...  Training loss: 1.7555...  0.0530 sec/batch
Epoch: 15/20...  Training Step: 9065...  Training loss: 1.7409...  0.0525 sec/batch
Epoch: 15/20...  Training Step: 9066...  Training loss: 1.6453...  0.0557 sec/batch
Epoch: 15/20...  Training Step: 9067...  Training loss: 1.6776...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 9068...  Training loss: 1.7542...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 9069...  Training loss: 1.7056...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 9070...  Training loss: 1.7109...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9071...  Training loss: 1.7788...  0.0565 sec/batch
Epoch: 15/20...  Training Step: 9072...  Training loss: 1.7036...  0.0525 sec/batch
Epoch: 15/20...  Training Step: 9073...  Training loss: 1.7441...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9074...  Training loss: 1.7399...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 9075...  Training loss: 1.7069...  0.0524 sec/batch
Epoch: 15/20...  Training Step: 9076...  Training loss: 1.7648...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 9077...  Training loss: 1.6926...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 9078...  Training loss: 1.7648...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 9079...  Training loss: 1.7077...  0.0567 sec/batch
Epoch: 15/20...  Training Step: 9080...  Training loss: 1.7678...  0.0562 sec/batch
Epoch: 15/20...  Training Step: 9081...  Training loss: 1.7758...  0.0554 sec/batch
Epoch: 15/20...  Training Step: 9082...  Training loss: 1.7448...  0.0596 sec/batch
Epoch: 15/20...  Training Step: 9083...  Training loss: 1.7114...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 9084...  Training loss: 1.7585...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 9085...  Training loss: 1.7864...  0.0543 sec/batch
Epoch: 15/20...  Training Step: 9086...  Training loss: 1.7830...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 9087...  Training loss: 1.7907...  0.0541 sec/batch
Epoch: 15/20...  Training Step: 9088...  Training loss: 1.7561...  0.0531 sec/batch
Epoch: 15/20...  Training Step: 9089...  Training loss: 1.8028...  0.0574 sec/batch
Epoch: 15/20...  Training Step: 9090...  Training loss: 1.7773...  0.0555 sec/batch
Epoch: 15/20...  Training Step: 9091...  Training loss: 1.7201...  0.0522 sec/batch
Epoch: 15/20...  Training Step: 9092...  Training loss: 1.7607...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 9093...  Training loss: 1.7744...  0.0541 sec/batch
Epoch: 15/20...  Training Step: 9094...  Training loss: 1.7560...  0.0588 sec/batch
Epoch: 15/20...  Training Step: 9095...  Training loss: 1.7274...  0.0578 sec/batch
Epoch: 15/20...  Training Step: 9096...  Training loss: 1.6934...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9097...  Training loss: 1.7520...  0.0586 sec/batch
Epoch: 15/20...  Training Step: 9098...  Training loss: 1.7585...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 9099...  Training loss: 1.7724...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 9100...  Training loss: 1.7268...  0.0607 sec/batch
Epoch: 15/20...  Training Step: 9101...  Training loss: 1.7137...  0.0531 sec/batch
Epoch: 15/20...  Training Step: 9102...  Training loss: 1.7330...  0.0575 sec/batch
Epoch: 15/20...  Training Step: 9103...  Training loss: 1.7721...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 9104...  Training loss: 1.7154...  0.0532 sec/batch
Epoch: 15/20...  Training Step: 9105...  Training loss: 1.7797...  0.0557 sec/batch
Epoch: 15/20...  Training Step: 9106...  Training loss: 1.7510...  0.0558 sec/batch
Epoch: 15/20...  Training Step: 9107...  Training loss: 1.7071...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 9108...  Training loss: 1.7762...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 9109...  Training loss: 1.7335...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 9110...  Training loss: 1.6881...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 9111...  Training loss: 1.7428...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 9112...  Training loss: 1.7866...  0.0525 sec/batch
Epoch: 15/20...  Training Step: 9113...  Training loss: 1.7547...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 9114...  Training loss: 1.7366...  0.0525 sec/batch
Epoch: 15/20...  Training Step: 9115...  Training loss: 1.7198...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 9116...  Training loss: 1.7263...  0.0567 sec/batch
Epoch: 15/20...  Training Step: 9117...  Training loss: 1.7057...  0.0601 sec/batch
Epoch: 15/20...  Training Step: 9118...  Training loss: 1.7434...  0.0602 sec/batch
Epoch: 15/20...  Training Step: 9119...  Training loss: 1.7294...  0.0551 sec/batch
Epoch: 15/20...  Training Step: 9120...  Training loss: 1.7288...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 9121...  Training loss: 1.7451...  0.0522 sec/batch
Epoch: 15/20...  Training Step: 9122...  Training loss: 1.7378...  0.0585 sec/batch
Epoch: 15/20...  Training Step: 9123...  Training loss: 1.7977...  0.0525 sec/batch
Epoch: 15/20...  Training Step: 9124...  Training loss: 1.7548...  0.0534 sec/batch
Epoch: 15/20...  Training Step: 9125...  Training loss: 1.6519...  0.0524 sec/batch
Epoch: 15/20...  Training Step: 9126...  Training loss: 1.7239...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 9127...  Training loss: 1.6902...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9128...  Training loss: 1.7013...  0.0551 sec/batch
Epoch: 15/20...  Training Step: 9129...  Training loss: 1.7609...  0.0538 sec/batch
Epoch: 15/20...  Training Step: 9130...  Training loss: 1.8093...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9131...  Training loss: 1.7777...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 9132...  Training loss: 1.7707...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 9133...  Training loss: 1.7062...  0.0584 sec/batch
Epoch: 15/20...  Training Step: 9134...  Training loss: 1.7438...  0.0522 sec/batch
Epoch: 15/20...  Training Step: 9135...  Training loss: 1.7182...  0.0552 sec/batch
Epoch: 15/20...  Training Step: 9136...  Training loss: 1.7420...  0.0552 sec/batch
Epoch: 15/20...  Training Step: 9137...  Training loss: 1.7288...  0.0557 sec/batch
Epoch: 15/20...  Training Step: 9138...  Training loss: 1.7381...  0.0522 sec/batch
Epoch: 15/20...  Training Step: 9139...  Training loss: 1.7323...  0.0563 sec/batch
Epoch: 15/20...  Training Step: 9140...  Training loss: 1.7435...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 9141...  Training loss: 1.7069...  0.0569 sec/batch
Epoch: 15/20...  Training Step: 9142...  Training loss: 1.7534...  0.0533 sec/batch
Epoch: 15/20...  Training Step: 9143...  Training loss: 1.7213...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 9144...  Training loss: 1.7547...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 9145...  Training loss: 1.7705...  0.0524 sec/batch
Epoch: 15/20...  Training Step: 9146...  Training loss: 1.7572...  0.0566 sec/batch
Epoch: 15/20...  Training Step: 9147...  Training loss: 1.7264...  0.0557 sec/batch
Epoch: 15/20...  Training Step: 9148...  Training loss: 1.7448...  0.0569 sec/batch
Epoch: 15/20...  Training Step: 9149...  Training loss: 1.7541...  0.0524 sec/batch
Epoch: 15/20...  Training Step: 9150...  Training loss: 1.7292...  0.0569 sec/batch
Epoch: 15/20...  Training Step: 9151...  Training loss: 1.7475...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 9152...  Training loss: 1.7560...  0.0576 sec/batch
Epoch: 15/20...  Training Step: 9153...  Training loss: 1.7311...  0.0530 sec/batch
Epoch: 15/20...  Training Step: 9154...  Training loss: 1.7068...  0.0587 sec/batch
Epoch: 15/20...  Training Step: 9155...  Training loss: 1.8044...  0.0580 sec/batch
Epoch: 15/20...  Training Step: 9156...  Training loss: 1.7977...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 9157...  Training loss: 1.7484...  0.0588 sec/batch
Epoch: 15/20...  Training Step: 9158...  Training loss: 1.8149...  0.0532 sec/batch
Epoch: 15/20...  Training Step: 9159...  Training loss: 1.7249...  0.0522 sec/batch
Epoch: 15/20...  Training Step: 9160...  Training loss: 1.8238...  0.0566 sec/batch
Epoch: 15/20...  Training Step: 9161...  Training loss: 1.7520...  0.0578 sec/batch
Epoch: 15/20...  Training Step: 9162...  Training loss: 1.7100...  0.0576 sec/batch
Epoch: 15/20...  Training Step: 9163...  Training loss: 1.7684...  0.0573 sec/batch
Epoch: 15/20...  Training Step: 9164...  Training loss: 1.7700...  0.0560 sec/batch
Epoch: 15/20...  Training Step: 9165...  Training loss: 1.8433...  0.0523 sec/batch
Epoch: 15/20...  Training Step: 9166...  Training loss: 1.7304...  0.0564 sec/batch
Epoch: 15/20...  Training Step: 9167...  Training loss: 1.7564...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 9168...  Training loss: 1.7591...  0.0603 sec/batch
Epoch: 15/20...  Training Step: 9169...  Training loss: 1.7534...  0.0575 sec/batch
Epoch: 15/20...  Training Step: 9170...  Training loss: 1.7450...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 9171...  Training loss: 1.7360...  0.0551 sec/batch
Epoch: 15/20...  Training Step: 9172...  Training loss: 1.7435...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 9173...  Training loss: 1.7313...  0.0525 sec/batch
Epoch: 15/20...  Training Step: 9174...  Training loss: 1.7257...  0.0521 sec/batch
Epoch: 15/20...  Training Step: 9175...  Training loss: 1.7161...  0.0530 sec/batch
Epoch: 15/20...  Training Step: 9176...  Training loss: 1.7295...  0.0585 sec/batch
Epoch: 15/20...  Training Step: 9177...  Training loss: 1.7211...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 9178...  Training loss: 1.7821...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 9179...  Training loss: 1.6806...  0.0525 sec/batch
Epoch: 15/20...  Training Step: 9180...  Training loss: 1.7549...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 9181...  Training loss: 1.7550...  0.0584 sec/batch
Epoch: 15/20...  Training Step: 9182...  Training loss: 1.7633...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 9183...  Training loss: 1.8238...  0.0540 sec/batch
Epoch: 15/20...  Training Step: 9184...  Training loss: 1.7651...  0.0530 sec/batch
Epoch: 15/20...  Training Step: 9185...  Training loss: 1.7138...  0.0541 sec/batch
Epoch: 15/20...  Training Step: 9186...  Training loss: 1.7266...  0.0533 sec/batch
Epoch: 15/20...  Training Step: 9187...  Training loss: 1.7778...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 9188...  Training loss: 1.7337...  0.0524 sec/batch
Epoch: 15/20...  Training Step: 9189...  Training loss: 1.7744...  0.0550 sec/batch
Epoch: 15/20...  Training Step: 9190...  Training loss: 1.7648...  0.0611 sec/batch
Epoch: 15/20...  Training Step: 9191...  Training loss: 1.7975...  0.0552 sec/batch
Epoch: 15/20...  Training Step: 9192...  Training loss: 1.7883...  0.0554 sec/batch
Epoch: 15/20...  Training Step: 9193...  Training loss: 1.7867...  0.0530 sec/batch
Epoch: 15/20...  Training Step: 9194...  Training loss: 1.8070...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 9195...  Training loss: 1.7479...  0.0579 sec/batch
Epoch: 15/20...  Training Step: 9196...  Training loss: 1.7388...  0.0571 sec/batch
Epoch: 15/20...  Training Step: 9197...  Training loss: 1.7400...  0.0559 sec/batch
Epoch: 15/20...  Training Step: 9198...  Training loss: 1.7304...  0.0581 sec/batch
Epoch: 15/20...  Training Step: 9199...  Training loss: 1.7291...  0.0539 sec/batch
Epoch: 15/20...  Training Step: 9200...  Training loss: 1.7289...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 9201...  Training loss: 1.7391...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 9202...  Training loss: 1.7100...  0.0556 sec/batch
Epoch: 15/20...  Training Step: 9203...  Training loss: 1.7283...  0.0569 sec/batch
Epoch: 15/20...  Training Step: 9204...  Training loss: 1.6846...  0.0580 sec/batch
Epoch: 15/20...  Training Step: 9205...  Training loss: 1.7783...  0.0559 sec/batch
Epoch: 15/20...  Training Step: 9206...  Training loss: 1.7940...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 9207...  Training loss: 1.7675...  0.0578 sec/batch
Epoch: 15/20...  Training Step: 9208...  Training loss: 1.7744...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9209...  Training loss: 1.7393...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 9210...  Training loss: 1.7081...  0.0541 sec/batch
Epoch: 15/20...  Training Step: 9211...  Training loss: 1.7272...  0.0578 sec/batch
Epoch: 15/20...  Training Step: 9212...  Training loss: 1.7344...  0.0521 sec/batch
Epoch: 15/20...  Training Step: 9213...  Training loss: 1.7429...  0.0554 sec/batch
Epoch: 15/20...  Training Step: 9214...  Training loss: 1.7304...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 9215...  Training loss: 1.7504...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 9216...  Training loss: 1.7399...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 9217...  Training loss: 1.7216...  0.0569 sec/batch
Epoch: 15/20...  Training Step: 9218...  Training loss: 1.7596...  0.0525 sec/batch
Epoch: 15/20...  Training Step: 9219...  Training loss: 1.6548...  0.0551 sec/batch
Epoch: 15/20...  Training Step: 9220...  Training loss: 1.7716...  0.0571 sec/batch
Epoch: 15/20...  Training Step: 9221...  Training loss: 1.7523...  0.0566 sec/batch
Epoch: 15/20...  Training Step: 9222...  Training loss: 1.7253...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 9223...  Training loss: 1.7188...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 9224...  Training loss: 1.7156...  0.0574 sec/batch
Epoch: 15/20...  Training Step: 9225...  Training loss: 1.7775...  0.0576 sec/batch
Epoch: 15/20...  Training Step: 9226...  Training loss: 1.7509...  0.0531 sec/batch
Epoch: 15/20...  Training Step: 9227...  Training loss: 1.7938...  0.0549 sec/batch
Epoch: 15/20...  Training Step: 9228...  Training loss: 1.8139...  0.0523 sec/batch
Epoch: 15/20...  Training Step: 9229...  Training loss: 1.7840...  0.0543 sec/batch
Epoch: 15/20...  Training Step: 9230...  Training loss: 1.7185...  0.0571 sec/batch
Epoch: 15/20...  Training Step: 9231...  Training loss: 1.7796...  0.0526 sec/batch
Epoch: 15/20...  Training Step: 9232...  Training loss: 1.7031...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9233...  Training loss: 1.7480...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 9234...  Training loss: 1.7606...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 9235...  Training loss: 1.7387...  0.0579 sec/batch
Epoch: 15/20...  Training Step: 9236...  Training loss: 1.7449...  0.0568 sec/batch
Epoch: 15/20...  Training Step: 9237...  Training loss: 1.7489...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 9238...  Training loss: 1.7199...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 9239...  Training loss: 1.7391...  0.0566 sec/batch
Epoch: 15/20...  Training Step: 9240...  Training loss: 1.7276...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 9241...  Training loss: 1.7784...  0.0525 sec/batch
Epoch: 15/20...  Training Step: 9242...  Training loss: 1.7887...  0.0532 sec/batch
Epoch: 15/20...  Training Step: 9243...  Training loss: 1.7497...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 9244...  Training loss: 1.8101...  0.0537 sec/batch
Epoch: 15/20...  Training Step: 9245...  Training loss: 1.8349...  0.0542 sec/batch
Epoch: 15/20...  Training Step: 9246...  Training loss: 1.8126...  0.0532 sec/batch
Epoch: 15/20...  Training Step: 9247...  Training loss: 1.7374...  0.0535 sec/batch
Epoch: 15/20...  Training Step: 9248...  Training loss: 1.8104...  0.0578 sec/batch
Epoch: 15/20...  Training Step: 9249...  Training loss: 1.7441...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 9250...  Training loss: 1.7663...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 9251...  Training loss: 1.7796...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 9252...  Training loss: 1.8142...  0.0542 sec/batch
Epoch: 15/20...  Training Step: 9253...  Training loss: 1.7368...  0.0529 sec/batch
Epoch: 15/20...  Training Step: 9254...  Training loss: 1.7305...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9255...  Training loss: 1.7574...  0.0530 sec/batch
Epoch: 15/20...  Training Step: 9256...  Training loss: 1.7681...  0.0519 sec/batch
Epoch: 15/20...  Training Step: 9257...  Training loss: 1.7090...  0.0557 sec/batch
Epoch: 15/20...  Training Step: 9258...  Training loss: 1.7617...  0.0550 sec/batch
Epoch: 15/20...  Training Step: 9259...  Training loss: 1.7846...  0.0584 sec/batch
Epoch: 15/20...  Training Step: 9260...  Training loss: 1.7605...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9261...  Training loss: 1.7856...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 9262...  Training loss: 1.7411...  0.0558 sec/batch
Epoch: 15/20...  Training Step: 9263...  Training loss: 1.7691...  0.0564 sec/batch
Epoch: 15/20...  Training Step: 9264...  Training loss: 1.7998...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 9265...  Training loss: 1.7700...  0.0545 sec/batch
Epoch: 15/20...  Training Step: 9266...  Training loss: 1.7605...  0.0551 sec/batch
Epoch: 15/20...  Training Step: 9267...  Training loss: 1.7226...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 9268...  Training loss: 1.7634...  0.0544 sec/batch
Epoch: 15/20...  Training Step: 9269...  Training loss: 1.7254...  0.0555 sec/batch
Epoch: 15/20...  Training Step: 9270...  Training loss: 1.7784...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9271...  Training loss: 1.7166...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9272...  Training loss: 1.7848...  0.0543 sec/batch
Epoch: 15/20...  Training Step: 9273...  Training loss: 1.7576...  0.0553 sec/batch
Epoch: 15/20...  Training Step: 9274...  Training loss: 1.7163...  0.0578 sec/batch
Epoch: 15/20...  Training Step: 9275...  Training loss: 1.7291...  0.0594 sec/batch
Epoch: 15/20...  Training Step: 9276...  Training loss: 1.7224...  0.0565 sec/batch
Epoch: 15/20...  Training Step: 9277...  Training loss: 1.7017...  0.0527 sec/batch
Epoch: 15/20...  Training Step: 9278...  Training loss: 1.7483...  0.0532 sec/batch
Epoch: 15/20...  Training Step: 9279...  Training loss: 1.7621...  0.0575 sec/batch
Epoch: 15/20...  Training Step: 9280...  Training loss: 1.7727...  0.0579 sec/batch
Epoch: 15/20...  Training Step: 9281...  Training loss: 1.7315...  0.0563 sec/batch
Epoch: 15/20...  Training Step: 9282...  Training loss: 1.7326...  0.0556 sec/batch
Epoch: 15/20...  Training Step: 9283...  Training loss: 1.7528...  0.0548 sec/batch
Epoch: 15/20...  Training Step: 9284...  Training loss: 1.7315...  0.0570 sec/batch
Epoch: 15/20...  Training Step: 9285...  Training loss: 1.7438...  0.0594 sec/batch
Epoch: 15/20...  Training Step: 9286...  Training loss: 1.7469...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 9287...  Training loss: 1.6935...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 9288...  Training loss: 1.7128...  0.0593 sec/batch
Epoch: 15/20...  Training Step: 9289...  Training loss: 1.7581...  0.0582 sec/batch
Epoch: 15/20...  Training Step: 9290...  Training loss: 1.7909...  0.0521 sec/batch
Epoch: 15/20...  Training Step: 9291...  Training loss: 1.8235...  0.0566 sec/batch
Epoch: 15/20...  Training Step: 9292...  Training loss: 1.7618...  0.0546 sec/batch
Epoch: 15/20...  Training Step: 9293...  Training loss: 1.7132...  0.0561 sec/batch
Epoch: 15/20...  Training Step: 9294...  Training loss: 1.7614...  0.0525 sec/batch
Epoch: 15/20...  Training Step: 9295...  Training loss: 1.7027...  0.0576 sec/batch
Epoch: 15/20...  Training Step: 9296...  Training loss: 1.7695...  0.0572 sec/batch
Epoch: 15/20...  Training Step: 9297...  Training loss: 1.7974...  0.0528 sec/batch
Epoch: 15/20...  Training Step: 9298...  Training loss: 1.7042...  0.0547 sec/batch
Epoch: 15/20...  Training Step: 9299...  Training loss: 1.7024...  0.0540 sec/batch
Epoch: 15/20...  Training Step: 9300...  Training loss: 1.7107...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9301...  Training loss: 1.8256...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9302...  Training loss: 1.8130...  0.0583 sec/batch
Epoch: 16/20...  Training Step: 9303...  Training loss: 1.7889...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9304...  Training loss: 1.7027...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9305...  Training loss: 1.7394...  0.0564 sec/batch
Epoch: 16/20...  Training Step: 9306...  Training loss: 1.7668...  0.0564 sec/batch
Epoch: 16/20...  Training Step: 9307...  Training loss: 1.7074...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9308...  Training loss: 1.6909...  0.0571 sec/batch
Epoch: 16/20...  Training Step: 9309...  Training loss: 1.6933...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9310...  Training loss: 1.7136...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9311...  Training loss: 1.7253...  0.0573 sec/batch
Epoch: 16/20...  Training Step: 9312...  Training loss: 1.7020...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9313...  Training loss: 1.7400...  0.0576 sec/batch
Epoch: 16/20...  Training Step: 9314...  Training loss: 1.7065...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9315...  Training loss: 1.7732...  0.0544 sec/batch
Epoch: 16/20...  Training Step: 9316...  Training loss: 1.7807...  0.0577 sec/batch
Epoch: 16/20...  Training Step: 9317...  Training loss: 1.7507...  0.0521 sec/batch
Epoch: 16/20...  Training Step: 9318...  Training loss: 1.7431...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9319...  Training loss: 1.7199...  0.0554 sec/batch
Epoch: 16/20...  Training Step: 9320...  Training loss: 1.7721...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9321...  Training loss: 1.8008...  0.0537 sec/batch
Epoch: 16/20...  Training Step: 9322...  Training loss: 1.7520...  0.0543 sec/batch
Epoch: 16/20...  Training Step: 9323...  Training loss: 1.7290...  0.0578 sec/batch
Epoch: 16/20...  Training Step: 9324...  Training loss: 1.7587...  0.0572 sec/batch
Epoch: 16/20...  Training Step: 9325...  Training loss: 1.7373...  0.0547 sec/batch
Epoch: 16/20...  Training Step: 9326...  Training loss: 1.7105...  0.0547 sec/batch
Epoch: 16/20...  Training Step: 9327...  Training loss: 1.7171...  0.0553 sec/batch
Epoch: 16/20...  Training Step: 9328...  Training loss: 1.7549...  0.0520 sec/batch
Epoch: 16/20...  Training Step: 9329...  Training loss: 1.7541...  0.0563 sec/batch
Epoch: 16/20...  Training Step: 9330...  Training loss: 1.7042...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9331...  Training loss: 1.7273...  0.0544 sec/batch
Epoch: 16/20...  Training Step: 9332...  Training loss: 1.7509...  0.0588 sec/batch
Epoch: 16/20...  Training Step: 9333...  Training loss: 1.7385...  0.0541 sec/batch
Epoch: 16/20...  Training Step: 9334...  Training loss: 1.7336...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9335...  Training loss: 1.7093...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9336...  Training loss: 1.7293...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9337...  Training loss: 1.7412...  0.0554 sec/batch
Epoch: 16/20...  Training Step: 9338...  Training loss: 1.7567...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9339...  Training loss: 1.7589...  0.0520 sec/batch
Epoch: 16/20...  Training Step: 9340...  Training loss: 1.7218...  0.0557 sec/batch
Epoch: 16/20...  Training Step: 9341...  Training loss: 1.7490...  0.0575 sec/batch
Epoch: 16/20...  Training Step: 9342...  Training loss: 1.7493...  0.0543 sec/batch
Epoch: 16/20...  Training Step: 9343...  Training loss: 1.7599...  0.0569 sec/batch
Epoch: 16/20...  Training Step: 9344...  Training loss: 1.7757...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9345...  Training loss: 1.7068...  0.0575 sec/batch
Epoch: 16/20...  Training Step: 9346...  Training loss: 1.7048...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9347...  Training loss: 1.6261...  0.0597 sec/batch
Epoch: 16/20...  Training Step: 9348...  Training loss: 1.7397...  0.0525 sec/batch
Epoch: 16/20...  Training Step: 9349...  Training loss: 1.7033...  0.0590 sec/batch
Epoch: 16/20...  Training Step: 9350...  Training loss: 1.7734...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9351...  Training loss: 1.7211...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9352...  Training loss: 1.7321...  0.0569 sec/batch
Epoch: 16/20...  Training Step: 9353...  Training loss: 1.7454...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9354...  Training loss: 1.7382...  0.0544 sec/batch
Epoch: 16/20...  Training Step: 9355...  Training loss: 1.7412...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9356...  Training loss: 1.7485...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9357...  Training loss: 1.7116...  0.0520 sec/batch
Epoch: 16/20...  Training Step: 9358...  Training loss: 1.7340...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9359...  Training loss: 1.7352...  0.0582 sec/batch
Epoch: 16/20...  Training Step: 9360...  Training loss: 1.7679...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9361...  Training loss: 1.7427...  0.0558 sec/batch
Epoch: 16/20...  Training Step: 9362...  Training loss: 1.7284...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9363...  Training loss: 1.7925...  0.0542 sec/batch
Epoch: 16/20...  Training Step: 9364...  Training loss: 1.7435...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9365...  Training loss: 1.7039...  0.0561 sec/batch
Epoch: 16/20...  Training Step: 9366...  Training loss: 1.6798...  0.0533 sec/batch
Epoch: 16/20...  Training Step: 9367...  Training loss: 1.7240...  0.0542 sec/batch
Epoch: 16/20...  Training Step: 9368...  Training loss: 1.7116...  0.0571 sec/batch
Epoch: 16/20...  Training Step: 9369...  Training loss: 1.7383...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9370...  Training loss: 1.7607...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9371...  Training loss: 1.7699...  0.0562 sec/batch
Epoch: 16/20...  Training Step: 9372...  Training loss: 1.7660...  0.0572 sec/batch
Epoch: 16/20...  Training Step: 9373...  Training loss: 1.6789...  0.0525 sec/batch
Epoch: 16/20...  Training Step: 9374...  Training loss: 1.7191...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9375...  Training loss: 1.7824...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9376...  Training loss: 1.7629...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9377...  Training loss: 1.7516...  0.0587 sec/batch
Epoch: 16/20...  Training Step: 9378...  Training loss: 1.7084...  0.0571 sec/batch
Epoch: 16/20...  Training Step: 9379...  Training loss: 1.7503...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9380...  Training loss: 1.7647...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9381...  Training loss: 1.6770...  0.0557 sec/batch
Epoch: 16/20...  Training Step: 9382...  Training loss: 1.7269...  0.0572 sec/batch
Epoch: 16/20...  Training Step: 9383...  Training loss: 1.6895...  0.0608 sec/batch
Epoch: 16/20...  Training Step: 9384...  Training loss: 1.7247...  0.0522 sec/batch
Epoch: 16/20...  Training Step: 9385...  Training loss: 1.7116...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9386...  Training loss: 1.7756...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9387...  Training loss: 1.7038...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9388...  Training loss: 1.7913...  0.0545 sec/batch
Epoch: 16/20...  Training Step: 9389...  Training loss: 1.7295...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9390...  Training loss: 1.7371...  0.0547 sec/batch
Epoch: 16/20...  Training Step: 9391...  Training loss: 1.6913...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9392...  Training loss: 1.8135...  0.0559 sec/batch
Epoch: 16/20...  Training Step: 9393...  Training loss: 1.7297...  0.0558 sec/batch
Epoch: 16/20...  Training Step: 9394...  Training loss: 1.7435...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9395...  Training loss: 1.7243...  0.0521 sec/batch
Epoch: 16/20...  Training Step: 9396...  Training loss: 1.7799...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9397...  Training loss: 1.7815...  0.0581 sec/batch
Epoch: 16/20...  Training Step: 9398...  Training loss: 1.6767...  0.0544 sec/batch
Epoch: 16/20...  Training Step: 9399...  Training loss: 1.7779...  0.0568 sec/batch
Epoch: 16/20...  Training Step: 9400...  Training loss: 1.7033...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9401...  Training loss: 1.6966...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9402...  Training loss: 1.6963...  0.0573 sec/batch
Epoch: 16/20...  Training Step: 9403...  Training loss: 1.7800...  0.0581 sec/batch
Epoch: 16/20...  Training Step: 9404...  Training loss: 1.7910...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9405...  Training loss: 1.7367...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9406...  Training loss: 1.7097...  0.0523 sec/batch
Epoch: 16/20...  Training Step: 9407...  Training loss: 1.7741...  0.0555 sec/batch
Epoch: 16/20...  Training Step: 9408...  Training loss: 1.7331...  0.0542 sec/batch
Epoch: 16/20...  Training Step: 9409...  Training loss: 1.7473...  0.0560 sec/batch
Epoch: 16/20...  Training Step: 9410...  Training loss: 1.6948...  0.0586 sec/batch
Epoch: 16/20...  Training Step: 9411...  Training loss: 1.6941...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9412...  Training loss: 1.7285...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9413...  Training loss: 1.7312...  0.0583 sec/batch
Epoch: 16/20...  Training Step: 9414...  Training loss: 1.7103...  0.0609 sec/batch
Epoch: 16/20...  Training Step: 9415...  Training loss: 1.7277...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9416...  Training loss: 1.7984...  0.0534 sec/batch
Epoch: 16/20...  Training Step: 9417...  Training loss: 1.6907...  0.0552 sec/batch
Epoch: 16/20...  Training Step: 9418...  Training loss: 1.7817...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9419...  Training loss: 1.7102...  0.0547 sec/batch
Epoch: 16/20...  Training Step: 9420...  Training loss: 1.7112...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9421...  Training loss: 1.7098...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9422...  Training loss: 1.6856...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9423...  Training loss: 1.7170...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9424...  Training loss: 1.7767...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9425...  Training loss: 1.7588...  0.0566 sec/batch
Epoch: 16/20...  Training Step: 9426...  Training loss: 1.7704...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9427...  Training loss: 1.7976...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9428...  Training loss: 1.6872...  0.0525 sec/batch
Epoch: 16/20...  Training Step: 9429...  Training loss: 1.7552...  0.0574 sec/batch
Epoch: 16/20...  Training Step: 9430...  Training loss: 1.7850...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9431...  Training loss: 1.7364...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9432...  Training loss: 1.8012...  0.0521 sec/batch
Epoch: 16/20...  Training Step: 9433...  Training loss: 1.7750...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9434...  Training loss: 1.7327...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9435...  Training loss: 1.7310...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9436...  Training loss: 1.7232...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9437...  Training loss: 1.7321...  0.0589 sec/batch
Epoch: 16/20...  Training Step: 9438...  Training loss: 1.7383...  0.0582 sec/batch
Epoch: 16/20...  Training Step: 9439...  Training loss: 1.7831...  0.0579 sec/batch
Epoch: 16/20...  Training Step: 9440...  Training loss: 1.7327...  0.0533 sec/batch
Epoch: 16/20...  Training Step: 9441...  Training loss: 1.7799...  0.0590 sec/batch
Epoch: 16/20...  Training Step: 9442...  Training loss: 1.6676...  0.0587 sec/batch
Epoch: 16/20...  Training Step: 9443...  Training loss: 1.7402...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9444...  Training loss: 1.7183...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9445...  Training loss: 1.6835...  0.0555 sec/batch
Epoch: 16/20...  Training Step: 9446...  Training loss: 1.7765...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9447...  Training loss: 1.7636...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9448...  Training loss: 1.7597...  0.0525 sec/batch
Epoch: 16/20...  Training Step: 9449...  Training loss: 1.7453...  0.0553 sec/batch
Epoch: 16/20...  Training Step: 9450...  Training loss: 1.7820...  0.0587 sec/batch
Epoch: 16/20...  Training Step: 9451...  Training loss: 1.7604...  0.0610 sec/batch
Epoch: 16/20...  Training Step: 9452...  Training loss: 1.7126...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9453...  Training loss: 1.7544...  0.0523 sec/batch
Epoch: 16/20...  Training Step: 9454...  Training loss: 1.7824...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9455...  Training loss: 1.7254...  0.0538 sec/batch
Epoch: 16/20...  Training Step: 9456...  Training loss: 1.7483...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9457...  Training loss: 1.7439...  0.0582 sec/batch
Epoch: 16/20...  Training Step: 9458...  Training loss: 1.7665...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9459...  Training loss: 1.7369...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9460...  Training loss: 1.7056...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9461...  Training loss: 1.6882...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9462...  Training loss: 1.7144...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9463...  Training loss: 1.7564...  0.0560 sec/batch
Epoch: 16/20...  Training Step: 9464...  Training loss: 1.7214...  0.0539 sec/batch
Epoch: 16/20...  Training Step: 9465...  Training loss: 1.7423...  0.0571 sec/batch
Epoch: 16/20...  Training Step: 9466...  Training loss: 1.7640...  0.0556 sec/batch
Epoch: 16/20...  Training Step: 9467...  Training loss: 1.7498...  0.0573 sec/batch
Epoch: 16/20...  Training Step: 9468...  Training loss: 1.7351...  0.0543 sec/batch
Epoch: 16/20...  Training Step: 9469...  Training loss: 1.7358...  0.0536 sec/batch
Epoch: 16/20...  Training Step: 9470...  Training loss: 1.6992...  0.0579 sec/batch
Epoch: 16/20...  Training Step: 9471...  Training loss: 1.7231...  0.0583 sec/batch
Epoch: 16/20...  Training Step: 9472...  Training loss: 1.7532...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9473...  Training loss: 1.7085...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9474...  Training loss: 1.7171...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9475...  Training loss: 1.6979...  0.0547 sec/batch
Epoch: 16/20...  Training Step: 9476...  Training loss: 1.7533...  0.0533 sec/batch
Epoch: 16/20...  Training Step: 9477...  Training loss: 1.7377...  0.0533 sec/batch
Epoch: 16/20...  Training Step: 9478...  Training loss: 1.7060...  0.0594 sec/batch
Epoch: 16/20...  Training Step: 9479...  Training loss: 1.7027...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9480...  Training loss: 1.7070...  0.0605 sec/batch
Epoch: 16/20...  Training Step: 9481...  Training loss: 1.6953...  0.0564 sec/batch
Epoch: 16/20...  Training Step: 9482...  Training loss: 1.7718...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9483...  Training loss: 1.7486...  0.0577 sec/batch
Epoch: 16/20...  Training Step: 9484...  Training loss: 1.7002...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9485...  Training loss: 1.6932...  0.0566 sec/batch
Epoch: 16/20...  Training Step: 9486...  Training loss: 1.7379...  0.0559 sec/batch
Epoch: 16/20...  Training Step: 9487...  Training loss: 1.7546...  0.0560 sec/batch
Epoch: 16/20...  Training Step: 9488...  Training loss: 1.7250...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9489...  Training loss: 1.7372...  0.0540 sec/batch
Epoch: 16/20...  Training Step: 9490...  Training loss: 1.7870...  0.0562 sec/batch
Epoch: 16/20...  Training Step: 9491...  Training loss: 1.7426...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9492...  Training loss: 1.7760...  0.0544 sec/batch
Epoch: 16/20...  Training Step: 9493...  Training loss: 1.7726...  0.0539 sec/batch
Epoch: 16/20...  Training Step: 9494...  Training loss: 1.7382...  0.0572 sec/batch
Epoch: 16/20...  Training Step: 9495...  Training loss: 1.7317...  0.0525 sec/batch
Epoch: 16/20...  Training Step: 9496...  Training loss: 1.7979...  0.0534 sec/batch
Epoch: 16/20...  Training Step: 9497...  Training loss: 1.7539...  0.0523 sec/batch
Epoch: 16/20...  Training Step: 9498...  Training loss: 1.8161...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9499...  Training loss: 1.7339...  0.0569 sec/batch
Epoch: 16/20...  Training Step: 9500...  Training loss: 1.7611...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9501...  Training loss: 1.7152...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9502...  Training loss: 1.7378...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9503...  Training loss: 1.7240...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9504...  Training loss: 1.7203...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9505...  Training loss: 1.7496...  0.0585 sec/batch
Epoch: 16/20...  Training Step: 9506...  Training loss: 1.7192...  0.0520 sec/batch
Epoch: 16/20...  Training Step: 9507...  Training loss: 1.7719...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9508...  Training loss: 1.7348...  0.0539 sec/batch
Epoch: 16/20...  Training Step: 9509...  Training loss: 1.7270...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9510...  Training loss: 1.7210...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9511...  Training loss: 1.7283...  0.0562 sec/batch
Epoch: 16/20...  Training Step: 9512...  Training loss: 1.7747...  0.0547 sec/batch
Epoch: 16/20...  Training Step: 9513...  Training loss: 1.7522...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9514...  Training loss: 1.7625...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9515...  Training loss: 1.7533...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9516...  Training loss: 1.7642...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9517...  Training loss: 1.7676...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9518...  Training loss: 1.7282...  0.0585 sec/batch
Epoch: 16/20...  Training Step: 9519...  Training loss: 1.8014...  0.0544 sec/batch
Epoch: 16/20...  Training Step: 9520...  Training loss: 1.7854...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9521...  Training loss: 1.7749...  0.0580 sec/batch
Epoch: 16/20...  Training Step: 9522...  Training loss: 1.7751...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9523...  Training loss: 1.7749...  0.0613 sec/batch
Epoch: 16/20...  Training Step: 9524...  Training loss: 1.7050...  0.0558 sec/batch
Epoch: 16/20...  Training Step: 9525...  Training loss: 1.7135...  0.0560 sec/batch
Epoch: 16/20...  Training Step: 9526...  Training loss: 1.7694...  0.0552 sec/batch
Epoch: 16/20...  Training Step: 9527...  Training loss: 1.7679...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9528...  Training loss: 1.7161...  0.0540 sec/batch
Epoch: 16/20...  Training Step: 9529...  Training loss: 1.7651...  0.0558 sec/batch
Epoch: 16/20...  Training Step: 9530...  Training loss: 1.7308...  0.0555 sec/batch
Epoch: 16/20...  Training Step: 9531...  Training loss: 1.8016...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9532...  Training loss: 1.6830...  0.0553 sec/batch
Epoch: 16/20...  Training Step: 9533...  Training loss: 1.7001...  0.0521 sec/batch
Epoch: 16/20...  Training Step: 9534...  Training loss: 1.7412...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9535...  Training loss: 1.6958...  0.0581 sec/batch
Epoch: 16/20...  Training Step: 9536...  Training loss: 1.7790...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9537...  Training loss: 1.7275...  0.0581 sec/batch
Epoch: 16/20...  Training Step: 9538...  Training loss: 1.6996...  0.0535 sec/batch
Epoch: 16/20...  Training Step: 9539...  Training loss: 1.7057...  0.0547 sec/batch
Epoch: 16/20...  Training Step: 9540...  Training loss: 1.7590...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9541...  Training loss: 1.6929...  0.0585 sec/batch
Epoch: 16/20...  Training Step: 9542...  Training loss: 1.6824...  0.0567 sec/batch
Epoch: 16/20...  Training Step: 9543...  Training loss: 1.6991...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9544...  Training loss: 1.7355...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9545...  Training loss: 1.7322...  0.0587 sec/batch
Epoch: 16/20...  Training Step: 9546...  Training loss: 1.7286...  0.0557 sec/batch
Epoch: 16/20...  Training Step: 9547...  Training loss: 1.7628...  0.0543 sec/batch
Epoch: 16/20...  Training Step: 9548...  Training loss: 1.7454...  0.0569 sec/batch
Epoch: 16/20...  Training Step: 9549...  Training loss: 1.7034...  0.0558 sec/batch
Epoch: 16/20...  Training Step: 9550...  Training loss: 1.7414...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9551...  Training loss: 1.7608...  0.0545 sec/batch
Epoch: 16/20...  Training Step: 9552...  Training loss: 1.6957...  0.0536 sec/batch
Epoch: 16/20...  Training Step: 9553...  Training loss: 1.7623...  0.0561 sec/batch
Epoch: 16/20...  Training Step: 9554...  Training loss: 1.7655...  0.0560 sec/batch
Epoch: 16/20...  Training Step: 9555...  Training loss: 1.7927...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9556...  Training loss: 1.7376...  0.0553 sec/batch
Epoch: 16/20...  Training Step: 9557...  Training loss: 1.7511...  0.0539 sec/batch
Epoch: 16/20...  Training Step: 9558...  Training loss: 1.7325...  0.0578 sec/batch
Epoch: 16/20...  Training Step: 9559...  Training loss: 1.7395...  0.0582 sec/batch
Epoch: 16/20...  Training Step: 9560...  Training loss: 1.7225...  0.0540 sec/batch
Epoch: 16/20...  Training Step: 9561...  Training loss: 1.7487...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9562...  Training loss: 1.6910...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9563...  Training loss: 1.7484...  0.0537 sec/batch
Epoch: 16/20...  Training Step: 9564...  Training loss: 1.7512...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9565...  Training loss: 1.7552...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9566...  Training loss: 1.6931...  0.0533 sec/batch
Epoch: 16/20...  Training Step: 9567...  Training loss: 1.7104...  0.0567 sec/batch
Epoch: 16/20...  Training Step: 9568...  Training loss: 1.7505...  0.0534 sec/batch
Epoch: 16/20...  Training Step: 9569...  Training loss: 1.7211...  0.0533 sec/batch
Epoch: 16/20...  Training Step: 9570...  Training loss: 1.6992...  0.0570 sec/batch
Epoch: 16/20...  Training Step: 9571...  Training loss: 1.6849...  0.0522 sec/batch
Epoch: 16/20...  Training Step: 9572...  Training loss: 1.7490...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9573...  Training loss: 1.7173...  0.0557 sec/batch
Epoch: 16/20...  Training Step: 9574...  Training loss: 1.7240...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9575...  Training loss: 1.7679...  0.0555 sec/batch
Epoch: 16/20...  Training Step: 9576...  Training loss: 1.7629...  0.0558 sec/batch
Epoch: 16/20...  Training Step: 9577...  Training loss: 1.8369...  0.0585 sec/batch
Epoch: 16/20...  Training Step: 9578...  Training loss: 1.7657...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9579...  Training loss: 1.7965...  0.0544 sec/batch
Epoch: 16/20...  Training Step: 9580...  Training loss: 1.7690...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9581...  Training loss: 1.7622...  0.0533 sec/batch
Epoch: 16/20...  Training Step: 9582...  Training loss: 1.6893...  0.0578 sec/batch
Epoch: 16/20...  Training Step: 9583...  Training loss: 1.6828...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9584...  Training loss: 1.7538...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9585...  Training loss: 1.7325...  0.0586 sec/batch
Epoch: 16/20...  Training Step: 9586...  Training loss: 1.7692...  0.0545 sec/batch
Epoch: 16/20...  Training Step: 9587...  Training loss: 1.7378...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9588...  Training loss: 1.7677...  0.0534 sec/batch
Epoch: 16/20...  Training Step: 9589...  Training loss: 1.7560...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9590...  Training loss: 1.7669...  0.0533 sec/batch
Epoch: 16/20...  Training Step: 9591...  Training loss: 1.7010...  0.0523 sec/batch
Epoch: 16/20...  Training Step: 9592...  Training loss: 1.7424...  0.0537 sec/batch
Epoch: 16/20...  Training Step: 9593...  Training loss: 1.6984...  0.0555 sec/batch
Epoch: 16/20...  Training Step: 9594...  Training loss: 1.7686...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9595...  Training loss: 1.7289...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9596...  Training loss: 1.6906...  0.0570 sec/batch
Epoch: 16/20...  Training Step: 9597...  Training loss: 1.7599...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9598...  Training loss: 1.7745...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9599...  Training loss: 1.7795...  0.0545 sec/batch
Epoch: 16/20...  Training Step: 9600...  Training loss: 1.7179...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9601...  Training loss: 1.7754...  0.0545 sec/batch
Epoch: 16/20...  Training Step: 9602...  Training loss: 1.8071...  0.0557 sec/batch
Epoch: 16/20...  Training Step: 9603...  Training loss: 1.7009...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9604...  Training loss: 1.7747...  0.0545 sec/batch
Epoch: 16/20...  Training Step: 9605...  Training loss: 1.7124...  0.0544 sec/batch
Epoch: 16/20...  Training Step: 9606...  Training loss: 1.7376...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9607...  Training loss: 1.7606...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9608...  Training loss: 1.7261...  0.0565 sec/batch
Epoch: 16/20...  Training Step: 9609...  Training loss: 1.7215...  0.0562 sec/batch
Epoch: 16/20...  Training Step: 9610...  Training loss: 1.7167...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9611...  Training loss: 1.7046...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9612...  Training loss: 1.6830...  0.0534 sec/batch
Epoch: 16/20...  Training Step: 9613...  Training loss: 1.7139...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9614...  Training loss: 1.6861...  0.0535 sec/batch
Epoch: 16/20...  Training Step: 9615...  Training loss: 1.7321...  0.0533 sec/batch
Epoch: 16/20...  Training Step: 9616...  Training loss: 1.7685...  0.0535 sec/batch
Epoch: 16/20...  Training Step: 9617...  Training loss: 1.7071...  0.0547 sec/batch
Epoch: 16/20...  Training Step: 9618...  Training loss: 1.6686...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9619...  Training loss: 1.7070...  0.0583 sec/batch
Epoch: 16/20...  Training Step: 9620...  Training loss: 1.7659...  0.0543 sec/batch
Epoch: 16/20...  Training Step: 9621...  Training loss: 1.7234...  0.0562 sec/batch
Epoch: 16/20...  Training Step: 9622...  Training loss: 1.6881...  0.0564 sec/batch
Epoch: 16/20...  Training Step: 9623...  Training loss: 1.7413...  0.0554 sec/batch
Epoch: 16/20...  Training Step: 9624...  Training loss: 1.7394...  0.0586 sec/batch
Epoch: 16/20...  Training Step: 9625...  Training loss: 1.7232...  0.0559 sec/batch
Epoch: 16/20...  Training Step: 9626...  Training loss: 1.7127...  0.0584 sec/batch
Epoch: 16/20...  Training Step: 9627...  Training loss: 1.6993...  0.0555 sec/batch
Epoch: 16/20...  Training Step: 9628...  Training loss: 1.7116...  0.0554 sec/batch
Epoch: 16/20...  Training Step: 9629...  Training loss: 1.7340...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9630...  Training loss: 1.7290...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9631...  Training loss: 1.7062...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9632...  Training loss: 1.7374...  0.0554 sec/batch
Epoch: 16/20...  Training Step: 9633...  Training loss: 1.7206...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9634...  Training loss: 1.7232...  0.0582 sec/batch
Epoch: 16/20...  Training Step: 9635...  Training loss: 1.7245...  0.0554 sec/batch
Epoch: 16/20...  Training Step: 9636...  Training loss: 1.7493...  0.0544 sec/batch
Epoch: 16/20...  Training Step: 9637...  Training loss: 1.6984...  0.0563 sec/batch
Epoch: 16/20...  Training Step: 9638...  Training loss: 1.7202...  0.0581 sec/batch
Epoch: 16/20...  Training Step: 9639...  Training loss: 1.6951...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9640...  Training loss: 1.7303...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9641...  Training loss: 1.7498...  0.0536 sec/batch
Epoch: 16/20...  Training Step: 9642...  Training loss: 1.7302...  0.0556 sec/batch
Epoch: 16/20...  Training Step: 9643...  Training loss: 1.6843...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9644...  Training loss: 1.7238...  0.0541 sec/batch
Epoch: 16/20...  Training Step: 9645...  Training loss: 1.7426...  0.0534 sec/batch
Epoch: 16/20...  Training Step: 9646...  Training loss: 1.7336...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9647...  Training loss: 1.7521...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9648...  Training loss: 1.7329...  0.0585 sec/batch
Epoch: 16/20...  Training Step: 9649...  Training loss: 1.7112...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9650...  Training loss: 1.7046...  0.0576 sec/batch
Epoch: 16/20...  Training Step: 9651...  Training loss: 1.7622...  0.0547 sec/batch
Epoch: 16/20...  Training Step: 9652...  Training loss: 1.7516...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9653...  Training loss: 1.7502...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9654...  Training loss: 1.7178...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9655...  Training loss: 1.7265...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9656...  Training loss: 1.7731...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9657...  Training loss: 1.8361...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9658...  Training loss: 1.7684...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9659...  Training loss: 1.7387...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9660...  Training loss: 1.7259...  0.0535 sec/batch
Epoch: 16/20...  Training Step: 9661...  Training loss: 1.7622...  0.0555 sec/batch
Epoch: 16/20...  Training Step: 9662...  Training loss: 1.7007...  0.0589 sec/batch
Epoch: 16/20...  Training Step: 9663...  Training loss: 1.6963...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9664...  Training loss: 1.6982...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9665...  Training loss: 1.7321...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9666...  Training loss: 1.7407...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9667...  Training loss: 1.7341...  0.0537 sec/batch
Epoch: 16/20...  Training Step: 9668...  Training loss: 1.7583...  0.0538 sec/batch
Epoch: 16/20...  Training Step: 9669...  Training loss: 1.7713...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9670...  Training loss: 1.7098...  0.0525 sec/batch
Epoch: 16/20...  Training Step: 9671...  Training loss: 1.7495...  0.0544 sec/batch
Epoch: 16/20...  Training Step: 9672...  Training loss: 1.8078...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9673...  Training loss: 1.7471...  0.0578 sec/batch
Epoch: 16/20...  Training Step: 9674...  Training loss: 1.7318...  0.0587 sec/batch
Epoch: 16/20...  Training Step: 9675...  Training loss: 1.7352...  0.0538 sec/batch
Epoch: 16/20...  Training Step: 9676...  Training loss: 1.7063...  0.0573 sec/batch
Epoch: 16/20...  Training Step: 9677...  Training loss: 1.7061...  0.0576 sec/batch
Epoch: 16/20...  Training Step: 9678...  Training loss: 1.8004...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9679...  Training loss: 1.7428...  0.0552 sec/batch
Epoch: 16/20...  Training Step: 9680...  Training loss: 1.7255...  0.0591 sec/batch
Epoch: 16/20...  Training Step: 9681...  Training loss: 1.6701...  0.0586 sec/batch
Epoch: 16/20...  Training Step: 9682...  Training loss: 1.7846...  0.0572 sec/batch
Epoch: 16/20...  Training Step: 9683...  Training loss: 1.7098...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9684...  Training loss: 1.7032...  0.0585 sec/batch
Epoch: 16/20...  Training Step: 9685...  Training loss: 1.7311...  0.0535 sec/batch
Epoch: 16/20...  Training Step: 9686...  Training loss: 1.6418...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9687...  Training loss: 1.6714...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9688...  Training loss: 1.7307...  0.0553 sec/batch
Epoch: 16/20...  Training Step: 9689...  Training loss: 1.6963...  0.0539 sec/batch
Epoch: 16/20...  Training Step: 9690...  Training loss: 1.7039...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9691...  Training loss: 1.7570...  0.0557 sec/batch
Epoch: 16/20...  Training Step: 9692...  Training loss: 1.6918...  0.0533 sec/batch
Epoch: 16/20...  Training Step: 9693...  Training loss: 1.7427...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9694...  Training loss: 1.7567...  0.0542 sec/batch
Epoch: 16/20...  Training Step: 9695...  Training loss: 1.6978...  0.0544 sec/batch
Epoch: 16/20...  Training Step: 9696...  Training loss: 1.7566...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9697...  Training loss: 1.7247...  0.0575 sec/batch
Epoch: 16/20...  Training Step: 9698...  Training loss: 1.7465...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9699...  Training loss: 1.7114...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9700...  Training loss: 1.7634...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9701...  Training loss: 1.7742...  0.0556 sec/batch
Epoch: 16/20...  Training Step: 9702...  Training loss: 1.7384...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9703...  Training loss: 1.7198...  0.0586 sec/batch
Epoch: 16/20...  Training Step: 9704...  Training loss: 1.7550...  0.0554 sec/batch
Epoch: 16/20...  Training Step: 9705...  Training loss: 1.7974...  0.0536 sec/batch
Epoch: 16/20...  Training Step: 9706...  Training loss: 1.7598...  0.0554 sec/batch
Epoch: 16/20...  Training Step: 9707...  Training loss: 1.7891...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9708...  Training loss: 1.7519...  0.0545 sec/batch
Epoch: 16/20...  Training Step: 9709...  Training loss: 1.7837...  0.0525 sec/batch
Epoch: 16/20...  Training Step: 9710...  Training loss: 1.7761...  0.0553 sec/batch
Epoch: 16/20...  Training Step: 9711...  Training loss: 1.7021...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9712...  Training loss: 1.7731...  0.0545 sec/batch
Epoch: 16/20...  Training Step: 9713...  Training loss: 1.7722...  0.0576 sec/batch
Epoch: 16/20...  Training Step: 9714...  Training loss: 1.7273...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9715...  Training loss: 1.7093...  0.0587 sec/batch
Epoch: 16/20...  Training Step: 9716...  Training loss: 1.7126...  0.0586 sec/batch
Epoch: 16/20...  Training Step: 9717...  Training loss: 1.7257...  0.0542 sec/batch
Epoch: 16/20...  Training Step: 9718...  Training loss: 1.7384...  0.0523 sec/batch
Epoch: 16/20...  Training Step: 9719...  Training loss: 1.7804...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9720...  Training loss: 1.7264...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9721...  Training loss: 1.7064...  0.0555 sec/batch
Epoch: 16/20...  Training Step: 9722...  Training loss: 1.7310...  0.0552 sec/batch
Epoch: 16/20...  Training Step: 9723...  Training loss: 1.7511...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9724...  Training loss: 1.6796...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9725...  Training loss: 1.7583...  0.0552 sec/batch
Epoch: 16/20...  Training Step: 9726...  Training loss: 1.7620...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9727...  Training loss: 1.7021...  0.0523 sec/batch
Epoch: 16/20...  Training Step: 9728...  Training loss: 1.7568...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9729...  Training loss: 1.7058...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9730...  Training loss: 1.6809...  0.0572 sec/batch
Epoch: 16/20...  Training Step: 9731...  Training loss: 1.7150...  0.0575 sec/batch
Epoch: 16/20...  Training Step: 9732...  Training loss: 1.7931...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9733...  Training loss: 1.7477...  0.0585 sec/batch
Epoch: 16/20...  Training Step: 9734...  Training loss: 1.7149...  0.0556 sec/batch
Epoch: 16/20...  Training Step: 9735...  Training loss: 1.6993...  0.0580 sec/batch
Epoch: 16/20...  Training Step: 9736...  Training loss: 1.7254...  0.0585 sec/batch
Epoch: 16/20...  Training Step: 9737...  Training loss: 1.6874...  0.0552 sec/batch
Epoch: 16/20...  Training Step: 9738...  Training loss: 1.7355...  0.0563 sec/batch
Epoch: 16/20...  Training Step: 9739...  Training loss: 1.7389...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9740...  Training loss: 1.7112...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9741...  Training loss: 1.7218...  0.0541 sec/batch
Epoch: 16/20...  Training Step: 9742...  Training loss: 1.7364...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9743...  Training loss: 1.7658...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9744...  Training loss: 1.7464...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9745...  Training loss: 1.6423...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9746...  Training loss: 1.7328...  0.0556 sec/batch
Epoch: 16/20...  Training Step: 9747...  Training loss: 1.6993...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9748...  Training loss: 1.6891...  0.0560 sec/batch
Epoch: 16/20...  Training Step: 9749...  Training loss: 1.7256...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9750...  Training loss: 1.7683...  0.0534 sec/batch
Epoch: 16/20...  Training Step: 9751...  Training loss: 1.7921...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9752...  Training loss: 1.7605...  0.0564 sec/batch
Epoch: 16/20...  Training Step: 9753...  Training loss: 1.6833...  0.0535 sec/batch
Epoch: 16/20...  Training Step: 9754...  Training loss: 1.7381...  0.0552 sec/batch
Epoch: 16/20...  Training Step: 9755...  Training loss: 1.7256...  0.0536 sec/batch
Epoch: 16/20...  Training Step: 9756...  Training loss: 1.7286...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9757...  Training loss: 1.7046...  0.0539 sec/batch
Epoch: 16/20...  Training Step: 9758...  Training loss: 1.7367...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9759...  Training loss: 1.7190...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9760...  Training loss: 1.7288...  0.0572 sec/batch
Epoch: 16/20...  Training Step: 9761...  Training loss: 1.7007...  0.0631 sec/batch
Epoch: 16/20...  Training Step: 9762...  Training loss: 1.7365...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9763...  Training loss: 1.7086...  0.0547 sec/batch
Epoch: 16/20...  Training Step: 9764...  Training loss: 1.7351...  0.0582 sec/batch
Epoch: 16/20...  Training Step: 9765...  Training loss: 1.7659...  0.0544 sec/batch
Epoch: 16/20...  Training Step: 9766...  Training loss: 1.7560...  0.0580 sec/batch
Epoch: 16/20...  Training Step: 9767...  Training loss: 1.7193...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9768...  Training loss: 1.7323...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9769...  Training loss: 1.7413...  0.0545 sec/batch
Epoch: 16/20...  Training Step: 9770...  Training loss: 1.7126...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9771...  Training loss: 1.7367...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9772...  Training loss: 1.7463...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9773...  Training loss: 1.7190...  0.0604 sec/batch
Epoch: 16/20...  Training Step: 9774...  Training loss: 1.6846...  0.0541 sec/batch
Epoch: 16/20...  Training Step: 9775...  Training loss: 1.7968...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9776...  Training loss: 1.7851...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9777...  Training loss: 1.7312...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9778...  Training loss: 1.8137...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9779...  Training loss: 1.7213...  0.0554 sec/batch
Epoch: 16/20...  Training Step: 9780...  Training loss: 1.7891...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9781...  Training loss: 1.7355...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9782...  Training loss: 1.6987...  0.0582 sec/batch
Epoch: 16/20...  Training Step: 9783...  Training loss: 1.7483...  0.0577 sec/batch
Epoch: 16/20...  Training Step: 9784...  Training loss: 1.7580...  0.0547 sec/batch
Epoch: 16/20...  Training Step: 9785...  Training loss: 1.8229...  0.0544 sec/batch
Epoch: 16/20...  Training Step: 9786...  Training loss: 1.7195...  0.0534 sec/batch
Epoch: 16/20...  Training Step: 9787...  Training loss: 1.7656...  0.0557 sec/batch
Epoch: 16/20...  Training Step: 9788...  Training loss: 1.7558...  0.0603 sec/batch
Epoch: 16/20...  Training Step: 9789...  Training loss: 1.7491...  0.0563 sec/batch
Epoch: 16/20...  Training Step: 9790...  Training loss: 1.7435...  0.0522 sec/batch
Epoch: 16/20...  Training Step: 9791...  Training loss: 1.7293...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9792...  Training loss: 1.7573...  0.0542 sec/batch
Epoch: 16/20...  Training Step: 9793...  Training loss: 1.7372...  0.0543 sec/batch
Epoch: 16/20...  Training Step: 9794...  Training loss: 1.7200...  0.0577 sec/batch
Epoch: 16/20...  Training Step: 9795...  Training loss: 1.6957...  0.0552 sec/batch
Epoch: 16/20...  Training Step: 9796...  Training loss: 1.7339...  0.0525 sec/batch
Epoch: 16/20...  Training Step: 9797...  Training loss: 1.7144...  0.0605 sec/batch
Epoch: 16/20...  Training Step: 9798...  Training loss: 1.7967...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9799...  Training loss: 1.6779...  0.0543 sec/batch
Epoch: 16/20...  Training Step: 9800...  Training loss: 1.7421...  0.0539 sec/batch
Epoch: 16/20...  Training Step: 9801...  Training loss: 1.7404...  0.0534 sec/batch
Epoch: 16/20...  Training Step: 9802...  Training loss: 1.7431...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9803...  Training loss: 1.8133...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9804...  Training loss: 1.7463...  0.0576 sec/batch
Epoch: 16/20...  Training Step: 9805...  Training loss: 1.6798...  0.0670 sec/batch
Epoch: 16/20...  Training Step: 9806...  Training loss: 1.7023...  0.0537 sec/batch
Epoch: 16/20...  Training Step: 9807...  Training loss: 1.7703...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9808...  Training loss: 1.7184...  0.0578 sec/batch
Epoch: 16/20...  Training Step: 9809...  Training loss: 1.7722...  0.0552 sec/batch
Epoch: 16/20...  Training Step: 9810...  Training loss: 1.7431...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9811...  Training loss: 1.7913...  0.0570 sec/batch
Epoch: 16/20...  Training Step: 9812...  Training loss: 1.7652...  0.0537 sec/batch
Epoch: 16/20...  Training Step: 9813...  Training loss: 1.7719...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9814...  Training loss: 1.7549...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9815...  Training loss: 1.7380...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9816...  Training loss: 1.7210...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9817...  Training loss: 1.7242...  0.0552 sec/batch
Epoch: 16/20...  Training Step: 9818...  Training loss: 1.7061...  0.0538 sec/batch
Epoch: 16/20...  Training Step: 9819...  Training loss: 1.7255...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9820...  Training loss: 1.7261...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9821...  Training loss: 1.7260...  0.0553 sec/batch
Epoch: 16/20...  Training Step: 9822...  Training loss: 1.6870...  0.0547 sec/batch
Epoch: 16/20...  Training Step: 9823...  Training loss: 1.7264...  0.0571 sec/batch
Epoch: 16/20...  Training Step: 9824...  Training loss: 1.6648...  0.0619 sec/batch
Epoch: 16/20...  Training Step: 9825...  Training loss: 1.7668...  0.0585 sec/batch
Epoch: 16/20...  Training Step: 9826...  Training loss: 1.7756...  0.0553 sec/batch
Epoch: 16/20...  Training Step: 9827...  Training loss: 1.7877...  0.0547 sec/batch
Epoch: 16/20...  Training Step: 9828...  Training loss: 1.7507...  0.0562 sec/batch
Epoch: 16/20...  Training Step: 9829...  Training loss: 1.7284...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9830...  Training loss: 1.7229...  0.0536 sec/batch
Epoch: 16/20...  Training Step: 9831...  Training loss: 1.7018...  0.0527 sec/batch
Epoch: 16/20...  Training Step: 9832...  Training loss: 1.7229...  0.0585 sec/batch
Epoch: 16/20...  Training Step: 9833...  Training loss: 1.7166...  0.0537 sec/batch
Epoch: 16/20...  Training Step: 9834...  Training loss: 1.7407...  0.0541 sec/batch
Epoch: 16/20...  Training Step: 9835...  Training loss: 1.7527...  0.0544 sec/batch
Epoch: 16/20...  Training Step: 9836...  Training loss: 1.7356...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9837...  Training loss: 1.6991...  0.0585 sec/batch
Epoch: 16/20...  Training Step: 9838...  Training loss: 1.7215...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9839...  Training loss: 1.6632...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9840...  Training loss: 1.7415...  0.0521 sec/batch
Epoch: 16/20...  Training Step: 9841...  Training loss: 1.7535...  0.0572 sec/batch
Epoch: 16/20...  Training Step: 9842...  Training loss: 1.7142...  0.0523 sec/batch
Epoch: 16/20...  Training Step: 9843...  Training loss: 1.6949...  0.0536 sec/batch
Epoch: 16/20...  Training Step: 9844...  Training loss: 1.7005...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9845...  Training loss: 1.7518...  0.0553 sec/batch
Epoch: 16/20...  Training Step: 9846...  Training loss: 1.7410...  0.0533 sec/batch
Epoch: 16/20...  Training Step: 9847...  Training loss: 1.7912...  0.0533 sec/batch
Epoch: 16/20...  Training Step: 9848...  Training loss: 1.7882...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9849...  Training loss: 1.7530...  0.0534 sec/batch
Epoch: 16/20...  Training Step: 9850...  Training loss: 1.7272...  0.0533 sec/batch
Epoch: 16/20...  Training Step: 9851...  Training loss: 1.7612...  0.0526 sec/batch
Epoch: 16/20...  Training Step: 9852...  Training loss: 1.6804...  0.0580 sec/batch
Epoch: 16/20...  Training Step: 9853...  Training loss: 1.7394...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9854...  Training loss: 1.7402...  0.0536 sec/batch
Epoch: 16/20...  Training Step: 9855...  Training loss: 1.7175...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9856...  Training loss: 1.7266...  0.0594 sec/batch
Epoch: 16/20...  Training Step: 9857...  Training loss: 1.7480...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9858...  Training loss: 1.6893...  0.0578 sec/batch
Epoch: 16/20...  Training Step: 9859...  Training loss: 1.7342...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9860...  Training loss: 1.7218...  0.0564 sec/batch
Epoch: 16/20...  Training Step: 9861...  Training loss: 1.7805...  0.0533 sec/batch
Epoch: 16/20...  Training Step: 9862...  Training loss: 1.7586...  0.0553 sec/batch
Epoch: 16/20...  Training Step: 9863...  Training loss: 1.7253...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9864...  Training loss: 1.8136...  0.0572 sec/batch
Epoch: 16/20...  Training Step: 9865...  Training loss: 1.8223...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9866...  Training loss: 1.8162...  0.0552 sec/batch
Epoch: 16/20...  Training Step: 9867...  Training loss: 1.7253...  0.0581 sec/batch
Epoch: 16/20...  Training Step: 9868...  Training loss: 1.7916...  0.0538 sec/batch
Epoch: 16/20...  Training Step: 9869...  Training loss: 1.7139...  0.0553 sec/batch
Epoch: 16/20...  Training Step: 9870...  Training loss: 1.7533...  0.0535 sec/batch
Epoch: 16/20...  Training Step: 9871...  Training loss: 1.7527...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9872...  Training loss: 1.7956...  0.0567 sec/batch
Epoch: 16/20...  Training Step: 9873...  Training loss: 1.7486...  0.0539 sec/batch
Epoch: 16/20...  Training Step: 9874...  Training loss: 1.7122...  0.0590 sec/batch
Epoch: 16/20...  Training Step: 9875...  Training loss: 1.7479...  0.0535 sec/batch
Epoch: 16/20...  Training Step: 9876...  Training loss: 1.7499...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9877...  Training loss: 1.7041...  0.0587 sec/batch
Epoch: 16/20...  Training Step: 9878...  Training loss: 1.7476...  0.0577 sec/batch
Epoch: 16/20...  Training Step: 9879...  Training loss: 1.7583...  0.0552 sec/batch
Epoch: 16/20...  Training Step: 9880...  Training loss: 1.7589...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9881...  Training loss: 1.7791...  0.0528 sec/batch
Epoch: 16/20...  Training Step: 9882...  Training loss: 1.7371...  0.0532 sec/batch
Epoch: 16/20...  Training Step: 9883...  Training loss: 1.7291...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9884...  Training loss: 1.7822...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9885...  Training loss: 1.7623...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9886...  Training loss: 1.7448...  0.0551 sec/batch
Epoch: 16/20...  Training Step: 9887...  Training loss: 1.7084...  0.0561 sec/batch
Epoch: 16/20...  Training Step: 9888...  Training loss: 1.7524...  0.0535 sec/batch
Epoch: 16/20...  Training Step: 9889...  Training loss: 1.7446...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9890...  Training loss: 1.7580...  0.0539 sec/batch
Epoch: 16/20...  Training Step: 9891...  Training loss: 1.6991...  0.0579 sec/batch
Epoch: 16/20...  Training Step: 9892...  Training loss: 1.7860...  0.0595 sec/batch
Epoch: 16/20...  Training Step: 9893...  Training loss: 1.7174...  0.0553 sec/batch
Epoch: 16/20...  Training Step: 9894...  Training loss: 1.7131...  0.0575 sec/batch
Epoch: 16/20...  Training Step: 9895...  Training loss: 1.7183...  0.0537 sec/batch
Epoch: 16/20...  Training Step: 9896...  Training loss: 1.7004...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9897...  Training loss: 1.6781...  0.0579 sec/batch
Epoch: 16/20...  Training Step: 9898...  Training loss: 1.7324...  0.0545 sec/batch
Epoch: 16/20...  Training Step: 9899...  Training loss: 1.7373...  0.0580 sec/batch
Epoch: 16/20...  Training Step: 9900...  Training loss: 1.7530...  0.0548 sec/batch
Epoch: 16/20...  Training Step: 9901...  Training loss: 1.7281...  0.0524 sec/batch
Epoch: 16/20...  Training Step: 9902...  Training loss: 1.7270...  0.0550 sec/batch
Epoch: 16/20...  Training Step: 9903...  Training loss: 1.7490...  0.0585 sec/batch
Epoch: 16/20...  Training Step: 9904...  Training loss: 1.7062...  0.0530 sec/batch
Epoch: 16/20...  Training Step: 9905...  Training loss: 1.7328...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9906...  Training loss: 1.7387...  0.0534 sec/batch
Epoch: 16/20...  Training Step: 9907...  Training loss: 1.6880...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9908...  Training loss: 1.6937...  0.0556 sec/batch
Epoch: 16/20...  Training Step: 9909...  Training loss: 1.7456...  0.0595 sec/batch
Epoch: 16/20...  Training Step: 9910...  Training loss: 1.7827...  0.0529 sec/batch
Epoch: 16/20...  Training Step: 9911...  Training loss: 1.7938...  0.0531 sec/batch
Epoch: 16/20...  Training Step: 9912...  Training loss: 1.7373...  0.0573 sec/batch
Epoch: 16/20...  Training Step: 9913...  Training loss: 1.7007...  0.0556 sec/batch
Epoch: 16/20...  Training Step: 9914...  Training loss: 1.7547...  0.0581 sec/batch
Epoch: 16/20...  Training Step: 9915...  Training loss: 1.6924...  0.0560 sec/batch
Epoch: 16/20...  Training Step: 9916...  Training loss: 1.7662...  0.0590 sec/batch
Epoch: 16/20...  Training Step: 9917...  Training loss: 1.7825...  0.0546 sec/batch
Epoch: 16/20...  Training Step: 9918...  Training loss: 1.7062...  0.0538 sec/batch
Epoch: 16/20...  Training Step: 9919...  Training loss: 1.6839...  0.0549 sec/batch
Epoch: 16/20...  Training Step: 9920...  Training loss: 1.6819...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 9921...  Training loss: 1.8217...  0.0531 sec/batch
Epoch: 17/20...  Training Step: 9922...  Training loss: 1.8034...  0.0576 sec/batch
Epoch: 17/20...  Training Step: 9923...  Training loss: 1.7813...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 9924...  Training loss: 1.7047...  0.0538 sec/batch
Epoch: 17/20...  Training Step: 9925...  Training loss: 1.7312...  0.0536 sec/batch
Epoch: 17/20...  Training Step: 9926...  Training loss: 1.7596...  0.0544 sec/batch
Epoch: 17/20...  Training Step: 9927...  Training loss: 1.7068...  0.0556 sec/batch
Epoch: 17/20...  Training Step: 9928...  Training loss: 1.6935...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 9929...  Training loss: 1.6806...  0.0560 sec/batch
Epoch: 17/20...  Training Step: 9930...  Training loss: 1.6857...  0.0543 sec/batch
Epoch: 17/20...  Training Step: 9931...  Training loss: 1.7154...  0.0585 sec/batch
Epoch: 17/20...  Training Step: 9932...  Training loss: 1.7093...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 9933...  Training loss: 1.7211...  0.0561 sec/batch
Epoch: 17/20...  Training Step: 9934...  Training loss: 1.6969...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 9935...  Training loss: 1.7535...  0.0543 sec/batch
Epoch: 17/20...  Training Step: 9936...  Training loss: 1.7702...  0.0576 sec/batch
Epoch: 17/20...  Training Step: 9937...  Training loss: 1.7384...  0.0579 sec/batch
Epoch: 17/20...  Training Step: 9938...  Training loss: 1.7639...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 9939...  Training loss: 1.7115...  0.0584 sec/batch
Epoch: 17/20...  Training Step: 9940...  Training loss: 1.7439...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 9941...  Training loss: 1.7821...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 9942...  Training loss: 1.7276...  0.0545 sec/batch
Epoch: 17/20...  Training Step: 9943...  Training loss: 1.7106...  0.0539 sec/batch
Epoch: 17/20...  Training Step: 9944...  Training loss: 1.7523...  0.0528 sec/batch
Epoch: 17/20...  Training Step: 9945...  Training loss: 1.6862...  0.0614 sec/batch
Epoch: 17/20...  Training Step: 9946...  Training loss: 1.7015...  0.0549 sec/batch
Epoch: 17/20...  Training Step: 9947...  Training loss: 1.7212...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 9948...  Training loss: 1.7617...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 9949...  Training loss: 1.7325...  0.0557 sec/batch
Epoch: 17/20...  Training Step: 9950...  Training loss: 1.7160...  0.0574 sec/batch
Epoch: 17/20...  Training Step: 9951...  Training loss: 1.7214...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 9952...  Training loss: 1.7285...  0.0526 sec/batch
Epoch: 17/20...  Training Step: 9953...  Training loss: 1.7103...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 9954...  Training loss: 1.7187...  0.0539 sec/batch
Epoch: 17/20...  Training Step: 9955...  Training loss: 1.7202...  0.0564 sec/batch
Epoch: 17/20...  Training Step: 9956...  Training loss: 1.7102...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 9957...  Training loss: 1.7553...  0.0594 sec/batch
Epoch: 17/20...  Training Step: 9958...  Training loss: 1.7241...  0.0539 sec/batch
Epoch: 17/20...  Training Step: 9959...  Training loss: 1.7403...  0.0551 sec/batch
Epoch: 17/20...  Training Step: 9960...  Training loss: 1.7149...  0.0539 sec/batch
Epoch: 17/20...  Training Step: 9961...  Training loss: 1.7379...  0.0564 sec/batch
Epoch: 17/20...  Training Step: 9962...  Training loss: 1.7556...  0.0571 sec/batch
Epoch: 17/20...  Training Step: 9963...  Training loss: 1.7344...  0.0570 sec/batch
Epoch: 17/20...  Training Step: 9964...  Training loss: 1.7513...  0.0524 sec/batch
Epoch: 17/20...  Training Step: 9965...  Training loss: 1.7214...  0.0540 sec/batch
Epoch: 17/20...  Training Step: 9966...  Training loss: 1.7225...  0.0551 sec/batch
Epoch: 17/20...  Training Step: 9967...  Training loss: 1.5985...  0.0567 sec/batch
Epoch: 17/20...  Training Step: 9968...  Training loss: 1.7217...  0.0554 sec/batch
Epoch: 17/20...  Training Step: 9969...  Training loss: 1.6706...  0.0531 sec/batch
Epoch: 17/20...  Training Step: 9970...  Training loss: 1.7242...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 9971...  Training loss: 1.7074...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 9972...  Training loss: 1.7014...  0.0549 sec/batch
Epoch: 17/20...  Training Step: 9973...  Training loss: 1.7438...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 9974...  Training loss: 1.7426...  0.0549 sec/batch
Epoch: 17/20...  Training Step: 9975...  Training loss: 1.7407...  0.0526 sec/batch
Epoch: 17/20...  Training Step: 9976...  Training loss: 1.7219...  0.0536 sec/batch
Epoch: 17/20...  Training Step: 9977...  Training loss: 1.6998...  0.0524 sec/batch
Epoch: 17/20...  Training Step: 9978...  Training loss: 1.7190...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 9979...  Training loss: 1.7079...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 9980...  Training loss: 1.7602...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 9981...  Training loss: 1.7325...  0.0561 sec/batch
Epoch: 17/20...  Training Step: 9982...  Training loss: 1.6976...  0.0531 sec/batch
Epoch: 17/20...  Training Step: 9983...  Training loss: 1.7623...  0.0573 sec/batch
Epoch: 17/20...  Training Step: 9984...  Training loss: 1.7286...  0.0531 sec/batch
Epoch: 17/20...  Training Step: 9985...  Training loss: 1.6825...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 9986...  Training loss: 1.6746...  0.0540 sec/batch
Epoch: 17/20...  Training Step: 9987...  Training loss: 1.7004...  0.0589 sec/batch
Epoch: 17/20...  Training Step: 9988...  Training loss: 1.6964...  0.0539 sec/batch
Epoch: 17/20...  Training Step: 9989...  Training loss: 1.7153...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 9990...  Training loss: 1.7343...  0.0555 sec/batch
Epoch: 17/20...  Training Step: 9991...  Training loss: 1.7934...  0.0567 sec/batch
Epoch: 17/20...  Training Step: 9992...  Training loss: 1.7450...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 9993...  Training loss: 1.6700...  0.0587 sec/batch
Epoch: 17/20...  Training Step: 9994...  Training loss: 1.7148...  0.0538 sec/batch
Epoch: 17/20...  Training Step: 9995...  Training loss: 1.7629...  0.0575 sec/batch
Epoch: 17/20...  Training Step: 9996...  Training loss: 1.7660...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 9997...  Training loss: 1.7319...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 9998...  Training loss: 1.7070...  0.0549 sec/batch
Epoch: 17/20...  Training Step: 9999...  Training loss: 1.7299...  0.0592 sec/batch
Epoch: 17/20...  Training Step: 10000...  Training loss: 1.7475...  0.0556 sec/batch
Epoch: 17/20...  Training Step: 10001...  Training loss: 1.6701...  0.0582 sec/batch
Epoch: 17/20...  Training Step: 10002...  Training loss: 1.7320...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 10003...  Training loss: 1.6907...  0.0538 sec/batch
Epoch: 17/20...  Training Step: 10004...  Training loss: 1.7118...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10005...  Training loss: 1.7016...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10006...  Training loss: 1.7677...  0.0521 sec/batch
Epoch: 17/20...  Training Step: 10007...  Training loss: 1.6908...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10008...  Training loss: 1.7776...  0.0573 sec/batch
Epoch: 17/20...  Training Step: 10009...  Training loss: 1.7222...  0.0573 sec/batch
Epoch: 17/20...  Training Step: 10010...  Training loss: 1.7410...  0.0576 sec/batch
Epoch: 17/20...  Training Step: 10011...  Training loss: 1.7178...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10012...  Training loss: 1.7785...  0.0562 sec/batch
Epoch: 17/20...  Training Step: 10013...  Training loss: 1.7498...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 10014...  Training loss: 1.7291...  0.0562 sec/batch
Epoch: 17/20...  Training Step: 10015...  Training loss: 1.7036...  0.0527 sec/batch
Epoch: 17/20...  Training Step: 10016...  Training loss: 1.7633...  0.0551 sec/batch
Epoch: 17/20...  Training Step: 10017...  Training loss: 1.7536...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10018...  Training loss: 1.6747...  0.0587 sec/batch
Epoch: 17/20...  Training Step: 10019...  Training loss: 1.7584...  0.0551 sec/batch
Epoch: 17/20...  Training Step: 10020...  Training loss: 1.6949...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10021...  Training loss: 1.6852...  0.0558 sec/batch
Epoch: 17/20...  Training Step: 10022...  Training loss: 1.6952...  0.0527 sec/batch
Epoch: 17/20...  Training Step: 10023...  Training loss: 1.7543...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10024...  Training loss: 1.8011...  0.0545 sec/batch
Epoch: 17/20...  Training Step: 10025...  Training loss: 1.7313...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 10026...  Training loss: 1.6904...  0.0536 sec/batch
Epoch: 17/20...  Training Step: 10027...  Training loss: 1.7584...  0.0551 sec/batch
Epoch: 17/20...  Training Step: 10028...  Training loss: 1.7130...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10029...  Training loss: 1.7186...  0.0562 sec/batch
Epoch: 17/20...  Training Step: 10030...  Training loss: 1.6736...  0.0592 sec/batch
Epoch: 17/20...  Training Step: 10031...  Training loss: 1.6894...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10032...  Training loss: 1.7118...  0.0593 sec/batch
Epoch: 17/20...  Training Step: 10033...  Training loss: 1.6981...  0.0530 sec/batch
Epoch: 17/20...  Training Step: 10034...  Training loss: 1.6997...  0.0577 sec/batch
Epoch: 17/20...  Training Step: 10035...  Training loss: 1.7617...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10036...  Training loss: 1.7525...  0.0528 sec/batch
Epoch: 17/20...  Training Step: 10037...  Training loss: 1.6649...  0.0525 sec/batch
Epoch: 17/20...  Training Step: 10038...  Training loss: 1.7597...  0.0555 sec/batch
Epoch: 17/20...  Training Step: 10039...  Training loss: 1.7072...  0.0526 sec/batch
Epoch: 17/20...  Training Step: 10040...  Training loss: 1.7103...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 10041...  Training loss: 1.7013...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10042...  Training loss: 1.6813...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 10043...  Training loss: 1.7260...  0.0571 sec/batch
Epoch: 17/20...  Training Step: 10044...  Training loss: 1.7432...  0.0528 sec/batch
Epoch: 17/20...  Training Step: 10045...  Training loss: 1.7498...  0.0567 sec/batch
Epoch: 17/20...  Training Step: 10046...  Training loss: 1.7557...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 10047...  Training loss: 1.7641...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10048...  Training loss: 1.6858...  0.0555 sec/batch
Epoch: 17/20...  Training Step: 10049...  Training loss: 1.7180...  0.0587 sec/batch
Epoch: 17/20...  Training Step: 10050...  Training loss: 1.7766...  0.0585 sec/batch
Epoch: 17/20...  Training Step: 10051...  Training loss: 1.7138...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10052...  Training loss: 1.7622...  0.0577 sec/batch
Epoch: 17/20...  Training Step: 10053...  Training loss: 1.7625...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10054...  Training loss: 1.7394...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10055...  Training loss: 1.7172...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10056...  Training loss: 1.7262...  0.0528 sec/batch
Epoch: 17/20...  Training Step: 10057...  Training loss: 1.7433...  0.0549 sec/batch
Epoch: 17/20...  Training Step: 10058...  Training loss: 1.7265...  0.0560 sec/batch
Epoch: 17/20...  Training Step: 10059...  Training loss: 1.7753...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10060...  Training loss: 1.7517...  0.0568 sec/batch
Epoch: 17/20...  Training Step: 10061...  Training loss: 1.7905...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 10062...  Training loss: 1.6440...  0.0563 sec/batch
Epoch: 17/20...  Training Step: 10063...  Training loss: 1.7623...  0.0552 sec/batch
Epoch: 17/20...  Training Step: 10064...  Training loss: 1.7069...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 10065...  Training loss: 1.6737...  0.0575 sec/batch
Epoch: 17/20...  Training Step: 10066...  Training loss: 1.7633...  0.0561 sec/batch
Epoch: 17/20...  Training Step: 10067...  Training loss: 1.7337...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 10068...  Training loss: 1.7292...  0.0554 sec/batch
Epoch: 17/20...  Training Step: 10069...  Training loss: 1.7597...  0.0526 sec/batch
Epoch: 17/20...  Training Step: 10070...  Training loss: 1.7652...  0.0558 sec/batch
Epoch: 17/20...  Training Step: 10071...  Training loss: 1.7415...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 10072...  Training loss: 1.7002...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 10073...  Training loss: 1.7329...  0.0574 sec/batch
Epoch: 17/20...  Training Step: 10074...  Training loss: 1.7620...  0.0556 sec/batch
Epoch: 17/20...  Training Step: 10075...  Training loss: 1.7180...  0.0544 sec/batch
Epoch: 17/20...  Training Step: 10076...  Training loss: 1.7477...  0.0528 sec/batch
Epoch: 17/20...  Training Step: 10077...  Training loss: 1.7451...  0.0551 sec/batch
Epoch: 17/20...  Training Step: 10078...  Training loss: 1.7584...  0.0575 sec/batch
Epoch: 17/20...  Training Step: 10079...  Training loss: 1.7201...  0.0555 sec/batch
Epoch: 17/20...  Training Step: 10080...  Training loss: 1.6946...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10081...  Training loss: 1.7231...  0.0561 sec/batch
Epoch: 17/20...  Training Step: 10082...  Training loss: 1.7035...  0.0525 sec/batch
Epoch: 17/20...  Training Step: 10083...  Training loss: 1.7534...  0.0577 sec/batch
Epoch: 17/20...  Training Step: 10084...  Training loss: 1.7237...  0.0561 sec/batch
Epoch: 17/20...  Training Step: 10085...  Training loss: 1.7520...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 10086...  Training loss: 1.7435...  0.0574 sec/batch
Epoch: 17/20...  Training Step: 10087...  Training loss: 1.7387...  0.0555 sec/batch
Epoch: 17/20...  Training Step: 10088...  Training loss: 1.7229...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10089...  Training loss: 1.7197...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 10090...  Training loss: 1.6945...  0.0567 sec/batch
Epoch: 17/20...  Training Step: 10091...  Training loss: 1.7221...  0.0581 sec/batch
Epoch: 17/20...  Training Step: 10092...  Training loss: 1.7483...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10093...  Training loss: 1.7250...  0.0530 sec/batch
Epoch: 17/20...  Training Step: 10094...  Training loss: 1.7119...  0.0574 sec/batch
Epoch: 17/20...  Training Step: 10095...  Training loss: 1.6974...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10096...  Training loss: 1.7245...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 10097...  Training loss: 1.7346...  0.0578 sec/batch
Epoch: 17/20...  Training Step: 10098...  Training loss: 1.7098...  0.0524 sec/batch
Epoch: 17/20...  Training Step: 10099...  Training loss: 1.7061...  0.0587 sec/batch
Epoch: 17/20...  Training Step: 10100...  Training loss: 1.6949...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10101...  Training loss: 1.7082...  0.0591 sec/batch
Epoch: 17/20...  Training Step: 10102...  Training loss: 1.7547...  0.0589 sec/batch
Epoch: 17/20...  Training Step: 10103...  Training loss: 1.7385...  0.0583 sec/batch
Epoch: 17/20...  Training Step: 10104...  Training loss: 1.6978...  0.0572 sec/batch
Epoch: 17/20...  Training Step: 10105...  Training loss: 1.6876...  0.0585 sec/batch
Epoch: 17/20...  Training Step: 10106...  Training loss: 1.7311...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10107...  Training loss: 1.7190...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10108...  Training loss: 1.7209...  0.0554 sec/batch
Epoch: 17/20...  Training Step: 10109...  Training loss: 1.7274...  0.0578 sec/batch
Epoch: 17/20...  Training Step: 10110...  Training loss: 1.7899...  0.0537 sec/batch
Epoch: 17/20...  Training Step: 10111...  Training loss: 1.7448...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 10112...  Training loss: 1.7718...  0.0545 sec/batch
Epoch: 17/20...  Training Step: 10113...  Training loss: 1.7441...  0.0598 sec/batch
Epoch: 17/20...  Training Step: 10114...  Training loss: 1.7055...  0.0531 sec/batch
Epoch: 17/20...  Training Step: 10115...  Training loss: 1.7159...  0.0565 sec/batch
Epoch: 17/20...  Training Step: 10116...  Training loss: 1.7848...  0.0526 sec/batch
Epoch: 17/20...  Training Step: 10117...  Training loss: 1.7394...  0.0573 sec/batch
Epoch: 17/20...  Training Step: 10118...  Training loss: 1.8056...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10119...  Training loss: 1.7007...  0.0531 sec/batch
Epoch: 17/20...  Training Step: 10120...  Training loss: 1.7489...  0.0537 sec/batch
Epoch: 17/20...  Training Step: 10121...  Training loss: 1.6939...  0.0583 sec/batch
Epoch: 17/20...  Training Step: 10122...  Training loss: 1.7180...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10123...  Training loss: 1.7284...  0.0588 sec/batch
Epoch: 17/20...  Training Step: 10124...  Training loss: 1.6994...  0.0528 sec/batch
Epoch: 17/20...  Training Step: 10125...  Training loss: 1.7272...  0.0525 sec/batch
Epoch: 17/20...  Training Step: 10126...  Training loss: 1.6998...  0.0566 sec/batch
Epoch: 17/20...  Training Step: 10127...  Training loss: 1.7537...  0.0566 sec/batch
Epoch: 17/20...  Training Step: 10128...  Training loss: 1.7319...  0.0545 sec/batch
Epoch: 17/20...  Training Step: 10129...  Training loss: 1.7237...  0.0570 sec/batch
Epoch: 17/20...  Training Step: 10130...  Training loss: 1.7071...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 10131...  Training loss: 1.7423...  0.0582 sec/batch
Epoch: 17/20...  Training Step: 10132...  Training loss: 1.7458...  0.0527 sec/batch
Epoch: 17/20...  Training Step: 10133...  Training loss: 1.7320...  0.0590 sec/batch
Epoch: 17/20...  Training Step: 10134...  Training loss: 1.7579...  0.0528 sec/batch
Epoch: 17/20...  Training Step: 10135...  Training loss: 1.7626...  0.0528 sec/batch
Epoch: 17/20...  Training Step: 10136...  Training loss: 1.7594...  0.0576 sec/batch
Epoch: 17/20...  Training Step: 10137...  Training loss: 1.7340...  0.0539 sec/batch
Epoch: 17/20...  Training Step: 10138...  Training loss: 1.7178...  0.0570 sec/batch
Epoch: 17/20...  Training Step: 10139...  Training loss: 1.7934...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10140...  Training loss: 1.7665...  0.0551 sec/batch
Epoch: 17/20...  Training Step: 10141...  Training loss: 1.7490...  0.0558 sec/batch
Epoch: 17/20...  Training Step: 10142...  Training loss: 1.7634...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10143...  Training loss: 1.7766...  0.0530 sec/batch
Epoch: 17/20...  Training Step: 10144...  Training loss: 1.6801...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 10145...  Training loss: 1.7182...  0.0539 sec/batch
Epoch: 17/20...  Training Step: 10146...  Training loss: 1.7520...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10147...  Training loss: 1.7714...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 10148...  Training loss: 1.7203...  0.0566 sec/batch
Epoch: 17/20...  Training Step: 10149...  Training loss: 1.7518...  0.0552 sec/batch
Epoch: 17/20...  Training Step: 10150...  Training loss: 1.6991...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10151...  Training loss: 1.7955...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 10152...  Training loss: 1.6993...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10153...  Training loss: 1.7093...  0.0583 sec/batch
Epoch: 17/20...  Training Step: 10154...  Training loss: 1.6870...  0.0569 sec/batch
Epoch: 17/20...  Training Step: 10155...  Training loss: 1.6935...  0.0598 sec/batch
Epoch: 17/20...  Training Step: 10156...  Training loss: 1.7632...  0.0552 sec/batch
Epoch: 17/20...  Training Step: 10157...  Training loss: 1.7202...  0.0530 sec/batch
Epoch: 17/20...  Training Step: 10158...  Training loss: 1.6821...  0.0538 sec/batch
Epoch: 17/20...  Training Step: 10159...  Training loss: 1.7139...  0.0556 sec/batch
Epoch: 17/20...  Training Step: 10160...  Training loss: 1.7502...  0.0564 sec/batch
Epoch: 17/20...  Training Step: 10161...  Training loss: 1.6940...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10162...  Training loss: 1.6788...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10163...  Training loss: 1.6906...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10164...  Training loss: 1.7247...  0.0556 sec/batch
Epoch: 17/20...  Training Step: 10165...  Training loss: 1.7180...  0.0543 sec/batch
Epoch: 17/20...  Training Step: 10166...  Training loss: 1.7291...  0.0530 sec/batch
Epoch: 17/20...  Training Step: 10167...  Training loss: 1.7283...  0.0549 sec/batch
Epoch: 17/20...  Training Step: 10168...  Training loss: 1.7308...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10169...  Training loss: 1.6928...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10170...  Training loss: 1.6992...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10171...  Training loss: 1.7160...  0.0554 sec/batch
Epoch: 17/20...  Training Step: 10172...  Training loss: 1.6857...  0.0525 sec/batch
Epoch: 17/20...  Training Step: 10173...  Training loss: 1.7469...  0.0577 sec/batch
Epoch: 17/20...  Training Step: 10174...  Training loss: 1.7560...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10175...  Training loss: 1.8030...  0.0563 sec/batch
Epoch: 17/20...  Training Step: 10176...  Training loss: 1.7135...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10177...  Training loss: 1.7184...  0.0597 sec/batch
Epoch: 17/20...  Training Step: 10178...  Training loss: 1.7137...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10179...  Training loss: 1.7264...  0.0528 sec/batch
Epoch: 17/20...  Training Step: 10180...  Training loss: 1.7203...  0.0560 sec/batch
Epoch: 17/20...  Training Step: 10181...  Training loss: 1.7463...  0.0526 sec/batch
Epoch: 17/20...  Training Step: 10182...  Training loss: 1.7076...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10183...  Training loss: 1.7348...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10184...  Training loss: 1.7151...  0.0559 sec/batch
Epoch: 17/20...  Training Step: 10185...  Training loss: 1.7429...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 10186...  Training loss: 1.6754...  0.0552 sec/batch
Epoch: 17/20...  Training Step: 10187...  Training loss: 1.7138...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10188...  Training loss: 1.7354...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10189...  Training loss: 1.7207...  0.0580 sec/batch
Epoch: 17/20...  Training Step: 10190...  Training loss: 1.6947...  0.0557 sec/batch
Epoch: 17/20...  Training Step: 10191...  Training loss: 1.6857...  0.0598 sec/batch
Epoch: 17/20...  Training Step: 10192...  Training loss: 1.7224...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10193...  Training loss: 1.6973...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 10194...  Training loss: 1.7018...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10195...  Training loss: 1.7648...  0.0541 sec/batch
Epoch: 17/20...  Training Step: 10196...  Training loss: 1.7615...  0.0545 sec/batch
Epoch: 17/20...  Training Step: 10197...  Training loss: 1.8220...  0.0554 sec/batch
Epoch: 17/20...  Training Step: 10198...  Training loss: 1.7674...  0.0552 sec/batch
Epoch: 17/20...  Training Step: 10199...  Training loss: 1.7880...  0.0569 sec/batch
Epoch: 17/20...  Training Step: 10200...  Training loss: 1.7605...  0.0569 sec/batch
Epoch: 17/20...  Training Step: 10201...  Training loss: 1.7563...  0.0539 sec/batch
Epoch: 17/20...  Training Step: 10202...  Training loss: 1.6724...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10203...  Training loss: 1.6880...  0.0567 sec/batch
Epoch: 17/20...  Training Step: 10204...  Training loss: 1.7378...  0.0536 sec/batch
Epoch: 17/20...  Training Step: 10205...  Training loss: 1.7120...  0.0570 sec/batch
Epoch: 17/20...  Training Step: 10206...  Training loss: 1.7415...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10207...  Training loss: 1.7120...  0.0551 sec/batch
Epoch: 17/20...  Training Step: 10208...  Training loss: 1.7471...  0.0544 sec/batch
Epoch: 17/20...  Training Step: 10209...  Training loss: 1.7266...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 10210...  Training loss: 1.7672...  0.0576 sec/batch
Epoch: 17/20...  Training Step: 10211...  Training loss: 1.7136...  0.0581 sec/batch
Epoch: 17/20...  Training Step: 10212...  Training loss: 1.7030...  0.0543 sec/batch
Epoch: 17/20...  Training Step: 10213...  Training loss: 1.6861...  0.0569 sec/batch
Epoch: 17/20...  Training Step: 10214...  Training loss: 1.7417...  0.0524 sec/batch
Epoch: 17/20...  Training Step: 10215...  Training loss: 1.7024...  0.0585 sec/batch
Epoch: 17/20...  Training Step: 10216...  Training loss: 1.6571...  0.0559 sec/batch
Epoch: 17/20...  Training Step: 10217...  Training loss: 1.7513...  0.0555 sec/batch
Epoch: 17/20...  Training Step: 10218...  Training loss: 1.7975...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10219...  Training loss: 1.7492...  0.0526 sec/batch
Epoch: 17/20...  Training Step: 10220...  Training loss: 1.7125...  0.0554 sec/batch
Epoch: 17/20...  Training Step: 10221...  Training loss: 1.7585...  0.0527 sec/batch
Epoch: 17/20...  Training Step: 10222...  Training loss: 1.8006...  0.0559 sec/batch
Epoch: 17/20...  Training Step: 10223...  Training loss: 1.6761...  0.0597 sec/batch
Epoch: 17/20...  Training Step: 10224...  Training loss: 1.7574...  0.0536 sec/batch
Epoch: 17/20...  Training Step: 10225...  Training loss: 1.7203...  0.0557 sec/batch
Epoch: 17/20...  Training Step: 10226...  Training loss: 1.7101...  0.0557 sec/batch
Epoch: 17/20...  Training Step: 10227...  Training loss: 1.7162...  0.0560 sec/batch
Epoch: 17/20...  Training Step: 10228...  Training loss: 1.7288...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10229...  Training loss: 1.7094...  0.0578 sec/batch
Epoch: 17/20...  Training Step: 10230...  Training loss: 1.7057...  0.0568 sec/batch
Epoch: 17/20...  Training Step: 10231...  Training loss: 1.6853...  0.0544 sec/batch
Epoch: 17/20...  Training Step: 10232...  Training loss: 1.6734...  0.0552 sec/batch
Epoch: 17/20...  Training Step: 10233...  Training loss: 1.7139...  0.0527 sec/batch
Epoch: 17/20...  Training Step: 10234...  Training loss: 1.6668...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10235...  Training loss: 1.7432...  0.0574 sec/batch
Epoch: 17/20...  Training Step: 10236...  Training loss: 1.7588...  0.0554 sec/batch
Epoch: 17/20...  Training Step: 10237...  Training loss: 1.6892...  0.0564 sec/batch
Epoch: 17/20...  Training Step: 10238...  Training loss: 1.6636...  0.0541 sec/batch
Epoch: 17/20...  Training Step: 10239...  Training loss: 1.6902...  0.0576 sec/batch
Epoch: 17/20...  Training Step: 10240...  Training loss: 1.7672...  0.0582 sec/batch
Epoch: 17/20...  Training Step: 10241...  Training loss: 1.7382...  0.0560 sec/batch
Epoch: 17/20...  Training Step: 10242...  Training loss: 1.6690...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 10243...  Training loss: 1.7270...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10244...  Training loss: 1.7256...  0.0523 sec/batch
Epoch: 17/20...  Training Step: 10245...  Training loss: 1.6976...  0.0563 sec/batch
Epoch: 17/20...  Training Step: 10246...  Training loss: 1.7076...  0.0526 sec/batch
Epoch: 17/20...  Training Step: 10247...  Training loss: 1.6708...  0.0531 sec/batch
Epoch: 17/20...  Training Step: 10248...  Training loss: 1.6769...  0.0543 sec/batch
Epoch: 17/20...  Training Step: 10249...  Training loss: 1.7255...  0.0531 sec/batch
Epoch: 17/20...  Training Step: 10250...  Training loss: 1.6986...  0.0525 sec/batch
Epoch: 17/20...  Training Step: 10251...  Training loss: 1.7000...  0.0527 sec/batch
Epoch: 17/20...  Training Step: 10252...  Training loss: 1.7089...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 10253...  Training loss: 1.7064...  0.0525 sec/batch
Epoch: 17/20...  Training Step: 10254...  Training loss: 1.7106...  0.0536 sec/batch
Epoch: 17/20...  Training Step: 10255...  Training loss: 1.7228...  0.0576 sec/batch
Epoch: 17/20...  Training Step: 10256...  Training loss: 1.7115...  0.0567 sec/batch
Epoch: 17/20...  Training Step: 10257...  Training loss: 1.6956...  0.0561 sec/batch
Epoch: 17/20...  Training Step: 10258...  Training loss: 1.7036...  0.0554 sec/batch
Epoch: 17/20...  Training Step: 10259...  Training loss: 1.6985...  0.0560 sec/batch
Epoch: 17/20...  Training Step: 10260...  Training loss: 1.7004...  0.0528 sec/batch
Epoch: 17/20...  Training Step: 10261...  Training loss: 1.7437...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10262...  Training loss: 1.7297...  0.0563 sec/batch
Epoch: 17/20...  Training Step: 10263...  Training loss: 1.6895...  0.0538 sec/batch
Epoch: 17/20...  Training Step: 10264...  Training loss: 1.6970...  0.0531 sec/batch
Epoch: 17/20...  Training Step: 10265...  Training loss: 1.7320...  0.0557 sec/batch
Epoch: 17/20...  Training Step: 10266...  Training loss: 1.7233...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10267...  Training loss: 1.7263...  0.0583 sec/batch
Epoch: 17/20...  Training Step: 10268...  Training loss: 1.7383...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 10269...  Training loss: 1.7194...  0.0530 sec/batch
Epoch: 17/20...  Training Step: 10270...  Training loss: 1.7104...  0.0568 sec/batch
Epoch: 17/20...  Training Step: 10271...  Training loss: 1.7502...  0.0576 sec/batch
Epoch: 17/20...  Training Step: 10272...  Training loss: 1.7470...  0.0540 sec/batch
Epoch: 17/20...  Training Step: 10273...  Training loss: 1.7330...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 10274...  Training loss: 1.7079...  0.0581 sec/batch
Epoch: 17/20...  Training Step: 10275...  Training loss: 1.7047...  0.0543 sec/batch
Epoch: 17/20...  Training Step: 10276...  Training loss: 1.7721...  0.0585 sec/batch
Epoch: 17/20...  Training Step: 10277...  Training loss: 1.8243...  0.0608 sec/batch
Epoch: 17/20...  Training Step: 10278...  Training loss: 1.7757...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 10279...  Training loss: 1.7338...  0.0552 sec/batch
Epoch: 17/20...  Training Step: 10280...  Training loss: 1.7267...  0.0525 sec/batch
Epoch: 17/20...  Training Step: 10281...  Training loss: 1.7687...  0.0530 sec/batch
Epoch: 17/20...  Training Step: 10282...  Training loss: 1.7063...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10283...  Training loss: 1.6878...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10284...  Training loss: 1.6804...  0.0523 sec/batch
Epoch: 17/20...  Training Step: 10285...  Training loss: 1.7107...  0.0536 sec/batch
Epoch: 17/20...  Training Step: 10286...  Training loss: 1.7375...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10287...  Training loss: 1.7063...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10288...  Training loss: 1.7689...  0.0582 sec/batch
Epoch: 17/20...  Training Step: 10289...  Training loss: 1.7611...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10290...  Training loss: 1.7442...  0.0549 sec/batch
Epoch: 17/20...  Training Step: 10291...  Training loss: 1.7210...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10292...  Training loss: 1.7998...  0.0537 sec/batch
Epoch: 17/20...  Training Step: 10293...  Training loss: 1.7361...  0.0526 sec/batch
Epoch: 17/20...  Training Step: 10294...  Training loss: 1.7366...  0.0617 sec/batch
Epoch: 17/20...  Training Step: 10295...  Training loss: 1.7041...  0.0527 sec/batch
Epoch: 17/20...  Training Step: 10296...  Training loss: 1.7255...  0.0545 sec/batch
Epoch: 17/20...  Training Step: 10297...  Training loss: 1.7026...  0.0537 sec/batch
Epoch: 17/20...  Training Step: 10298...  Training loss: 1.7882...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10299...  Training loss: 1.7408...  0.0579 sec/batch
Epoch: 17/20...  Training Step: 10300...  Training loss: 1.7189...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10301...  Training loss: 1.6717...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10302...  Training loss: 1.7780...  0.0572 sec/batch
Epoch: 17/20...  Training Step: 10303...  Training loss: 1.7135...  0.0603 sec/batch
Epoch: 17/20...  Training Step: 10304...  Training loss: 1.7218...  0.0572 sec/batch
Epoch: 17/20...  Training Step: 10305...  Training loss: 1.7528...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10306...  Training loss: 1.6434...  0.0539 sec/batch
Epoch: 17/20...  Training Step: 10307...  Training loss: 1.6493...  0.0524 sec/batch
Epoch: 17/20...  Training Step: 10308...  Training loss: 1.7317...  0.0527 sec/batch
Epoch: 17/20...  Training Step: 10309...  Training loss: 1.6822...  0.0549 sec/batch
Epoch: 17/20...  Training Step: 10310...  Training loss: 1.7070...  0.0549 sec/batch
Epoch: 17/20...  Training Step: 10311...  Training loss: 1.7558...  0.0551 sec/batch
Epoch: 17/20...  Training Step: 10312...  Training loss: 1.6693...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10313...  Training loss: 1.7061...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 10314...  Training loss: 1.7506...  0.0541 sec/batch
Epoch: 17/20...  Training Step: 10315...  Training loss: 1.6871...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 10316...  Training loss: 1.7492...  0.0556 sec/batch
Epoch: 17/20...  Training Step: 10317...  Training loss: 1.6988...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10318...  Training loss: 1.7134...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10319...  Training loss: 1.6853...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10320...  Training loss: 1.7309...  0.0524 sec/batch
Epoch: 17/20...  Training Step: 10321...  Training loss: 1.7849...  0.0555 sec/batch
Epoch: 17/20...  Training Step: 10322...  Training loss: 1.7408...  0.0528 sec/batch
Epoch: 17/20...  Training Step: 10323...  Training loss: 1.6966...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10324...  Training loss: 1.7530...  0.0528 sec/batch
Epoch: 17/20...  Training Step: 10325...  Training loss: 1.7841...  0.0538 sec/batch
Epoch: 17/20...  Training Step: 10326...  Training loss: 1.7709...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 10327...  Training loss: 1.7557...  0.0526 sec/batch
Epoch: 17/20...  Training Step: 10328...  Training loss: 1.7284...  0.0536 sec/batch
Epoch: 17/20...  Training Step: 10329...  Training loss: 1.7859...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 10330...  Training loss: 1.7792...  0.0589 sec/batch
Epoch: 17/20...  Training Step: 10331...  Training loss: 1.7015...  0.0588 sec/batch
Epoch: 17/20...  Training Step: 10332...  Training loss: 1.7401...  0.0527 sec/batch
Epoch: 17/20...  Training Step: 10333...  Training loss: 1.7603...  0.0543 sec/batch
Epoch: 17/20...  Training Step: 10334...  Training loss: 1.7281...  0.0527 sec/batch
Epoch: 17/20...  Training Step: 10335...  Training loss: 1.7098...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10336...  Training loss: 1.6823...  0.0569 sec/batch
Epoch: 17/20...  Training Step: 10337...  Training loss: 1.7104...  0.0537 sec/batch
Epoch: 17/20...  Training Step: 10338...  Training loss: 1.7358...  0.0540 sec/batch
Epoch: 17/20...  Training Step: 10339...  Training loss: 1.7723...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10340...  Training loss: 1.7235...  0.0531 sec/batch
Epoch: 17/20...  Training Step: 10341...  Training loss: 1.6996...  0.0561 sec/batch
Epoch: 17/20...  Training Step: 10342...  Training loss: 1.7161...  0.0587 sec/batch
Epoch: 17/20...  Training Step: 10343...  Training loss: 1.7376...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10344...  Training loss: 1.6832...  0.0540 sec/batch
Epoch: 17/20...  Training Step: 10345...  Training loss: 1.7365...  0.0566 sec/batch
Epoch: 17/20...  Training Step: 10346...  Training loss: 1.7529...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 10347...  Training loss: 1.7013...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10348...  Training loss: 1.7701...  0.0539 sec/batch
Epoch: 17/20...  Training Step: 10349...  Training loss: 1.7031...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 10350...  Training loss: 1.6721...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10351...  Training loss: 1.7107...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10352...  Training loss: 1.7570...  0.0541 sec/batch
Epoch: 17/20...  Training Step: 10353...  Training loss: 1.7387...  0.0526 sec/batch
Epoch: 17/20...  Training Step: 10354...  Training loss: 1.7124...  0.0552 sec/batch
Epoch: 17/20...  Training Step: 10355...  Training loss: 1.6848...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10356...  Training loss: 1.7185...  0.0552 sec/batch
Epoch: 17/20...  Training Step: 10357...  Training loss: 1.6802...  0.0567 sec/batch
Epoch: 17/20...  Training Step: 10358...  Training loss: 1.7197...  0.0543 sec/batch
Epoch: 17/20...  Training Step: 10359...  Training loss: 1.7234...  0.0581 sec/batch
Epoch: 17/20...  Training Step: 10360...  Training loss: 1.7165...  0.0570 sec/batch
Epoch: 17/20...  Training Step: 10361...  Training loss: 1.7054...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 10362...  Training loss: 1.7174...  0.0557 sec/batch
Epoch: 17/20...  Training Step: 10363...  Training loss: 1.7526...  0.0531 sec/batch
Epoch: 17/20...  Training Step: 10364...  Training loss: 1.7280...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 10365...  Training loss: 1.6205...  0.0551 sec/batch
Epoch: 17/20...  Training Step: 10366...  Training loss: 1.7152...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10367...  Training loss: 1.6905...  0.0582 sec/batch
Epoch: 17/20...  Training Step: 10368...  Training loss: 1.6828...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 10369...  Training loss: 1.7126...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 10370...  Training loss: 1.7710...  0.0551 sec/batch
Epoch: 17/20...  Training Step: 10371...  Training loss: 1.7578...  0.0523 sec/batch
Epoch: 17/20...  Training Step: 10372...  Training loss: 1.7541...  0.0549 sec/batch
Epoch: 17/20...  Training Step: 10373...  Training loss: 1.6814...  0.0554 sec/batch
Epoch: 17/20...  Training Step: 10374...  Training loss: 1.7255...  0.0578 sec/batch
Epoch: 17/20...  Training Step: 10375...  Training loss: 1.6918...  0.0560 sec/batch
Epoch: 17/20...  Training Step: 10376...  Training loss: 1.7175...  0.0601 sec/batch
Epoch: 17/20...  Training Step: 10377...  Training loss: 1.7234...  0.0540 sec/batch
Epoch: 17/20...  Training Step: 10378...  Training loss: 1.7147...  0.0549 sec/batch
Epoch: 17/20...  Training Step: 10379...  Training loss: 1.7077...  0.0563 sec/batch
Epoch: 17/20...  Training Step: 10380...  Training loss: 1.7242...  0.0583 sec/batch
Epoch: 17/20...  Training Step: 10381...  Training loss: 1.6752...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10382...  Training loss: 1.7298...  0.0570 sec/batch
Epoch: 17/20...  Training Step: 10383...  Training loss: 1.6751...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10384...  Training loss: 1.7226...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10385...  Training loss: 1.7529...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10386...  Training loss: 1.7423...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 10387...  Training loss: 1.7022...  0.0576 sec/batch
Epoch: 17/20...  Training Step: 10388...  Training loss: 1.7290...  0.0541 sec/batch
Epoch: 17/20...  Training Step: 10389...  Training loss: 1.7298...  0.0559 sec/batch
Epoch: 17/20...  Training Step: 10390...  Training loss: 1.7219...  0.0593 sec/batch
Epoch: 17/20...  Training Step: 10391...  Training loss: 1.7289...  0.0556 sec/batch
Epoch: 17/20...  Training Step: 10392...  Training loss: 1.7589...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10393...  Training loss: 1.7108...  0.0562 sec/batch
Epoch: 17/20...  Training Step: 10394...  Training loss: 1.6749...  0.0568 sec/batch
Epoch: 17/20...  Training Step: 10395...  Training loss: 1.7905...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 10396...  Training loss: 1.7567...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 10397...  Training loss: 1.7143...  0.0571 sec/batch
Epoch: 17/20...  Training Step: 10398...  Training loss: 1.7926...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 10399...  Training loss: 1.7014...  0.0578 sec/batch
Epoch: 17/20...  Training Step: 10400...  Training loss: 1.7964...  0.0542 sec/batch
Epoch: 17/20...  Training Step: 10401...  Training loss: 1.7336...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 10402...  Training loss: 1.6963...  0.0545 sec/batch
Epoch: 17/20...  Training Step: 10403...  Training loss: 1.7343...  0.0543 sec/batch
Epoch: 17/20...  Training Step: 10404...  Training loss: 1.7439...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10405...  Training loss: 1.8127...  0.0527 sec/batch
Epoch: 17/20...  Training Step: 10406...  Training loss: 1.7137...  0.0551 sec/batch
Epoch: 17/20...  Training Step: 10407...  Training loss: 1.7266...  0.0609 sec/batch
Epoch: 17/20...  Training Step: 10408...  Training loss: 1.7369...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10409...  Training loss: 1.7517...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10410...  Training loss: 1.7221...  0.0536 sec/batch
Epoch: 17/20...  Training Step: 10411...  Training loss: 1.7148...  0.0566 sec/batch
Epoch: 17/20...  Training Step: 10412...  Training loss: 1.7330...  0.0569 sec/batch
Epoch: 17/20...  Training Step: 10413...  Training loss: 1.7441...  0.0578 sec/batch
Epoch: 17/20...  Training Step: 10414...  Training loss: 1.7111...  0.0581 sec/batch
Epoch: 17/20...  Training Step: 10415...  Training loss: 1.6931...  0.0565 sec/batch
Epoch: 17/20...  Training Step: 10416...  Training loss: 1.7181...  0.0589 sec/batch
Epoch: 17/20...  Training Step: 10417...  Training loss: 1.7212...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10418...  Training loss: 1.7672...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10419...  Training loss: 1.6645...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10420...  Training loss: 1.7378...  0.0540 sec/batch
Epoch: 17/20...  Training Step: 10421...  Training loss: 1.7275...  0.0558 sec/batch
Epoch: 17/20...  Training Step: 10422...  Training loss: 1.7448...  0.0557 sec/batch
Epoch: 17/20...  Training Step: 10423...  Training loss: 1.8072...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10424...  Training loss: 1.7245...  0.0557 sec/batch
Epoch: 17/20...  Training Step: 10425...  Training loss: 1.6956...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 10426...  Training loss: 1.6704...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10427...  Training loss: 1.7676...  0.0556 sec/batch
Epoch: 17/20...  Training Step: 10428...  Training loss: 1.7130...  0.0579 sec/batch
Epoch: 17/20...  Training Step: 10429...  Training loss: 1.7421...  0.0530 sec/batch
Epoch: 17/20...  Training Step: 10430...  Training loss: 1.7524...  0.0554 sec/batch
Epoch: 17/20...  Training Step: 10431...  Training loss: 1.7791...  0.0536 sec/batch
Epoch: 17/20...  Training Step: 10432...  Training loss: 1.7640...  0.0530 sec/batch
Epoch: 17/20...  Training Step: 10433...  Training loss: 1.7615...  0.0605 sec/batch
Epoch: 17/20...  Training Step: 10434...  Training loss: 1.7841...  0.0544 sec/batch
Epoch: 17/20...  Training Step: 10435...  Training loss: 1.7347...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10436...  Training loss: 1.7245...  0.0554 sec/batch
Epoch: 17/20...  Training Step: 10437...  Training loss: 1.7061...  0.0566 sec/batch
Epoch: 17/20...  Training Step: 10438...  Training loss: 1.7056...  0.0558 sec/batch
Epoch: 17/20...  Training Step: 10439...  Training loss: 1.7100...  0.0541 sec/batch
Epoch: 17/20...  Training Step: 10440...  Training loss: 1.7180...  0.0536 sec/batch
Epoch: 17/20...  Training Step: 10441...  Training loss: 1.7152...  0.0540 sec/batch
Epoch: 17/20...  Training Step: 10442...  Training loss: 1.6736...  0.0552 sec/batch
Epoch: 17/20...  Training Step: 10443...  Training loss: 1.7058...  0.0593 sec/batch
Epoch: 17/20...  Training Step: 10444...  Training loss: 1.6655...  0.0540 sec/batch
Epoch: 17/20...  Training Step: 10445...  Training loss: 1.7413...  0.0552 sec/batch
Epoch: 17/20...  Training Step: 10446...  Training loss: 1.7752...  0.0544 sec/batch
Epoch: 17/20...  Training Step: 10447...  Training loss: 1.7530...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10448...  Training loss: 1.7423...  0.0525 sec/batch
Epoch: 17/20...  Training Step: 10449...  Training loss: 1.7248...  0.0582 sec/batch
Epoch: 17/20...  Training Step: 10450...  Training loss: 1.7011...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10451...  Training loss: 1.6968...  0.0581 sec/batch
Epoch: 17/20...  Training Step: 10452...  Training loss: 1.7196...  0.0547 sec/batch
Epoch: 17/20...  Training Step: 10453...  Training loss: 1.7108...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10454...  Training loss: 1.7130...  0.0554 sec/batch
Epoch: 17/20...  Training Step: 10455...  Training loss: 1.7556...  0.0559 sec/batch
Epoch: 17/20...  Training Step: 10456...  Training loss: 1.7254...  0.0563 sec/batch
Epoch: 17/20...  Training Step: 10457...  Training loss: 1.6892...  0.0563 sec/batch
Epoch: 17/20...  Training Step: 10458...  Training loss: 1.7099...  0.0556 sec/batch
Epoch: 17/20...  Training Step: 10459...  Training loss: 1.6340...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10460...  Training loss: 1.7256...  0.0538 sec/batch
Epoch: 17/20...  Training Step: 10461...  Training loss: 1.7285...  0.0560 sec/batch
Epoch: 17/20...  Training Step: 10462...  Training loss: 1.6967...  0.0556 sec/batch
Epoch: 17/20...  Training Step: 10463...  Training loss: 1.7043...  0.0586 sec/batch
Epoch: 17/20...  Training Step: 10464...  Training loss: 1.6918...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10465...  Training loss: 1.7638...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10466...  Training loss: 1.7282...  0.0590 sec/batch
Epoch: 17/20...  Training Step: 10467...  Training loss: 1.7466...  0.0586 sec/batch
Epoch: 17/20...  Training Step: 10468...  Training loss: 1.7726...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10469...  Training loss: 1.7500...  0.0558 sec/batch
Epoch: 17/20...  Training Step: 10470...  Training loss: 1.7013...  0.0557 sec/batch
Epoch: 17/20...  Training Step: 10471...  Training loss: 1.7493...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10472...  Training loss: 1.6713...  0.0552 sec/batch
Epoch: 17/20...  Training Step: 10473...  Training loss: 1.7307...  0.0549 sec/batch
Epoch: 17/20...  Training Step: 10474...  Training loss: 1.7321...  0.0563 sec/batch
Epoch: 17/20...  Training Step: 10475...  Training loss: 1.7038...  0.0552 sec/batch
Epoch: 17/20...  Training Step: 10476...  Training loss: 1.7330...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10477...  Training loss: 1.7127...  0.0525 sec/batch
Epoch: 17/20...  Training Step: 10478...  Training loss: 1.6624...  0.0546 sec/batch
Epoch: 17/20...  Training Step: 10479...  Training loss: 1.7224...  0.0595 sec/batch
Epoch: 17/20...  Training Step: 10480...  Training loss: 1.7032...  0.0581 sec/batch
Epoch: 17/20...  Training Step: 10481...  Training loss: 1.7812...  0.0550 sec/batch
Epoch: 17/20...  Training Step: 10482...  Training loss: 1.7416...  0.0551 sec/batch
Epoch: 17/20...  Training Step: 10483...  Training loss: 1.7249...  0.0579 sec/batch
Epoch: 17/20...  Training Step: 10484...  Training loss: 1.7829...  0.0558 sec/batch
Epoch: 17/20...  Training Step: 10485...  Training loss: 1.8207...  0.0534 sec/batch
Epoch: 17/20...  Training Step: 10486...  Training loss: 1.7875...  0.0528 sec/batch
Epoch: 17/20...  Training Step: 10487...  Training loss: 1.7471...  0.0537 sec/batch
Epoch: 17/20...  Training Step: 10488...  Training loss: 1.7867...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10489...  Training loss: 1.7107...  0.0591 sec/batch
Epoch: 17/20...  Training Step: 10490...  Training loss: 1.7409...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10491...  Training loss: 1.7446...  0.0525 sec/batch
Epoch: 17/20...  Training Step: 10492...  Training loss: 1.7684...  0.0587 sec/batch
Epoch: 17/20...  Training Step: 10493...  Training loss: 1.7481...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10494...  Training loss: 1.7134...  0.0555 sec/batch
Epoch: 17/20...  Training Step: 10495...  Training loss: 1.7283...  0.0557 sec/batch
Epoch: 17/20...  Training Step: 10496...  Training loss: 1.7451...  0.0554 sec/batch
Epoch: 17/20...  Training Step: 10497...  Training loss: 1.6927...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10498...  Training loss: 1.7627...  0.0527 sec/batch
Epoch: 17/20...  Training Step: 10499...  Training loss: 1.7660...  0.0553 sec/batch
Epoch: 17/20...  Training Step: 10500...  Training loss: 1.7503...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10501...  Training loss: 1.7844...  0.0562 sec/batch
Epoch: 17/20...  Training Step: 10502...  Training loss: 1.7503...  0.0541 sec/batch
Epoch: 17/20...  Training Step: 10503...  Training loss: 1.7259...  0.0549 sec/batch
Epoch: 17/20...  Training Step: 10504...  Training loss: 1.7773...  0.0527 sec/batch
Epoch: 17/20...  Training Step: 10505...  Training loss: 1.7587...  0.0544 sec/batch
Epoch: 17/20...  Training Step: 10506...  Training loss: 1.7235...  0.0551 sec/batch
Epoch: 17/20...  Training Step: 10507...  Training loss: 1.6964...  0.0595 sec/batch
Epoch: 17/20...  Training Step: 10508...  Training loss: 1.7290...  0.0589 sec/batch
Epoch: 17/20...  Training Step: 10509...  Training loss: 1.7104...  0.0585 sec/batch
Epoch: 17/20...  Training Step: 10510...  Training loss: 1.7624...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 10511...  Training loss: 1.6898...  0.0554 sec/batch
Epoch: 17/20...  Training Step: 10512...  Training loss: 1.7805...  0.0589 sec/batch
Epoch: 17/20...  Training Step: 10513...  Training loss: 1.7302...  0.0529 sec/batch
Epoch: 17/20...  Training Step: 10514...  Training loss: 1.6689...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 10515...  Training loss: 1.7038...  0.0526 sec/batch
Epoch: 17/20...  Training Step: 10516...  Training loss: 1.6926...  0.0581 sec/batch
Epoch: 17/20...  Training Step: 10517...  Training loss: 1.6858...  0.0568 sec/batch
Epoch: 17/20...  Training Step: 10518...  Training loss: 1.7299...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10519...  Training loss: 1.7440...  0.0532 sec/batch
Epoch: 17/20...  Training Step: 10520...  Training loss: 1.7565...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10521...  Training loss: 1.7105...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 10522...  Training loss: 1.7276...  0.0533 sec/batch
Epoch: 17/20...  Training Step: 10523...  Training loss: 1.7202...  0.0569 sec/batch
Epoch: 17/20...  Training Step: 10524...  Training loss: 1.6985...  0.0526 sec/batch
Epoch: 17/20...  Training Step: 10525...  Training loss: 1.7237...  0.0565 sec/batch
Epoch: 17/20...  Training Step: 10526...  Training loss: 1.7201...  0.0556 sec/batch
Epoch: 17/20...  Training Step: 10527...  Training loss: 1.6728...  0.0525 sec/batch
Epoch: 17/20...  Training Step: 10528...  Training loss: 1.7001...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 10529...  Training loss: 1.7181...  0.0570 sec/batch
Epoch: 17/20...  Training Step: 10530...  Training loss: 1.7783...  0.0568 sec/batch
Epoch: 17/20...  Training Step: 10531...  Training loss: 1.7796...  0.0531 sec/batch
Epoch: 17/20...  Training Step: 10532...  Training loss: 1.7371...  0.0537 sec/batch
Epoch: 17/20...  Training Step: 10533...  Training loss: 1.6673...  0.0535 sec/batch
Epoch: 17/20...  Training Step: 10534...  Training loss: 1.7375...  0.0580 sec/batch
Epoch: 17/20...  Training Step: 10535...  Training loss: 1.6808...  0.0577 sec/batch
Epoch: 17/20...  Training Step: 10536...  Training loss: 1.7435...  0.0580 sec/batch
Epoch: 17/20...  Training Step: 10537...  Training loss: 1.7642...  0.0538 sec/batch
Epoch: 17/20...  Training Step: 10538...  Training loss: 1.6926...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 10539...  Training loss: 1.6802...  0.0548 sec/batch
Epoch: 17/20...  Training Step: 10540...  Training loss: 1.6849...  0.0526 sec/batch
Epoch: 18/20...  Training Step: 10541...  Training loss: 1.8147...  0.0572 sec/batch
Epoch: 18/20...  Training Step: 10542...  Training loss: 1.7914...  0.0523 sec/batch
Epoch: 18/20...  Training Step: 10543...  Training loss: 1.7674...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 10544...  Training loss: 1.7088...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 10545...  Training loss: 1.7372...  0.0557 sec/batch
Epoch: 18/20...  Training Step: 10546...  Training loss: 1.7487...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10547...  Training loss: 1.6874...  0.0534 sec/batch
Epoch: 18/20...  Training Step: 10548...  Training loss: 1.6916...  0.0544 sec/batch
Epoch: 18/20...  Training Step: 10549...  Training loss: 1.6610...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 10550...  Training loss: 1.7013...  0.0554 sec/batch
Epoch: 18/20...  Training Step: 10551...  Training loss: 1.7100...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 10552...  Training loss: 1.6651...  0.0617 sec/batch
Epoch: 18/20...  Training Step: 10553...  Training loss: 1.7246...  0.0552 sec/batch
Epoch: 18/20...  Training Step: 10554...  Training loss: 1.6884...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 10555...  Training loss: 1.7389...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 10556...  Training loss: 1.7608...  0.0543 sec/batch
Epoch: 18/20...  Training Step: 10557...  Training loss: 1.7504...  0.0592 sec/batch
Epoch: 18/20...  Training Step: 10558...  Training loss: 1.7170...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10559...  Training loss: 1.6945...  0.0535 sec/batch
Epoch: 18/20...  Training Step: 10560...  Training loss: 1.7449...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 10561...  Training loss: 1.7863...  0.0564 sec/batch
Epoch: 18/20...  Training Step: 10562...  Training loss: 1.7231...  0.0554 sec/batch
Epoch: 18/20...  Training Step: 10563...  Training loss: 1.7027...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 10564...  Training loss: 1.7216...  0.0575 sec/batch
Epoch: 18/20...  Training Step: 10565...  Training loss: 1.7116...  0.0559 sec/batch
Epoch: 18/20...  Training Step: 10566...  Training loss: 1.6562...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 10567...  Training loss: 1.7021...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10568...  Training loss: 1.7149...  0.0578 sec/batch
Epoch: 18/20...  Training Step: 10569...  Training loss: 1.7322...  0.0537 sec/batch
Epoch: 18/20...  Training Step: 10570...  Training loss: 1.6921...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 10571...  Training loss: 1.6868...  0.0565 sec/batch
Epoch: 18/20...  Training Step: 10572...  Training loss: 1.7524...  0.0552 sec/batch
Epoch: 18/20...  Training Step: 10573...  Training loss: 1.7230...  0.0533 sec/batch
Epoch: 18/20...  Training Step: 10574...  Training loss: 1.7129...  0.0552 sec/batch
Epoch: 18/20...  Training Step: 10575...  Training loss: 1.6870...  0.0536 sec/batch
Epoch: 18/20...  Training Step: 10576...  Training loss: 1.6966...  0.0532 sec/batch
Epoch: 18/20...  Training Step: 10577...  Training loss: 1.7236...  0.0532 sec/batch
Epoch: 18/20...  Training Step: 10578...  Training loss: 1.7440...  0.0522 sec/batch
Epoch: 18/20...  Training Step: 10579...  Training loss: 1.7482...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10580...  Training loss: 1.6990...  0.0577 sec/batch
Epoch: 18/20...  Training Step: 10581...  Training loss: 1.7215...  0.0533 sec/batch
Epoch: 18/20...  Training Step: 10582...  Training loss: 1.7517...  0.0583 sec/batch
Epoch: 18/20...  Training Step: 10583...  Training loss: 1.7305...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 10584...  Training loss: 1.7432...  0.0571 sec/batch
Epoch: 18/20...  Training Step: 10585...  Training loss: 1.6847...  0.0534 sec/batch
Epoch: 18/20...  Training Step: 10586...  Training loss: 1.7017...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 10587...  Training loss: 1.5982...  0.0581 sec/batch
Epoch: 18/20...  Training Step: 10588...  Training loss: 1.7170...  0.0603 sec/batch
Epoch: 18/20...  Training Step: 10589...  Training loss: 1.6582...  0.0578 sec/batch
Epoch: 18/20...  Training Step: 10590...  Training loss: 1.7269...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 10591...  Training loss: 1.6763...  0.0567 sec/batch
Epoch: 18/20...  Training Step: 10592...  Training loss: 1.6865...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 10593...  Training loss: 1.7124...  0.0536 sec/batch
Epoch: 18/20...  Training Step: 10594...  Training loss: 1.7260...  0.0557 sec/batch
Epoch: 18/20...  Training Step: 10595...  Training loss: 1.7436...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10596...  Training loss: 1.7170...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 10597...  Training loss: 1.6949...  0.0574 sec/batch
Epoch: 18/20...  Training Step: 10598...  Training loss: 1.6992...  0.0580 sec/batch
Epoch: 18/20...  Training Step: 10599...  Training loss: 1.7012...  0.0544 sec/batch
Epoch: 18/20...  Training Step: 10600...  Training loss: 1.7530...  0.0554 sec/batch
Epoch: 18/20...  Training Step: 10601...  Training loss: 1.7206...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 10602...  Training loss: 1.6910...  0.0552 sec/batch
Epoch: 18/20...  Training Step: 10603...  Training loss: 1.7461...  0.0591 sec/batch
Epoch: 18/20...  Training Step: 10604...  Training loss: 1.7083...  0.0538 sec/batch
Epoch: 18/20...  Training Step: 10605...  Training loss: 1.6706...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10606...  Training loss: 1.6594...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 10607...  Training loss: 1.6952...  0.0618 sec/batch
Epoch: 18/20...  Training Step: 10608...  Training loss: 1.7120...  0.0581 sec/batch
Epoch: 18/20...  Training Step: 10609...  Training loss: 1.7071...  0.0552 sec/batch
Epoch: 18/20...  Training Step: 10610...  Training loss: 1.7314...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 10611...  Training loss: 1.7858...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 10612...  Training loss: 1.7418...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10613...  Training loss: 1.6439...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10614...  Training loss: 1.7075...  0.0559 sec/batch
Epoch: 18/20...  Training Step: 10615...  Training loss: 1.7519...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 10616...  Training loss: 1.7478...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 10617...  Training loss: 1.7221...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 10618...  Training loss: 1.6905...  0.0545 sec/batch
Epoch: 18/20...  Training Step: 10619...  Training loss: 1.7219...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10620...  Training loss: 1.7576...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 10621...  Training loss: 1.6663...  0.0546 sec/batch
Epoch: 18/20...  Training Step: 10622...  Training loss: 1.7027...  0.0526 sec/batch
Epoch: 18/20...  Training Step: 10623...  Training loss: 1.6923...  0.0543 sec/batch
Epoch: 18/20...  Training Step: 10624...  Training loss: 1.6906...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 10625...  Training loss: 1.6894...  0.0564 sec/batch
Epoch: 18/20...  Training Step: 10626...  Training loss: 1.7638...  0.0580 sec/batch
Epoch: 18/20...  Training Step: 10627...  Training loss: 1.6745...  0.0521 sec/batch
Epoch: 18/20...  Training Step: 10628...  Training loss: 1.7465...  0.0560 sec/batch
Epoch: 18/20...  Training Step: 10629...  Training loss: 1.6958...  0.0589 sec/batch
Epoch: 18/20...  Training Step: 10630...  Training loss: 1.7131...  0.0523 sec/batch
Epoch: 18/20...  Training Step: 10631...  Training loss: 1.6972...  0.0555 sec/batch
Epoch: 18/20...  Training Step: 10632...  Training loss: 1.7703...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 10633...  Training loss: 1.7048...  0.0543 sec/batch
Epoch: 18/20...  Training Step: 10634...  Training loss: 1.7216...  0.0583 sec/batch
Epoch: 18/20...  Training Step: 10635...  Training loss: 1.7088...  0.0534 sec/batch
Epoch: 18/20...  Training Step: 10636...  Training loss: 1.7580...  0.0578 sec/batch
Epoch: 18/20...  Training Step: 10637...  Training loss: 1.7397...  0.0555 sec/batch
Epoch: 18/20...  Training Step: 10638...  Training loss: 1.6657...  0.0534 sec/batch
Epoch: 18/20...  Training Step: 10639...  Training loss: 1.7452...  0.0570 sec/batch
Epoch: 18/20...  Training Step: 10640...  Training loss: 1.7092...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10641...  Training loss: 1.6888...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 10642...  Training loss: 1.6646...  0.0546 sec/batch
Epoch: 18/20...  Training Step: 10643...  Training loss: 1.7259...  0.0552 sec/batch
Epoch: 18/20...  Training Step: 10644...  Training loss: 1.7650...  0.0561 sec/batch
Epoch: 18/20...  Training Step: 10645...  Training loss: 1.7266...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10646...  Training loss: 1.6838...  0.0542 sec/batch
Epoch: 18/20...  Training Step: 10647...  Training loss: 1.7453...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10648...  Training loss: 1.7321...  0.0543 sec/batch
Epoch: 18/20...  Training Step: 10649...  Training loss: 1.7137...  0.0544 sec/batch
Epoch: 18/20...  Training Step: 10650...  Training loss: 1.6754...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10651...  Training loss: 1.6562...  0.0569 sec/batch
Epoch: 18/20...  Training Step: 10652...  Training loss: 1.6809...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10653...  Training loss: 1.7067...  0.0526 sec/batch
Epoch: 18/20...  Training Step: 10654...  Training loss: 1.6849...  0.0543 sec/batch
Epoch: 18/20...  Training Step: 10655...  Training loss: 1.7323...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10656...  Training loss: 1.7433...  0.0542 sec/batch
Epoch: 18/20...  Training Step: 10657...  Training loss: 1.6892...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 10658...  Training loss: 1.7560...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10659...  Training loss: 1.7029...  0.0521 sec/batch
Epoch: 18/20...  Training Step: 10660...  Training loss: 1.7112...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10661...  Training loss: 1.6776...  0.0534 sec/batch
Epoch: 18/20...  Training Step: 10662...  Training loss: 1.6720...  0.0565 sec/batch
Epoch: 18/20...  Training Step: 10663...  Training loss: 1.7134...  0.0578 sec/batch
Epoch: 18/20...  Training Step: 10664...  Training loss: 1.7401...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 10665...  Training loss: 1.7337...  0.0591 sec/batch
Epoch: 18/20...  Training Step: 10666...  Training loss: 1.7489...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10667...  Training loss: 1.7643...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10668...  Training loss: 1.6822...  0.0578 sec/batch
Epoch: 18/20...  Training Step: 10669...  Training loss: 1.7059...  0.0546 sec/batch
Epoch: 18/20...  Training Step: 10670...  Training loss: 1.7716...  0.0557 sec/batch
Epoch: 18/20...  Training Step: 10671...  Training loss: 1.7211...  0.0565 sec/batch
Epoch: 18/20...  Training Step: 10672...  Training loss: 1.7657...  0.0545 sec/batch
Epoch: 18/20...  Training Step: 10673...  Training loss: 1.7585...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 10674...  Training loss: 1.7224...  0.0519 sec/batch
Epoch: 18/20...  Training Step: 10675...  Training loss: 1.7006...  0.0585 sec/batch
Epoch: 18/20...  Training Step: 10676...  Training loss: 1.6920...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 10677...  Training loss: 1.7137...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 10678...  Training loss: 1.7186...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 10679...  Training loss: 1.7572...  0.0556 sec/batch
Epoch: 18/20...  Training Step: 10680...  Training loss: 1.7400...  0.0591 sec/batch
Epoch: 18/20...  Training Step: 10681...  Training loss: 1.7772...  0.0572 sec/batch
Epoch: 18/20...  Training Step: 10682...  Training loss: 1.6454...  0.0555 sec/batch
Epoch: 18/20...  Training Step: 10683...  Training loss: 1.7469...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10684...  Training loss: 1.6978...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 10685...  Training loss: 1.6623...  0.0561 sec/batch
Epoch: 18/20...  Training Step: 10686...  Training loss: 1.7555...  0.0523 sec/batch
Epoch: 18/20...  Training Step: 10687...  Training loss: 1.7457...  0.0526 sec/batch
Epoch: 18/20...  Training Step: 10688...  Training loss: 1.7484...  0.0572 sec/batch
Epoch: 18/20...  Training Step: 10689...  Training loss: 1.7294...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 10690...  Training loss: 1.7425...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 10691...  Training loss: 1.7457...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 10692...  Training loss: 1.7166...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 10693...  Training loss: 1.7141...  0.0546 sec/batch
Epoch: 18/20...  Training Step: 10694...  Training loss: 1.7849...  0.0521 sec/batch
Epoch: 18/20...  Training Step: 10695...  Training loss: 1.7014...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 10696...  Training loss: 1.6977...  0.0540 sec/batch
Epoch: 18/20...  Training Step: 10697...  Training loss: 1.7271...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10698...  Training loss: 1.7370...  0.0532 sec/batch
Epoch: 18/20...  Training Step: 10699...  Training loss: 1.7245...  0.0532 sec/batch
Epoch: 18/20...  Training Step: 10700...  Training loss: 1.6941...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 10701...  Training loss: 1.6776...  0.0556 sec/batch
Epoch: 18/20...  Training Step: 10702...  Training loss: 1.6959...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10703...  Training loss: 1.7324...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 10704...  Training loss: 1.7371...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 10705...  Training loss: 1.7358...  0.0520 sec/batch
Epoch: 18/20...  Training Step: 10706...  Training loss: 1.7202...  0.0580 sec/batch
Epoch: 18/20...  Training Step: 10707...  Training loss: 1.7131...  0.0570 sec/batch
Epoch: 18/20...  Training Step: 10708...  Training loss: 1.7156...  0.0526 sec/batch
Epoch: 18/20...  Training Step: 10709...  Training loss: 1.7144...  0.0583 sec/batch
Epoch: 18/20...  Training Step: 10710...  Training loss: 1.7042...  0.0522 sec/batch
Epoch: 18/20...  Training Step: 10711...  Training loss: 1.6984...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10712...  Training loss: 1.7298...  0.0523 sec/batch
Epoch: 18/20...  Training Step: 10713...  Training loss: 1.6901...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 10714...  Training loss: 1.6951...  0.0584 sec/batch
Epoch: 18/20...  Training Step: 10715...  Training loss: 1.6742...  0.0532 sec/batch
Epoch: 18/20...  Training Step: 10716...  Training loss: 1.7102...  0.0620 sec/batch
Epoch: 18/20...  Training Step: 10717...  Training loss: 1.7050...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10718...  Training loss: 1.6860...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10719...  Training loss: 1.6844...  0.0523 sec/batch
Epoch: 18/20...  Training Step: 10720...  Training loss: 1.6902...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10721...  Training loss: 1.6797...  0.0543 sec/batch
Epoch: 18/20...  Training Step: 10722...  Training loss: 1.7691...  0.0532 sec/batch
Epoch: 18/20...  Training Step: 10723...  Training loss: 1.7585...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 10724...  Training loss: 1.6753...  0.0552 sec/batch
Epoch: 18/20...  Training Step: 10725...  Training loss: 1.6722...  0.0586 sec/batch
Epoch: 18/20...  Training Step: 10726...  Training loss: 1.7155...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 10727...  Training loss: 1.7242...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10728...  Training loss: 1.6940...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 10729...  Training loss: 1.7209...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10730...  Training loss: 1.7831...  0.0537 sec/batch
Epoch: 18/20...  Training Step: 10731...  Training loss: 1.7144...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10732...  Training loss: 1.7639...  0.0544 sec/batch
Epoch: 18/20...  Training Step: 10733...  Training loss: 1.7260...  0.0536 sec/batch
Epoch: 18/20...  Training Step: 10734...  Training loss: 1.7057...  0.0587 sec/batch
Epoch: 18/20...  Training Step: 10735...  Training loss: 1.6877...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 10736...  Training loss: 1.7686...  0.0521 sec/batch
Epoch: 18/20...  Training Step: 10737...  Training loss: 1.7466...  0.0544 sec/batch
Epoch: 18/20...  Training Step: 10738...  Training loss: 1.7914...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10739...  Training loss: 1.7042...  0.0555 sec/batch
Epoch: 18/20...  Training Step: 10740...  Training loss: 1.7461...  0.0587 sec/batch
Epoch: 18/20...  Training Step: 10741...  Training loss: 1.6815...  0.0567 sec/batch
Epoch: 18/20...  Training Step: 10742...  Training loss: 1.7101...  0.0556 sec/batch
Epoch: 18/20...  Training Step: 10743...  Training loss: 1.6847...  0.0561 sec/batch
Epoch: 18/20...  Training Step: 10744...  Training loss: 1.6808...  0.0561 sec/batch
Epoch: 18/20...  Training Step: 10745...  Training loss: 1.7181...  0.0557 sec/batch
Epoch: 18/20...  Training Step: 10746...  Training loss: 1.7049...  0.0566 sec/batch
Epoch: 18/20...  Training Step: 10747...  Training loss: 1.7425...  0.0566 sec/batch
Epoch: 18/20...  Training Step: 10748...  Training loss: 1.7271...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 10749...  Training loss: 1.7060...  0.0571 sec/batch
Epoch: 18/20...  Training Step: 10750...  Training loss: 1.6989...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10751...  Training loss: 1.7158...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 10752...  Training loss: 1.7278...  0.0520 sec/batch
Epoch: 18/20...  Training Step: 10753...  Training loss: 1.7360...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10754...  Training loss: 1.7480...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10755...  Training loss: 1.7511...  0.0576 sec/batch
Epoch: 18/20...  Training Step: 10756...  Training loss: 1.7380...  0.0574 sec/batch
Epoch: 18/20...  Training Step: 10757...  Training loss: 1.7465...  0.0567 sec/batch
Epoch: 18/20...  Training Step: 10758...  Training loss: 1.7062...  0.0541 sec/batch
Epoch: 18/20...  Training Step: 10759...  Training loss: 1.8046...  0.0532 sec/batch
Epoch: 18/20...  Training Step: 10760...  Training loss: 1.7520...  0.0580 sec/batch
Epoch: 18/20...  Training Step: 10761...  Training loss: 1.7645...  0.0518 sec/batch
Epoch: 18/20...  Training Step: 10762...  Training loss: 1.7548...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 10763...  Training loss: 1.7502...  0.0574 sec/batch
Epoch: 18/20...  Training Step: 10764...  Training loss: 1.6806...  0.0526 sec/batch
Epoch: 18/20...  Training Step: 10765...  Training loss: 1.7205...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 10766...  Training loss: 1.7516...  0.0542 sec/batch
Epoch: 18/20...  Training Step: 10767...  Training loss: 1.7677...  0.0580 sec/batch
Epoch: 18/20...  Training Step: 10768...  Training loss: 1.6982...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 10769...  Training loss: 1.7266...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 10770...  Training loss: 1.7001...  0.0521 sec/batch
Epoch: 18/20...  Training Step: 10771...  Training loss: 1.7713...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10772...  Training loss: 1.6895...  0.0522 sec/batch
Epoch: 18/20...  Training Step: 10773...  Training loss: 1.6809...  0.0577 sec/batch
Epoch: 18/20...  Training Step: 10774...  Training loss: 1.7005...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 10775...  Training loss: 1.6778...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10776...  Training loss: 1.7672...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 10777...  Training loss: 1.7153...  0.0523 sec/batch
Epoch: 18/20...  Training Step: 10778...  Training loss: 1.6889...  0.0541 sec/batch
Epoch: 18/20...  Training Step: 10779...  Training loss: 1.6844...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 10780...  Training loss: 1.7318...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10781...  Training loss: 1.6816...  0.0545 sec/batch
Epoch: 18/20...  Training Step: 10782...  Training loss: 1.6910...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 10783...  Training loss: 1.6798...  0.0576 sec/batch
Epoch: 18/20...  Training Step: 10784...  Training loss: 1.7155...  0.0583 sec/batch
Epoch: 18/20...  Training Step: 10785...  Training loss: 1.7254...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 10786...  Training loss: 1.6925...  0.0522 sec/batch
Epoch: 18/20...  Training Step: 10787...  Training loss: 1.7326...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 10788...  Training loss: 1.7451...  0.0544 sec/batch
Epoch: 18/20...  Training Step: 10789...  Training loss: 1.6794...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 10790...  Training loss: 1.6886...  0.0586 sec/batch
Epoch: 18/20...  Training Step: 10791...  Training loss: 1.7083...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 10792...  Training loss: 1.6890...  0.0523 sec/batch
Epoch: 18/20...  Training Step: 10793...  Training loss: 1.7274...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 10794...  Training loss: 1.7258...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10795...  Training loss: 1.7726...  0.0541 sec/batch
Epoch: 18/20...  Training Step: 10796...  Training loss: 1.7067...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 10797...  Training loss: 1.7192...  0.0562 sec/batch
Epoch: 18/20...  Training Step: 10798...  Training loss: 1.7043...  0.0587 sec/batch
Epoch: 18/20...  Training Step: 10799...  Training loss: 1.7220...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 10800...  Training loss: 1.7252...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10801...  Training loss: 1.7257...  0.0572 sec/batch
Epoch: 18/20...  Training Step: 10802...  Training loss: 1.6764...  0.0552 sec/batch
Epoch: 18/20...  Training Step: 10803...  Training loss: 1.7284...  0.0557 sec/batch
Epoch: 18/20...  Training Step: 10804...  Training loss: 1.7298...  0.0535 sec/batch
Epoch: 18/20...  Training Step: 10805...  Training loss: 1.7280...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10806...  Training loss: 1.6680...  0.0576 sec/batch
Epoch: 18/20...  Training Step: 10807...  Training loss: 1.6972...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10808...  Training loss: 1.7202...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10809...  Training loss: 1.7004...  0.0558 sec/batch
Epoch: 18/20...  Training Step: 10810...  Training loss: 1.6618...  0.0555 sec/batch
Epoch: 18/20...  Training Step: 10811...  Training loss: 1.6847...  0.0522 sec/batch
Epoch: 18/20...  Training Step: 10812...  Training loss: 1.7270...  0.0573 sec/batch
Epoch: 18/20...  Training Step: 10813...  Training loss: 1.6990...  0.0572 sec/batch
Epoch: 18/20...  Training Step: 10814...  Training loss: 1.6806...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 10815...  Training loss: 1.7465...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10816...  Training loss: 1.7532...  0.0542 sec/batch
Epoch: 18/20...  Training Step: 10817...  Training loss: 1.8046...  0.0558 sec/batch
Epoch: 18/20...  Training Step: 10818...  Training loss: 1.7501...  0.0561 sec/batch
Epoch: 18/20...  Training Step: 10819...  Training loss: 1.7654...  0.0591 sec/batch
Epoch: 18/20...  Training Step: 10820...  Training loss: 1.7539...  0.0521 sec/batch
Epoch: 18/20...  Training Step: 10821...  Training loss: 1.7377...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10822...  Training loss: 1.6599...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10823...  Training loss: 1.6693...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10824...  Training loss: 1.7531...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10825...  Training loss: 1.7042...  0.0539 sec/batch
Epoch: 18/20...  Training Step: 10826...  Training loss: 1.7446...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 10827...  Training loss: 1.7050...  0.0581 sec/batch
Epoch: 18/20...  Training Step: 10828...  Training loss: 1.7362...  0.0579 sec/batch
Epoch: 18/20...  Training Step: 10829...  Training loss: 1.7168...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10830...  Training loss: 1.7545...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 10831...  Training loss: 1.7127...  0.0568 sec/batch
Epoch: 18/20...  Training Step: 10832...  Training loss: 1.7147...  0.0545 sec/batch
Epoch: 18/20...  Training Step: 10833...  Training loss: 1.6947...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 10834...  Training loss: 1.7593...  0.0607 sec/batch
Epoch: 18/20...  Training Step: 10835...  Training loss: 1.7069...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10836...  Training loss: 1.6516...  0.0522 sec/batch
Epoch: 18/20...  Training Step: 10837...  Training loss: 1.7224...  0.0586 sec/batch
Epoch: 18/20...  Training Step: 10838...  Training loss: 1.7757...  0.0574 sec/batch
Epoch: 18/20...  Training Step: 10839...  Training loss: 1.7346...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 10840...  Training loss: 1.6984...  0.0588 sec/batch
Epoch: 18/20...  Training Step: 10841...  Training loss: 1.7480...  0.0581 sec/batch
Epoch: 18/20...  Training Step: 10842...  Training loss: 1.7862...  0.0583 sec/batch
Epoch: 18/20...  Training Step: 10843...  Training loss: 1.6693...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 10844...  Training loss: 1.7515...  0.0565 sec/batch
Epoch: 18/20...  Training Step: 10845...  Training loss: 1.6947...  0.0540 sec/batch
Epoch: 18/20...  Training Step: 10846...  Training loss: 1.7093...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10847...  Training loss: 1.7173...  0.0542 sec/batch
Epoch: 18/20...  Training Step: 10848...  Training loss: 1.7140...  0.0544 sec/batch
Epoch: 18/20...  Training Step: 10849...  Training loss: 1.7047...  0.0580 sec/batch
Epoch: 18/20...  Training Step: 10850...  Training loss: 1.7035...  0.0546 sec/batch
Epoch: 18/20...  Training Step: 10851...  Training loss: 1.6815...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 10852...  Training loss: 1.6795...  0.0570 sec/batch
Epoch: 18/20...  Training Step: 10853...  Training loss: 1.6826...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 10854...  Training loss: 1.6715...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10855...  Training loss: 1.7331...  0.0566 sec/batch
Epoch: 18/20...  Training Step: 10856...  Training loss: 1.7494...  0.0552 sec/batch
Epoch: 18/20...  Training Step: 10857...  Training loss: 1.6896...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10858...  Training loss: 1.6516...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 10859...  Training loss: 1.6680...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 10860...  Training loss: 1.7552...  0.0546 sec/batch
Epoch: 18/20...  Training Step: 10861...  Training loss: 1.7107...  0.0566 sec/batch
Epoch: 18/20...  Training Step: 10862...  Training loss: 1.6685...  0.0621 sec/batch
Epoch: 18/20...  Training Step: 10863...  Training loss: 1.7331...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10864...  Training loss: 1.7112...  0.0575 sec/batch
Epoch: 18/20...  Training Step: 10865...  Training loss: 1.7008...  0.0532 sec/batch
Epoch: 18/20...  Training Step: 10866...  Training loss: 1.7015...  0.0545 sec/batch
Epoch: 18/20...  Training Step: 10867...  Training loss: 1.6923...  0.0540 sec/batch
Epoch: 18/20...  Training Step: 10868...  Training loss: 1.6890...  0.0546 sec/batch
Epoch: 18/20...  Training Step: 10869...  Training loss: 1.7181...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 10870...  Training loss: 1.7018...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 10871...  Training loss: 1.6703...  0.0559 sec/batch
Epoch: 18/20...  Training Step: 10872...  Training loss: 1.7033...  0.0585 sec/batch
Epoch: 18/20...  Training Step: 10873...  Training loss: 1.6909...  0.0569 sec/batch
Epoch: 18/20...  Training Step: 10874...  Training loss: 1.6848...  0.0580 sec/batch
Epoch: 18/20...  Training Step: 10875...  Training loss: 1.6998...  0.0545 sec/batch
Epoch: 18/20...  Training Step: 10876...  Training loss: 1.7222...  0.0556 sec/batch
Epoch: 18/20...  Training Step: 10877...  Training loss: 1.6791...  0.0522 sec/batch
Epoch: 18/20...  Training Step: 10878...  Training loss: 1.6856...  0.0558 sec/batch
Epoch: 18/20...  Training Step: 10879...  Training loss: 1.6746...  0.0583 sec/batch
Epoch: 18/20...  Training Step: 10880...  Training loss: 1.6942...  0.0546 sec/batch
Epoch: 18/20...  Training Step: 10881...  Training loss: 1.7230...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10882...  Training loss: 1.6852...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10883...  Training loss: 1.6825...  0.0546 sec/batch
Epoch: 18/20...  Training Step: 10884...  Training loss: 1.6714...  0.0569 sec/batch
Epoch: 18/20...  Training Step: 10885...  Training loss: 1.7031...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10886...  Training loss: 1.7100...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10887...  Training loss: 1.7220...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10888...  Training loss: 1.7355...  0.0523 sec/batch
Epoch: 18/20...  Training Step: 10889...  Training loss: 1.6935...  0.0534 sec/batch
Epoch: 18/20...  Training Step: 10890...  Training loss: 1.7064...  0.0554 sec/batch
Epoch: 18/20...  Training Step: 10891...  Training loss: 1.7632...  0.0589 sec/batch
Epoch: 18/20...  Training Step: 10892...  Training loss: 1.7166...  0.0577 sec/batch
Epoch: 18/20...  Training Step: 10893...  Training loss: 1.7249...  0.0554 sec/batch
Epoch: 18/20...  Training Step: 10894...  Training loss: 1.6995...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 10895...  Training loss: 1.6821...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10896...  Training loss: 1.7668...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10897...  Training loss: 1.8063...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10898...  Training loss: 1.7499...  0.0565 sec/batch
Epoch: 18/20...  Training Step: 10899...  Training loss: 1.7164...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 10900...  Training loss: 1.7187...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10901...  Training loss: 1.7423...  0.0521 sec/batch
Epoch: 18/20...  Training Step: 10902...  Training loss: 1.6999...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 10903...  Training loss: 1.6729...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 10904...  Training loss: 1.6727...  0.0570 sec/batch
Epoch: 18/20...  Training Step: 10905...  Training loss: 1.7006...  0.0556 sec/batch
Epoch: 18/20...  Training Step: 10906...  Training loss: 1.7369...  0.0572 sec/batch
Epoch: 18/20...  Training Step: 10907...  Training loss: 1.7029...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10908...  Training loss: 1.7235...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 10909...  Training loss: 1.7350...  0.0571 sec/batch
Epoch: 18/20...  Training Step: 10910...  Training loss: 1.7165...  0.0521 sec/batch
Epoch: 18/20...  Training Step: 10911...  Training loss: 1.6905...  0.0569 sec/batch
Epoch: 18/20...  Training Step: 10912...  Training loss: 1.7798...  0.0594 sec/batch
Epoch: 18/20...  Training Step: 10913...  Training loss: 1.7153...  0.0597 sec/batch
Epoch: 18/20...  Training Step: 10914...  Training loss: 1.7158...  0.0543 sec/batch
Epoch: 18/20...  Training Step: 10915...  Training loss: 1.6984...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 10916...  Training loss: 1.7055...  0.0533 sec/batch
Epoch: 18/20...  Training Step: 10917...  Training loss: 1.6734...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10918...  Training loss: 1.7826...  0.0534 sec/batch
Epoch: 18/20...  Training Step: 10919...  Training loss: 1.7474...  0.0546 sec/batch
Epoch: 18/20...  Training Step: 10920...  Training loss: 1.6926...  0.0533 sec/batch
Epoch: 18/20...  Training Step: 10921...  Training loss: 1.6415...  0.0581 sec/batch
Epoch: 18/20...  Training Step: 10922...  Training loss: 1.7730...  0.0541 sec/batch
Epoch: 18/20...  Training Step: 10923...  Training loss: 1.6992...  0.0567 sec/batch
Epoch: 18/20...  Training Step: 10924...  Training loss: 1.7046...  0.0523 sec/batch
Epoch: 18/20...  Training Step: 10925...  Training loss: 1.7246...  0.0558 sec/batch
Epoch: 18/20...  Training Step: 10926...  Training loss: 1.6334...  0.0542 sec/batch
Epoch: 18/20...  Training Step: 10927...  Training loss: 1.6660...  0.0593 sec/batch
Epoch: 18/20...  Training Step: 10928...  Training loss: 1.7353...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10929...  Training loss: 1.6900...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 10930...  Training loss: 1.6619...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10931...  Training loss: 1.7532...  0.0522 sec/batch
Epoch: 18/20...  Training Step: 10932...  Training loss: 1.6607...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 10933...  Training loss: 1.6973...  0.0538 sec/batch
Epoch: 18/20...  Training Step: 10934...  Training loss: 1.7389...  0.0564 sec/batch
Epoch: 18/20...  Training Step: 10935...  Training loss: 1.6894...  0.0580 sec/batch
Epoch: 18/20...  Training Step: 10936...  Training loss: 1.7203...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 10937...  Training loss: 1.6733...  0.0541 sec/batch
Epoch: 18/20...  Training Step: 10938...  Training loss: 1.7370...  0.0526 sec/batch
Epoch: 18/20...  Training Step: 10939...  Training loss: 1.6878...  0.0552 sec/batch
Epoch: 18/20...  Training Step: 10940...  Training loss: 1.7456...  0.0574 sec/batch
Epoch: 18/20...  Training Step: 10941...  Training loss: 1.7568...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 10942...  Training loss: 1.7183...  0.0616 sec/batch
Epoch: 18/20...  Training Step: 10943...  Training loss: 1.6746...  0.0534 sec/batch
Epoch: 18/20...  Training Step: 10944...  Training loss: 1.7239...  0.0543 sec/batch
Epoch: 18/20...  Training Step: 10945...  Training loss: 1.7600...  0.0581 sec/batch
Epoch: 18/20...  Training Step: 10946...  Training loss: 1.7530...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10947...  Training loss: 1.7609...  0.0544 sec/batch
Epoch: 18/20...  Training Step: 10948...  Training loss: 1.7250...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 10949...  Training loss: 1.7772...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10950...  Training loss: 1.7476...  0.0542 sec/batch
Epoch: 18/20...  Training Step: 10951...  Training loss: 1.7063...  0.0542 sec/batch
Epoch: 18/20...  Training Step: 10952...  Training loss: 1.7341...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10953...  Training loss: 1.7377...  0.0541 sec/batch
Epoch: 18/20...  Training Step: 10954...  Training loss: 1.7165...  0.0578 sec/batch
Epoch: 18/20...  Training Step: 10955...  Training loss: 1.6871...  0.0522 sec/batch
Epoch: 18/20...  Training Step: 10956...  Training loss: 1.6748...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 10957...  Training loss: 1.6912...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 10958...  Training loss: 1.7247...  0.0576 sec/batch
Epoch: 18/20...  Training Step: 10959...  Training loss: 1.7726...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 10960...  Training loss: 1.7084...  0.0532 sec/batch
Epoch: 18/20...  Training Step: 10961...  Training loss: 1.6957...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 10962...  Training loss: 1.6964...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10963...  Training loss: 1.7139...  0.0584 sec/batch
Epoch: 18/20...  Training Step: 10964...  Training loss: 1.6965...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 10965...  Training loss: 1.7516...  0.0579 sec/batch
Epoch: 18/20...  Training Step: 10966...  Training loss: 1.7448...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10967...  Training loss: 1.6742...  0.0542 sec/batch
Epoch: 18/20...  Training Step: 10968...  Training loss: 1.7413...  0.0545 sec/batch
Epoch: 18/20...  Training Step: 10969...  Training loss: 1.7012...  0.0584 sec/batch
Epoch: 18/20...  Training Step: 10970...  Training loss: 1.6696...  0.0579 sec/batch
Epoch: 18/20...  Training Step: 10971...  Training loss: 1.7014...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10972...  Training loss: 1.7607...  0.0535 sec/batch
Epoch: 18/20...  Training Step: 10973...  Training loss: 1.7266...  0.0560 sec/batch
Epoch: 18/20...  Training Step: 10974...  Training loss: 1.7025...  0.0541 sec/batch
Epoch: 18/20...  Training Step: 10975...  Training loss: 1.6691...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 10976...  Training loss: 1.6946...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10977...  Training loss: 1.6894...  0.0542 sec/batch
Epoch: 18/20...  Training Step: 10978...  Training loss: 1.7062...  0.0535 sec/batch
Epoch: 18/20...  Training Step: 10979...  Training loss: 1.6882...  0.0593 sec/batch
Epoch: 18/20...  Training Step: 10980...  Training loss: 1.7041...  0.0562 sec/batch
Epoch: 18/20...  Training Step: 10981...  Training loss: 1.7094...  0.0607 sec/batch
Epoch: 18/20...  Training Step: 10982...  Training loss: 1.7118...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 10983...  Training loss: 1.7584...  0.0544 sec/batch
Epoch: 18/20...  Training Step: 10984...  Training loss: 1.7043...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 10985...  Training loss: 1.6315...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 10986...  Training loss: 1.7144...  0.0557 sec/batch
Epoch: 18/20...  Training Step: 10987...  Training loss: 1.6745...  0.0546 sec/batch
Epoch: 18/20...  Training Step: 10988...  Training loss: 1.6480...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10989...  Training loss: 1.7090...  0.0600 sec/batch
Epoch: 18/20...  Training Step: 10990...  Training loss: 1.7517...  0.0537 sec/batch
Epoch: 18/20...  Training Step: 10991...  Training loss: 1.7530...  0.0545 sec/batch
Epoch: 18/20...  Training Step: 10992...  Training loss: 1.7353...  0.0582 sec/batch
Epoch: 18/20...  Training Step: 10993...  Training loss: 1.6677...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 10994...  Training loss: 1.7283...  0.0526 sec/batch
Epoch: 18/20...  Training Step: 10995...  Training loss: 1.6798...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 10996...  Training loss: 1.6996...  0.0523 sec/batch
Epoch: 18/20...  Training Step: 10997...  Training loss: 1.7182...  0.0526 sec/batch
Epoch: 18/20...  Training Step: 10998...  Training loss: 1.7183...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 10999...  Training loss: 1.6994...  0.0567 sec/batch
Epoch: 18/20...  Training Step: 11000...  Training loss: 1.7092...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 11001...  Training loss: 1.6728...  0.0587 sec/batch
Epoch: 18/20...  Training Step: 11002...  Training loss: 1.7128...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 11003...  Training loss: 1.6951...  0.0564 sec/batch
Epoch: 18/20...  Training Step: 11004...  Training loss: 1.7026...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 11005...  Training loss: 1.7479...  0.0595 sec/batch
Epoch: 18/20...  Training Step: 11006...  Training loss: 1.7453...  0.0542 sec/batch
Epoch: 18/20...  Training Step: 11007...  Training loss: 1.6910...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 11008...  Training loss: 1.7133...  0.0523 sec/batch
Epoch: 18/20...  Training Step: 11009...  Training loss: 1.7010...  0.0572 sec/batch
Epoch: 18/20...  Training Step: 11010...  Training loss: 1.6823...  0.0565 sec/batch
Epoch: 18/20...  Training Step: 11011...  Training loss: 1.7001...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 11012...  Training loss: 1.7270...  0.0563 sec/batch
Epoch: 18/20...  Training Step: 11013...  Training loss: 1.7185...  0.0577 sec/batch
Epoch: 18/20...  Training Step: 11014...  Training loss: 1.6766...  0.0533 sec/batch
Epoch: 18/20...  Training Step: 11015...  Training loss: 1.7623...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 11016...  Training loss: 1.7598...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 11017...  Training loss: 1.7273...  0.0558 sec/batch
Epoch: 18/20...  Training Step: 11018...  Training loss: 1.7864...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 11019...  Training loss: 1.6898...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 11020...  Training loss: 1.7749...  0.0533 sec/batch
Epoch: 18/20...  Training Step: 11021...  Training loss: 1.7060...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 11022...  Training loss: 1.6935...  0.0571 sec/batch
Epoch: 18/20...  Training Step: 11023...  Training loss: 1.7210...  0.0570 sec/batch
Epoch: 18/20...  Training Step: 11024...  Training loss: 1.7170...  0.0537 sec/batch
Epoch: 18/20...  Training Step: 11025...  Training loss: 1.8067...  0.0554 sec/batch
Epoch: 18/20...  Training Step: 11026...  Training loss: 1.6960...  0.0539 sec/batch
Epoch: 18/20...  Training Step: 11027...  Training loss: 1.7313...  0.0579 sec/batch
Epoch: 18/20...  Training Step: 11028...  Training loss: 1.7262...  0.0520 sec/batch
Epoch: 18/20...  Training Step: 11029...  Training loss: 1.7251...  0.0584 sec/batch
Epoch: 18/20...  Training Step: 11030...  Training loss: 1.7080...  0.0585 sec/batch
Epoch: 18/20...  Training Step: 11031...  Training loss: 1.7172...  0.0557 sec/batch
Epoch: 18/20...  Training Step: 11032...  Training loss: 1.7290...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 11033...  Training loss: 1.7198...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 11034...  Training loss: 1.7065...  0.0556 sec/batch
Epoch: 18/20...  Training Step: 11035...  Training loss: 1.6681...  0.0575 sec/batch
Epoch: 18/20...  Training Step: 11036...  Training loss: 1.6986...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 11037...  Training loss: 1.6959...  0.0540 sec/batch
Epoch: 18/20...  Training Step: 11038...  Training loss: 1.7854...  0.0582 sec/batch
Epoch: 18/20...  Training Step: 11039...  Training loss: 1.6535...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 11040...  Training loss: 1.7138...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 11041...  Training loss: 1.7132...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 11042...  Training loss: 1.7223...  0.0572 sec/batch
Epoch: 18/20...  Training Step: 11043...  Training loss: 1.8028...  0.0580 sec/batch
Epoch: 18/20...  Training Step: 11044...  Training loss: 1.7120...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 11045...  Training loss: 1.6810...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 11046...  Training loss: 1.6547...  0.0556 sec/batch
Epoch: 18/20...  Training Step: 11047...  Training loss: 1.7361...  0.0555 sec/batch
Epoch: 18/20...  Training Step: 11048...  Training loss: 1.7018...  0.0600 sec/batch
Epoch: 18/20...  Training Step: 11049...  Training loss: 1.7592...  0.0556 sec/batch
Epoch: 18/20...  Training Step: 11050...  Training loss: 1.7320...  0.0532 sec/batch
Epoch: 18/20...  Training Step: 11051...  Training loss: 1.7447...  0.0565 sec/batch
Epoch: 18/20...  Training Step: 11052...  Training loss: 1.7448...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 11053...  Training loss: 1.7701...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 11054...  Training loss: 1.7626...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 11055...  Training loss: 1.7298...  0.0548 sec/batch
Epoch: 18/20...  Training Step: 11056...  Training loss: 1.7054...  0.0563 sec/batch
Epoch: 18/20...  Training Step: 11057...  Training loss: 1.7116...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 11058...  Training loss: 1.6883...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 11059...  Training loss: 1.6854...  0.0578 sec/batch
Epoch: 18/20...  Training Step: 11060...  Training loss: 1.7086...  0.0526 sec/batch
Epoch: 18/20...  Training Step: 11061...  Training loss: 1.6966...  0.0576 sec/batch
Epoch: 18/20...  Training Step: 11062...  Training loss: 1.6715...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 11063...  Training loss: 1.7268...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 11064...  Training loss: 1.6386...  0.0552 sec/batch
Epoch: 18/20...  Training Step: 11065...  Training loss: 1.7379...  0.0562 sec/batch
Epoch: 18/20...  Training Step: 11066...  Training loss: 1.7518...  0.0574 sec/batch
Epoch: 18/20...  Training Step: 11067...  Training loss: 1.7412...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 11068...  Training loss: 1.7248...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 11069...  Training loss: 1.7183...  0.0560 sec/batch
Epoch: 18/20...  Training Step: 11070...  Training loss: 1.6872...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 11071...  Training loss: 1.6858...  0.0526 sec/batch
Epoch: 18/20...  Training Step: 11072...  Training loss: 1.7158...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 11073...  Training loss: 1.7001...  0.0540 sec/batch
Epoch: 18/20...  Training Step: 11074...  Training loss: 1.7062...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 11075...  Training loss: 1.7234...  0.0541 sec/batch
Epoch: 18/20...  Training Step: 11076...  Training loss: 1.7177...  0.0532 sec/batch
Epoch: 18/20...  Training Step: 11077...  Training loss: 1.6845...  0.0522 sec/batch
Epoch: 18/20...  Training Step: 11078...  Training loss: 1.7062...  0.0544 sec/batch
Epoch: 18/20...  Training Step: 11079...  Training loss: 1.6434...  0.0546 sec/batch
Epoch: 18/20...  Training Step: 11080...  Training loss: 1.7292...  0.0554 sec/batch
Epoch: 18/20...  Training Step: 11081...  Training loss: 1.7498...  0.0530 sec/batch
Epoch: 18/20...  Training Step: 11082...  Training loss: 1.6847...  0.0557 sec/batch
Epoch: 18/20...  Training Step: 11083...  Training loss: 1.7007...  0.0554 sec/batch
Epoch: 18/20...  Training Step: 11084...  Training loss: 1.6774...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 11085...  Training loss: 1.7380...  0.0608 sec/batch
Epoch: 18/20...  Training Step: 11086...  Training loss: 1.7077...  0.0545 sec/batch
Epoch: 18/20...  Training Step: 11087...  Training loss: 1.7511...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 11088...  Training loss: 1.7755...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 11089...  Training loss: 1.7594...  0.0578 sec/batch
Epoch: 18/20...  Training Step: 11090...  Training loss: 1.6629...  0.0555 sec/batch
Epoch: 18/20...  Training Step: 11091...  Training loss: 1.7359...  0.0526 sec/batch
Epoch: 18/20...  Training Step: 11092...  Training loss: 1.6690...  0.0544 sec/batch
Epoch: 18/20...  Training Step: 11093...  Training loss: 1.7294...  0.0555 sec/batch
Epoch: 18/20...  Training Step: 11094...  Training loss: 1.6917...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 11095...  Training loss: 1.6869...  0.0520 sec/batch
Epoch: 18/20...  Training Step: 11096...  Training loss: 1.7174...  0.0574 sec/batch
Epoch: 18/20...  Training Step: 11097...  Training loss: 1.7145...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 11098...  Training loss: 1.6626...  0.0537 sec/batch
Epoch: 18/20...  Training Step: 11099...  Training loss: 1.7237...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 11100...  Training loss: 1.6983...  0.0545 sec/batch
Epoch: 18/20...  Training Step: 11101...  Training loss: 1.7414...  0.0572 sec/batch
Epoch: 18/20...  Training Step: 11102...  Training loss: 1.7378...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 11103...  Training loss: 1.6974...  0.0574 sec/batch
Epoch: 18/20...  Training Step: 11104...  Training loss: 1.7753...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 11105...  Training loss: 1.7999...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 11106...  Training loss: 1.7678...  0.0585 sec/batch
Epoch: 18/20...  Training Step: 11107...  Training loss: 1.7264...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 11108...  Training loss: 1.7784...  0.0532 sec/batch
Epoch: 18/20...  Training Step: 11109...  Training loss: 1.7116...  0.0560 sec/batch
Epoch: 18/20...  Training Step: 11110...  Training loss: 1.7326...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 11111...  Training loss: 1.7408...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 11112...  Training loss: 1.7696...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 11113...  Training loss: 1.7032...  0.0545 sec/batch
Epoch: 18/20...  Training Step: 11114...  Training loss: 1.7204...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 11115...  Training loss: 1.7376...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 11116...  Training loss: 1.7464...  0.0544 sec/batch
Epoch: 18/20...  Training Step: 11117...  Training loss: 1.6533...  0.0582 sec/batch
Epoch: 18/20...  Training Step: 11118...  Training loss: 1.7061...  0.0554 sec/batch
Epoch: 18/20...  Training Step: 11119...  Training loss: 1.7732...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 11120...  Training loss: 1.7486...  0.0575 sec/batch
Epoch: 18/20...  Training Step: 11121...  Training loss: 1.7624...  0.0560 sec/batch
Epoch: 18/20...  Training Step: 11122...  Training loss: 1.7283...  0.0546 sec/batch
Epoch: 18/20...  Training Step: 11123...  Training loss: 1.7208...  0.0579 sec/batch
Epoch: 18/20...  Training Step: 11124...  Training loss: 1.7477...  0.0542 sec/batch
Epoch: 18/20...  Training Step: 11125...  Training loss: 1.7537...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 11126...  Training loss: 1.7247...  0.0579 sec/batch
Epoch: 18/20...  Training Step: 11127...  Training loss: 1.6619...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 11128...  Training loss: 1.7349...  0.0565 sec/batch
Epoch: 18/20...  Training Step: 11129...  Training loss: 1.7022...  0.0546 sec/batch
Epoch: 18/20...  Training Step: 11130...  Training loss: 1.7606...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 11131...  Training loss: 1.6791...  0.0528 sec/batch
Epoch: 18/20...  Training Step: 11132...  Training loss: 1.7472...  0.0578 sec/batch
Epoch: 18/20...  Training Step: 11133...  Training loss: 1.7179...  0.0547 sec/batch
Epoch: 18/20...  Training Step: 11134...  Training loss: 1.7192...  0.0541 sec/batch
Epoch: 18/20...  Training Step: 11135...  Training loss: 1.7104...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 11136...  Training loss: 1.6756...  0.0583 sec/batch
Epoch: 18/20...  Training Step: 11137...  Training loss: 1.6544...  0.0551 sec/batch
Epoch: 18/20...  Training Step: 11138...  Training loss: 1.7162...  0.0556 sec/batch
Epoch: 18/20...  Training Step: 11139...  Training loss: 1.7421...  0.0534 sec/batch
Epoch: 18/20...  Training Step: 11140...  Training loss: 1.7302...  0.0531 sec/batch
Epoch: 18/20...  Training Step: 11141...  Training loss: 1.6925...  0.0526 sec/batch
Epoch: 18/20...  Training Step: 11142...  Training loss: 1.7147...  0.0523 sec/batch
Epoch: 18/20...  Training Step: 11143...  Training loss: 1.7163...  0.0573 sec/batch
Epoch: 18/20...  Training Step: 11144...  Training loss: 1.6747...  0.0567 sec/batch
Epoch: 18/20...  Training Step: 11145...  Training loss: 1.7277...  0.0527 sec/batch
Epoch: 18/20...  Training Step: 11146...  Training loss: 1.7176...  0.0563 sec/batch
Epoch: 18/20...  Training Step: 11147...  Training loss: 1.6609...  0.0540 sec/batch
Epoch: 18/20...  Training Step: 11148...  Training loss: 1.6787...  0.0532 sec/batch
Epoch: 18/20...  Training Step: 11149...  Training loss: 1.7115...  0.0524 sec/batch
Epoch: 18/20...  Training Step: 11150...  Training loss: 1.7570...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 11151...  Training loss: 1.7684...  0.0540 sec/batch
Epoch: 18/20...  Training Step: 11152...  Training loss: 1.7257...  0.0549 sec/batch
Epoch: 18/20...  Training Step: 11153...  Training loss: 1.6746...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 11154...  Training loss: 1.7163...  0.0581 sec/batch
Epoch: 18/20...  Training Step: 11155...  Training loss: 1.6579...  0.0553 sec/batch
Epoch: 18/20...  Training Step: 11156...  Training loss: 1.7254...  0.0603 sec/batch
Epoch: 18/20...  Training Step: 11157...  Training loss: 1.7661...  0.0550 sec/batch
Epoch: 18/20...  Training Step: 11158...  Training loss: 1.7038...  0.0525 sec/batch
Epoch: 18/20...  Training Step: 11159...  Training loss: 1.6732...  0.0529 sec/batch
Epoch: 18/20...  Training Step: 11160...  Training loss: 1.6655...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11161...  Training loss: 1.7863...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11162...  Training loss: 1.7836...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11163...  Training loss: 1.7613...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11164...  Training loss: 1.6923...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11165...  Training loss: 1.7062...  0.0576 sec/batch
Epoch: 19/20...  Training Step: 11166...  Training loss: 1.7467...  0.0576 sec/batch
Epoch: 19/20...  Training Step: 11167...  Training loss: 1.6815...  0.0552 sec/batch
Epoch: 19/20...  Training Step: 11168...  Training loss: 1.6708...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11169...  Training loss: 1.6423...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11170...  Training loss: 1.6692...  0.0533 sec/batch
Epoch: 19/20...  Training Step: 11171...  Training loss: 1.6934...  0.0523 sec/batch
Epoch: 19/20...  Training Step: 11172...  Training loss: 1.6707...  0.0550 sec/batch
Epoch: 19/20...  Training Step: 11173...  Training loss: 1.7175...  0.0553 sec/batch
Epoch: 19/20...  Training Step: 11174...  Training loss: 1.6852...  0.0592 sec/batch
Epoch: 19/20...  Training Step: 11175...  Training loss: 1.7595...  0.0615 sec/batch
Epoch: 19/20...  Training Step: 11176...  Training loss: 1.7569...  0.0555 sec/batch
Epoch: 19/20...  Training Step: 11177...  Training loss: 1.7306...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11178...  Training loss: 1.7073...  0.0589 sec/batch
Epoch: 19/20...  Training Step: 11179...  Training loss: 1.6859...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11180...  Training loss: 1.7268...  0.0552 sec/batch
Epoch: 19/20...  Training Step: 11181...  Training loss: 1.7626...  0.0557 sec/batch
Epoch: 19/20...  Training Step: 11182...  Training loss: 1.7152...  0.0614 sec/batch
Epoch: 19/20...  Training Step: 11183...  Training loss: 1.6991...  0.0535 sec/batch
Epoch: 19/20...  Training Step: 11184...  Training loss: 1.7246...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11185...  Training loss: 1.7061...  0.0559 sec/batch
Epoch: 19/20...  Training Step: 11186...  Training loss: 1.6618...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11187...  Training loss: 1.7159...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11188...  Training loss: 1.7220...  0.0693 sec/batch
Epoch: 19/20...  Training Step: 11189...  Training loss: 1.7264...  0.0539 sec/batch
Epoch: 19/20...  Training Step: 11190...  Training loss: 1.6689...  0.0524 sec/batch
Epoch: 19/20...  Training Step: 11191...  Training loss: 1.6797...  0.0636 sec/batch
Epoch: 19/20...  Training Step: 11192...  Training loss: 1.7258...  0.0606 sec/batch
Epoch: 19/20...  Training Step: 11193...  Training loss: 1.7069...  0.0589 sec/batch
Epoch: 19/20...  Training Step: 11194...  Training loss: 1.6838...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11195...  Training loss: 1.7092...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11196...  Training loss: 1.7162...  0.0552 sec/batch
Epoch: 19/20...  Training Step: 11197...  Training loss: 1.7135...  0.0581 sec/batch
Epoch: 19/20...  Training Step: 11198...  Training loss: 1.7148...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11199...  Training loss: 1.7305...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11200...  Training loss: 1.6888...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11201...  Training loss: 1.7147...  0.0537 sec/batch
Epoch: 19/20...  Training Step: 11202...  Training loss: 1.7214...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11203...  Training loss: 1.7105...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11204...  Training loss: 1.7293...  0.0536 sec/batch
Epoch: 19/20...  Training Step: 11205...  Training loss: 1.6926...  0.0591 sec/batch
Epoch: 19/20...  Training Step: 11206...  Training loss: 1.6981...  0.0538 sec/batch
Epoch: 19/20...  Training Step: 11207...  Training loss: 1.5846...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11208...  Training loss: 1.6924...  0.0543 sec/batch
Epoch: 19/20...  Training Step: 11209...  Training loss: 1.6621...  0.0524 sec/batch
Epoch: 19/20...  Training Step: 11210...  Training loss: 1.7202...  0.0576 sec/batch
Epoch: 19/20...  Training Step: 11211...  Training loss: 1.6920...  0.0552 sec/batch
Epoch: 19/20...  Training Step: 11212...  Training loss: 1.6715...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11213...  Training loss: 1.6975...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11214...  Training loss: 1.7190...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11215...  Training loss: 1.7276...  0.0523 sec/batch
Epoch: 19/20...  Training Step: 11216...  Training loss: 1.7313...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11217...  Training loss: 1.6755...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11218...  Training loss: 1.7062...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11219...  Training loss: 1.6971...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11220...  Training loss: 1.7712...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11221...  Training loss: 1.6940...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11222...  Training loss: 1.6771...  0.0521 sec/batch
Epoch: 19/20...  Training Step: 11223...  Training loss: 1.7228...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11224...  Training loss: 1.7127...  0.0553 sec/batch
Epoch: 19/20...  Training Step: 11225...  Training loss: 1.6635...  0.0536 sec/batch
Epoch: 19/20...  Training Step: 11226...  Training loss: 1.6274...  0.0542 sec/batch
Epoch: 19/20...  Training Step: 11227...  Training loss: 1.6948...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11228...  Training loss: 1.6809...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11229...  Training loss: 1.6955...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11230...  Training loss: 1.7121...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11231...  Training loss: 1.7610...  0.0581 sec/batch
Epoch: 19/20...  Training Step: 11232...  Training loss: 1.7132...  0.0550 sec/batch
Epoch: 19/20...  Training Step: 11233...  Training loss: 1.6618...  0.0542 sec/batch
Epoch: 19/20...  Training Step: 11234...  Training loss: 1.6832...  0.0556 sec/batch
Epoch: 19/20...  Training Step: 11235...  Training loss: 1.7528...  0.0538 sec/batch
Epoch: 19/20...  Training Step: 11236...  Training loss: 1.7301...  0.0555 sec/batch
Epoch: 19/20...  Training Step: 11237...  Training loss: 1.7128...  0.0573 sec/batch
Epoch: 19/20...  Training Step: 11238...  Training loss: 1.6989...  0.0524 sec/batch
Epoch: 19/20...  Training Step: 11239...  Training loss: 1.7264...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11240...  Training loss: 1.7278...  0.0573 sec/batch
Epoch: 19/20...  Training Step: 11241...  Training loss: 1.6492...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11242...  Training loss: 1.7108...  0.0573 sec/batch
Epoch: 19/20...  Training Step: 11243...  Training loss: 1.6686...  0.0584 sec/batch
Epoch: 19/20...  Training Step: 11244...  Training loss: 1.6730...  0.0519 sec/batch
Epoch: 19/20...  Training Step: 11245...  Training loss: 1.6760...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11246...  Training loss: 1.7433...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11247...  Training loss: 1.6726...  0.0558 sec/batch
Epoch: 19/20...  Training Step: 11248...  Training loss: 1.7646...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11249...  Training loss: 1.7105...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11250...  Training loss: 1.7196...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11251...  Training loss: 1.6639...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11252...  Training loss: 1.7444...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11253...  Training loss: 1.7165...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11254...  Training loss: 1.7130...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11255...  Training loss: 1.6970...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11256...  Training loss: 1.7528...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11257...  Training loss: 1.7220...  0.0580 sec/batch
Epoch: 19/20...  Training Step: 11258...  Training loss: 1.6375...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11259...  Training loss: 1.7391...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11260...  Training loss: 1.6738...  0.0580 sec/batch
Epoch: 19/20...  Training Step: 11261...  Training loss: 1.6879...  0.0593 sec/batch
Epoch: 19/20...  Training Step: 11262...  Training loss: 1.6732...  0.0523 sec/batch
Epoch: 19/20...  Training Step: 11263...  Training loss: 1.7543...  0.0532 sec/batch
Epoch: 19/20...  Training Step: 11264...  Training loss: 1.7462...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11265...  Training loss: 1.7250...  0.0557 sec/batch
Epoch: 19/20...  Training Step: 11266...  Training loss: 1.6579...  0.0568 sec/batch
Epoch: 19/20...  Training Step: 11267...  Training loss: 1.7373...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11268...  Training loss: 1.6991...  0.0566 sec/batch
Epoch: 19/20...  Training Step: 11269...  Training loss: 1.7133...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11270...  Training loss: 1.6365...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11271...  Training loss: 1.6717...  0.0559 sec/batch
Epoch: 19/20...  Training Step: 11272...  Training loss: 1.7081...  0.0532 sec/batch
Epoch: 19/20...  Training Step: 11273...  Training loss: 1.6948...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11274...  Training loss: 1.6833...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11275...  Training loss: 1.7503...  0.0520 sec/batch
Epoch: 19/20...  Training Step: 11276...  Training loss: 1.7460...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11277...  Training loss: 1.6725...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11278...  Training loss: 1.7128...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11279...  Training loss: 1.6919...  0.0533 sec/batch
Epoch: 19/20...  Training Step: 11280...  Training loss: 1.6862...  0.0575 sec/batch
Epoch: 19/20...  Training Step: 11281...  Training loss: 1.6684...  0.0539 sec/batch
Epoch: 19/20...  Training Step: 11282...  Training loss: 1.6519...  0.0543 sec/batch
Epoch: 19/20...  Training Step: 11283...  Training loss: 1.6908...  0.0532 sec/batch
Epoch: 19/20...  Training Step: 11284...  Training loss: 1.7287...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11285...  Training loss: 1.7374...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11286...  Training loss: 1.7423...  0.0584 sec/batch
Epoch: 19/20...  Training Step: 11287...  Training loss: 1.7623...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11288...  Training loss: 1.6803...  0.0532 sec/batch
Epoch: 19/20...  Training Step: 11289...  Training loss: 1.6995...  0.0574 sec/batch
Epoch: 19/20...  Training Step: 11290...  Training loss: 1.7674...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11291...  Training loss: 1.7116...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11292...  Training loss: 1.7633...  0.0573 sec/batch
Epoch: 19/20...  Training Step: 11293...  Training loss: 1.7356...  0.0614 sec/batch
Epoch: 19/20...  Training Step: 11294...  Training loss: 1.7023...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11295...  Training loss: 1.6836...  0.0540 sec/batch
Epoch: 19/20...  Training Step: 11296...  Training loss: 1.7093...  0.0576 sec/batch
Epoch: 19/20...  Training Step: 11297...  Training loss: 1.6982...  0.0580 sec/batch
Epoch: 19/20...  Training Step: 11298...  Training loss: 1.7102...  0.0550 sec/batch
Epoch: 19/20...  Training Step: 11299...  Training loss: 1.7597...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11300...  Training loss: 1.7152...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11301...  Training loss: 1.7442...  0.0592 sec/batch
Epoch: 19/20...  Training Step: 11302...  Training loss: 1.6340...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11303...  Training loss: 1.7040...  0.0577 sec/batch
Epoch: 19/20...  Training Step: 11304...  Training loss: 1.6810...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11305...  Training loss: 1.6593...  0.0522 sec/batch
Epoch: 19/20...  Training Step: 11306...  Training loss: 1.7233...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11307...  Training loss: 1.7419...  0.0559 sec/batch
Epoch: 19/20...  Training Step: 11308...  Training loss: 1.6856...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11309...  Training loss: 1.7360...  0.0542 sec/batch
Epoch: 19/20...  Training Step: 11310...  Training loss: 1.7373...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11311...  Training loss: 1.7303...  0.0568 sec/batch
Epoch: 19/20...  Training Step: 11312...  Training loss: 1.6911...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11313...  Training loss: 1.7152...  0.0583 sec/batch
Epoch: 19/20...  Training Step: 11314...  Training loss: 1.7475...  0.0586 sec/batch
Epoch: 19/20...  Training Step: 11315...  Training loss: 1.7144...  0.0556 sec/batch
Epoch: 19/20...  Training Step: 11316...  Training loss: 1.7179...  0.0540 sec/batch
Epoch: 19/20...  Training Step: 11317...  Training loss: 1.7340...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11318...  Training loss: 1.7223...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11319...  Training loss: 1.7036...  0.0580 sec/batch
Epoch: 19/20...  Training Step: 11320...  Training loss: 1.6622...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11321...  Training loss: 1.6724...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11322...  Training loss: 1.6884...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11323...  Training loss: 1.7467...  0.0568 sec/batch
Epoch: 19/20...  Training Step: 11324...  Training loss: 1.7183...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11325...  Training loss: 1.7200...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11326...  Training loss: 1.7147...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11327...  Training loss: 1.7246...  0.0564 sec/batch
Epoch: 19/20...  Training Step: 11328...  Training loss: 1.6997...  0.0550 sec/batch
Epoch: 19/20...  Training Step: 11329...  Training loss: 1.6971...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11330...  Training loss: 1.6771...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11331...  Training loss: 1.6911...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11332...  Training loss: 1.7039...  0.0543 sec/batch
Epoch: 19/20...  Training Step: 11333...  Training loss: 1.7001...  0.0532 sec/batch
Epoch: 19/20...  Training Step: 11334...  Training loss: 1.6782...  0.0574 sec/batch
Epoch: 19/20...  Training Step: 11335...  Training loss: 1.7071...  0.0533 sec/batch
Epoch: 19/20...  Training Step: 11336...  Training loss: 1.6920...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11337...  Training loss: 1.7169...  0.0540 sec/batch
Epoch: 19/20...  Training Step: 11338...  Training loss: 1.6848...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11339...  Training loss: 1.7098...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11340...  Training loss: 1.6748...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11341...  Training loss: 1.6810...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11342...  Training loss: 1.7250...  0.0543 sec/batch
Epoch: 19/20...  Training Step: 11343...  Training loss: 1.7343...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11344...  Training loss: 1.6871...  0.0583 sec/batch
Epoch: 19/20...  Training Step: 11345...  Training loss: 1.6759...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11346...  Training loss: 1.6932...  0.0575 sec/batch
Epoch: 19/20...  Training Step: 11347...  Training loss: 1.7160...  0.0555 sec/batch
Epoch: 19/20...  Training Step: 11348...  Training loss: 1.6968...  0.0554 sec/batch
Epoch: 19/20...  Training Step: 11349...  Training loss: 1.6943...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11350...  Training loss: 1.7598...  0.0541 sec/batch
Epoch: 19/20...  Training Step: 11351...  Training loss: 1.7197...  0.0583 sec/batch
Epoch: 19/20...  Training Step: 11352...  Training loss: 1.7543...  0.0564 sec/batch
Epoch: 19/20...  Training Step: 11353...  Training loss: 1.7155...  0.0553 sec/batch
Epoch: 19/20...  Training Step: 11354...  Training loss: 1.7028...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11355...  Training loss: 1.6979...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11356...  Training loss: 1.7809...  0.0553 sec/batch
Epoch: 19/20...  Training Step: 11357...  Training loss: 1.7060...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11358...  Training loss: 1.7659...  0.0523 sec/batch
Epoch: 19/20...  Training Step: 11359...  Training loss: 1.6972...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11360...  Training loss: 1.7322...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11361...  Training loss: 1.6735...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11362...  Training loss: 1.7194...  0.0533 sec/batch
Epoch: 19/20...  Training Step: 11363...  Training loss: 1.6962...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11364...  Training loss: 1.6977...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11365...  Training loss: 1.6966...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11366...  Training loss: 1.7024...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11367...  Training loss: 1.7343...  0.0588 sec/batch
Epoch: 19/20...  Training Step: 11368...  Training loss: 1.7250...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11369...  Training loss: 1.6750...  0.0558 sec/batch
Epoch: 19/20...  Training Step: 11370...  Training loss: 1.6836...  0.0556 sec/batch
Epoch: 19/20...  Training Step: 11371...  Training loss: 1.7079...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11372...  Training loss: 1.7284...  0.0579 sec/batch
Epoch: 19/20...  Training Step: 11373...  Training loss: 1.7270...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11374...  Training loss: 1.7305...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11375...  Training loss: 1.7429...  0.0575 sec/batch
Epoch: 19/20...  Training Step: 11376...  Training loss: 1.7336...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11377...  Training loss: 1.7315...  0.0540 sec/batch
Epoch: 19/20...  Training Step: 11378...  Training loss: 1.6920...  0.0522 sec/batch
Epoch: 19/20...  Training Step: 11379...  Training loss: 1.7712...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11380...  Training loss: 1.7709...  0.0553 sec/batch
Epoch: 19/20...  Training Step: 11381...  Training loss: 1.7287...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11382...  Training loss: 1.7457...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11383...  Training loss: 1.7697...  0.0538 sec/batch
Epoch: 19/20...  Training Step: 11384...  Training loss: 1.6674...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11385...  Training loss: 1.6827...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11386...  Training loss: 1.7505...  0.0579 sec/batch
Epoch: 19/20...  Training Step: 11387...  Training loss: 1.7508...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11388...  Training loss: 1.6821...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11389...  Training loss: 1.7288...  0.0571 sec/batch
Epoch: 19/20...  Training Step: 11390...  Training loss: 1.6929...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11391...  Training loss: 1.7784...  0.0580 sec/batch
Epoch: 19/20...  Training Step: 11392...  Training loss: 1.6830...  0.0542 sec/batch
Epoch: 19/20...  Training Step: 11393...  Training loss: 1.6687...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11394...  Training loss: 1.7098...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11395...  Training loss: 1.6827...  0.0585 sec/batch
Epoch: 19/20...  Training Step: 11396...  Training loss: 1.7331...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11397...  Training loss: 1.6959...  0.0553 sec/batch
Epoch: 19/20...  Training Step: 11398...  Training loss: 1.6657...  0.0519 sec/batch
Epoch: 19/20...  Training Step: 11399...  Training loss: 1.6928...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11400...  Training loss: 1.6947...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11401...  Training loss: 1.6626...  0.0558 sec/batch
Epoch: 19/20...  Training Step: 11402...  Training loss: 1.6789...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11403...  Training loss: 1.6730...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11404...  Training loss: 1.7074...  0.0550 sec/batch
Epoch: 19/20...  Training Step: 11405...  Training loss: 1.7026...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11406...  Training loss: 1.7090...  0.0521 sec/batch
Epoch: 19/20...  Training Step: 11407...  Training loss: 1.7323...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11408...  Training loss: 1.7253...  0.0524 sec/batch
Epoch: 19/20...  Training Step: 11409...  Training loss: 1.6566...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11410...  Training loss: 1.6850...  0.0522 sec/batch
Epoch: 19/20...  Training Step: 11411...  Training loss: 1.7119...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11412...  Training loss: 1.6754...  0.0522 sec/batch
Epoch: 19/20...  Training Step: 11413...  Training loss: 1.7180...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11414...  Training loss: 1.7077...  0.0573 sec/batch
Epoch: 19/20...  Training Step: 11415...  Training loss: 1.7474...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11416...  Training loss: 1.6854...  0.0584 sec/batch
Epoch: 19/20...  Training Step: 11417...  Training loss: 1.7141...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11418...  Training loss: 1.7173...  0.0534 sec/batch
Epoch: 19/20...  Training Step: 11419...  Training loss: 1.7088...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11420...  Training loss: 1.6948...  0.0532 sec/batch
Epoch: 19/20...  Training Step: 11421...  Training loss: 1.7106...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11422...  Training loss: 1.6713...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11423...  Training loss: 1.7041...  0.0522 sec/batch
Epoch: 19/20...  Training Step: 11424...  Training loss: 1.7089...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11425...  Training loss: 1.7302...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11426...  Training loss: 1.6524...  0.0524 sec/batch
Epoch: 19/20...  Training Step: 11427...  Training loss: 1.7106...  0.0559 sec/batch
Epoch: 19/20...  Training Step: 11428...  Training loss: 1.7047...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11429...  Training loss: 1.6970...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11430...  Training loss: 1.6638...  0.0578 sec/batch
Epoch: 19/20...  Training Step: 11431...  Training loss: 1.6777...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11432...  Training loss: 1.6991...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11433...  Training loss: 1.6806...  0.0553 sec/batch
Epoch: 19/20...  Training Step: 11434...  Training loss: 1.6842...  0.0520 sec/batch
Epoch: 19/20...  Training Step: 11435...  Training loss: 1.7294...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11436...  Training loss: 1.7273...  0.0550 sec/batch
Epoch: 19/20...  Training Step: 11437...  Training loss: 1.8056...  0.0573 sec/batch
Epoch: 19/20...  Training Step: 11438...  Training loss: 1.7264...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11439...  Training loss: 1.7638...  0.0550 sec/batch
Epoch: 19/20...  Training Step: 11440...  Training loss: 1.7572...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11441...  Training loss: 1.7278...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11442...  Training loss: 1.6615...  0.0552 sec/batch
Epoch: 19/20...  Training Step: 11443...  Training loss: 1.6840...  0.0519 sec/batch
Epoch: 19/20...  Training Step: 11444...  Training loss: 1.7342...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11445...  Training loss: 1.7046...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11446...  Training loss: 1.7316...  0.0587 sec/batch
Epoch: 19/20...  Training Step: 11447...  Training loss: 1.7063...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11448...  Training loss: 1.7226...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11449...  Training loss: 1.6936...  0.0543 sec/batch
Epoch: 19/20...  Training Step: 11450...  Training loss: 1.7561...  0.0567 sec/batch
Epoch: 19/20...  Training Step: 11451...  Training loss: 1.7009...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11452...  Training loss: 1.6945...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11453...  Training loss: 1.6758...  0.0567 sec/batch
Epoch: 19/20...  Training Step: 11454...  Training loss: 1.7242...  0.0580 sec/batch
Epoch: 19/20...  Training Step: 11455...  Training loss: 1.6932...  0.0561 sec/batch
Epoch: 19/20...  Training Step: 11456...  Training loss: 1.6560...  0.0581 sec/batch
Epoch: 19/20...  Training Step: 11457...  Training loss: 1.7216...  0.0543 sec/batch
Epoch: 19/20...  Training Step: 11458...  Training loss: 1.7566...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11459...  Training loss: 1.7254...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11460...  Training loss: 1.6739...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11461...  Training loss: 1.7547...  0.0552 sec/batch
Epoch: 19/20...  Training Step: 11462...  Training loss: 1.7825...  0.0560 sec/batch
Epoch: 19/20...  Training Step: 11463...  Training loss: 1.6657...  0.0522 sec/batch
Epoch: 19/20...  Training Step: 11464...  Training loss: 1.7510...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11465...  Training loss: 1.6902...  0.0583 sec/batch
Epoch: 19/20...  Training Step: 11466...  Training loss: 1.6948...  0.0537 sec/batch
Epoch: 19/20...  Training Step: 11467...  Training loss: 1.7242...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11468...  Training loss: 1.7127...  0.0578 sec/batch
Epoch: 19/20...  Training Step: 11469...  Training loss: 1.6796...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11470...  Training loss: 1.6823...  0.0522 sec/batch
Epoch: 19/20...  Training Step: 11471...  Training loss: 1.6806...  0.0533 sec/batch
Epoch: 19/20...  Training Step: 11472...  Training loss: 1.6659...  0.0570 sec/batch
Epoch: 19/20...  Training Step: 11473...  Training loss: 1.6873...  0.0565 sec/batch
Epoch: 19/20...  Training Step: 11474...  Training loss: 1.6474...  0.0532 sec/batch
Epoch: 19/20...  Training Step: 11475...  Training loss: 1.7060...  0.0542 sec/batch
Epoch: 19/20...  Training Step: 11476...  Training loss: 1.7354...  0.0552 sec/batch
Epoch: 19/20...  Training Step: 11477...  Training loss: 1.6775...  0.0543 sec/batch
Epoch: 19/20...  Training Step: 11478...  Training loss: 1.6448...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11479...  Training loss: 1.6918...  0.0561 sec/batch
Epoch: 19/20...  Training Step: 11480...  Training loss: 1.7547...  0.0582 sec/batch
Epoch: 19/20...  Training Step: 11481...  Training loss: 1.6877...  0.0580 sec/batch
Epoch: 19/20...  Training Step: 11482...  Training loss: 1.6383...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11483...  Training loss: 1.6985...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11484...  Training loss: 1.6890...  0.0520 sec/batch
Epoch: 19/20...  Training Step: 11485...  Training loss: 1.6958...  0.0534 sec/batch
Epoch: 19/20...  Training Step: 11486...  Training loss: 1.6996...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11487...  Training loss: 1.6605...  0.0533 sec/batch
Epoch: 19/20...  Training Step: 11488...  Training loss: 1.6734...  0.0560 sec/batch
Epoch: 19/20...  Training Step: 11489...  Training loss: 1.7233...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11490...  Training loss: 1.6774...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11491...  Training loss: 1.7030...  0.0609 sec/batch
Epoch: 19/20...  Training Step: 11492...  Training loss: 1.7007...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11493...  Training loss: 1.7029...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11494...  Training loss: 1.6956...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11495...  Training loss: 1.6964...  0.0524 sec/batch
Epoch: 19/20...  Training Step: 11496...  Training loss: 1.7098...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11497...  Training loss: 1.6552...  0.0543 sec/batch
Epoch: 19/20...  Training Step: 11498...  Training loss: 1.6771...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11499...  Training loss: 1.6665...  0.0553 sec/batch
Epoch: 19/20...  Training Step: 11500...  Training loss: 1.7085...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11501...  Training loss: 1.6982...  0.0522 sec/batch
Epoch: 19/20...  Training Step: 11502...  Training loss: 1.7037...  0.0552 sec/batch
Epoch: 19/20...  Training Step: 11503...  Training loss: 1.6687...  0.0555 sec/batch
Epoch: 19/20...  Training Step: 11504...  Training loss: 1.6901...  0.0543 sec/batch
Epoch: 19/20...  Training Step: 11505...  Training loss: 1.6839...  0.0552 sec/batch
Epoch: 19/20...  Training Step: 11506...  Training loss: 1.6995...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11507...  Training loss: 1.7332...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11508...  Training loss: 1.7318...  0.0577 sec/batch
Epoch: 19/20...  Training Step: 11509...  Training loss: 1.7007...  0.0593 sec/batch
Epoch: 19/20...  Training Step: 11510...  Training loss: 1.6871...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11511...  Training loss: 1.7459...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11512...  Training loss: 1.7036...  0.0574 sec/batch
Epoch: 19/20...  Training Step: 11513...  Training loss: 1.7014...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11514...  Training loss: 1.7016...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11515...  Training loss: 1.6718...  0.0558 sec/batch
Epoch: 19/20...  Training Step: 11516...  Training loss: 1.7745...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11517...  Training loss: 1.8095...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11518...  Training loss: 1.7297...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11519...  Training loss: 1.7128...  0.0523 sec/batch
Epoch: 19/20...  Training Step: 11520...  Training loss: 1.6889...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11521...  Training loss: 1.7410...  0.0542 sec/batch
Epoch: 19/20...  Training Step: 11522...  Training loss: 1.6661...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11523...  Training loss: 1.6550...  0.0575 sec/batch
Epoch: 19/20...  Training Step: 11524...  Training loss: 1.6637...  0.0570 sec/batch
Epoch: 19/20...  Training Step: 11525...  Training loss: 1.7105...  0.0582 sec/batch
Epoch: 19/20...  Training Step: 11526...  Training loss: 1.7135...  0.0522 sec/batch
Epoch: 19/20...  Training Step: 11527...  Training loss: 1.6843...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11528...  Training loss: 1.7411...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11529...  Training loss: 1.7202...  0.0532 sec/batch
Epoch: 19/20...  Training Step: 11530...  Training loss: 1.7038...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11531...  Training loss: 1.6969...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11532...  Training loss: 1.7893...  0.0535 sec/batch
Epoch: 19/20...  Training Step: 11533...  Training loss: 1.7082...  0.0582 sec/batch
Epoch: 19/20...  Training Step: 11534...  Training loss: 1.7069...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11535...  Training loss: 1.6933...  0.0542 sec/batch
Epoch: 19/20...  Training Step: 11536...  Training loss: 1.6943...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11537...  Training loss: 1.6799...  0.0566 sec/batch
Epoch: 19/20...  Training Step: 11538...  Training loss: 1.7536...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11539...  Training loss: 1.7442...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11540...  Training loss: 1.6934...  0.0537 sec/batch
Epoch: 19/20...  Training Step: 11541...  Training loss: 1.6466...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11542...  Training loss: 1.7604...  0.0543 sec/batch
Epoch: 19/20...  Training Step: 11543...  Training loss: 1.6655...  0.0625 sec/batch
Epoch: 19/20...  Training Step: 11544...  Training loss: 1.7131...  0.0523 sec/batch
Epoch: 19/20...  Training Step: 11545...  Training loss: 1.7037...  0.0595 sec/batch
Epoch: 19/20...  Training Step: 11546...  Training loss: 1.6265...  0.0574 sec/batch
Epoch: 19/20...  Training Step: 11547...  Training loss: 1.6341...  0.0532 sec/batch
Epoch: 19/20...  Training Step: 11548...  Training loss: 1.7120...  0.0523 sec/batch
Epoch: 19/20...  Training Step: 11549...  Training loss: 1.6644...  0.0533 sec/batch
Epoch: 19/20...  Training Step: 11550...  Training loss: 1.6836...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11551...  Training loss: 1.7290...  0.0542 sec/batch
Epoch: 19/20...  Training Step: 11552...  Training loss: 1.6692...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11553...  Training loss: 1.7021...  0.0543 sec/batch
Epoch: 19/20...  Training Step: 11554...  Training loss: 1.7363...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11555...  Training loss: 1.6661...  0.0577 sec/batch
Epoch: 19/20...  Training Step: 11556...  Training loss: 1.6952...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11557...  Training loss: 1.6944...  0.0542 sec/batch
Epoch: 19/20...  Training Step: 11558...  Training loss: 1.7124...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11559...  Training loss: 1.6874...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11560...  Training loss: 1.7345...  0.0557 sec/batch
Epoch: 19/20...  Training Step: 11561...  Training loss: 1.7473...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11562...  Training loss: 1.6800...  0.0522 sec/batch
Epoch: 19/20...  Training Step: 11563...  Training loss: 1.6479...  0.0621 sec/batch
Epoch: 19/20...  Training Step: 11564...  Training loss: 1.7285...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11565...  Training loss: 1.7469...  0.0561 sec/batch
Epoch: 19/20...  Training Step: 11566...  Training loss: 1.7463...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11567...  Training loss: 1.7736...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11568...  Training loss: 1.7087...  0.0542 sec/batch
Epoch: 19/20...  Training Step: 11569...  Training loss: 1.7579...  0.0532 sec/batch
Epoch: 19/20...  Training Step: 11570...  Training loss: 1.7511...  0.0524 sec/batch
Epoch: 19/20...  Training Step: 11571...  Training loss: 1.6891...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11572...  Training loss: 1.7144...  0.0591 sec/batch
Epoch: 19/20...  Training Step: 11573...  Training loss: 1.7327...  0.0575 sec/batch
Epoch: 19/20...  Training Step: 11574...  Training loss: 1.7059...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11575...  Training loss: 1.6826...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11576...  Training loss: 1.6577...  0.0534 sec/batch
Epoch: 19/20...  Training Step: 11577...  Training loss: 1.6920...  0.0521 sec/batch
Epoch: 19/20...  Training Step: 11578...  Training loss: 1.7209...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11579...  Training loss: 1.7374...  0.0567 sec/batch
Epoch: 19/20...  Training Step: 11580...  Training loss: 1.6976...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11581...  Training loss: 1.6651...  0.0563 sec/batch
Epoch: 19/20...  Training Step: 11582...  Training loss: 1.6801...  0.0559 sec/batch
Epoch: 19/20...  Training Step: 11583...  Training loss: 1.7269...  0.0561 sec/batch
Epoch: 19/20...  Training Step: 11584...  Training loss: 1.6731...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11585...  Training loss: 1.7392...  0.0552 sec/batch
Epoch: 19/20...  Training Step: 11586...  Training loss: 1.7321...  0.0577 sec/batch
Epoch: 19/20...  Training Step: 11587...  Training loss: 1.6748...  0.0585 sec/batch
Epoch: 19/20...  Training Step: 11588...  Training loss: 1.7304...  0.0542 sec/batch
Epoch: 19/20...  Training Step: 11589...  Training loss: 1.6898...  0.0523 sec/batch
Epoch: 19/20...  Training Step: 11590...  Training loss: 1.6502...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11591...  Training loss: 1.7038...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11592...  Training loss: 1.7546...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11593...  Training loss: 1.7214...  0.0555 sec/batch
Epoch: 19/20...  Training Step: 11594...  Training loss: 1.6763...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11595...  Training loss: 1.6754...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11596...  Training loss: 1.6859...  0.0565 sec/batch
Epoch: 19/20...  Training Step: 11597...  Training loss: 1.6578...  0.0574 sec/batch
Epoch: 19/20...  Training Step: 11598...  Training loss: 1.6695...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11599...  Training loss: 1.6795...  0.0559 sec/batch
Epoch: 19/20...  Training Step: 11600...  Training loss: 1.6670...  0.0587 sec/batch
Epoch: 19/20...  Training Step: 11601...  Training loss: 1.6827...  0.0581 sec/batch
Epoch: 19/20...  Training Step: 11602...  Training loss: 1.7047...  0.0541 sec/batch
Epoch: 19/20...  Training Step: 11603...  Training loss: 1.7176...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11604...  Training loss: 1.7229...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11605...  Training loss: 1.6041...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11606...  Training loss: 1.6996...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11607...  Training loss: 1.6616...  0.0569 sec/batch
Epoch: 19/20...  Training Step: 11608...  Training loss: 1.6541...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11609...  Training loss: 1.7148...  0.0539 sec/batch
Epoch: 19/20...  Training Step: 11610...  Training loss: 1.7419...  0.0521 sec/batch
Epoch: 19/20...  Training Step: 11611...  Training loss: 1.7303...  0.0572 sec/batch
Epoch: 19/20...  Training Step: 11612...  Training loss: 1.7414...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11613...  Training loss: 1.6569...  0.0536 sec/batch
Epoch: 19/20...  Training Step: 11614...  Training loss: 1.7108...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11615...  Training loss: 1.6784...  0.0587 sec/batch
Epoch: 19/20...  Training Step: 11616...  Training loss: 1.7032...  0.0523 sec/batch
Epoch: 19/20...  Training Step: 11617...  Training loss: 1.7004...  0.0542 sec/batch
Epoch: 19/20...  Training Step: 11618...  Training loss: 1.6797...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11619...  Training loss: 1.6865...  0.0522 sec/batch
Epoch: 19/20...  Training Step: 11620...  Training loss: 1.6864...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11621...  Training loss: 1.6488...  0.0558 sec/batch
Epoch: 19/20...  Training Step: 11622...  Training loss: 1.6911...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11623...  Training loss: 1.6617...  0.0541 sec/batch
Epoch: 19/20...  Training Step: 11624...  Training loss: 1.7051...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11625...  Training loss: 1.7273...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11626...  Training loss: 1.7246...  0.0540 sec/batch
Epoch: 19/20...  Training Step: 11627...  Training loss: 1.6890...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11628...  Training loss: 1.7188...  0.0538 sec/batch
Epoch: 19/20...  Training Step: 11629...  Training loss: 1.7067...  0.0579 sec/batch
Epoch: 19/20...  Training Step: 11630...  Training loss: 1.6951...  0.0542 sec/batch
Epoch: 19/20...  Training Step: 11631...  Training loss: 1.7179...  0.0555 sec/batch
Epoch: 19/20...  Training Step: 11632...  Training loss: 1.7091...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11633...  Training loss: 1.6923...  0.0532 sec/batch
Epoch: 19/20...  Training Step: 11634...  Training loss: 1.6413...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11635...  Training loss: 1.7521...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11636...  Training loss: 1.7232...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11637...  Training loss: 1.7182...  0.0577 sec/batch
Epoch: 19/20...  Training Step: 11638...  Training loss: 1.7766...  0.0575 sec/batch
Epoch: 19/20...  Training Step: 11639...  Training loss: 1.6659...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11640...  Training loss: 1.7628...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11641...  Training loss: 1.7125...  0.0571 sec/batch
Epoch: 19/20...  Training Step: 11642...  Training loss: 1.6869...  0.0570 sec/batch
Epoch: 19/20...  Training Step: 11643...  Training loss: 1.7363...  0.0536 sec/batch
Epoch: 19/20...  Training Step: 11644...  Training loss: 1.7216...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11645...  Training loss: 1.7810...  0.0560 sec/batch
Epoch: 19/20...  Training Step: 11646...  Training loss: 1.6903...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11647...  Training loss: 1.7381...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11648...  Training loss: 1.7079...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11649...  Training loss: 1.7133...  0.0566 sec/batch
Epoch: 19/20...  Training Step: 11650...  Training loss: 1.7130...  0.0524 sec/batch
Epoch: 19/20...  Training Step: 11651...  Training loss: 1.7081...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11652...  Training loss: 1.7254...  0.0571 sec/batch
Epoch: 19/20...  Training Step: 11653...  Training loss: 1.6983...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11654...  Training loss: 1.6768...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11655...  Training loss: 1.6600...  0.0553 sec/batch
Epoch: 19/20...  Training Step: 11656...  Training loss: 1.7025...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11657...  Training loss: 1.6840...  0.0553 sec/batch
Epoch: 19/20...  Training Step: 11658...  Training loss: 1.7564...  0.0532 sec/batch
Epoch: 19/20...  Training Step: 11659...  Training loss: 1.6328...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11660...  Training loss: 1.7146...  0.0549 sec/batch
Epoch: 19/20...  Training Step: 11661...  Training loss: 1.6867...  0.0540 sec/batch
Epoch: 19/20...  Training Step: 11662...  Training loss: 1.7144...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11663...  Training loss: 1.7757...  0.0576 sec/batch
Epoch: 19/20...  Training Step: 11664...  Training loss: 1.7221...  0.0539 sec/batch
Epoch: 19/20...  Training Step: 11665...  Training loss: 1.6718...  0.0558 sec/batch
Epoch: 19/20...  Training Step: 11666...  Training loss: 1.6638...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11667...  Training loss: 1.7304...  0.0591 sec/batch
Epoch: 19/20...  Training Step: 11668...  Training loss: 1.6870...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11669...  Training loss: 1.7461...  0.0582 sec/batch
Epoch: 19/20...  Training Step: 11670...  Training loss: 1.7085...  0.0573 sec/batch
Epoch: 19/20...  Training Step: 11671...  Training loss: 1.7481...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11672...  Training loss: 1.7535...  0.0564 sec/batch
Epoch: 19/20...  Training Step: 11673...  Training loss: 1.7526...  0.0584 sec/batch
Epoch: 19/20...  Training Step: 11674...  Training loss: 1.7491...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11675...  Training loss: 1.7131...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11676...  Training loss: 1.7004...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11677...  Training loss: 1.6836...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11678...  Training loss: 1.6866...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11679...  Training loss: 1.6764...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11680...  Training loss: 1.6939...  0.0575 sec/batch
Epoch: 19/20...  Training Step: 11681...  Training loss: 1.7129...  0.0553 sec/batch
Epoch: 19/20...  Training Step: 11682...  Training loss: 1.6715...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11683...  Training loss: 1.7037...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11684...  Training loss: 1.6347...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11685...  Training loss: 1.7209...  0.0597 sec/batch
Epoch: 19/20...  Training Step: 11686...  Training loss: 1.7799...  0.0582 sec/batch
Epoch: 19/20...  Training Step: 11687...  Training loss: 1.7112...  0.0548 sec/batch
Epoch: 19/20...  Training Step: 11688...  Training loss: 1.7181...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11689...  Training loss: 1.7078...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11690...  Training loss: 1.6821...  0.0581 sec/batch
Epoch: 19/20...  Training Step: 11691...  Training loss: 1.6776...  0.0534 sec/batch
Epoch: 19/20...  Training Step: 11692...  Training loss: 1.6827...  0.0589 sec/batch
Epoch: 19/20...  Training Step: 11693...  Training loss: 1.6870...  0.0590 sec/batch
Epoch: 19/20...  Training Step: 11694...  Training loss: 1.7008...  0.0582 sec/batch
Epoch: 19/20...  Training Step: 11695...  Training loss: 1.7141...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11696...  Training loss: 1.7123...  0.0540 sec/batch
Epoch: 19/20...  Training Step: 11697...  Training loss: 1.6446...  0.0558 sec/batch
Epoch: 19/20...  Training Step: 11698...  Training loss: 1.6750...  0.0564 sec/batch
Epoch: 19/20...  Training Step: 11699...  Training loss: 1.6181...  0.0541 sec/batch
Epoch: 19/20...  Training Step: 11700...  Training loss: 1.7104...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11701...  Training loss: 1.7168...  0.0525 sec/batch
Epoch: 19/20...  Training Step: 11702...  Training loss: 1.6936...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11703...  Training loss: 1.6843...  0.0608 sec/batch
Epoch: 19/20...  Training Step: 11704...  Training loss: 1.6641...  0.0579 sec/batch
Epoch: 19/20...  Training Step: 11705...  Training loss: 1.7203...  0.0533 sec/batch
Epoch: 19/20...  Training Step: 11706...  Training loss: 1.7075...  0.0567 sec/batch
Epoch: 19/20...  Training Step: 11707...  Training loss: 1.7413...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11708...  Training loss: 1.7554...  0.0577 sec/batch
Epoch: 19/20...  Training Step: 11709...  Training loss: 1.7582...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11710...  Training loss: 1.6738...  0.0581 sec/batch
Epoch: 19/20...  Training Step: 11711...  Training loss: 1.7217...  0.0565 sec/batch
Epoch: 19/20...  Training Step: 11712...  Training loss: 1.6589...  0.0576 sec/batch
Epoch: 19/20...  Training Step: 11713...  Training loss: 1.7187...  0.0564 sec/batch
Epoch: 19/20...  Training Step: 11714...  Training loss: 1.7187...  0.0580 sec/batch
Epoch: 19/20...  Training Step: 11715...  Training loss: 1.6904...  0.0521 sec/batch
Epoch: 19/20...  Training Step: 11716...  Training loss: 1.6998...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11717...  Training loss: 1.6820...  0.0584 sec/batch
Epoch: 19/20...  Training Step: 11718...  Training loss: 1.6603...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11719...  Training loss: 1.7029...  0.0531 sec/batch
Epoch: 19/20...  Training Step: 11720...  Training loss: 1.6656...  0.0624 sec/batch
Epoch: 19/20...  Training Step: 11721...  Training loss: 1.7621...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11722...  Training loss: 1.7067...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11723...  Training loss: 1.6960...  0.0550 sec/batch
Epoch: 19/20...  Training Step: 11724...  Training loss: 1.7637...  0.0539 sec/batch
Epoch: 19/20...  Training Step: 11725...  Training loss: 1.8060...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11726...  Training loss: 1.7639...  0.0578 sec/batch
Epoch: 19/20...  Training Step: 11727...  Training loss: 1.7027...  0.0564 sec/batch
Epoch: 19/20...  Training Step: 11728...  Training loss: 1.7637...  0.0571 sec/batch
Epoch: 19/20...  Training Step: 11729...  Training loss: 1.6806...  0.0524 sec/batch
Epoch: 19/20...  Training Step: 11730...  Training loss: 1.7217...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11731...  Training loss: 1.7206...  0.0523 sec/batch
Epoch: 19/20...  Training Step: 11732...  Training loss: 1.7716...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11733...  Training loss: 1.7028...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11734...  Training loss: 1.6988...  0.0606 sec/batch
Epoch: 19/20...  Training Step: 11735...  Training loss: 1.7145...  0.0523 sec/batch
Epoch: 19/20...  Training Step: 11736...  Training loss: 1.7433...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11737...  Training loss: 1.6605...  0.0553 sec/batch
Epoch: 19/20...  Training Step: 11738...  Training loss: 1.7135...  0.0520 sec/batch
Epoch: 19/20...  Training Step: 11739...  Training loss: 1.7433...  0.0545 sec/batch
Epoch: 19/20...  Training Step: 11740...  Training loss: 1.7281...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11741...  Training loss: 1.7368...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11742...  Training loss: 1.6997...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11743...  Training loss: 1.7160...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11744...  Training loss: 1.7506...  0.0586 sec/batch
Epoch: 19/20...  Training Step: 11745...  Training loss: 1.7442...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11746...  Training loss: 1.7381...  0.0526 sec/batch
Epoch: 19/20...  Training Step: 11747...  Training loss: 1.6681...  0.0562 sec/batch
Epoch: 19/20...  Training Step: 11748...  Training loss: 1.7139...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11749...  Training loss: 1.6971...  0.0551 sec/batch
Epoch: 19/20...  Training Step: 11750...  Training loss: 1.7375...  0.0537 sec/batch
Epoch: 19/20...  Training Step: 11751...  Training loss: 1.6825...  0.0529 sec/batch
Epoch: 19/20...  Training Step: 11752...  Training loss: 1.7592...  0.0564 sec/batch
Epoch: 19/20...  Training Step: 11753...  Training loss: 1.7225...  0.0547 sec/batch
Epoch: 19/20...  Training Step: 11754...  Training loss: 1.6856...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11755...  Training loss: 1.6886...  0.0523 sec/batch
Epoch: 19/20...  Training Step: 11756...  Training loss: 1.6667...  0.0524 sec/batch
Epoch: 19/20...  Training Step: 11757...  Training loss: 1.6692...  0.0600 sec/batch
Epoch: 19/20...  Training Step: 11758...  Training loss: 1.7035...  0.0543 sec/batch
Epoch: 19/20...  Training Step: 11759...  Training loss: 1.7243...  0.0528 sec/batch
Epoch: 19/20...  Training Step: 11760...  Training loss: 1.7269...  0.0527 sec/batch
Epoch: 19/20...  Training Step: 11761...  Training loss: 1.6720...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11762...  Training loss: 1.6866...  0.0554 sec/batch
Epoch: 19/20...  Training Step: 11763...  Training loss: 1.6878...  0.0550 sec/batch
Epoch: 19/20...  Training Step: 11764...  Training loss: 1.6838...  0.0552 sec/batch
Epoch: 19/20...  Training Step: 11765...  Training loss: 1.6893...  0.0533 sec/batch
Epoch: 19/20...  Training Step: 11766...  Training loss: 1.7194...  0.0544 sec/batch
Epoch: 19/20...  Training Step: 11767...  Training loss: 1.6707...  0.0546 sec/batch
Epoch: 19/20...  Training Step: 11768...  Training loss: 1.6681...  0.0550 sec/batch
Epoch: 19/20...  Training Step: 11769...  Training loss: 1.6868...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11770...  Training loss: 1.7385...  0.0530 sec/batch
Epoch: 19/20...  Training Step: 11771...  Training loss: 1.7724...  0.0539 sec/batch
Epoch: 19/20...  Training Step: 11772...  Training loss: 1.6954...  0.0552 sec/batch
Epoch: 19/20...  Training Step: 11773...  Training loss: 1.6382...  0.0523 sec/batch
Epoch: 19/20...  Training Step: 11774...  Training loss: 1.7159...  0.0532 sec/batch
Epoch: 19/20...  Training Step: 11775...  Training loss: 1.6484...  0.0625 sec/batch
Epoch: 19/20...  Training Step: 11776...  Training loss: 1.7174...  0.0584 sec/batch
Epoch: 19/20...  Training Step: 11777...  Training loss: 1.7394...  0.0553 sec/batch
Epoch: 19/20...  Training Step: 11778...  Training loss: 1.6819...  0.0556 sec/batch
Epoch: 19/20...  Training Step: 11779...  Training loss: 1.6656...  0.0533 sec/batch
Epoch: 19/20...  Training Step: 11780...  Training loss: 1.6610...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 11781...  Training loss: 1.7724...  0.0579 sec/batch
Epoch: 20/20...  Training Step: 11782...  Training loss: 1.7656...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 11783...  Training loss: 1.7636...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 11784...  Training loss: 1.6728...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 11785...  Training loss: 1.6997...  0.0537 sec/batch
Epoch: 20/20...  Training Step: 11786...  Training loss: 1.7201...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 11787...  Training loss: 1.6862...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 11788...  Training loss: 1.6463...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 11789...  Training loss: 1.6416...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 11790...  Training loss: 1.6680...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 11791...  Training loss: 1.7121...  0.0543 sec/batch
Epoch: 20/20...  Training Step: 11792...  Training loss: 1.6696...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 11793...  Training loss: 1.7136...  0.0556 sec/batch
Epoch: 20/20...  Training Step: 11794...  Training loss: 1.6564...  0.0575 sec/batch
Epoch: 20/20...  Training Step: 11795...  Training loss: 1.7255...  0.0521 sec/batch
Epoch: 20/20...  Training Step: 11796...  Training loss: 1.7465...  0.0577 sec/batch
Epoch: 20/20...  Training Step: 11797...  Training loss: 1.7343...  0.0533 sec/batch
Epoch: 20/20...  Training Step: 11798...  Training loss: 1.6957...  0.0541 sec/batch
Epoch: 20/20...  Training Step: 11799...  Training loss: 1.6696...  0.0532 sec/batch
Epoch: 20/20...  Training Step: 11800...  Training loss: 1.7134...  0.0578 sec/batch
Epoch: 20/20...  Training Step: 11801...  Training loss: 1.7534...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 11802...  Training loss: 1.6894...  0.0570 sec/batch
Epoch: 20/20...  Training Step: 11803...  Training loss: 1.6731...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 11804...  Training loss: 1.7090...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 11805...  Training loss: 1.6725...  0.0531 sec/batch
Epoch: 20/20...  Training Step: 11806...  Training loss: 1.6607...  0.0570 sec/batch
Epoch: 20/20...  Training Step: 11807...  Training loss: 1.6728...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 11808...  Training loss: 1.7285...  0.0554 sec/batch
Epoch: 20/20...  Training Step: 11809...  Training loss: 1.7119...  0.0565 sec/batch
Epoch: 20/20...  Training Step: 11810...  Training loss: 1.6665...  0.0558 sec/batch
Epoch: 20/20...  Training Step: 11811...  Training loss: 1.6702...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 11812...  Training loss: 1.7139...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 11813...  Training loss: 1.6958...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 11814...  Training loss: 1.6761...  0.0584 sec/batch
Epoch: 20/20...  Training Step: 11815...  Training loss: 1.6808...  0.0560 sec/batch
Epoch: 20/20...  Training Step: 11816...  Training loss: 1.7087...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 11817...  Training loss: 1.7131...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 11818...  Training loss: 1.7172...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 11819...  Training loss: 1.7361...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 11820...  Training loss: 1.6715...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 11821...  Training loss: 1.7041...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 11822...  Training loss: 1.7281...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 11823...  Training loss: 1.7150...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 11824...  Training loss: 1.7346...  0.0612 sec/batch
Epoch: 20/20...  Training Step: 11825...  Training loss: 1.6969...  0.0578 sec/batch
Epoch: 20/20...  Training Step: 11826...  Training loss: 1.6876...  0.0573 sec/batch
Epoch: 20/20...  Training Step: 11827...  Training loss: 1.5924...  0.0580 sec/batch
Epoch: 20/20...  Training Step: 11828...  Training loss: 1.7064...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 11829...  Training loss: 1.6611...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 11830...  Training loss: 1.7163...  0.0604 sec/batch
Epoch: 20/20...  Training Step: 11831...  Training loss: 1.6707...  0.0572 sec/batch
Epoch: 20/20...  Training Step: 11832...  Training loss: 1.6767...  0.0570 sec/batch
Epoch: 20/20...  Training Step: 11833...  Training loss: 1.6925...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 11834...  Training loss: 1.7175...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 11835...  Training loss: 1.6995...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 11836...  Training loss: 1.7081...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 11837...  Training loss: 1.6693...  0.0562 sec/batch
Epoch: 20/20...  Training Step: 11838...  Training loss: 1.7094...  0.0531 sec/batch
Epoch: 20/20...  Training Step: 11839...  Training loss: 1.6887...  0.0536 sec/batch
Epoch: 20/20...  Training Step: 11840...  Training loss: 1.7360...  0.0566 sec/batch
Epoch: 20/20...  Training Step: 11841...  Training loss: 1.6812...  0.0597 sec/batch
Epoch: 20/20...  Training Step: 11842...  Training loss: 1.6752...  0.0571 sec/batch
Epoch: 20/20...  Training Step: 11843...  Training loss: 1.7299...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 11844...  Training loss: 1.7026...  0.0550 sec/batch
Epoch: 20/20...  Training Step: 11845...  Training loss: 1.6586...  0.0580 sec/batch
Epoch: 20/20...  Training Step: 11846...  Training loss: 1.6222...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 11847...  Training loss: 1.6644...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 11848...  Training loss: 1.6784...  0.0532 sec/batch
Epoch: 20/20...  Training Step: 11849...  Training loss: 1.6930...  0.0571 sec/batch
Epoch: 20/20...  Training Step: 11850...  Training loss: 1.6978...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 11851...  Training loss: 1.7596...  0.0522 sec/batch
Epoch: 20/20...  Training Step: 11852...  Training loss: 1.6985...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 11853...  Training loss: 1.6312...  0.0589 sec/batch
Epoch: 20/20...  Training Step: 11854...  Training loss: 1.6715...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 11855...  Training loss: 1.7388...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 11856...  Training loss: 1.7239...  0.0562 sec/batch
Epoch: 20/20...  Training Step: 11857...  Training loss: 1.7197...  0.0557 sec/batch
Epoch: 20/20...  Training Step: 11858...  Training loss: 1.6595...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 11859...  Training loss: 1.6972...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 11860...  Training loss: 1.7365...  0.0585 sec/batch
Epoch: 20/20...  Training Step: 11861...  Training loss: 1.6064...  0.0559 sec/batch
Epoch: 20/20...  Training Step: 11862...  Training loss: 1.6835...  0.0519 sec/batch
Epoch: 20/20...  Training Step: 11863...  Training loss: 1.6585...  0.0536 sec/batch
Epoch: 20/20...  Training Step: 11864...  Training loss: 1.6888...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 11865...  Training loss: 1.6885...  0.0535 sec/batch
Epoch: 20/20...  Training Step: 11866...  Training loss: 1.7329...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 11867...  Training loss: 1.6622...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 11868...  Training loss: 1.7370...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 11869...  Training loss: 1.6973...  0.0565 sec/batch
Epoch: 20/20...  Training Step: 11870...  Training loss: 1.7133...  0.0543 sec/batch
Epoch: 20/20...  Training Step: 11871...  Training loss: 1.6499...  0.0547 sec/batch
Epoch: 20/20...  Training Step: 11872...  Training loss: 1.7546...  0.0535 sec/batch
Epoch: 20/20...  Training Step: 11873...  Training loss: 1.6930...  0.0541 sec/batch
Epoch: 20/20...  Training Step: 11874...  Training loss: 1.7208...  0.0565 sec/batch
Epoch: 20/20...  Training Step: 11875...  Training loss: 1.6988...  0.0547 sec/batch
Epoch: 20/20...  Training Step: 11876...  Training loss: 1.7161...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 11877...  Training loss: 1.7146...  0.0587 sec/batch
Epoch: 20/20...  Training Step: 11878...  Training loss: 1.6353...  0.0563 sec/batch
Epoch: 20/20...  Training Step: 11879...  Training loss: 1.7216...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 11880...  Training loss: 1.6886...  0.0543 sec/batch
Epoch: 20/20...  Training Step: 11881...  Training loss: 1.6784...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 11882...  Training loss: 1.6654...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 11883...  Training loss: 1.7326...  0.0554 sec/batch
Epoch: 20/20...  Training Step: 11884...  Training loss: 1.7540...  0.0518 sec/batch
Epoch: 20/20...  Training Step: 11885...  Training loss: 1.7168...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 11886...  Training loss: 1.6505...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 11887...  Training loss: 1.7294...  0.0521 sec/batch
Epoch: 20/20...  Training Step: 11888...  Training loss: 1.7190...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 11889...  Training loss: 1.7028...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 11890...  Training loss: 1.6637...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 11891...  Training loss: 1.6531...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 11892...  Training loss: 1.6809...  0.0552 sec/batch
Epoch: 20/20...  Training Step: 11893...  Training loss: 1.6744...  0.0541 sec/batch
Epoch: 20/20...  Training Step: 11894...  Training loss: 1.6764...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 11895...  Training loss: 1.7321...  0.0541 sec/batch
Epoch: 20/20...  Training Step: 11896...  Training loss: 1.7441...  0.0578 sec/batch
Epoch: 20/20...  Training Step: 11897...  Training loss: 1.6627...  0.0531 sec/batch
Epoch: 20/20...  Training Step: 11898...  Training loss: 1.7351...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 11899...  Training loss: 1.7061...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 11900...  Training loss: 1.6930...  0.0523 sec/batch
Epoch: 20/20...  Training Step: 11901...  Training loss: 1.6593...  0.0553 sec/batch
Epoch: 20/20...  Training Step: 11902...  Training loss: 1.6561...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 11903...  Training loss: 1.6939...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 11904...  Training loss: 1.7104...  0.0554 sec/batch
Epoch: 20/20...  Training Step: 11905...  Training loss: 1.7250...  0.0565 sec/batch
Epoch: 20/20...  Training Step: 11906...  Training loss: 1.7386...  0.0570 sec/batch
Epoch: 20/20...  Training Step: 11907...  Training loss: 1.7410...  0.0585 sec/batch
Epoch: 20/20...  Training Step: 11908...  Training loss: 1.6836...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 11909...  Training loss: 1.7034...  0.0580 sec/batch
Epoch: 20/20...  Training Step: 11910...  Training loss: 1.7405...  0.0531 sec/batch
Epoch: 20/20...  Training Step: 11911...  Training loss: 1.7159...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 11912...  Training loss: 1.7367...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 11913...  Training loss: 1.7584...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 11914...  Training loss: 1.7043...  0.0578 sec/batch
Epoch: 20/20...  Training Step: 11915...  Training loss: 1.6647...  0.0543 sec/batch
Epoch: 20/20...  Training Step: 11916...  Training loss: 1.6928...  0.0522 sec/batch
Epoch: 20/20...  Training Step: 11917...  Training loss: 1.7108...  0.0554 sec/batch
Epoch: 20/20...  Training Step: 11918...  Training loss: 1.7000...  0.0557 sec/batch
Epoch: 20/20...  Training Step: 11919...  Training loss: 1.7342...  0.0578 sec/batch
Epoch: 20/20...  Training Step: 11920...  Training loss: 1.7303...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 11921...  Training loss: 1.7344...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 11922...  Training loss: 1.6122...  0.0574 sec/batch
Epoch: 20/20...  Training Step: 11923...  Training loss: 1.7212...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 11924...  Training loss: 1.6896...  0.0565 sec/batch
Epoch: 20/20...  Training Step: 11925...  Training loss: 1.6242...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 11926...  Training loss: 1.7467...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 11927...  Training loss: 1.7262...  0.0521 sec/batch
Epoch: 20/20...  Training Step: 11928...  Training loss: 1.7142...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 11929...  Training loss: 1.7063...  0.0543 sec/batch
Epoch: 20/20...  Training Step: 11930...  Training loss: 1.7384...  0.0554 sec/batch
Epoch: 20/20...  Training Step: 11931...  Training loss: 1.7279...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 11932...  Training loss: 1.6826...  0.0623 sec/batch
Epoch: 20/20...  Training Step: 11933...  Training loss: 1.7067...  0.0533 sec/batch
Epoch: 20/20...  Training Step: 11934...  Training loss: 1.7569...  0.0560 sec/batch
Epoch: 20/20...  Training Step: 11935...  Training loss: 1.6788...  0.0587 sec/batch
Epoch: 20/20...  Training Step: 11936...  Training loss: 1.7067...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 11937...  Training loss: 1.6982...  0.0588 sec/batch
Epoch: 20/20...  Training Step: 11938...  Training loss: 1.7157...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 11939...  Training loss: 1.6928...  0.0561 sec/batch
Epoch: 20/20...  Training Step: 11940...  Training loss: 1.6660...  0.0583 sec/batch
Epoch: 20/20...  Training Step: 11941...  Training loss: 1.6799...  0.0539 sec/batch
Epoch: 20/20...  Training Step: 11942...  Training loss: 1.6668...  0.0555 sec/batch
Epoch: 20/20...  Training Step: 11943...  Training loss: 1.7246...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 11944...  Training loss: 1.6840...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 11945...  Training loss: 1.7255...  0.0534 sec/batch
Epoch: 20/20...  Training Step: 11946...  Training loss: 1.7077...  0.0582 sec/batch
Epoch: 20/20...  Training Step: 11947...  Training loss: 1.6939...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 11948...  Training loss: 1.6829...  0.0550 sec/batch
Epoch: 20/20...  Training Step: 11949...  Training loss: 1.6862...  0.0590 sec/batch
Epoch: 20/20...  Training Step: 11950...  Training loss: 1.6643...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 11951...  Training loss: 1.6785...  0.0533 sec/batch
Epoch: 20/20...  Training Step: 11952...  Training loss: 1.7086...  0.0540 sec/batch
Epoch: 20/20...  Training Step: 11953...  Training loss: 1.6955...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 11954...  Training loss: 1.6673...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 11955...  Training loss: 1.6727...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 11956...  Training loss: 1.7019...  0.0543 sec/batch
Epoch: 20/20...  Training Step: 11957...  Training loss: 1.6966...  0.0533 sec/batch
Epoch: 20/20...  Training Step: 11958...  Training loss: 1.6639...  0.0543 sec/batch
Epoch: 20/20...  Training Step: 11959...  Training loss: 1.6561...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 11960...  Training loss: 1.6498...  0.0522 sec/batch
Epoch: 20/20...  Training Step: 11961...  Training loss: 1.6635...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 11962...  Training loss: 1.7366...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 11963...  Training loss: 1.7184...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 11964...  Training loss: 1.6661...  0.0555 sec/batch
Epoch: 20/20...  Training Step: 11965...  Training loss: 1.6556...  0.0533 sec/batch
Epoch: 20/20...  Training Step: 11966...  Training loss: 1.7013...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 11967...  Training loss: 1.7274...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 11968...  Training loss: 1.6698...  0.0579 sec/batch
Epoch: 20/20...  Training Step: 11969...  Training loss: 1.7075...  0.0569 sec/batch
Epoch: 20/20...  Training Step: 11970...  Training loss: 1.7529...  0.0547 sec/batch
Epoch: 20/20...  Training Step: 11971...  Training loss: 1.7054...  0.0618 sec/batch
Epoch: 20/20...  Training Step: 11972...  Training loss: 1.7362...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 11973...  Training loss: 1.7077...  0.0563 sec/batch
Epoch: 20/20...  Training Step: 11974...  Training loss: 1.6844...  0.0558 sec/batch
Epoch: 20/20...  Training Step: 11975...  Training loss: 1.6954...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 11976...  Training loss: 1.7733...  0.0539 sec/batch
Epoch: 20/20...  Training Step: 11977...  Training loss: 1.7167...  0.0552 sec/batch
Epoch: 20/20...  Training Step: 11978...  Training loss: 1.7720...  0.0520 sec/batch
Epoch: 20/20...  Training Step: 11979...  Training loss: 1.6932...  0.0575 sec/batch
Epoch: 20/20...  Training Step: 11980...  Training loss: 1.7355...  0.0550 sec/batch
Epoch: 20/20...  Training Step: 11981...  Training loss: 1.6759...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 11982...  Training loss: 1.6869...  0.0553 sec/batch
Epoch: 20/20...  Training Step: 11983...  Training loss: 1.7020...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 11984...  Training loss: 1.6842...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 11985...  Training loss: 1.7028...  0.0523 sec/batch
Epoch: 20/20...  Training Step: 11986...  Training loss: 1.6886...  0.0567 sec/batch
Epoch: 20/20...  Training Step: 11987...  Training loss: 1.7166...  0.0563 sec/batch
Epoch: 20/20...  Training Step: 11988...  Training loss: 1.7189...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 11989...  Training loss: 1.6862...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 11990...  Training loss: 1.6850...  0.0561 sec/batch
Epoch: 20/20...  Training Step: 11991...  Training loss: 1.6928...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 11992...  Training loss: 1.7037...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 11993...  Training loss: 1.7252...  0.0562 sec/batch
Epoch: 20/20...  Training Step: 11994...  Training loss: 1.7424...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 11995...  Training loss: 1.7304...  0.0550 sec/batch
Epoch: 20/20...  Training Step: 11996...  Training loss: 1.7253...  0.0557 sec/batch
Epoch: 20/20...  Training Step: 11997...  Training loss: 1.7235...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 11998...  Training loss: 1.6603...  0.0522 sec/batch
Epoch: 20/20...  Training Step: 11999...  Training loss: 1.7814...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 12000...  Training loss: 1.7521...  0.0580 sec/batch
Epoch: 20/20...  Training Step: 12001...  Training loss: 1.7320...  0.0540 sec/batch
Epoch: 20/20...  Training Step: 12002...  Training loss: 1.7335...  0.0523 sec/batch
Epoch: 20/20...  Training Step: 12003...  Training loss: 1.7629...  0.0563 sec/batch
Epoch: 20/20...  Training Step: 12004...  Training loss: 1.6746...  0.0523 sec/batch
Epoch: 20/20...  Training Step: 12005...  Training loss: 1.6822...  0.0559 sec/batch
Epoch: 20/20...  Training Step: 12006...  Training loss: 1.7326...  0.0581 sec/batch
Epoch: 20/20...  Training Step: 12007...  Training loss: 1.7421...  0.0522 sec/batch
Epoch: 20/20...  Training Step: 12008...  Training loss: 1.6749...  0.0585 sec/batch
Epoch: 20/20...  Training Step: 12009...  Training loss: 1.7202...  0.0588 sec/batch
Epoch: 20/20...  Training Step: 12010...  Training loss: 1.6909...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12011...  Training loss: 1.7724...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 12012...  Training loss: 1.6724...  0.0568 sec/batch
Epoch: 20/20...  Training Step: 12013...  Training loss: 1.6679...  0.0593 sec/batch
Epoch: 20/20...  Training Step: 12014...  Training loss: 1.7043...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12015...  Training loss: 1.6443...  0.0543 sec/batch
Epoch: 20/20...  Training Step: 12016...  Training loss: 1.7286...  0.0539 sec/batch
Epoch: 20/20...  Training Step: 12017...  Training loss: 1.6884...  0.0600 sec/batch
Epoch: 20/20...  Training Step: 12018...  Training loss: 1.6443...  0.0584 sec/batch
Epoch: 20/20...  Training Step: 12019...  Training loss: 1.6845...  0.0564 sec/batch
Epoch: 20/20...  Training Step: 12020...  Training loss: 1.6887...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 12021...  Training loss: 1.6475...  0.0590 sec/batch
Epoch: 20/20...  Training Step: 12022...  Training loss: 1.6540...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12023...  Training loss: 1.6631...  0.0520 sec/batch
Epoch: 20/20...  Training Step: 12024...  Training loss: 1.6895...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12025...  Training loss: 1.7156...  0.0523 sec/batch
Epoch: 20/20...  Training Step: 12026...  Training loss: 1.7140...  0.0531 sec/batch
Epoch: 20/20...  Training Step: 12027...  Training loss: 1.7238...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12028...  Training loss: 1.7047...  0.0532 sec/batch
Epoch: 20/20...  Training Step: 12029...  Training loss: 1.6654...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12030...  Training loss: 1.6903...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 12031...  Training loss: 1.7076...  0.0582 sec/batch
Epoch: 20/20...  Training Step: 12032...  Training loss: 1.6693...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 12033...  Training loss: 1.7155...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12034...  Training loss: 1.6926...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 12035...  Training loss: 1.7618...  0.0555 sec/batch
Epoch: 20/20...  Training Step: 12036...  Training loss: 1.6839...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 12037...  Training loss: 1.6856...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 12038...  Training loss: 1.6692...  0.0575 sec/batch
Epoch: 20/20...  Training Step: 12039...  Training loss: 1.6998...  0.0533 sec/batch
Epoch: 20/20...  Training Step: 12040...  Training loss: 1.7077...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 12041...  Training loss: 1.7253...  0.0584 sec/batch
Epoch: 20/20...  Training Step: 12042...  Training loss: 1.6555...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 12043...  Training loss: 1.7224...  0.0540 sec/batch
Epoch: 20/20...  Training Step: 12044...  Training loss: 1.6895...  0.0570 sec/batch
Epoch: 20/20...  Training Step: 12045...  Training loss: 1.7212...  0.0553 sec/batch
Epoch: 20/20...  Training Step: 12046...  Training loss: 1.6674...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 12047...  Training loss: 1.6870...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 12048...  Training loss: 1.7067...  0.0547 sec/batch
Epoch: 20/20...  Training Step: 12049...  Training loss: 1.7006...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12050...  Training loss: 1.6710...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 12051...  Training loss: 1.6545...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 12052...  Training loss: 1.6967...  0.0554 sec/batch
Epoch: 20/20...  Training Step: 12053...  Training loss: 1.6901...  0.0559 sec/batch
Epoch: 20/20...  Training Step: 12054...  Training loss: 1.6867...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 12055...  Training loss: 1.7093...  0.0552 sec/batch
Epoch: 20/20...  Training Step: 12056...  Training loss: 1.7152...  0.0522 sec/batch
Epoch: 20/20...  Training Step: 12057...  Training loss: 1.8003...  0.0556 sec/batch
Epoch: 20/20...  Training Step: 12058...  Training loss: 1.7220...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 12059...  Training loss: 1.7499...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 12060...  Training loss: 1.7343...  0.0522 sec/batch
Epoch: 20/20...  Training Step: 12061...  Training loss: 1.7266...  0.0541 sec/batch
Epoch: 20/20...  Training Step: 12062...  Training loss: 1.6363...  0.0520 sec/batch
Epoch: 20/20...  Training Step: 12063...  Training loss: 1.6534...  0.0552 sec/batch
Epoch: 20/20...  Training Step: 12064...  Training loss: 1.7243...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 12065...  Training loss: 1.6800...  0.0523 sec/batch
Epoch: 20/20...  Training Step: 12066...  Training loss: 1.7033...  0.0578 sec/batch
Epoch: 20/20...  Training Step: 12067...  Training loss: 1.6876...  0.0522 sec/batch
Epoch: 20/20...  Training Step: 12068...  Training loss: 1.6940...  0.0552 sec/batch
Epoch: 20/20...  Training Step: 12069...  Training loss: 1.7125...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12070...  Training loss: 1.7197...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 12071...  Training loss: 1.6721...  0.0570 sec/batch
Epoch: 20/20...  Training Step: 12072...  Training loss: 1.7023...  0.0595 sec/batch
Epoch: 20/20...  Training Step: 12073...  Training loss: 1.6732...  0.0535 sec/batch
Epoch: 20/20...  Training Step: 12074...  Training loss: 1.7116...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 12075...  Training loss: 1.6876...  0.0543 sec/batch
Epoch: 20/20...  Training Step: 12076...  Training loss: 1.6357...  0.0521 sec/batch
Epoch: 20/20...  Training Step: 12077...  Training loss: 1.7213...  0.0565 sec/batch
Epoch: 20/20...  Training Step: 12078...  Training loss: 1.7450...  0.0584 sec/batch
Epoch: 20/20...  Training Step: 12079...  Training loss: 1.7378...  0.0533 sec/batch
Epoch: 20/20...  Training Step: 12080...  Training loss: 1.6735...  0.0610 sec/batch
Epoch: 20/20...  Training Step: 12081...  Training loss: 1.7282...  0.0535 sec/batch
Epoch: 20/20...  Training Step: 12082...  Training loss: 1.7866...  0.0532 sec/batch
Epoch: 20/20...  Training Step: 12083...  Training loss: 1.6601...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12084...  Training loss: 1.7734...  0.0553 sec/batch
Epoch: 20/20...  Training Step: 12085...  Training loss: 1.6879...  0.0560 sec/batch
Epoch: 20/20...  Training Step: 12086...  Training loss: 1.6917...  0.0532 sec/batch
Epoch: 20/20...  Training Step: 12087...  Training loss: 1.7150...  0.0543 sec/batch
Epoch: 20/20...  Training Step: 12088...  Training loss: 1.6820...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 12089...  Training loss: 1.6878...  0.0552 sec/batch
Epoch: 20/20...  Training Step: 12090...  Training loss: 1.6546...  0.0567 sec/batch
Epoch: 20/20...  Training Step: 12091...  Training loss: 1.6427...  0.0579 sec/batch
Epoch: 20/20...  Training Step: 12092...  Training loss: 1.6675...  0.0520 sec/batch
Epoch: 20/20...  Training Step: 12093...  Training loss: 1.6625...  0.0559 sec/batch
Epoch: 20/20...  Training Step: 12094...  Training loss: 1.6514...  0.0557 sec/batch
Epoch: 20/20...  Training Step: 12095...  Training loss: 1.6661...  0.0585 sec/batch
Epoch: 20/20...  Training Step: 12096...  Training loss: 1.7358...  0.0574 sec/batch
Epoch: 20/20...  Training Step: 12097...  Training loss: 1.6663...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12098...  Training loss: 1.6481...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 12099...  Training loss: 1.6595...  0.0531 sec/batch
Epoch: 20/20...  Training Step: 12100...  Training loss: 1.7479...  0.0541 sec/batch
Epoch: 20/20...  Training Step: 12101...  Training loss: 1.6960...  0.0570 sec/batch
Epoch: 20/20...  Training Step: 12102...  Training loss: 1.6513...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 12103...  Training loss: 1.6961...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 12104...  Training loss: 1.6962...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 12105...  Training loss: 1.6790...  0.0543 sec/batch
Epoch: 20/20...  Training Step: 12106...  Training loss: 1.6916...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12107...  Training loss: 1.6654...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12108...  Training loss: 1.6700...  0.0535 sec/batch
Epoch: 20/20...  Training Step: 12109...  Training loss: 1.6985...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 12110...  Training loss: 1.6914...  0.0554 sec/batch
Epoch: 20/20...  Training Step: 12111...  Training loss: 1.6636...  0.0583 sec/batch
Epoch: 20/20...  Training Step: 12112...  Training loss: 1.6842...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12113...  Training loss: 1.6750...  0.0578 sec/batch
Epoch: 20/20...  Training Step: 12114...  Training loss: 1.6938...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 12115...  Training loss: 1.6806...  0.0572 sec/batch
Epoch: 20/20...  Training Step: 12116...  Training loss: 1.6977...  0.0570 sec/batch
Epoch: 20/20...  Training Step: 12117...  Training loss: 1.6552...  0.0564 sec/batch
Epoch: 20/20...  Training Step: 12118...  Training loss: 1.6697...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 12119...  Training loss: 1.6389...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12120...  Training loss: 1.6794...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 12121...  Training loss: 1.7102...  0.0593 sec/batch
Epoch: 20/20...  Training Step: 12122...  Training loss: 1.6937...  0.0541 sec/batch
Epoch: 20/20...  Training Step: 12123...  Training loss: 1.6542...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 12124...  Training loss: 1.6717...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 12125...  Training loss: 1.6913...  0.0564 sec/batch
Epoch: 20/20...  Training Step: 12126...  Training loss: 1.7009...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 12127...  Training loss: 1.7266...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 12128...  Training loss: 1.6994...  0.0550 sec/batch
Epoch: 20/20...  Training Step: 12129...  Training loss: 1.6949...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 12130...  Training loss: 1.6923...  0.0521 sec/batch
Epoch: 20/20...  Training Step: 12131...  Training loss: 1.7241...  0.0577 sec/batch
Epoch: 20/20...  Training Step: 12132...  Training loss: 1.7066...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12133...  Training loss: 1.7189...  0.0547 sec/batch
Epoch: 20/20...  Training Step: 12134...  Training loss: 1.6629...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 12135...  Training loss: 1.6702...  0.0531 sec/batch
Epoch: 20/20...  Training Step: 12136...  Training loss: 1.7342...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 12137...  Training loss: 1.7905...  0.0567 sec/batch
Epoch: 20/20...  Training Step: 12138...  Training loss: 1.7437...  0.0552 sec/batch
Epoch: 20/20...  Training Step: 12139...  Training loss: 1.6889...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12140...  Training loss: 1.6852...  0.0550 sec/batch
Epoch: 20/20...  Training Step: 12141...  Training loss: 1.7394...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12142...  Training loss: 1.6574...  0.0553 sec/batch
Epoch: 20/20...  Training Step: 12143...  Training loss: 1.6571...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12144...  Training loss: 1.6531...  0.0533 sec/batch
Epoch: 20/20...  Training Step: 12145...  Training loss: 1.6885...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12146...  Training loss: 1.6750...  0.0580 sec/batch
Epoch: 20/20...  Training Step: 12147...  Training loss: 1.6774...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 12148...  Training loss: 1.7154...  0.0550 sec/batch
Epoch: 20/20...  Training Step: 12149...  Training loss: 1.7216...  0.0563 sec/batch
Epoch: 20/20...  Training Step: 12150...  Training loss: 1.6881...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 12151...  Training loss: 1.6952...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12152...  Training loss: 1.7714...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12153...  Training loss: 1.7238...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 12154...  Training loss: 1.6908...  0.0573 sec/batch
Epoch: 20/20...  Training Step: 12155...  Training loss: 1.6851...  0.0547 sec/batch
Epoch: 20/20...  Training Step: 12156...  Training loss: 1.6715...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12157...  Training loss: 1.6519...  0.0540 sec/batch
Epoch: 20/20...  Training Step: 12158...  Training loss: 1.7652...  0.0521 sec/batch
Epoch: 20/20...  Training Step: 12159...  Training loss: 1.7206...  0.0584 sec/batch
Epoch: 20/20...  Training Step: 12160...  Training loss: 1.6788...  0.0547 sec/batch
Epoch: 20/20...  Training Step: 12161...  Training loss: 1.6252...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 12162...  Training loss: 1.7640...  0.0580 sec/batch
Epoch: 20/20...  Training Step: 12163...  Training loss: 1.6709...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 12164...  Training loss: 1.6999...  0.0582 sec/batch
Epoch: 20/20...  Training Step: 12165...  Training loss: 1.7134...  0.0532 sec/batch
Epoch: 20/20...  Training Step: 12166...  Training loss: 1.6021...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 12167...  Training loss: 1.6300...  0.0578 sec/batch
Epoch: 20/20...  Training Step: 12168...  Training loss: 1.7262...  0.0568 sec/batch
Epoch: 20/20...  Training Step: 12169...  Training loss: 1.6742...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12170...  Training loss: 1.6671...  0.0539 sec/batch
Epoch: 20/20...  Training Step: 12171...  Training loss: 1.7126...  0.0547 sec/batch
Epoch: 20/20...  Training Step: 12172...  Training loss: 1.6445...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12173...  Training loss: 1.6696...  0.0555 sec/batch
Epoch: 20/20...  Training Step: 12174...  Training loss: 1.7289...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 12175...  Training loss: 1.6702...  0.0559 sec/batch
Epoch: 20/20...  Training Step: 12176...  Training loss: 1.7210...  0.0559 sec/batch
Epoch: 20/20...  Training Step: 12177...  Training loss: 1.6678...  0.0552 sec/batch
Epoch: 20/20...  Training Step: 12178...  Training loss: 1.7001...  0.0520 sec/batch
Epoch: 20/20...  Training Step: 12179...  Training loss: 1.6485...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 12180...  Training loss: 1.7270...  0.0609 sec/batch
Epoch: 20/20...  Training Step: 12181...  Training loss: 1.7493...  0.0533 sec/batch
Epoch: 20/20...  Training Step: 12182...  Training loss: 1.6981...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 12183...  Training loss: 1.6714...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12184...  Training loss: 1.7245...  0.0550 sec/batch
Epoch: 20/20...  Training Step: 12185...  Training loss: 1.7569...  0.0581 sec/batch
Epoch: 20/20...  Training Step: 12186...  Training loss: 1.7252...  0.0577 sec/batch
Epoch: 20/20...  Training Step: 12187...  Training loss: 1.7360...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 12188...  Training loss: 1.7083...  0.0521 sec/batch
Epoch: 20/20...  Training Step: 12189...  Training loss: 1.7488...  0.0531 sec/batch
Epoch: 20/20...  Training Step: 12190...  Training loss: 1.7334...  0.0596 sec/batch
Epoch: 20/20...  Training Step: 12191...  Training loss: 1.6800...  0.0554 sec/batch
Epoch: 20/20...  Training Step: 12192...  Training loss: 1.7160...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12193...  Training loss: 1.7383...  0.0547 sec/batch
Epoch: 20/20...  Training Step: 12194...  Training loss: 1.6896...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 12195...  Training loss: 1.6658...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12196...  Training loss: 1.6577...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 12197...  Training loss: 1.7015...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12198...  Training loss: 1.7291...  0.0588 sec/batch
Epoch: 20/20...  Training Step: 12199...  Training loss: 1.7419...  0.0541 sec/batch
Epoch: 20/20...  Training Step: 12200...  Training loss: 1.7018...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 12201...  Training loss: 1.6688...  0.0562 sec/batch
Epoch: 20/20...  Training Step: 12202...  Training loss: 1.6718...  0.0553 sec/batch
Epoch: 20/20...  Training Step: 12203...  Training loss: 1.7038...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 12204...  Training loss: 1.6495...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12205...  Training loss: 1.7188...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 12206...  Training loss: 1.7313...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12207...  Training loss: 1.6811...  0.0522 sec/batch
Epoch: 20/20...  Training Step: 12208...  Training loss: 1.7020...  0.0563 sec/batch
Epoch: 20/20...  Training Step: 12209...  Training loss: 1.6813...  0.0561 sec/batch
Epoch: 20/20...  Training Step: 12210...  Training loss: 1.6398...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 12211...  Training loss: 1.6849...  0.0554 sec/batch
Epoch: 20/20...  Training Step: 12212...  Training loss: 1.7692...  0.0554 sec/batch
Epoch: 20/20...  Training Step: 12213...  Training loss: 1.6929...  0.0576 sec/batch
Epoch: 20/20...  Training Step: 12214...  Training loss: 1.6791...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 12215...  Training loss: 1.6541...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 12216...  Training loss: 1.7045...  0.0541 sec/batch
Epoch: 20/20...  Training Step: 12217...  Training loss: 1.6666...  0.0585 sec/batch
Epoch: 20/20...  Training Step: 12218...  Training loss: 1.6825...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 12219...  Training loss: 1.6854...  0.0559 sec/batch
Epoch: 20/20...  Training Step: 12220...  Training loss: 1.6834...  0.0574 sec/batch
Epoch: 20/20...  Training Step: 12221...  Training loss: 1.6778...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12222...  Training loss: 1.7015...  0.0523 sec/batch
Epoch: 20/20...  Training Step: 12223...  Training loss: 1.7263...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 12224...  Training loss: 1.7085...  0.0579 sec/batch
Epoch: 20/20...  Training Step: 12225...  Training loss: 1.6108...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 12226...  Training loss: 1.6869...  0.0547 sec/batch
Epoch: 20/20...  Training Step: 12227...  Training loss: 1.6698...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 12228...  Training loss: 1.6541...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 12229...  Training loss: 1.6915...  0.0587 sec/batch
Epoch: 20/20...  Training Step: 12230...  Training loss: 1.7385...  0.0566 sec/batch
Epoch: 20/20...  Training Step: 12231...  Training loss: 1.7213...  0.0563 sec/batch
Epoch: 20/20...  Training Step: 12232...  Training loss: 1.7119...  0.0618 sec/batch
Epoch: 20/20...  Training Step: 12233...  Training loss: 1.6602...  0.0533 sec/batch
Epoch: 20/20...  Training Step: 12234...  Training loss: 1.7123...  0.0553 sec/batch
Epoch: 20/20...  Training Step: 12235...  Training loss: 1.6692...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 12236...  Training loss: 1.6814...  0.0560 sec/batch
Epoch: 20/20...  Training Step: 12237...  Training loss: 1.6972...  0.0581 sec/batch
Epoch: 20/20...  Training Step: 12238...  Training loss: 1.6916...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 12239...  Training loss: 1.6754...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 12240...  Training loss: 1.6983...  0.0541 sec/batch
Epoch: 20/20...  Training Step: 12241...  Training loss: 1.6541...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 12242...  Training loss: 1.6916...  0.0576 sec/batch
Epoch: 20/20...  Training Step: 12243...  Training loss: 1.6520...  0.0580 sec/batch
Epoch: 20/20...  Training Step: 12244...  Training loss: 1.7004...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 12245...  Training loss: 1.7071...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 12246...  Training loss: 1.7088...  0.0555 sec/batch
Epoch: 20/20...  Training Step: 12247...  Training loss: 1.6917...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 12248...  Training loss: 1.6918...  0.0539 sec/batch
Epoch: 20/20...  Training Step: 12249...  Training loss: 1.6874...  0.0553 sec/batch
Epoch: 20/20...  Training Step: 12250...  Training loss: 1.6849...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12251...  Training loss: 1.7022...  0.0579 sec/batch
Epoch: 20/20...  Training Step: 12252...  Training loss: 1.7038...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 12253...  Training loss: 1.6932...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 12254...  Training loss: 1.6446...  0.0562 sec/batch
Epoch: 20/20...  Training Step: 12255...  Training loss: 1.7350...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 12256...  Training loss: 1.7382...  0.0521 sec/batch
Epoch: 20/20...  Training Step: 12257...  Training loss: 1.6885...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 12258...  Training loss: 1.7716...  0.0566 sec/batch
Epoch: 20/20...  Training Step: 12259...  Training loss: 1.6895...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 12260...  Training loss: 1.7798...  0.0579 sec/batch
Epoch: 20/20...  Training Step: 12261...  Training loss: 1.6879...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 12262...  Training loss: 1.6589...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12263...  Training loss: 1.7295...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12264...  Training loss: 1.7129...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 12265...  Training loss: 1.7792...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 12266...  Training loss: 1.6878...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12267...  Training loss: 1.7024...  0.0560 sec/batch
Epoch: 20/20...  Training Step: 12268...  Training loss: 1.7061...  0.0563 sec/batch
Epoch: 20/20...  Training Step: 12269...  Training loss: 1.7073...  0.0550 sec/batch
Epoch: 20/20...  Training Step: 12270...  Training loss: 1.6966...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12271...  Training loss: 1.6805...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12272...  Training loss: 1.7204...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 12273...  Training loss: 1.7039...  0.0593 sec/batch
Epoch: 20/20...  Training Step: 12274...  Training loss: 1.6720...  0.0519 sec/batch
Epoch: 20/20...  Training Step: 12275...  Training loss: 1.6586...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 12276...  Training loss: 1.6762...  0.0540 sec/batch
Epoch: 20/20...  Training Step: 12277...  Training loss: 1.6832...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 12278...  Training loss: 1.7415...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12279...  Training loss: 1.6366...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 12280...  Training loss: 1.7099...  0.0550 sec/batch
Epoch: 20/20...  Training Step: 12281...  Training loss: 1.7020...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 12282...  Training loss: 1.7151...  0.0554 sec/batch
Epoch: 20/20...  Training Step: 12283...  Training loss: 1.7718...  0.0547 sec/batch
Epoch: 20/20...  Training Step: 12284...  Training loss: 1.7207...  0.0553 sec/batch
Epoch: 20/20...  Training Step: 12285...  Training loss: 1.6564...  0.0543 sec/batch
Epoch: 20/20...  Training Step: 12286...  Training loss: 1.6604...  0.0543 sec/batch
Epoch: 20/20...  Training Step: 12287...  Training loss: 1.7250...  0.0584 sec/batch
Epoch: 20/20...  Training Step: 12288...  Training loss: 1.6712...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12289...  Training loss: 1.7501...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12290...  Training loss: 1.7184...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 12291...  Training loss: 1.7330...  0.0569 sec/batch
Epoch: 20/20...  Training Step: 12292...  Training loss: 1.7173...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12293...  Training loss: 1.7523...  0.0552 sec/batch
Epoch: 20/20...  Training Step: 12294...  Training loss: 1.7398...  0.0578 sec/batch
Epoch: 20/20...  Training Step: 12295...  Training loss: 1.7138...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12296...  Training loss: 1.6912...  0.0522 sec/batch
Epoch: 20/20...  Training Step: 12297...  Training loss: 1.7066...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12298...  Training loss: 1.6631...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 12299...  Training loss: 1.6684...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 12300...  Training loss: 1.6916...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12301...  Training loss: 1.6693...  0.0581 sec/batch
Epoch: 20/20...  Training Step: 12302...  Training loss: 1.6468...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12303...  Training loss: 1.6937...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12304...  Training loss: 1.6189...  0.0560 sec/batch
Epoch: 20/20...  Training Step: 12305...  Training loss: 1.7215...  0.0573 sec/batch
Epoch: 20/20...  Training Step: 12306...  Training loss: 1.7552...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 12307...  Training loss: 1.7166...  0.0555 sec/batch
Epoch: 20/20...  Training Step: 12308...  Training loss: 1.7409...  0.0543 sec/batch
Epoch: 20/20...  Training Step: 12309...  Training loss: 1.7003...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 12310...  Training loss: 1.6953...  0.0573 sec/batch
Epoch: 20/20...  Training Step: 12311...  Training loss: 1.6668...  0.0547 sec/batch
Epoch: 20/20...  Training Step: 12312...  Training loss: 1.6954...  0.0571 sec/batch
Epoch: 20/20...  Training Step: 12313...  Training loss: 1.6740...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12314...  Training loss: 1.6803...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 12315...  Training loss: 1.6988...  0.0557 sec/batch
Epoch: 20/20...  Training Step: 12316...  Training loss: 1.6863...  0.0521 sec/batch
Epoch: 20/20...  Training Step: 12317...  Training loss: 1.6574...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 12318...  Training loss: 1.6949...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 12319...  Training loss: 1.6161...  0.0556 sec/batch
Epoch: 20/20...  Training Step: 12320...  Training loss: 1.7114...  0.0578 sec/batch
Epoch: 20/20...  Training Step: 12321...  Training loss: 1.6914...  0.0553 sec/batch
Epoch: 20/20...  Training Step: 12322...  Training loss: 1.6690...  0.0554 sec/batch
Epoch: 20/20...  Training Step: 12323...  Training loss: 1.6710...  0.0580 sec/batch
Epoch: 20/20...  Training Step: 12324...  Training loss: 1.6511...  0.0531 sec/batch
Epoch: 20/20...  Training Step: 12325...  Training loss: 1.7204...  0.0583 sec/batch
Epoch: 20/20...  Training Step: 12326...  Training loss: 1.7008...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 12327...  Training loss: 1.7310...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12328...  Training loss: 1.7569...  0.0564 sec/batch
Epoch: 20/20...  Training Step: 12329...  Training loss: 1.7448...  0.0541 sec/batch
Epoch: 20/20...  Training Step: 12330...  Training loss: 1.6821...  0.0575 sec/batch
Epoch: 20/20...  Training Step: 12331...  Training loss: 1.7094...  0.0571 sec/batch
Epoch: 20/20...  Training Step: 12332...  Training loss: 1.6463...  0.0540 sec/batch
Epoch: 20/20...  Training Step: 12333...  Training loss: 1.7090...  0.0539 sec/batch
Epoch: 20/20...  Training Step: 12334...  Training loss: 1.6899...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 12335...  Training loss: 1.6691...  0.0540 sec/batch
Epoch: 20/20...  Training Step: 12336...  Training loss: 1.6742...  0.0578 sec/batch
Epoch: 20/20...  Training Step: 12337...  Training loss: 1.6903...  0.0612 sec/batch
Epoch: 20/20...  Training Step: 12338...  Training loss: 1.6376...  0.0588 sec/batch
Epoch: 20/20...  Training Step: 12339...  Training loss: 1.6938...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 12340...  Training loss: 1.6707...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12341...  Training loss: 1.7485...  0.0523 sec/batch
Epoch: 20/20...  Training Step: 12342...  Training loss: 1.7112...  0.0581 sec/batch
Epoch: 20/20...  Training Step: 12343...  Training loss: 1.6859...  0.0545 sec/batch
Epoch: 20/20...  Training Step: 12344...  Training loss: 1.7720...  0.0540 sec/batch
Epoch: 20/20...  Training Step: 12345...  Training loss: 1.7965...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 12346...  Training loss: 1.7539...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12347...  Training loss: 1.6928...  0.0533 sec/batch
Epoch: 20/20...  Training Step: 12348...  Training loss: 1.7679...  0.0523 sec/batch
Epoch: 20/20...  Training Step: 12349...  Training loss: 1.6979...  0.0531 sec/batch
Epoch: 20/20...  Training Step: 12350...  Training loss: 1.7258...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12351...  Training loss: 1.7354...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 12352...  Training loss: 1.7484...  0.0522 sec/batch
Epoch: 20/20...  Training Step: 12353...  Training loss: 1.7088...  0.0557 sec/batch
Epoch: 20/20...  Training Step: 12354...  Training loss: 1.7013...  0.0553 sec/batch
Epoch: 20/20...  Training Step: 12355...  Training loss: 1.6923...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 12356...  Training loss: 1.7091...  0.0590 sec/batch
Epoch: 20/20...  Training Step: 12357...  Training loss: 1.6557...  0.0532 sec/batch
Epoch: 20/20...  Training Step: 12358...  Training loss: 1.6970...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12359...  Training loss: 1.7428...  0.0542 sec/batch
Epoch: 20/20...  Training Step: 12360...  Training loss: 1.7183...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12361...  Training loss: 1.7381...  0.0527 sec/batch
Epoch: 20/20...  Training Step: 12362...  Training loss: 1.6925...  0.0533 sec/batch
Epoch: 20/20...  Training Step: 12363...  Training loss: 1.6778...  0.0519 sec/batch
Epoch: 20/20...  Training Step: 12364...  Training loss: 1.7397...  0.0571 sec/batch
Epoch: 20/20...  Training Step: 12365...  Training loss: 1.7403...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 12366...  Training loss: 1.7142...  0.0522 sec/batch
Epoch: 20/20...  Training Step: 12367...  Training loss: 1.6702...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 12368...  Training loss: 1.7181...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12369...  Training loss: 1.6855...  0.0575 sec/batch
Epoch: 20/20...  Training Step: 12370...  Training loss: 1.7289...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 12371...  Training loss: 1.6571...  0.0577 sec/batch
Epoch: 20/20...  Training Step: 12372...  Training loss: 1.7489...  0.0521 sec/batch
Epoch: 20/20...  Training Step: 12373...  Training loss: 1.7043...  0.0535 sec/batch
Epoch: 20/20...  Training Step: 12374...  Training loss: 1.6770...  0.0563 sec/batch
Epoch: 20/20...  Training Step: 12375...  Training loss: 1.6918...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 12376...  Training loss: 1.6583...  0.0563 sec/batch
Epoch: 20/20...  Training Step: 12377...  Training loss: 1.6550...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 12378...  Training loss: 1.7050...  0.0556 sec/batch
Epoch: 20/20...  Training Step: 12379...  Training loss: 1.7108...  0.0523 sec/batch
Epoch: 20/20...  Training Step: 12380...  Training loss: 1.7227...  0.0551 sec/batch
Epoch: 20/20...  Training Step: 12381...  Training loss: 1.6736...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 12382...  Training loss: 1.6739...  0.0567 sec/batch
Epoch: 20/20...  Training Step: 12383...  Training loss: 1.7028...  0.0521 sec/batch
Epoch: 20/20...  Training Step: 12384...  Training loss: 1.6666...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12385...  Training loss: 1.6926...  0.0532 sec/batch
Epoch: 20/20...  Training Step: 12386...  Training loss: 1.7307...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12387...  Training loss: 1.6602...  0.0529 sec/batch
Epoch: 20/20...  Training Step: 12388...  Training loss: 1.6478...  0.0524 sec/batch
Epoch: 20/20...  Training Step: 12389...  Training loss: 1.7086...  0.0549 sec/batch
Epoch: 20/20...  Training Step: 12390...  Training loss: 1.7536...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 12391...  Training loss: 1.7516...  0.0544 sec/batch
Epoch: 20/20...  Training Step: 12392...  Training loss: 1.6915...  0.0528 sec/batch
Epoch: 20/20...  Training Step: 12393...  Training loss: 1.6489...  0.0526 sec/batch
Epoch: 20/20...  Training Step: 12394...  Training loss: 1.6845...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12395...  Training loss: 1.6501...  0.0548 sec/batch
Epoch: 20/20...  Training Step: 12396...  Training loss: 1.7106...  0.0546 sec/batch
Epoch: 20/20...  Training Step: 12397...  Training loss: 1.7425...  0.0582 sec/batch
Epoch: 20/20...  Training Step: 12398...  Training loss: 1.6676...  0.0530 sec/batch
Epoch: 20/20...  Training Step: 12399...  Training loss: 1.6673...  0.0525 sec/batch
Epoch: 20/20...  Training Step: 12400...  Training loss: 1.6495...  0.0565 sec/batch

Training complete

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_checkpoint_state</span><span class="p">(</span><span class="s1">&#39;checkpoints&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[15]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>model_checkpoint_path: &#34;checkpoints/i12400_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i200_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i400_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i600_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i800_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i1000_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i1200_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i1400_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i1600_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i1800_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i2000_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i2200_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i2400_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i2600_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i2800_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i3000_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i3200_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i3400_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i3600_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i3800_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i4000_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i4200_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i4400_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i4600_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i4800_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i5000_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i5200_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i5400_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i5600_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i5800_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i6000_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i6200_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i6400_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i6600_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i6800_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i7000_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i7200_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i7400_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i7600_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i7800_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i8000_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i8200_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i8400_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i8600_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i8800_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i9000_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i9200_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i9400_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i9600_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i9800_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i10000_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i10200_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i10400_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i10600_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i10800_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i11000_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i11200_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i11400_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i11600_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i11800_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i12000_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i12200_l128.ckpt&#34;
all_model_checkpoint_paths: &#34;checkpoints/i12400_l128.ckpt&#34;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Sampling">Sampling<a class="anchor-link" href="#Sampling">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sampler">Sampler<a class="anchor-link" href="#Sampler">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Sampler</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">prime</span><span class="o">=</span><span class="s2">&quot;The &quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get sample model outputs from checkpoint.</span>
<span class="sd">        </span>
<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">        : model: CharRNNModel object</span>
<span class="sd">        : data: Dataset</span>
<span class="sd">        : checkpoint: Checkpoint from which to get samples</span>
<span class="sd">        : n_samples: Number of samples</span>
<span class="sd">        : prime: Word to prime sampling</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">prime</span><span class="p">]</span>
        <span class="n">num_chars</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">chars</span><span class="p">)</span>
        
        <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
        
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
            <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">)</span>
            <span class="n">new_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">initial_state</span><span class="p">)</span>
            
            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">prime</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">chars_to_ints</span><span class="p">[</span><span class="n">c</span><span class="p">]</span>
                <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span><span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                        <span class="n">model</span><span class="o">.</span><span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.</span><span class="p">,</span>
                        <span class="n">model</span><span class="o">.</span><span class="n">initial_state</span><span class="p">:</span> <span class="n">new_state</span><span class="p">}</span>
                <span class="n">preds</span><span class="p">,</span> <span class="n">new_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">prediction</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">final_state</span><span class="p">],</span> 
                                             <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>
                
            <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pick_top_n</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">num_chars</span><span class="p">)</span>
            <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">ints_to_chars</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>
            
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
                <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span>
                <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span><span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                        <span class="n">model</span><span class="o">.</span><span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.</span><span class="p">,</span>
                        <span class="n">model</span><span class="o">.</span><span class="n">initial_state</span><span class="p">:</span> <span class="n">new_state</span><span class="p">}</span>
                <span class="n">preds</span><span class="p">,</span> <span class="n">new_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">prediction</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">final_state</span><span class="p">],</span>
                                             <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>
                
                <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pick_top_n</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">num_chars</span><span class="p">)</span>
                <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">ints_to_chars</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>
                
        <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    
    
    <span class="k">def</span> <span class="nf">pick_top_n</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">num_chars</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Pick random char among top_n chars.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
        <span class="n">p</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">p</span><span class="p">)[:</span><span class="o">-</span><span class="n">top_n</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">p</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">num_chars</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">c</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">CharRNNModel</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span>
                     <span class="n">batch_size</span><span class="p">,</span>
                     <span class="n">num_steps</span><span class="p">,</span>
                     <span class="n">lstm_size</span><span class="p">,</span>
                     <span class="n">num_layers</span><span class="p">,</span>
                     <span class="n">learning_rate</span><span class="p">,</span>
                     <span class="n">grad_clip</span><span class="p">,</span>
                     <span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Building CharRNN model ...

Created placeholders

Built LSTM cell
Built LSTM cell
Built LSTM layers

Built output layer

Added training loss computation

Built optimizer

Built CharRNN model

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sampler</span> <span class="o">=</span> <span class="n">Sampler</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">prime</span> <span class="o">=</span> <span class="s2">&quot;Far&quot;</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">&quot;checkpoints/i1000_l128.ckpt&quot;</span>

<span class="n">samp</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">prime</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samp</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from checkpoints/i1000_l128.ckpt
Farsne the her thom, af has sore the wer on anlend ther the tham whathe wet and
of that we the sar hor ald on a wers to are wathed wo sansind tore anderitt him ansist as thited and.

&#34;Te the sere sin withe alled and ald, withing to he
mase woult and this thor witing as to to and had and he thare the he with ot
the wart ot
thitt hith thite at houss on
hit anden hid, the sead to her woud, the thang, hin womt ware we wans..


I thore sore the to we he wers, wan her ald hat seed was he the har sand this, and on he sonsing of of ald ond anl hor, shere to she her and the the sans, alt her. An he tint he sons, thor has wis thor ho hat so couthing thould hererisgiliding and ant and hit heard, thar wis him,&#34; and
and ard on has was and alerer thoung wam an had sind on winh her some he and tarer of woun tho han her shat he wert thar antithing ande theull.

&#34;The that
was the this her to his here wo lese he andented he
thimhing tare he ther he wound ansed ta wate te shes ther hit watte and the ceentang
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">checkpoint</span> <span class="o">=</span> <span class="s2">&quot;checkpoints/i10000_l128.ckpt&quot;</span>

<span class="n">samp</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">prime</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samp</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from checkpoints/i10000_l128.ckpt
Farr to
the sould of
her
and shillent, at her houre to the persor and has been was to thing and this take her home and a minner.

&#34;Tant the mernate, as you and would so sere and a lart of that all the more is a passe that&#39;s not to make.&#34;

&#34;They&#39;s be he would not stall to see, as you husd all her to see.&#34;

She was that the propers hears the ware wonesting of this, and stand that why say and thing, and
stor the peare which withohe that so what see his feeting of an and the cauner of time in the compines of
the carriathel of him of the some tried of him.

&#34;Yes, he can there and and well. I have some and the thaps on the the peeper,&#34; she was a sease,
though
they stond where had
house to how with the standing him, when the where her with a pact he said out his forte the stinging that he had tried
intorethed
take her
hid as to him
that which she was she children had
that the
servine with his forgetter to him one to her, but the cartical on the comple one head, as a late alouch of the terrys
had 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s1">&#39;checkpoints&#39;</span><span class="p">)</span>

<span class="n">samp</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">prime</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samp</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from checkpoints/i12400_l128.ckpt
Farnane to ast was to the were,&#34;
shad he so and here, and which.

&#34;Tell, and she he saw,&#34; she was and the taking the corner of their heer tarking out of
the man han at the
still with at the solestly highing
thoughtself-to sat, the sairs and ansuneds of the past, and his thought of the mather of the princess of the to attart to herself. &#34;Whos the sens of meaning to at the conversation would be sented how,&#34; and that would now so her and to step of an the hompering
of the most son of his sent, and her stalls, she without his cancest that she had been said, stronged, he were bettingt and short of the pair. And then the consress off and something
that was
strought on, what she cannot his collecting of at a corricons, so said, andry. &#34;You don&#39;t be as staying out at the stranger windors in the count oversore women that,&#34; she said, but the warts, and was to see. Though whith he had
taken were aledery that they was not went in his for a constoning. The
creckened and
ansonering her and and was not s
</pre>
</div>
</div>

</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
